Design review checklist for Reliability - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Design review checklist for Reliability
Article
2025-02-27
10 contributors
Feedback
In this article
This checklist presents a set of recommendations for you to use to evaluate the reliability, resiliency, and failure recovery strategies in your architecture design. To ensure reliability, identify the best infrastructure and application design for your workload. Make these decisions based on your business requirements that are mapped to availability and recoverability target metrics.
To implement a reliable design, thoroughly consider decision points in your design and be aware of how those decisions affect your workload. This checklist and the accompanying guides provide resources to help you make those decisions. Make workload reliability a central consideration throughout the workload design, development, and operation lifecycle.
Checklist
Approach your design with a focus on reliability to help ensure that you design a workload that's resilient, manageable, and repeatable. If you don't include reliability practices and consider the tradeoffs, your design is potentially at risk. Carefully consider all the points covered in the checklist to instill confidence in your system's success.
Code
Recommendation
☐
RE:01
Focus your workload design on simplicity and efficiency.
Use a practical approach to avoid unnecessary complexity while meeting your business goals and requirements.
☐
RE:02
Identify and rate user and system flows.
Use a criticality scale based on your business requirements to prioritize the flows.
☐
RE:03
Use failure mode analysis (FMA) to identify potential failures in your workload.
Identify dependencies and failure points, and develop mitigation strategies for those failures.
☐
RE:04
Define reliability and recovery targets
for your workload. Use the targets to inform your design and as the foundation of your health model.
☐
RE:05
RE:05
RE:05
Add redundancy at different levels, especially for critical flows
, to help meet your reliability targets. Consider redundant infrastructure components such as compute and network, and multiple instances of your solution.
☐
RE:06
RE:06
Implement a timely and reliable scaling strategy at the application, data, and infrastructure levels
. Base the scaling strategy on actual or predicted usage patterns and minimize manual intervention.
☐
RE:07
Strengthen the resiliency of your workload by implementing self-preservation and self-healing measures
. Use built-in features and well-established cloud patterns to help your workload remain functional during and recover from incidents.
☐
RE:08
Test for resiliency and availability scenarios by applying the principles of chaos engineering
. Ensure that your graceful degradation implementation and scaling strategies are effective by performing active malfunction and simulated load testing.
☐
RE:09
Implement structured, tested, and documented business continuity and disaster recovery (BCDR) plans
that align with the recovery targets. Plans must cover all components and the system as a whole.
☐
RE:10
Measure and model the solution's health signals
. Continuously capture uptime and other reliability data from across the workload and also from individual components and key flows.
Next steps
We recommend that you review the Reliability tradeoffs to explore other concepts.
Reliability tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cloud design patterns that support reliability - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Cloud design patterns that support reliability
Article
2024-10-10
2 contributors
Feedback
In this article
When you design workload architectures, you should use industry patterns that address common challenges. Patterns can help you make intentional tradeoffs within workloads and optimize for your desired outcome. They can also help mitigate risks that originate from specific problems, which can impact security, performance, cost, and operations. If not mitigated, those risks will eventually cause reliability issues. These patterns are backed by real-world experience, are designed for cloud scale and operating models, and are inherently vendor agnostic. Using well-known patterns as a way to standardize your workload design is a component of operational excellence.
Many design patterns directly support one or more architecture pillars. Design patterns that support the Reliability pillar prioritize workload availability, self-preservation, recovery, data and processing integrity, and containment of malfunctions.
Design patterns for reliability
The following table summarizes cloud design patterns that support the goals of reliability.
Pattern
Summary
Ambassador
Encapsulates and manages network communications by offloading cross-cutting tasks that are related to network communication. The resulting helper services initiate communication on behalf of the client. This mediation point provides an opportunity to add reliability patterns to network communication, such as retry or buffering.
Backends for Frontends
Individualizes the service layer of a workload by creating separate services that are exclusive to a specific frontend interface. Because of this separation, a malfunction in the service layer that supports one client might not affect the availability of another client's access. When you treat various clients differently, you can prioritize reliability efforts based on expected client access patterns.
Bulkhead
Introduces intentional and complete segmentation between components to isolate the blast radius of malfunctions. This failure isolation strategy attempts to contain faults to just the bulkhead that's experiencing the problem, preventing impact to other bulkheads.
Cache-Aside
Optimizes access to frequently read data by introducing a cache that's populated on demand. The cache is then used on subsequent requests for the same data. Caching creates data replication and, in limited ways, can be used to preserve the availability of frequently accessed data if the origin data store is temporarily unavailable. Additionally, if there's a malfunction in the cache, the workload can fall back to the origin data store.
Circuit Breaker
Prevents continuous requests to a malfunctioning or unavailable dependency. By doing so, this  pattern prevents overloading a faulting dependency. You can also use this pattern to trigger graceful degradation in the workload. Circuit breakers are often coupled with automatic recovery to provide both self-preservation and self-healing.
Claim Check
Separates data from the messaging flow, providing a way to separately retrieve the data related to a message. Message buses don't provide the same reliability and disaster recovery that are often present in dedicated data stores, so separating the data from the message can provide increased reliability for the underlying data. This separation also allows for a message queue recovery approach after a disaster.
Compensating Transaction
Provides a mechanism to recover from failures by reversing the effects of previously applied actions. This pattern addresses malfunctions in critical workload paths by using compensation actions, which can involve processes like directly rolling back data changes, breaking transaction locks, or even executing native system behavior to reverse the effect.
Competing Consumers
Applies distributed and concurrent processing to efficiently handle items in a queue. This model builds redundancy in queue processing by treating consumers as replicas, so an instance failure doesn't prevent other consumers from processing queue messages.
Event Sourcing
Treats state change as series of events, capturing them in an immutable, append-only log. You can use this pattern when a reliable history of changes is crucial in a complex business process. It also facilitates state reconstruction if you need to recover state stores.
Federated Identity
Delegates trust to an identity provider that's external to the workload for managing users and providing authentication for your application. Offloading user management and authentication shifts reliability for those components to the identity provider, which usually has a high SLA. Additionally, during workload disaster recovery, authentication components probably don't need to be addressed as part of the workload recovery plan.
Gateway Aggregation
Simplifies client interactions with your workload by aggregating calls to multiple backend services in a single request. This topology enables you to shift transient fault handling from a distributed implementation across clients to a centralized implementation.
Gateway Offloading
Offloads request processing to a gateway device before and after forwarding the request to a backend node. Offloading this responsibility to a gateway reduces the complexity of application code on backend nodes. In some cases, offloading completely replaces functionality with a reliable platform-provided feature.
Gateway Routing
Routes incoming network requests to various backend systems based on request intents, business logic, and backend availability. Gateway routing enables you to route traffic to only healthy nodes in your system.
Geode
Deploys systems that operate in active-active availability modes across multiple geographies. This pattern uses data replication to support the ideal that any client can connect to any geographical instance. It can help your workload withstand one or more regional outages.
Health Endpoint Monitoring
Provides a way to monitor the health or status of a system by exposing an endpoint that's specifically designed for that purpose. You can use this endpoint to manage your workload's health and for alerting and dashboarding. You can also use it as a signal for self-healing remediation.
Index Table
Optimizes data retrieval in distributed data stores by enabling clients to look up metadata so that data can be directly retrieved, avoiding the need to do full data store scans. Because clients are pointed to their shard, partition, or endpoint through a lookup process, you can use this pattern to facilitate a failover approach for data access.
Leader Election
Establishes a
leader
of instances of a distributed application. The leader coordinates responsibilities that are related to accomplishing a goal. This pattern mitigates the effect of node malfunctions by reliably redirecting work. It also implements failover via consensus algorithms when a leader malfunctions.
Pipes and Filters
Breaks down complex data processing into a series of independent stages to achieve a specific outcome. The single responsibility of each stage enables focused attention and avoids the distraction of commingled data processing.
Priority Queue
Ensures that higher-priority items are processed and completed before lower-priority items. Separating items based on business priority enables you to focus reliability efforts on the most critical work.
Publisher/Subscriber
Decouples components of an architecture by replacing direct client-to-service or client-to-services communication with communication via an intermediate message broker or event bus.
Queue-Based Load Leveling
Controls the level of incoming requests or tasks by buffering them in a queue and letting the queue processor handle them at a controlled pace. This approach can provide resilience against sudden spikes in demand by decoupling the arrival of tasks from their processing. It can also isolate malfunctions in queue processing so that they don't affect intake.
Rate Limiting
Controls the rate of client requests to reduce throttling errors and avoid unbounded retry-on-error scenarios. This tactic protects the client by acknowledging the limitations and costs of communicating with a service when the service is designed to avoid reaching specified limits. It works by controlling the number and/or size of operations that are sent to the service during a specific time period.
Retry
Addresses failures that might be transient or intermittent by retrying certain operations, in a controlled way. Mitigating transient faults in a distributed system is a key technique for improving a workload's resilience.
Saga distributed transactions
Coordinates long-running and potentially complex transactions by decomposing the work into sequences of smaller, independent transactions. Each transaction must also have compensating actions to reverse failures in execution and maintain integrity. Because monolithic transactions across multiple distributed systems are usually impossible, this pattern provides consistency and reliability by implementing atomicity and compensation.
Scheduler Agent Supervisor
Efficiently distributes and redistributes tasks across a system based on factors that are observable in the system. This pattern uses health metrics to detect failures and reroute tasks to a healthy agent in order to mitigate the effects of a malfunction.
Sequential Convoy
Maintains concurrent messaging ingress while also supporting processing in a defined order. This pattern can eliminate race conditions that are hard to troubleshoot, contentious message handling, or other workarounds for addressing incorrectly ordered messages that can lead to malfunctions.
Sharding
Directs load to a specific logical destination to handle the specific request, enabling colocation for optimization. Because the data or processing is isolated to the shard, a malfunction in one shard remains isolated to that shard.
Strangler Fig
Provides an approach for systematically replacing the components of a running system with new components, often during a migration or modernization of the system. This pattern's incremental approach can help mitigate risks during a transition.
Throttling
Imposes limits on the rate or throughput of incoming requests to a resource or component. You can design the limits to help prevent resource exhaustion that might lead to malfunctions. You can also use this pattern as a control mechanism in a graceful degradation plan.
Next steps
Review the cloud design patterns that support the other Azure Well-Architected Framework pillars:
Cloud design patterns that support security
Cloud design patterns that support cost optimization
Cloud design patterns that support operational excellence
Cloud design patterns that support performance efficiency
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing a disaster recovery strategy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing a disaster recovery strategy
Article
2025-04-03
5 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:09
Implement structured, tested, and documented business continuity and disaster recovery (BCDR) plans that align with the recovery targets. Plans must cover all components and the system as a whole.
This guide describes recommendations for designing a reliable disaster recovery strategy for a workload. To meet internal service-level objectives (SLOs) or even a service-level agreement (SLA) that you have guaranteed for your customers, you must have a robust and reliable disaster recovery strategy. Failures and other major issues are expected. Your preparations to deal with these incidents determine how much your customers can trust your business to reliably deliver for them. A disaster recovery strategy is the backbone of preparation for major incidents.
Definitions
Term
Definition
Failover
The automated and/or manual shifting of production workload traffic from an unavailable region to an unaffected geographical region.
Failback
The automated and/or manual shifting of production workload traffic from a failover region back to the primary region.
Key design strategies
This guide assumes that you have already performed the following tasks as part of your reliability planning:
Identify
critical and noncritical flows
.
Perform
failure mode analysis (FMA)
for your flows.
Identify
reliability targets
.
Design for reliability through
redundancy
,
scaling
,
self-preservation, and self-healing
.
Design a robust
testing strategy
.
A reliable disaster recovery (DR) strategy builds on the foundation of a reliable workload architecture. Address reliability at every stage of building your workload to ensure that necessary pieces for optimized recovery are in place before you start designing your DR strategy. This foundation ensures that your workload's reliability targets, like recovery time objective (RTO) and recovery point objective (RPO), are realistic and achievable.
Maintain a disaster-recovery plan
The cornerstone of a reliable DR strategy for a workload is the
DR plan
. Your plan should be a living document that's routinely reviewed and updated as your environment evolves. Present the plan to the appropriate teams (operations, technology leadership, and business stakeholders) regularly (every six months, for example). Store it in a highly available, secure data store such as OneDrive for Business.
Follow these recommendations to develop your DR plan:
Clearly define what constitutes a disaster and therefore requires activation of the DR plan.
Disasters are large-scale issues. They might be regional outages, outages of services like Microsoft Entra ID or Azure DNS, or severe malicious attacks like ransomware attacks or DDoS attacks.
Identify failure modes that aren't considered disasters, such as the failure of a single resource, so that operators don't mistakenly invoke their DR escalations. These failure modes can be addressed by troubleshooting the issue in place, redeploying the failed resources, or utilizing a
Backup Plan
Build the DR plan on your FMA documentation. Ensure that your DR plan captures the failure modes and mitigation strategies for outages that are defined as disasters. Update both your DR plan and your FMA documents in parallel so they're accurate when the environment changes or when testing uncovers unexpected behaviors.
Whether you develop DR plans for nonproduction environments depends on your business requirements and cost impacts. For example, if you offer quality-assurance (QA) environments to certain customers for prerelease testing, you might want to include those environments in your DR planning.
Clearly define roles and responsibilities within the workload team and understand any related external roles within your organization. Roles should include:
The party responsible for declaring a disaster.
The party responsible for declaring incident closure.
Operations roles.
Testing and validation roles.
Internal and external communications roles.
Retrospective and root-cause analysis (RCA) lead roles.
Define the escalation paths that the workload team must follow to ensure that recovery status is communicated to stakeholders.
Capture component-level recovery procedures, data estate-level recovery, and workload-wide recovery processes. Include a prescribed order of operations to ensure that components are recovered in the least impactful way. For example, recover and check databases before you recover the application.
Detail each component-level recovery procedure as a step-by-step guide. Include screenshots if possible.
Define your team's responsibilities versus your cloud hosting provider's responsibilities. For example, Microsoft is responsible for restoring a PaaS (platform as a service), but you're responsible for rehydrating data and applying your configuration to the service.
Include prerequisites for running the procedure. For example, list the required scripts or credentials that need to be gathered.
Capture the root cause of the incident and perform mitigation before you start recovery. For example, if the cause of the incident is a security issue, mitigate that issue before you recover the affected systems in your failover environment.
Depending on the
redundancy design
for your workload, you might need to do significant post-failover work before you make the workload available to your customers again. Post-failover work could include DNS updates, database connection string updates, and traffic routing changes. Capture all of the post-failover work in your recovery procedures.
Note
Your redundancy design might allow you to automatically recover from major incidents fully or partially, so be sure that your plan includes processes and procedures around these scenarios. For example, if you have a fully active-active design that spans
availability zones or regions
, you might be able to transparently fail over automatically after an availability zone or regional outage and minimize the steps in your DR plan that need to be performed. Similarly, if you designed your workload by using
deployment stamps
, you might suffer only a partial outage if the stamps are deployed zonally. In this case, your DR plan should cover how to recover stamps in unaffected zones or regions.
If you need to redeploy your app in the failover environment, use tooling to automate the deployment process as much as possible. Ensure that your DevOps pipelines have been predeployed and configured in the failover environments so that you can immediately begin your app deployments. Use automated end-to-end deployments, with manual approval gates where necessary, to ensure a consistent and efficient deployment process. The full deployment duration needs to align with your recovery targets.
When a stage of the deployment process requires manual intervention, document the manual steps. Clearly define roles and responsibilities.
Automate as much of the procedure as you can. In your scripts, use declarative programming because it allows idempotence. When you can't use declarative programming, be mindful about developing and running your custom code. Use retry logic and circuit breaker logic to avoid wasting time on scripts that are stuck on a broken task. Because you run these scripts only in emergencies, you don't want incorrectly developed scripts to cause more damage or slow down your recovery process.
Note
Automation poses risks. Trained operators need to monitor the automated processes carefully and intervene if any process encounters issues. To minimize the risk that automation will react to false positives, be thorough in your DR drills. Test all phases of the plan. Simulate detection to generate alerting, and then move through the entire recovery procedure.
Remember that your DR drills should validate or inform updates to your recovery target metrics. If you find that your automation is susceptible to false positives, you might need to increase your failover thresholds.
Separate the failback plan from the DR plan to avoid potential confusion with the DR procedures. The failback plan should follow all of the DR plan's development and maintenance recommendations and should be structured in the same way. Any manual steps that were necessary for failover should be mirrored in the failback plan. Failback might happen quickly after failover, or it might take days or weeks. Consider failback as separate from failover.
The need to fail back is situational. If you're routing traffic between regions for performance reasons, failing back the load originally in the failed-over region is important. In other cases, you might have designed your workload to function fully regardless of which production environment it's located in at any time.
Conduct disaster-recovery drills
A DR testing practice is as important as a well-developed DR plan. Many industries have compliance frameworks that require a specified number of DR drills to be performed regularly. Regardless of your industry, regular DR drills are paramount to your success.
Follow these recommendations for successful DR drills:
Perform at least one production DR drill per year. Tabletop (dry run) drills or nonproduction drills help ensure that the involved parties are familiar with their roles and responsibilities. These drills also help operators build familiarity ("muscle memory") by following recovery processes. But only production drills truly test the validity of the DR plan and the RTO and RPO metrics. Use your production drills to time recovery processes for components and flows to ensure that the RTO and RPO targets that have been defined for your workload are achievable. For functions that are out of your control, like DNS propagation, ensure that the RTO and RPO targets for the flows that involve those functions account for possible delays beyond your control.
Use tabletop drills not only to build familiarity for seasoned operators but also to educate new operators about DR processes and procedures. Senior operators should take time to let new operators perform their role and should watch for improvement opportunities. If a new operator is hesitant or confused by a step in a procedure, review that procedure to ensure that it's clearly written.
Considerations
Performing DR drills in production can cause unexpected catastrophic failures. Be sure to test recovery procedures in nonproduction environments during your initial deployments.
Give your team as much maintenance time as possible during drills. When planning for maintenance time, use the recovery metrics that you capture during
testing
as
minimum time necessary
allotments.
As your DR drill practices mature, you learn which procedures you can run in parallel and which you must run in sequence. Early in your drill practices, assume that every procedure must be run in sequence and that you need extra time in each step to handle unanticipated issues.
Define and maintain Backup Plans for resources within critical flows
Backup is an important part of your overall recovery process. Oftentimes it is just a part of your environment that needs recovery. DR plans are usually application or even region wide. Accidental or malicious deletion of data, file corruption, malware, and targeted ransomware attacks can all affect the availability of your workload. Having solid backup plans for each part of your environment is just as important as having an effective DR plan, as a DR plan depends on a solid backup plan to be effective. Like your DR plan, backup plans also need to be agreed upon by the appropriate levels of management, revisited regularly for possible updates and documented in a highly available, secure data store.
Determine appropriate backup solutions for the different Azure services that are part of the critical paths within your workload.
Define required retention periods for each different service.
Understand that one tool may not work for everything. Azure Backup tools can cover many resource types but not all.
Sometimes the best option to restore certain types of objects is a redeployment from some level type of highly-available repository. (Azure DevOps, GitHub or others)
Data services will have different requirements than application related objects.
Be sure to consider a multi-region storage strategy for your backup data to create cross-region recoverability.
Run regular, scheduled test restores of backup data to ensure that services are working as expected.
Azure facilitation
Many Azure products have built-in failover capabilities. Familiarize yourself with these capabilities and include them in recovery procedures. See the
DR for Azure data platform series
for guidance about preparing an enterprise data estate for DR.
For IaaS (infrastructure as a service) systems, use
Azure Site Recovery
to automate failover and recovery. Refer to the following articles for common PaaS products:
Azure App Service
Azure Container Apps
Azure Kubernetes Service
Azure SQL Database
Azure Event Hubs
Azure Cache for Redis
Many Azure products have built-in backup capabilities. Familiarize yourself with these capabilities and include them in recovery procedures.
For IaaS (infrastructure as a service) systems, use
Azure Backup
to facilitate backup of VMs and VM related services and some data services. Refer to the following articles for common products:
Azure App Service
Azure Kubernetes Service
Azure SQL Database
Azure Files
Related links
Recommendations for designing for redundancy
Recommendations for highly available multi-region design
Recommendations for using availability zones and regions
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Failure mode analysis recommendations - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for performing failure mode analysis
Article
2024-10-08
9 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:03
Use failure mode analysis (FMA) to identify potential failures in your workload.
Identify dependencies and failure points, and develop mitigation strategies for those failures.
This guide describes the best practices for performing failure mode analysis (FMA) for your workload. FMA is the practice of identifying potential points of failure within your workload and the associated flows and planning mitigation actions accordingly. At each step of the flow, you identify the blast radius of multiple failure types, which helps you design a new workload or refactor an existing workload to minimize the widespread effect of failures.
A key tenet of FMA is that failures happen no matter how many layers of resiliency you apply. More complex environments are exposed to more types of failures. Given this reality, FMA allows you to design your workload to withstand most types of failures and recover gracefully when a failure occurs.
If you skip FMA altogether or perform an incomplete analysis, your workload is at risk of unpredicted behavior and potential outages caused by suboptimal design.
Definitions
Term
Definition
Failure mode
A type of problem that can cause one or more workload components to be degraded or severely affected to the point of being unavailable.
Mitigation
The activities that you have identified to address problems either proactively or reactively.
Detection
Your infrastructure, data, and app monitoring and alerting processes and procedures.
Key design strategies
Review and implement the
recommendations for identifying flows
. It’s assumed that you have identified and prioritized user and system flows based on criticality.
The data that you have gathered and the artifacts that you have created in your work provide you with a concrete description of your data paths involved throughout the flows. To be successful in your FMA work, accuracy and thoroughness in your artifacts is critical.
After you determine the critical flows, you can plan their required components. Next, follow each flow step by step to identify dependencies, including third-party services and potential points of failure, and plan your mitigation strategies.
Decompose the workload
As you move from ideation to design, you need to identify the component types that are required to support your workload. Your workload determines the necessary components that you must plan for. Typically, you need to plan for ingress control, networking, compute, data, storage, supporting services (like authentication, messaging, and secret or key management), and egress control. At this stage in your design work, you might not know the specific technologies that you'll deploy, so your design might look like the following example.
After you create your initial architecture design, you can overlay your flows to identify the discrete components that are used in those flows and create lists or workflow diagrams that describe the flows and their components. To understand the criticality of the components, use the criticality definitions that you have assigned to the flows. Consider the effect of a component malfunction on your flows.
Identify dependencies
Identify your workload dependencies to perform your single point-of-failure analysis. Decomposing your workload and overlaying flows provides insight into dependencies that are internal and external to the workload.
Internal dependencies are components in the workload scope that are required for the workload to function. Typical internal dependencies include APIs or secret/key management solutions like Azure Key Vault. For these dependencies, capture the reliability data, like availability SLAs and scaling limits. External dependencies are required components outside the scope of the workload, such as another application or third-party service. Typical external dependencies include authentication solutions, like Microsoft Entra ID, and cloud connectivity solutions, like Azure ExpressRoute.
Identify and document the dependencies in your workload, and include them in your flow documentation artifacts.
Evaluate failure points
In your workload's critical flows, consider each component and determine how that component, and its dependencies, might be affected by a failure mode. Remember that there are many failure modes to consider when planning for resiliency and recovery. Any one component can be affected by more than one failure mode at any given time. These failure modes include:
Regional outage. An entire Azure region is unavailable.
Availability zone outage. An Azure availability zone is unavailable.
Service outage. One or more Azure services are unavailable.
Distributed denial-of-service (DDoS) or other malicious attack.
App or component misconfiguration.
Operator error.
Planned maintenance outage.
Component overload.
The analysis should always be in the context of the flow you're attempting to analyze, so be sure to document the effect on the user and expected result of that flow. For example, if you have an e-commerce application and you’re analyzing your customer flow, the effect of a particular failure mode on one or more components might be that all customers are unable to complete the checkout.
Consider the likelihood of each type of failure mode. Some are very unlikely, like multi-zone or multi-region outages, and adding mitigation planning beyond redundancy isn't a good use of resources and time.
Mitigation
Mitigation strategies fall into two broad categories: building more resiliency and designing for degraded performance.
Building more resiliency includes adding redundancy to your components, like infrastructure, data, and networking, and ensuring that your application design follows best practices for durability, for example breaking up monolithic applications into isolated apps and microservices. For more information, see
Recommendations for redundancy
and
Recommendations for self-preservation
.
To design for degraded performance, identify potential failure points that might disable one or more components of your flow but don't fully disable that flow. To maintain the functionality of the end-to-end flow, you might need to reroute one or more steps to other components or accept that a failed component runs a function, so the function is no longer available in the user experience. To return to the e-commerce application example, a failed component like a microservice might cause your recommendation engine to be unavailable, but the customers can still search for products and complete their transaction.
You also need to plan mitigation around dependencies. Strong dependencies play a critical role in application function and availability. If they're absent or experiencing a malfunction, there might be significant effect. The absence of weak dependencies might only affect specific features and not affect overall availability. This distinction reflects the cost to maintain the high availability relationship between the service and its dependencies. Classify dependencies as either strong or weak to help you identify which components are essential to the application.
If the application has strong dependencies that it can't operate without, the availability and recovery targets of these dependencies should align with the targets of the application itself. Minimize dependencies to achieve control over application reliability. For more information, see
Minimize coordination between application services to achieve scalability
.
If the application lifecycle is closely coupled with the lifecycle of its dependencies, the operational agility of the application might be limited, particularly for new releases.
Detection
Failure detection is essential to ensure that you have correctly identified failure points in your analysis and properly planned your mitigation strategies. Detection in this context means the monitoring of your infrastructure, data and application, and alerting when issues arise. Automate detection as much as possible, and build redundancy into your operations processes to ensure that alerts are always caught and are responded to quickly enough to meet your business requirements. For more information, see the
Recommendations for monitoring
.
Outcome
For the outcome of your analysis, create a set of documents that effectively communicate your findings, the decisions that you have made relative to the flow components and mitigation, and the effect of the failure on your workload.
In your analysis, prioritize the failure modes and mitigation strategies that you have identified based on severity and likelihood. Use this prioritization to focus your documentation on those failure modes that are common and severe enough to warrant spending the time, effort, and resources on designing mitigation strategies around. For example, there might be some failure modes that are very rare in occurrence or detection. Designing mitigation strategies around them isn't worth the cost.
Refer to the following
example table
for a documentation starting point.
During your initial FMA exercise, the documents you produce will be mostly theoretical planning. The FMA documents should be reviewed and updated regularly to ensure that they stay up-to-date with your workload. Chaos testing and real-world experiences will help you refine your analyses over time.
Azure facilitation
Use
Azure Monitor
and
Log Analytics
to detect issues in your workload. For further insight into issues related to your infrastructure, apps, and databases, use tools like
Application Insights
,
Container Insights
,
Network Insights
,
VM Insights
, and
SQL Insights
.
Azure Chaos Studio
is a managed service that uses chaos engineering to help you measure, understand, and improve your cloud application and service resilience.
For information about applying FMA principles to common Azure services, see
Failure mode analysis for Azure applications
.
Example
The following table shows an FMA example for an e-commerce website that's hosted on Azure App Service instances with Azure SQL databases and is fronted by Azure Front Door.
User flow
: User sign in, product search, and shopping cart interaction
Component
Risk
Likelihood
Effect/Mitigation/Note
Outage
Microsoft Entra ID
Service outage
Low
Full workload outage. Dependent on Microsoft to remediate.
Full
Microsoft Entra ID
Misconfiguration
Medium
Users unable to sign in. No downstream effect. Help desk reports configuration issue to identity team.
None
Azure Front Door
Service outage
Low
Full outage for external users. Dependent on Microsoft to remediate.
External only
Azure Front Door
Regional outage
Very low
Minimal effect. Azure Front Door is a global service, so global traffic routing directs traffic through non-effected Azure regions.
None
Azure Front Door
Misconfiguration
Medium
Misconfigurations should be caught during deployment. If these happen during a configuration update, administrators must roll back changes. Configuration update causes a brief external outage.
External only
Azure Front Door
DDoS attack
Medium
Potential for disruption. Microsoft manages DDoS (L3 and L4) protection and Azure Web Application Firewall blocks most threats. Potential risk of effect from L7 attacks.
Potential for partial outage
Azure SQL
Service outage
Low
Full workload outage. Dependent on Microsoft to remediate.
Full
Azure SQL
Regional outage
Very low
Auto-failover group fails over to secondary region. Potential outage during failover. Recovery time objectives (RTOs) and recovery point objectives (RPOs) to be determined during reliability testing.
Potential full
Azure SQL
Availability zone outage
Low
No effect
None
Azure SQL
Malicious attack (injection)
Medium
Minimal risk. All Azure SQL instances are virtual network-bound through private endpoints and network security groups (NSGs) add further intra-virtual network protection.
Low risk, potential for partial outage
App Service
Service outage
Low
Full workload outage. Dependent on Microsoft to remediate.
Full
App Service
Regional outage
Very low
Minimal effect. Latency for users in effected regions. Azure Front Door automatically routes traffic to non-effected regions.
None
App Service
Availability zone outage
Low
No effect. App services have been deployed as zone redundant. Without zone redundancy, there's a potential for effect.
None
App Service
DDoS attack
Medium
Minimal effect. Ingress traffic is protected by Azure Front Door and Azure Web Application Firewall.
None
Related links
Failure mode analysis for Azure applications
Resiliency and dependencies
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for highly available multi-region design - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for highly available multi-region design
Article
2024-01-15
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:05
Add redundancy at different levels, especially for critical flows
, to help meet your reliability targets. Consider redundant infrastructure components such as compute and network, and multiple instances of your solution.
Related guides:
Redundancy
|
Using availability zones and regions
This guide describes the recommendations for designing a highly available multi-region cloud environment. High availability is a foundational tenet of designing for reliability. A highly available architecture can help you avoid downtime as much as possible and recover efficiently if downtime does occur.
Active-active
and
active-passive
are general architecture types that can be applied in different ways, depending on the platform you deploy your environment on. This guide focuses on a multi-region cloud environment design. On Azure, you can also design an active-active or active-passive architecture within a single region by using
availability zones
. For detailed guidance on designing a highly available architecture by using availability zones, see the
Azure Well-Architected Framework guide
.
Key design strategies
Active-active and active-passive are the two fundamental approaches to designing a highly available cloud environment. Active-active environments are designed to handle production loads in every region in which you deploy your workload. Active-passive environments are designed to handle production loads only in the primary region but fail over to the secondary (passive) region when necessary. Selecting the best Azure regions for your workload is a key part of designing a highly available multi-region environment. For guidance on selecting Azure regions, see the
Select Azure Regions guide
.
This section describes design options that you should consider when you evaluate each pattern and refine your architecture to meet your business requirements.
See
Deployment Stamps pattern
for guidance on architecting your workload in a repeatable, scalable way. This design pattern can help you optimize your high-availability design for efficient management.
The following sections describe the design options of the two patterns.
Deploy in active-active for zero downtime
Active-active at capacity
: Mirrored deployment stamps in two or more Azure regions, each configured to handle production workloads for the region or regions they serve and scalable to handle loads from other regions in case of a regional outage.
Networking: Use
latency
or
weighted
global routing to spread traffic among regions.
Data replication and consistency: Use a globally distributed data store like
Azure Cosmos DB
for multi-region read and write capabilities. For relational databases, use
readable replicas
with read-only connection strings.
Advantage of this design: Lower operating costs than an overprovisioned design.
Disadvantage of this design: Possible degradation of the user experience when scaling up to meet the demands of a full load if another region experiences an outage.
Active-active overprovisioned
: Mirrored deployment stamps in two or more Azure regions, each overprovisioned to handle production workloads for the region or regions they serve and to handle loads from other regions in case of a regional outage.
Networking: Use
latency
or
weighted
global routing to spread traffic among regions.
Data replication and consistency: Use a globally distributed data store like
Azure Cosmos DB
for multi-region read and write capabilities. For relational databases, use
readable replicas
with read-only connection strings.
Advantage of this design: The most resilient design possible.
Disadvantage of this design: Higher operating costs than a scalable design.
Common advantages of both designs: High resiliency and low risk of full workload outage.
Common disadvantages of both designs: Higher operating costs and management burden due to various factors, including the necessity of managing the synchronization of application state and data.
Deploy in active-passive for disaster recovery
Warm spare
: One primary region and one or more secondary regions. The secondary region is deployed with the minimum possible compute and data sizing and runs without load. This region is known as a
warm spare
region. Upon failover, the compute and data resources are scaled to handle the load from the primary region.
Networking: Use
priority
global routing.
Data replication and consistency: Replicate your database to your passive region and use the automatic failover capabilities of platform as a service (PaaS) solutions like
Azure Cosmos DB
and
Azure SQL Database
.
Advantage of this design: Shortest recovery time among the active-passive designs.
Disadvantage of this design: Highest operating cost among the active-passive designs.
Cold spare
: One primary region and one or more secondary regions. The secondary region is scaled to handle full load, but all compute resources are stopped. This region is known as a
cold spare
region. You need to start the resources before failover.
Networking: Use
priority
global routing.
Data replication and consistency: Replicate your database to your passive region and use the automatic failover capabilities of PaaS solutions like
Azure Cosmos DB
and
Azure SQL Database
.
Advantage of this design: Lower operating costs than the warm spare design.
Disadvantage of this design: Longer recovery time than the warm spare design.
Redeploy on disaster
: One primary region and one or more secondary regions. Only the necessary networking is deployed in the secondary region. Operators must run provisioning scripts in the secondary region to fail over the workloads. This design is known as
redeploy on disaster
.
Networking: Use
priority
global routing.
Data replication and consistency: Deploy new database instances and rehydrate the data from backups.
Advantage of this design: Lowest operating costs.
Disadvantage of this design: Longest recovery time.
Common advantages of active-passive designs: Lower operating costs and less day-to-day management burden than active-active designs. No need to synchronize application state.
Common disadvantages of active-passive designs: Longer, more complex recovery process. Higher likelihood of needing manual intervention for a successful failover.
Note
Regardless of your high-availability design, remember to configure redundancy for supporting services like Azure DevOps infrastructure, jump boxes, monitoring, and any other critical service that's necessary to administer the workload.
Azure facilitation
Azure Front Door
combines the global routing functionality of Azure Traffic Manager with a content delivery system and web application firewall to help you manage your high-availability workload.
Azure Cosmos DB
is a globally distributed NoSQL database platform that can help you run an active-active environment and minimize the chance of downtime when a regional outage occurs.
Related links
Multi-region N-tier application
Multi-region load balancing
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for identifying and rating flows - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for identifying and rating flows
Article
2024-01-25
8 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:02
Identify and rate user and system flows.
Use a criticality scale based on your business requirements to prioritize the flows.
This guide describes the recommendations for identifying and prioritizing workload flows. Identifying and prioritizing workload flows involves mapping user flows and system flows to determine their criticality to the organization. This practice ensures you identify and prioritize the most critical workload functionality to reduce the risk of damaging failures. Failure to identify and prioritize workload flows can lead to system breakdowns and compromised workload reliability.
Definitions
Term
Definition
User flow
The paths or sequences of actions that users take within an application or system.
System flow
The flow of information and processes within a system. The system automatically follows this flow to enable user flows or workload functionality.
Key design strategies
When you design your workload, it's essential to define the user flows and system flows. User flows chart the movement of a user through your application. They focus on the user interface, interactions, decisions, and the steps required to complete a task. User flows provide a user-centric perspective on user experience and interface design. System flows chart the internal workings of your workload. They focus on data movement, input processing, output processing, and interactions among workload components, backend services, and external APIs. System flows indicate the intricate details of how the workload operates internally.
You should identify and define flows early in the design phase of your workload. It gives you a clearer understanding of what affects the reliability of your workload. It aligns your architectural decisions closely with the reliability goals of your workload.
Identify all user and system flows
The output of identifying all user and system flows is a catalog of all the flows in your workload. This identification process requires you to map out every user interaction and process within a system from beginning to end. This mapping is a prerequisite for identifying critical flows. Here are recommendations for identifying all user and system flows in a workload:
Interview stakeholders.
Stakeholders can provide valuable information to identify flows, and they can even help you map and prioritize flows. You can also interview users, business analysts, and technical teams to gather insights about user interactions and dependencies within the workload.
Review documentation.
In the design phase, you might not have documentation to review. However, if documentation exists, you should use it. Ask for system architecture diagrams, user manuals, and process descriptions. These documents can help you understand the intended functionality of the workload and its individual flows.
Observe the workload.
Monitor the workload in operation, noting how users interact with it and how different components speak with each other. You should analyze system logs, performance metrics, and user activity logs to identify patterns, frequent tasks, and system responses.
List identified flows.
The interviews, documentation, and observation should enable you to identify all the flows in the workload. Compile a list of all the flows you identify and categorize them into user flows (focusing on user interactions) and system flows (focusing on backend processes and data movement).
Define flow start and end points.
For each identified flow, clearly define where the flow starts and where it ends. For user flows, document each user interaction and its expected outcome. Focus on the user experience and interface design. For system flows, you need to identify its underlying triggers and expected outcomes.
Break down each flow.
Break down each flow into individual steps, describing the actions, decisions, or processes that occur at each point. Note how each step interacts with other parts of the system, including dependencies on other flows or external systems. You should be able to pinpoint how flows integrate with and affect the workload and user experience. This dual approach provides a holistic view of your entire workload.
Document unique outputs.
Identify any alternative paths or exceptions within each flow, such as error handling or conditional branching. If a flow has multiple possible outcomes, you should add it to the catalog as distinct entries. For user flows, you should identify the intended behavior of the interaction. For system flows, you should identify the intended behavior of the process.
Visualize with diagrams.
Create flowcharts or diagrams to visually represent the flow and its steps. You can use tools like Microsoft Visio, UML sequence diagrams, use-case diagrams, simple drawing tools, or a descriptive list in text format (
see
Example flow catalog
).
Update flow mapping iteratively.
Flow mapping is an iterative process. Flows can change, split, or combine, especially in the design phase. As the workload flows become more clearly defined, you should update the catalog of flows to match. Validate and refine your flow diagrams with feedback from stakeholders to ensure accuracy and completeness.
Identify business processes for each flow
Business processes are a series of tasks to achieve an output, such as order fulfillment, customer service management, or inventory control. The identification of business processes for each flow involves mapping flows to one or more business processes. This mapping helps you understand the importance of each flow to the business.
You might have existing documentation or business plans that provide a mapping of flows to business processes. Sometimes user manuals, training materials, or system specifications can provide insights into the intended use and purpose of the workload and its flows. If not, you need to map flows to the business processes they support. Here are recommendations to identify business processes for each flow:
Use workload outputs.
You can use the workload outputs and flow breakdown to correlate flows with the business processes they support. First, review the outputs the workload generates. The output could be sales reports, data files, or completed tasks.
Conduct interviews.
Speak with team members and stakeholders who interact with the workload. You should ask specific questions about their daily tasks, how they use the workload, and what objectives they achieve with it. Technical teams often have a deeper understanding the workload structure and can provide insights into the business processes it supports.
Monitor workload usage.
For existing workloads, monitor the workload and look for patterns in usage that indicate underlying business processes, such as data entry, order processing, or customer interaction.
Connect the output to a business process.
Connect the dots from the flow outputs to the overall business process they support. For example, if a flow step involves processing customer orders, then it directly supports the business process of order fulfillment. Order fulfillment contributes to the business objective of maintaining customer satisfaction and generating revenue. Finally, use the flow breakdown to help determine which flow created the sales report.
Identify process owners and stakeholders for each flow
The process owner for a flow is the individual that's responsible for the successful execution of a given process. They're responsible for that process and the flows that support it. You should identify the process owner for each workload flow. You should also identify the stakeholders for each flow. Stakeholders can be involved in the workload, have dependencies on a flow, or manage a dependency that the flow has.
You might have a responsibility assignment matrix (RAM) or RACI matrix that already identifies process owners and stakeholders. Typically, process owners are responsible or accountable for a process, and you consult or inform stakeholders.
Identify escalation paths for each flow
The identification of escalation paths is about determining channels for escalating issues related to a flow. Issues that need escalation could be urgent updates, security concerns, degradations, or technical incidents. The goal of identifying an escalation path is to ensure timely and effective resolution of issues.
The escalation path you map out should start with the person or group most likely to resolve a particular issue. If this person or group can't resolve the issue, the escalation path should identify the next point of contact. The next point of contact has broader responsibilities and is able to coordinate mitigation strategies with more parts of the organization. The number of people on an escalation path varies by flow and organization. Too many people on an escalation path can slow the resolution efforts.
Identify business impact of each flow
The identification of the business impact of each flow is essential for understanding how each flow contributes to key business objectives. Business impact could include revenue generation, customer satisfaction, or operational efficiency. By understanding both the positive and negative impact of each flow, you can prioritize efforts to ensure the reliability of the flows that matter the most to your business. It's important to consider the direct impact of flow failure and its indirect effect on other interconnected processes. Here are steps to identify the business impact of each flow:
Identify positive impact.
Determine the expected benefits when a flow runs as intended. The expected benefits could include improved efficiency, increased revenue, enhanced customer satisfaction, or any other positive effect on the business.
Identify negative impact.
Assess the potential negative impacts if a process fails or doesn't work as expected. Consider quantifying specific losses, such as revenue drops. Include subjective effects like damage to reputation, erosion of customer trust, or adverse effects on other related business processes.
Define capacity and availability assumptions.
Establish assumptions about the expected capacity and availability of each process. Consider factors like throughput per unit of time, expected business hours, and target percentage uptime. If there are expectations for recovery time objective (RTO) or recovery point objective (RPO), you should include these expectations. These assumptions help in understanding reliability requirements of each flow.
By systematically evaluating these aspects, you can gain a comprehensive view of how each flow impacts the business and make strategic decisions about reliability optimization.
Assign a criticality rating to each flow
A detailed evaluation of flow importance relative to the overall business impacts allows you to assign a criticality rating to each flow. You can use quantitative or qualitative criticality ratings. The purpose is to sort the flows by priority and assign a label that allows you to identify the critical flows. This process is a logical continuation of identifying, mapping, and aligning with business processes and impact. Use the following criticality descriptions to assign your critical ratings:
High criticality
: High criticality flows are integral to core business functions. They directly affect critical aspects of a business such as customer experience, financial transactions, security protocols, human health, and safety. The failure or disruption of these flows could lead to significant immediate or long-term negative effects. Examples of negatives effects include loss of revenue, breach of trust, and legal issues. Prioritizing these flows ensures that the most crucial aspects of the workload are robust and resilient.
Medium criticality
: Medium criticality flows are important for the complete functionality of the system but don't directly interface with the customer or critical business operations. For example, if an issue disrupts an internal data processing flow, you can retry the data processing without immediate external effects. These flows are essential for smooth operations but offer a buffer in terms of immediate customer or financial effect, allowing for managed responses to issues.
Low criticality
: Low criticality flows don't have a direct or significant effect on the core business functions or customer experience. Examples include ancillary processes like nightly log transfers or optional user features such as feedback surveys. While these flows contribute to the overall system, their disruption is unlikely to cause significant immediate business or operational issues.
By following this structured approach to assigning criticality, you can effectively prioritize resources and focus on maintaining and enhancing the reliability and effectiveness of your most critical flows.
Tradeoff
: Higher expectations for reliability sometimes coincide with higher setup costs, operational costs, and management burden for operators. Ensure that stakeholders understand the potential cost increases of improving the reliability of critical flows.
Organizational alignment
Cloud Adoption Framework provides guidance for workloads that require business criticality classification.
For more information, see
business criticality in cloud management
.
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Reliability quick links - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Read in English
Table of contents
Read in English
Edit
Share via
Facebook
x.com
LinkedIn
Email
Table of contents
Reliability quick links
Apply reliability guidance to your architecture to make your workload resilient to malfunction and to ensure that it returns to a fully functioning state after a failure occurs.
Learn key points
Quickstart
Design principles
Checklist
Tradeoffs
Reliability patterns
Azure Well-Architected Review assessment
Training
Reliability
video
Inside Azure datacenter architecture with Mark Russinovich
Review design principles
Concept
Design for business requirements
Design for resilience
Design for recovery
Design for operations
Keep it simple
Set and measure reliability targets
How-To Guide
Identify flows
Perform failure mode analysis
Set reliability targets
Design a monitoring and alerting strategy
Achieve reliability targets
How-To Guide
Design for redundancy
Use availability zones and regions
Implement highly available multi-region design
Partition data
Reliably scale
Design for self-healing and preservation
Design with simplicity
Test and conduct drills
How-To Guide
Design a testing strategy
Design a recovery strategy
Explore related resources
Reference
Azure Advisor: Reliability recommendations
Azure reliability documentation
Site reliability engineering documentation
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for defining reliability targets - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for defining reliability targets
Article
2024-08-20
10 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:04
Define reliability and recovery targets
for your workload. Use the targets to inform your design and as the foundation of your health model.
This guide describes the recommendations for defining availability and recovery target metrics for critical workloads and flows. You should derive reliability targets from workshop exercises with business stakeholders. Then refine those targets by monitoring and testing your workloads.
Set realistic expectations with your internal stakeholders about workload reliability. Then they can use contractual agreements to communicate those expectations to customers. Realistic expectations also help stakeholders understand and support your architectural design decisions and know that you're designing to optimally meet the targets that you agree on.
Consider using the following metrics to quantify your business requirements.
Term
Definition
Service-level objective (SLO)
A measure of the performance and reliability of a workload or application. An SLO is a specific, measurable target that you set for particular customer interactions. It's a target that you set for your workload or application based on the quality of service that your customers expect to receive.
Service-level indicator (SLI)
A quantitative measurement of a particular aspect of a service's performance. You can use an SLI to measure your workload's compliance with an SLO.
Service-level agreement (SLA)
A contractual agreement between the service provider and the service customer. Failure to meet the agreement might have financial consequences for the service provider.
Mean time to recover (MTTR)
The time taken to restore a component after a failure is detected.
Mean time between failure (MTBF)
The duration for which the workload can perform the expected function without interruption until it fails.
Recovery time objective (RTO)
The maximum acceptable time that an application can be unavailable after an incident.
Recovery point objective (RPO)
The maximum acceptable duration of data loss during an incident.
Key design strategies
Reliability targets represent the desired quality goal of a workload,
as promised to its users and the business stakeholders. That goal includes both availability and recoverability of the workload. Keep in mind that reliability targets differ from performance targets, but you should include performance targets in reliability targets. Consider the following reliability targets:
Availability targets
define the quality standards for a system to remain accessible and functional. If it doesn't meet these standards, the system is considered unreliable. Use SLOs to help check whether your system meets these standards. Business and technical stakeholders collaborate to set realistic SLOs and consider factors like comparative analysis, user experience, and the workload profile.
Correctness targets
ensure that the workload properly performs its functions with consistent quality. To measure correctness, quantify the workload's indicators so that you can combine them into a unified, objective score.
Recovery targets
correspond to RTO, RPO, MTTR, and MTBF metrics, which quantify the effectiveness of your plans and testing for business continuity and disaster recovery.
To set reliability targets, business stakeholders define broad requirements. Then, technical experts assess the current state of the workload and work towards achieving and maintaining targets through monitoring and alerts. Both parties must agree on realistic targets.
Identify and score user and system flows
based on their importance to your business requirements. Use these scores to guide the design, review, testing, and incident management of your workload. Set reliability targets for these flows, and understand that failing to meet those targets can significantly affect your business.
Tradeoff
: You might have a gap between the technical limits of your system and its business impact, like throughput versus transactions per second. Bridging this gap can be tough. Aim for a practical and cost-effective solution instead of overengineering.
Set availability objectives
The overall SLO of a workload reflects the
holistic quality, including all its dependencies.
A mature declaration of the SLO should indicate the overall business target for that workload, not just a composite of those dependencies. For example, if customers expect 99.99% availability, the overall SLO should aim for that goal, even if one part only achieves 99.80%.
Stakeholders evaluate the customer experience and consider how downtime affects revenue. They compare this loss to the cost of designing and operating the business flow. Decision makers then decide if they should spend more money on reliability to avoid revenue loss and maintain their reputation.
Workload owners
use financial goals to determine objectives.
Business requirements map to measurable metrics. The goal is to identify a set of factors that influence the quality of the customer experience.
Workload architects
make many technical decisions based on SLOs.
SLOs can:
Serve as critical input into architectural decisions when you consider other dependencies.
Provide a near real-time view and shared understanding of the health of a workload to enable objective discussions. They also help the workload team prioritize efforts to improve reliability and develop new features.
Act as a primary signal for deployment operations, which drives automated rollback if problems occur and provides validation that the changes achieve the expected improvements to the customer experience.
Speed up remediation and recovery by focusing on objectives, drive automated notification of problems to customers, and build trust between teams in your organization.
Important
You must know the difference between SLAs and SLOs. Although SLAs and SLOs might use or even present similar data, their intent is different. An SLA is a formal contract between an organization and its customers, and it has direct financial and legal implications if the organization fails to deliver on its promise. Organizations use SLOs to evaluate whether the potential downtime is within the tolerable limits.
SLOs and SLAs share a business relationship and should be independently controlled. If the SLA serves as a business tactic, the organization might intentionally set it to a high value based on the business owner's goals. Conversely, SLOs can be higher. Consider mission-critical workloads as an example. This workload class can't afford long downtimes because the effects, including financial loss and even threats to human safety, are significant. Therefore, SLOs typically target 99.999% uptime, commonly referred to as the
five nines
. If SLOs don't meet those targets, organizations must react quickly to mitigate failures and prevent the outcomes of a failed SLA.
The
example
in this article sets a high SLA to support business goals.
Cloud platform and technology providers publish SLAs on their offerings. You should consider the SLAs as part of the SLO calculation, but you shouldn't use them as is without understanding the SLA's scope of coverage. For more information, see
Assess the impact of Microsoft SLAs
.
Consider common SLOs and influencing factors
Every SLO targets a specific quality criteria. Consider these common SLOs for reliability. This list isn't exhaustive. Add SLOs based on your business requirements.
Success rate
measures the success of requests and processes relative to those that return an error or fail their task.
Latency
measures the time between when a request for an operation is initiated and when the result is available or the process is complete.
Capacity
measures concurrent usage, such as the number of throttling-based responses.
Availability
measures uptime from the perspective of customers.
Throughput
measures the minimum data transfer rate during a certain amount of time. Throughput is measured as a data-rate unit, such as transactions per second (TPS) or requests per second (RPS).
Understand the scenarios and tolerances for your workload on Azure. Both Azure services and application components affect the workload SLO. Combine responses from the following table to derive the overall SLO. Use these questions as examples to evaluate the workload component's utility.
Component characteristics
Customer interaction
Other factors
- Does it expose
request or response APIs?
- Does it have
query APIs
?
- Is it a
compute
component?
- Is it a
job processing
component?
-
Control plane and management plane access
for public-facing Azure services.
-
Data plane access
, for example create, read, update, and delete (CRUD) operations.
- Does your
release process
involve downtime?
- What's the likelihood of
introducing bugs
? If the workload integrates with other systems, you might need to consider integration bugs.
- How do
routine operations
like patching affect the availability target? Have you factored in partner dependencies?
- Is your
staffing
sufficient to support constant emergency and emergency backup on-call rotation?
- Does the application have
noisy neighbors
outside of your scope of control that can potentially cause disruptions?
Determine the SLO scope
You can set SLOs at various levels, such as for each application, workload, or a specific flow, in your system. Set level-specific SLOs so that you can customize SLOs based on each component's importance.
In software as a service (SaaS) solutions, measure SLOs per customer to optimize each customer's experience. Customers might have different infrastructure resources in their segments. For such cases, a system-wide SLO that aggregates all resources across customer segments might not make sense. Instead, measure SLOs that align with each customer's specific context. For more information, see
Tenancy models for a multitenant solution
.
Define composite SLO targets
SLOs must be
measurable
and
measured within an observability window
.
SLOs are often percentages like 99.90%, but they can also be statements. Use both methods to get a numerical value that includes all factors.
An SLO consists of measurable SLIs that define acceptable factors. SLIs are metrics with a set threshold that can be alerted. You can collect them from a platform or an application. Different components emit relevant SLIs. When you choose SLIs, consider factors that influence the SLO.
For example, to calculate the SLO for a flow that uses a response and request API, measure server latency and request-processing time. Throughput and error rates don't apply to continuous compute environments like virtual machines (VMs), scale sets, or Azure Batch.
For control plane access, consider error rates and latency for API responses and long-running operations like resource creation. Data plane access depends on the APIs used, each with their own SLO targets.
A good SLI shows when you might breach an SLO. It's usually measured in percentiles. Here are some commonly used percentiles and the estimated time of noncompliance to the expected availability.
Objective
Noncompliance per week
Noncompliance per month
Noncompliance per year
99%
1.68 hours
7.20 hours
3.65 days
99.90%
10.10 minutes
43.20 minutes
8.76 hours
99.95%
5 minutes
21.60 minutes
4.38 hours
99.99%
1.01 minutes
4.32 minutes
52.56 minutes
99.999%
6 seconds
25.90 seconds
5.26 minutes
Important
A composite SLO value is a product distribution of the contributing factors.
An example composite SLO is 99.95% × 99.99999% = ~99.95%.
When you create composite SLOs for different flows, consider their varying criticality and relevance. Flows might have components that you deem as noncritical and omit from your calculations. You can justify their omission based on whether their brief unavailability affects the customer's experience. In some cases, a component might not be relevant to the use case that you consider for the SLO. You can omit these components from the calculation, too.
The same principle applies to operations. Certain operations might introduce risks or affect the SLO, and others are insignificant. The decision should be explicit and built on consensus.
For an illustrative example of how to define and measure SLOs and SLIs, see the
Example
section.
Assess the impact of Microsoft SLAs
A Microsoft SLA provides insight into the availability of areas that Microsoft commits to.
SLAs don't guarantee an offering as a whole
. When you evaluate SLAs, have a good understanding of the coverage that's provided around the published percentile.
Consider Web Apps, a feature of Azure App Service. The feature is considered available when it returns a
200 OK
status in a given use case. Within that specific context and timeframe, it doesn't cover a financially backed guarantee on the availability of features like Easy Auth or slot switching. You should consider areas that aren't mentioned explicitly in the agreement as available by the platform's best effort.
So, if your workload relies on deployment slots, you can't derive your SLO solely from the App Service SLA. As a workload team, you need to hedge and predict the uptime availability. However, this prediction can be uncertain, which is why closely tying your SLO to the platform's SLA can be problematic.
Consider another example. If Azure Front Door has 99.99% availability, your design must adhere to specific criteria that's published in the agreement. For example, your back end must include storage, you need a
GET
operation that can retrieve a file of at least 50 KB in size, and you need to deploy agents across multiple places in at least five geographically diverse locations. This narrow use case of Azure Front Door doesn't guarantee features like caching, routing rules, or a web application firewall. These aspects fall outside the scope of the SLA.
Implement multiregion targets
From a reliability perspective, multiregion deployment is an implementation of the principle of redundancy. The goal is to mitigate the risk of a regional outage or degraded performance. This strategy, when properly designed, can improve SLOs because it adds a secondary region for failover purposes.
There are two main use cases:
High availability pattern, in which you distribute a load across regions for more capacity. High availability doesn't restrict workload users to a region, and the entire system's performance contributes to the SLO.
Bulkhead pattern, in which you restrict customers to specific regions to segment them. In such cases, treat multiregion deployments as separate deployments, or
stamps
, in each region. Measure the health of each stamp separately, with the SLIs that are appropriate to your workload. Consider your overall workload's SLO based on the health of each stamp. If you can fail over between stamps, then your overall workload SLO is higher because a failure in one stamp is recoverable through a failover to another stamp.
Tradeoff
: Determine whether the risk reduction is worth the added complexity. Multiregion targets also introduce operational complexities, such as coordinating deployments, ensuring data consistency, and handling latency. Those operations are significant during recovery. Your team should weigh these complexities against the increased resiliency.
Pay attention to how much redundancy you need to meet high SLOs. For example, Microsoft guarantees higher SLAs for multiregion deployments of Azure Cosmos DB than it guarantees for single-region deployments.
Define recovery metrics
Definitions for realistic recovery targets, like RTO, RPO, MTTR, and MTBF metrics, rely on your
failure mode analysis
and your plans and testing for business continuity and
disaster recovery
. When you define these targets, factor in the platform-provided recovery guarantees. Microsoft publishes RTO and RPO guarantees only for some products, like
Azure SQL Database
.
Before you finish this work, discuss aspirational targets with stakeholders, and ensure that your architecture design supports the recovery targets to the best of your understanding. Clearly communicate to stakeholders that any flows or entire workloads that aren't thoroughly tested for recovery metrics shouldn't have guaranteed SLAs. Make sure that stakeholders understand that recovery targets can change over time as workloads are updated. The workload can become more complex as you add customers or as you adopt new technologies to improve the customer experience. These changes can increase or decrease your recovery metrics.
Note
MTBF can be challenging to define and guarantee. Platform as a service (PaaS) or SaaS models can fail and recover without any notification from the cloud provider, and the process can be completely transparent to you or your customers. If you define targets for this metric, cover only components that are under your control.
When you define recovery targets, define thresholds to initiate a recovery. For example, if a web node is unavailable for more than five minutes, automatically add a new node to the pool. Define thresholds for all components, and consider what the recovery for a specific component involves, including the effect on other components and dependencies. Your thresholds should also account for
transient faults
to ensure that you don't start recovery actions too quickly. Document and share with the stakeholders the potential risks, like data loss or session interruptions for customers, of recovery operations.
Monitor and visualize the targets
Use the data that you gather for your reliability targets to build your health model for each workload and the associated critical flows. A health model defines
healthy
,
degraded
, and
unhealthy
states for the flows and workloads. When the state changes, the model should alert the responsible parties. For detailed design considerations and recommendations, see
Health modeling guidance
.
To keep your operations teams and workload stakeholders informed, create a visualization that reflects the real-time status and overall trends of the workload health model. Discuss visualization solutions with the stakeholders to ensure that you deliver information that they value and that's easy to consume. They might also want to see generated reports weekly, monthly, or quarterly.
Azure facilitation
Azure SLAs provide the Microsoft commitments for uptime and connectivity. Different services have different SLAs, and sometimes products within a service have different SLAs. For more information, see
SLAs for online services
.
The Azure SLA includes procedures for obtaining a service credit if your workload doesn't meet the SLA, along with definitions of availability for each service. That aspect of the SLA acts as an enforcement policy.
Explore the Azure Monitor
dashboards
for your visualization system.
Example
Contoso, Ltd. is designing a new mobile experience for their event ticketing system. Here's the high-level architecture.
An architecture diagram with various Azure components. A mobile ticket scanning device connects to Azure Front Door, which has Transport Layer Security (TLS), web application firewall (WAF) policies, and rules. Azure Front Door connects to Container Apps through an Azure Private Link connection. Build agent VMs connect to Azure DevOps, Container Apps, and private endpoints. SQL Managed Instance is in a box that's labeled *External team*. A workload observability platform box contains a workspace in Azure Monitor Logs, Application Insights, Azure Managed Grafana, alerts, and diagnostics settings. The architecture also shows the icons for Azure DNS, Microsoft Entra ID, Azure Key Vault, and managed identities.
The Grafana logo is a trademark of its respective company. No endorsement is implied by the use of this mark.
Components
Here are some components that illustrate the concept of SLO definition. There are components in this architecture that aren't included in the following list. For example, even though Key Vault is part of the critical request flow, it isn't part of the response use case. If Key Vault is unavailable, the application continues to function by using secrets that are loaded during startup. However, if the application needs to scale, Key Vault availability becomes critical because new nodes need to be loaded with secrets. In this example, scaling operations aren't considered. Other components are omitted for brevity.
Azure Front Door
is the single point of entry that exposes an API that customers use to send requests.
Azure Container Apps
is the environment that the workload team owns and uses to run business logic for the application.
SQL Managed Instance
is owned and managed by another team and is a critical dependency of the workload.
Azure Private Link
provides private connectivity between Azure Front Door and Container Apps deployments. SQL Managed Instance is also exposed to the application through a private endpoint.
In this architecture, the API team defines an initial SLO target for critical flows in the application. They adopt the strategy that's described in
Factors that influence SLOs
. They aim to define objectives that cover the core functionality without overly emphasizing supplemental features. They measure the health of three critical user flows, which involve all core cloud functionalities and execute code across deployments. However, these flows don't cover all of the code or data access. Here are the influencing factors.
Calculate a composite SLO
Azure availability SLO:
The financial commitment SLA for Azure serves as a proxy to assess platform reliability.
Azure component
Applicable SLA coverage
Not covered by SLA
Adjusted SLO
Azure Front Door
99.99% for successful HTTP
GET
operations
Caching, rules engine
99.98%
Container Apps
99.95% based on deployed apps that are reachable by the built-in ingress
Autoscaling, token store capabilities
99.95%
SQL Managed Instance
99.99% based on the connection to the SQL Server instance
Performance, data retention
99.80%
Private Link
99.99% based on whole minutes when the private endpoint network didn't accept traffic or when traffic didn't flow between the endpoint and the Private Link service
Individual failures lasting less than one minute
99.99%
The adjustment is based on several factors that depend on the workload team's promise to their objectives. One factor might be confidence in the platform's capability based on prior experience. For example, for Container Apps and Private Link, the team feels comfortable taking the SLA value as is.
There are also nuanced factors. For example, the team lowers the SLO value for SQL Managed Instance to 99.80% to account for potential failures in their data operations, such as schema changes and taking backups.
The team sets the composite SLO by calculating the impact of individual, adjusted SLO values. This value is 99.72%.
There are other contributing factors. The architecture relies on Azure networking components like virtual networks and network security groups (NSGs) that don't have a published SLA. The workload team decides to consider those factors with 99.99% availability for each component.
A composite SLO based on predicted platform availability: 99.68% per month.
Application code SLO:
The team acknowledges that bugs in their application code or stored procedures can affect system availability, and they allocate one hour of monthly downtime to account for code-related errors.
They use common
downtime percentiles
to estimate the SLO for individual factors like code defects, scaling problems, and other code-related considerations.
A composite SLO based on code and data availability: 99.86% per month.
Resource and application configuration SLO:
The team recognizes that cloud resources and application code must be properly configured. This target includes setting up autoscaling rules, deploying NSG rules, and selecting the correct size of SKUs. To account for configuration errors, they budget 10 minutes of monthly downtime, which is about 99.98% availability.
A composite SLO based on configuration availability: 99.95% per month.
Operations SLO:
The workload team develops good DevOps culture by following Well-Architected Framework principles for Operational Excellence. They deploy cloud resources, configuration, and code every sprint.
The team considers deployments to be a risk because they can destabilize a running system. There might be errors as a result of TLS certificate updates, DNS changes, or tool errors. The team also considers potential downtime caused by emergency fixes. They budget a total of 20 minutes of monthly downtime, which is approximately 99.95% availability.
Maintenance windows are designated time periods during which system maintenance or updates occur. The API is mostly unused for approximately four hours each day. To reduce the risk of unavailability, the team can schedule maintenance tasks during those less-active hours. This approach leads to a higher SLO, but the team decides not to include the maintenance window as part of their SLO.
A composite SLO based on operations availability: 99.95% per month.
External dependencies SLO:
The team considers SQL Managed Instance as the primary dependency, which already has a 99.80% availability factored into the overall platform availability. No other external dependencies are considered.
A composite SLO based on external dependencies: Not applicable.
Determine the overall composite SLO result
The overall composite SLO target is set at 99.45%, which is equivalent to approximately four hours of downtime per month.
To meet the SLO target of only four hours of unavailability per month, the workload team establishes an on-call rotation. Both customer support and synthetic transaction monitoring can invoke on-call site reliability engineering (SRE) support to promptly start recovery steps to address SLO problems.
Set the workload SLA
The SLA for the workload is 99.90% availability per month.
The workload team's legal and finance departments set the SLA for the workload at 99.90% availability per month, which exceeds the SLO target of 99.45%. They make this decision after they analyze financial payouts versus projected customer growth based on an attractive SLA. The SLA covers two core user flows and includes performance considerations, not just availability. It's a calculated risk taken by the business team to benefit the business, and the engineering team is aware of the commitment.
Set the correctness SLO
The application's core user flows must be available and usably, or even competitively, responsive. The team sets a response time SLO specifically for the API, excluding client processing time and internet network traversal. They evaluate this SLO only during periods of availability. They choose the 75th percentile as both the SLO target and the performance measurement, which captures the typical customer experience and excludes worst-case scenarios.
Related links
Health modeling and observability of mission-critical workloads on Azure
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing a reliable monitoring and alerting strategy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing a reliable monitoring and alerting strategy
Article
2024-02-15
8 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:10
Measure and model the solution's health indicators. Continuously capture uptime and other reliability data from across the workload and also from individual components and key flows.
This guide describes the recommendations for designing a reliable monitoring and alerting strategy. Implement this strategy to keep your operations teams informed of your environment's health status and ensure that you meet the established reliability targets for your workload.
Definitions
Term
Definition
Metrics
Numerical values that are collected at regular intervals. Metrics describe some aspects of a system at a particular time.
Resource logs
Data that a system generates. It provides information about the state of the system.
Traces
Data that provides information about the path that a request travels through services and components.
Key design strategies
Before you create a monitoring and alerting strategy, perform the following tasks for your workload as part of your reliability planning:
Identify
critical and noncritical flows
.
Perform
failure mode analysis (FMA)
for your flows.
Identify
reliability targets
.
Design for reliability by implementing
redundancy
,
scaling
,
self-preservation, and self-healing
.
Design a robust
testing strategy
.
Model the health
of your workload and its components.
Create a monitoring and alerting strategy to ensure that your workload operates reliably. A monitoring and alerting strategy provides awareness to your operations teams so they're notified of changes in your workload's condition and can quickly address issues. Build a robust and reliable monitoring strategy by creating a
health model
for your critical flows and the components that these critical flows comprise. The health model defines healthy, degraded, and unhealthy states. Design your operational posture to immediately catch changes in these states. When health states change from healthy to degraded or unhealthy, alerting mechanisms trigger the
automatic corrective measures
and notifies appropriate teams.
Implement the following recommendations to design a monitoring and alerting strategy that meets the requirements of your business.
Implement an overall monitoring strategy
Understand the difference between
metrics
,
logs
, and
traces
.
Enable
logging
for all cloud resources. Use automation and governance in your deployments to enable diagnostic logging throughout your environment.
Forward all diagnostic logs to a centralized data sink and analytics platform, like a
Log Analytics workspace
. If you have regional data sovereignty requirements, you must use local data sinks in the regions that are subject to those requirements.
Tradeoff
: There are cost implications for storing and querying logs. Notice how your log analysis and retention affects your budget, and determine the best balance of utilization to meet your requirements. For more information, see
Best practices for cost optimization
.
If your workloads are subject to one or more compliance frameworks, some of the component logs that handle sensitive information are also subject to those frameworks. Send the relevant component logs to a security information and event management (SIEM) system, like
Microsoft Sentinel
.
Create a
log retention policy
that incorporates long-term retention requirements that the compliance frameworks impose on your workload.
Use
structured logging
for all log messages to optimize querying the log data.
Configure alerts to trigger when values pass critical thresholds that correlate to a health model state change, like green to yellow or red.
Threshold configuration is a practice of continuous improvement. As your workload evolves, the thresholds you define might change. In some cases,
dynamic thresholds
are a good option for your monitoring strategy.
Consider using alerts when states improve, such as red to yellow or red to green, so that the operations teams can track these events for future reference.
Visualize the real-time health of your environment.
Use data that's gathered during incidents to continuously improve your health models and your monitoring and alerting strategy.
Incorporate cloud platform monitoring and alerting services, including:
Platform-level health, like
Azure Service Health
.
Resource-level health, like
Azure Resource Health
.
Incorporate purpose-built advanced monitoring and analytics that your cloud provider offers, like Azure Monitor
insight tools
.
Implement backup and recovery monitoring to capture:
The data replication status to ensure that your workload achieves recovery within the target recovery point objective (RPO).
Successful and failed backups and recoveries.
The recovery duration to inform your
disaster recovery planning
.
Monitor applications
Create health probes or
check functions
and run them regularly from outside the application. Ensure that you test from multiple locations that are geographically close to your customers.
Log data while the application runs in the production environment. You need sufficient information to diagnose the cause of issues in the production state.
Log events at service boundaries. Include a correlation ID that flows across service boundaries. If a transaction flows through multiple services and one of them fails, the correlation ID helps you track requests across your application and pinpoint why the transaction failed.
Use asynchronous logging. Synchronous logging operations sometimes block your application code, which causes requests to back up as logs are written. Use asynchronous logging to preserve availability during application logging.
Separate application logging from auditing. Audit records are commonly maintained for compliance or regulatory requirements and must be complete. To avoid dropped transactions, maintain audit logs separate from diagnostic logs.
Use
telemetry correlation
to ensure that you can map transactions through the end-to-end application and critical system flows. This process is vital for performing root cause analysis (RCA) for failures. Collect platform-level metrics and logs, such as CPU percentage, network in, network out, and disk operations per second, from the application to inform a health model and to detect and predict issues. This approach can help distinguish between transient and nontransient faults.
Use white box monitoring to instrument the application with semantic logs and metrics. Collect application-level metrics and logs, such as memory consumption or request latency, from the application to inform a health model and to detect and predict issues.
Use black box monitoring to measure platform services and the resulting customer experience. Black box monitoring tests externally visible application behavior without knowledge of the internals of the system. This approach is common for measuring customer-centric service-level indicators (SLIs), service-level objectives (SLOs), and service-level agreements (SLAs).
Note
For more information about application monitoring, see
Health Endpoint Monitoring pattern
.
Monitor data and storage
Monitor the availability metrics of your storage containers. When this metric drops below 100 percent, it indicates failing writes. Transient drops in availability might happen when your cloud provider manages the load. Track the availability trends to determine if there's an issue with your workload.
In some cases, a drop in the availability metrics for a storage container indicates a bottleneck in the compute layer that's associated with the storage container.
There are many metrics to monitor for databases. In the context of reliability, the important metrics to monitor include:
Query duration
Timeouts
Wait times
Memory pressure
Locks
Azure facilitation
Azure Monitor
is a comprehensive monitoring solution that's used to collect, analyze, and respond to monitoring data from your cloud and on-premises environments.
Log Analytics
is a tool in the Azure portal that's used to edit and run log queries against data in the Log Analytics workspace.
Application Insights
is an extension of Azure Monitor. It provides application performance monitoring (APM) features.
Azure Monitor insights
are advanced analytics tools that help monitor Azure services, like virtual machines, application services, and containers. Insights are built on top of Azure Monitor and Log Analytics.
Azure Monitor for SAP solutions
is an Azure-native monitoring product for SAP landscapes that run on Azure.
Azure Policy
helps to enforce organizational standards and to assess compliance at scale.
Azure Business Continuity Center
gives you insights into your business continuity estate. As you apply the approaches given for business continuity and disaster recovery (BCDR), use Azure Business Continuity Center to centralize management of business continuity protection across Azure and hybrid workloads. Azure Business Continuity Center pinpoints resources that lack proper protection (via backup or disaster recovery) and takes corrective actions. The tool facilitates unified monitoring and lets you establish governance and auditing compliance through Azure Policy, all conveniently accessible in one location.
For multiple workspace best practices, see
Design a Log Analytics workspace architecture
.
Example
For examples of real-world monitoring solutions, see
Web application monitoring on Azure
and
Baseline architecture for an Azure Kubernetes Service cluster
.
Related links
Alerting for DevOps
Alerting for operations
Monitoring and diagnostics guidance
Web application monitoring on Azure
Community links
Azure Monitor Baseline Alerts (AMBA)
is a central repository of alert definitions that customers and partners can use to improve their observability experience through the adoption of Azure Monitor.
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Data partitioning recommendations for reliability - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for data partitioning
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:06
Implement a timely and reliable scaling strategy at the application, data, and infrastructure levels. Base the scaling strategy on actual or predicted usage patterns and minimize manual intervention.
Related guide:
Scaling
This guide describes the recommendations for designing a data partitioning strategy for the database and data storage technology that you deploy. This strategy helps you improve the reliability of your data estate.
Key design strategies
In many large-scale solutions,
partitions
are used to divide data so that it can be managed and accessed separately. Partitioning data improves scalability, reduces contention, and optimizes performance. Implement data partitioning to divide data by usage pattern. For example, you can archive older data in inexpensive data storage. Choose your partitioning strategy carefully to maximize the benefits and minimize adverse effects.
Note
In this article, the term
partitioning
means the process of physically dividing data into separate data stores. It differs from SQL Server table partitioning.
You can partition data to:
Improve scalability.
When you scale up a single database system, the database eventually reaches a physical hardware limit. If you divide data across multiple partitions, with each partition hosted on a separate server, you can scale out the system almost indefinitely.
Improve performance.
In each partition, data access operations are performed over a smaller volume of data compared to data that isn't partitioned. Partition data to make your system more efficient. Operations that affect more than one partition can run in parallel.
Improve security.
In some cases, you can separate sensitive and nonsensitive data into different partitions, and apply different security controls to the sensitive data.
Provide operational flexibility.
You can partition data to fine-tune operations, maximize administrative efficiency, and minimize cost. For example, you can define strategies for management, monitoring, backup and restore, and other administrative tasks based on the importance of the data in each partition.
Match the data store to the pattern of use.
You can deploy each partition on a different type of data store based on the cost and the built-in features that the data store offers. For example, you can store large binary data in blob storage, and store structured data in a document database. For more information, see
Understand data store models
.
Improve availability.
To avoid a single point of failure, you can separate data across multiple servers. If one instance fails, only the data in that partition is unavailable. Operations continue in other partitions. This consideration is less relevant for managed platform as a service (PaaS) data stores because they have built-in redundancy.
Select the right partitioning strategy
There are three typical strategies for partitioning data:
Horizontal partitioning
(often called
sharding
). In this strategy, each partition is a separate data store, but all partitions have the same schema. Each partition is known as a
shard
and holds a subset of the data, such as a set of customer orders.
Vertical partitioning.
In this strategy, each partition holds a subset of the fields for items in the data store. The fields are divided according to their pattern of use. For example, frequently accessed fields might be placed in one vertical partition and less frequently accessed fields in another.
Functional partitioning.
In this strategy, data is aggregated according to how each bounded context in the system uses the data. For example, an e-commerce system might store invoice data in one partition and product inventory data in another.
Consider combining these strategies when you design a partitioning scheme. For example, you might divide data into shards and then use vertical partitioning to further subdivide the data in each shard.
Horizontal partitioning (sharding)
The following image shows an example of horizontal partitioning, or sharding. This example divides product inventory data into shards that are based on the product key. Each shard holds the data for a contiguous range of shard keys (A-G and H-Z), organized alphabetically. When you perform sharding, it spreads the load over more computers, which reduces contention and improves performance.
The most important factor is the sharding key that you choose. It can be difficult to change the key after the system is in operation. The key must ensure that data is partitioned to spread the workload as evenly as possible across the shards.
The shards don't have to be the same size. It's more important to balance the number of requests. Some shards might be large, but each item in the shard has a low number of access operations. Other shards might be smaller, but each item in the shard is accessed more frequently. It's also important to ensure that a single shard doesn't exceed the scale limits, in terms of capacity and processing resources, of the data store.
Avoid creating
hot
partitions that can affect performance and availability. For example, if you use the first letter of a customer's name, it can create an unbalanced distribution because some letters are more common than others. Instead, use a customer identifier hash to distribute data evenly across partitions.
Choose a sharding key that minimizes the future need to split large shards, combine small shards into larger partitions, or change the schema. These operations are time-consuming and might require you to take one or more shards offline.
If shards are replicated, you can keep some of the replicas online while others are split, merged, or reconfigured. However, the system might limit the operations that can be performed during the reconfiguration. For example, the data in the replicas might be marked as read-only to prevent data inconsistences.
For more information, see
Sharding pattern
.
Vertical partitioning
The most common use for vertical partitioning is to reduce the I/O and performance costs that are associated with fetching frequently accessed items. The following image shows an example of vertical partitioning. In this example, different properties of an item are stored in different partitions. One partition holds data that's accessed more frequently, including product name, description, and price. Another partition holds inventory data, including the stock count and the last ordered date.
In this example, the application regularly queries the product name, description, and price when it displays the product details to customers. The stock count and last ordered date are in a separate partition because these two items are commonly used together.
See the following advantages of vertical partitioning:
You can separate relatively slow-moving data (product name, description, and price) from more dynamic data (stock level and last ordered date). Slow-moving data is a good candidate for an application to cache in memory.
You can store sensitive data in a separate partition with added security controls.
Vertical partitioning can reduce the amount of concurrent access that's needed.
Vertical partitioning operates at the entity level within a data store, partially normalizing an entity to break it down from a
wide
item to a set of
narrow
items. It's ideally suited for column-oriented data stores, such as HBase and Cassandra. If the data in a collection of columns is unlikely to change, consider using column stores in SQL Server.
Functional partitioning
When a bounded context can be identified for each distinct business area in an application, functional partitioning can improve isolation and data access performance. Another common use for functional partitioning is to separate read-write data from read-only data. The following image shows an overview of functional partitioning that has inventory data separated from customer data.
This partitioning strategy can help reduce data access contention across different parts of a system.
Design partitions for scalability
It's vital to consider the size and workload for each partition. Balance them so that data is distributed to achieve maximum scalability. However, you must also partition the data so that it doesn't exceed the scaling limits of a single partition store.
Follow these steps when you design partitions for scalability:
Analyze the application to understand the data access patterns, such as the size of the result set that each query returns, frequency of access, inherent latency, and server-side compute processing requirements. In many cases, a few major entities demand most of the processing resources.
Use this analysis to determine the current and future scalability targets, such as the data size and workload. Then distribute the data across the partitions to meet the scalability target. For horizontal partitioning, choose the right shard key to ensure even distribution. For more information, see
Sharding pattern
.
Ensure that each partition has enough resources to handle the scalability requirements in terms of the data size and throughput. Depending on the data store, there might be a limit for each partition on the amount of storage space, processing power, or network bandwidth. If the requirements are likely to exceed these limits, you might need to refine your partitioning strategy or split data out further. You might need to combine two or more strategies.
Monitor the system to verify that data is distributed as expected and that the partitions can handle the load. Actual usage doesn't always match what an analysis predicts. You might have to rebalance the partitions or redesign some parts of the system to yield the required balance.
Some cloud environments allocate resources based on infrastructure boundaries. Ensure that the limits of your selected boundary provide enough room for anticipated growth in data volume, data storage, processing power, and bandwidth.
For example, if you use Azure Table Storage, there's a limit to the volume of requests that a single partition can handle in a particular period of time. For more information, see
Scalability and performance targets for standard storage accounts
. A busy shard might require more resources than a single partition can handle. You might need to repartition the shard to spread the load. If the total size or throughput of these tables exceeds the capacity of a storage account, you might need to create more storage accounts and spread the tables across these accounts.
Design partitions for query performance
You can boost query performance by using small datasets and running parallel queries. Each partition should contain a small proportion of the entire dataset. This reduction in volume can improve the performance of queries. However, partitioning isn't an alternative to appropriate database design and configuration. Ensure that you implement the necessary indexes.
Follow these steps when you design partitions for query performance:
Examine the application requirements and performance.
Use business requirements to determine the critical queries that must always perform quickly.
Monitor the system to identify queries that perform slowly.
Determine the queries that perform most frequently. Even if a single query has a minimal cost, cumulative resource consumption can be significant.
Partition the data that's causing slow performance.
Limit the size of each partition so that the query response time is within target.
If you use horizontal partitioning, design the shard key so that the application can easily select the appropriate partition. This specification prevents the query from scanning every partition.
Consider the location of a partition. Try to keep data in partitions that are geographically close to the applications and users that access it.
If an entity has throughput and query performance requirements, use functional partitioning that's based on that entity. If this allocation still doesn't satisfy the requirements, you can add horizontal partitioning. A single partitioning strategy is usually adequate, but in some cases, it's more efficient to combine both strategies.
Run queries in parallel across partitions to improve performance.
Design partitions for availability
Partition data to improve the availability of applications. Partitioning ensures that the entire dataset doesn't have a single point of failure, and you can independently manage individual subsets of the dataset.
Consider the following factors that affect availability:
Determine the criticality of the data.
Identify the critical business data, such as transactions, and the less critical operational data, such as log files.
Store critical data in highly available partitions, and create an appropriate backup plan.
Establish separate management and monitoring procedures for different datasets.
Place data that has the same level of criticality in the same partition so that it can be backed up at the same frequency. For example, you might need to back up partitions that hold transaction data more often than partitions that hold logging or trace information.
Manage individual partitions.
Design partitions to support independent management and maintenance. This practice provides several advantages, for example:
If a partition fails, it can be recovered independently without applications that access data in other partitions.
Partitioning data by geographic area allows scheduled maintenance tasks to occur at off-peak hours for each location. Ensure that partitions aren't so large that they prevent planned maintenance from finishing during this period.
Replicate critical data across partitions.
This strategy improves availability and performance but can also introduce consistency issues. It takes time to synchronize changes with every replica. During synchronization, different partitions contain different data values.
Optimize application code to use partitions
Partitioning adds complexity to the design and development of your system. Partition data as a fundamental part of your system design even if the system initially only contains a single partition. If you address partitioning as an afterthought, it's challenging because you already have a live system to maintain. You might:
Have to modify data access logic.
Have to migrate large quantities of existing data to distribute it across partitions.
Run into challenges because users expect to continue using the system during the migration.
In some cases, partitioning isn't important because the initial dataset is small and a single server can easily handle it. Some workloads can go without partitions, but many commercial systems need to expand as the number of users increase.
Some small data stores also benefit from partitioning. For example, hundreds of concurrent clients might access a small data store. If you partition the data in this situation, it can help to reduce contention and improve throughput.
Consider the following points when you design a data partitioning scheme:
Minimize cross-partition data access operations.
Try to keep data for the most common database operations together in a partition to minimize cross-partition data access operations. It can be more time-consuming to query across partitions rather than querying within a single partition. But optimizing partitions for one set of queries might adversely affect other sets of queries. If you must query across partitions, minimize query time by running parallel queries and aggregating the results within the application. In some cases, you can't use this approach, for example if the result from one query is used in the next query.
Replicate static reference data.
If queries use relatively static reference data, such as postal code tables or product lists, consider replicating this data in all the partitions to reduce separate lookup operations in different partitions. This approach can also reduce the likelihood of the reference data becoming a
hot
dataset with heavy traffic from across the entire system. There are extra costs associated with synchronizing changes to the reference data.
Minimize cross-partition joins.
Where possible, minimize requirements for referential integrity across vertical and functional partitions. In these schemes, the application is responsible for maintaining referential integrity across partitions. Queries that join data across multiple partitions are inefficient because the application typically performs consecutive queries that are based on a key and then a foreign key. Instead, consider replicating or de-normalizing the relevant data. If cross-partition joins are necessary, run parallel queries over the partitions and join the data within the application.
Embrace eventual consistency.
Evaluate whether strong consistency is a requirement. A common approach in distributed systems is to implement eventual consistency. The data in each partition is updated separately, and the application logic ensures that the updates finish successfully. The application logic also handles the inconsistencies that arise from querying data while an eventually consistent operation runs.
Consider how queries locate the correct partition.
If a query must scan all partitions to locate the required data, it significantly affects performance, even when multiple parallel queries run. With vertical and functional partitioning, queries can specify the partition. On the other hand, horizontal partitioning can make locating an item difficult because every shard has the same schema. A typical solution is to maintain a map that's used to look up the shard location of items. Implement this map in the sharding logic of the application. It can also be maintained by the data store if the data store supports transparent sharding.
Rebalance shards periodically.
With horizontal partitioning, rebalancing shards can help evenly distribute the data by size and workload. Rebalance shards to minimize hotspots, maximize query performance, and work around physical storage limitations. This task is complex and often requires a custom tool or process.
Replicate partitions.
Replicate each partition to provide added protection against failure. If a single replica fails, queries are directed to a working copy.
Extend scalability to a different level.
If you reach the physical limits of a partitioning strategy, you might need to extend the scalability to a different level. For example, if partitioning is at the database level, you might need to locate or replicate partitions in multiple databases. If partitioning is already at the database level, and there are physical limitations, you might need to locate or replicate partitions in multiple hosting accounts.
Avoid transactions that access data in multiple partitions.
Some data stores implement transactional consistency and integrity for operations that modify data but only when the data is located in a single partition. If you need transactional support across multiple partitions, implement it as part of your application logic because most partitioning systems don't provide native support.
All data stores require some operational management and monitoring activity. These tasks include loading data, backing up and restoring data, reorganizing data, and ensuring that the system performs correctly and efficiently.
Consider the following factors that affect operational management:
Implement appropriate management and operational tasks when the data is partitioned.
These tasks might include backup and restore, archiving data, monitoring the system, and other administrative tasks. For example, it can be challenging to maintain logical consistency during backup and restore operations.
Load data into multiple partitions, and add new data that comes from other sources.
Some tools and utilities might not support sharded data operations, such as loading data into the correct partition.
Archive and delete data regularly.
To prevent the excessive growth of partitions, archive and delete data every month. You might need to transform the data to match a different archive schema.
Locate data integrity problems.
Consider running a periodic process to locate data integrity problems, such as data in one partition that references missing information in another. The process can either automatically attempt to fix these issues or generate a report for manual review.
Rebalance partitions
As a system matures, you might have to adjust the partitioning scheme. For example, individual partitions might start receiving a disproportionate volume of traffic and become hot, leading to excessive contention. Or you might have underestimated the volume of data in some partitions, which causes the partitions to approach capacity limits.
Some data stores, such as Azure Cosmos DB, can automatically rebalance partitions. In other cases, you can rebalance partitions in two stages:
Determine a new partitioning strategy.
Which partitions need to be split or combined?
What's the new partition key?
Migrate data from the old partitioning scheme to the new set of partitions.
You might need to make partitions unavailable while you relocate data, which is called
offline migration
. Depending on the data store, you might migrate data between partitions while they're in use. This technique is called
online migration
.
Offline migration
Offline migration reduces the chance of contention occurring. To perform offline migration:
Mark the partition as offline. You can mark a partition as read-only so that applications can still read the data while you move it.
Split-merge and move the data to the new partitions.
Verify the data.
Bring the new partitions online.
Remove the old partition.
Online migration
Online migration is more complex but less disruptive compared to offline migration. The process is similar to offline migration, but you don't mark the original partition as offline. Depending on the granularity of the migration process, for example item by item versus shard by shard, the data access code in the client applications might have to read and write data that's in two locations, the original partition and the new partition.
Azure facilitation
The following sections describe recommendations for partitioning data that's stored in Azure services.
Partition in Azure SQL Database
A single SQL database has a limit to the volume of data that it can contain. Throughput is constrained by architectural factors and the number of concurrent connections that it supports.
Elastic pools
support horizontal scaling for a SQL database. Use elastic pools to partition your data into shards that are spread across multiple SQL databases. You can also add or remove shards as the volume of data grows and shrinks. Elastic pools can also help reduce contention by distributing the load across databases.
Each shard is implemented as a SQL database. A shard can hold more than one dataset. Each dataset is called a
shardlet
. Each database has metadata that describes the shardlets that it contains. A shardlet can be a single data item or a group of items that share the same shardlet key. For example, in a multitenant application, the shardlet key can be the tenant ID, and all data for a tenant can be in the same shardlet.
Applications are responsible for associating a dataset with a shardlet key. A separate SQL database acts as a global shard map manager. This database has a list of all the shards and shardlets in the system. The application connects to the shard map manager database to obtain a copy of the shard map. It caches the shard map locally and uses the map to route data requests to the appropriate shard. This functionality is hidden behind a series of APIs that are contained in the
client library of the Elastic Database feature of SQL Database
, which is available for Java and .NET.
For more information about elastic pools, see
Scaling out with SQL Database
.
To reduce latency and improve availability, you can replicate the global shard map manager database. With the premium pricing tiers, you can configure active geo-replication to continuously copy data to databases in different regions.
Alternatively, use
SQL Data Sync for SQL Database
or
Azure Data Factory
to replicate the shard map manager database across regions. This form of replication runs periodically and is more suitable if the shard map changes infrequently and doesn't require the premium tier.
Elastic Database provides two schemes for mapping data to shardlets and storing them in shards:
A
list shard map
associates a single key with a shardlet. For example, in a multitenant system, the data for each tenant can be associated with a unique key and stored in its own shardlet. To guarantee isolation, each shardlet can be held within its own shard.
Download a
Visio file
of this diagram.
A
range shard map
associates a set of contiguous key values with a shardlet. For example, you can group the data for a set of tenants, each with their own key, within the same shardlet. This scheme is less expensive than a list shard map because tenants share data storage, but it provides less isolation.
Download a
Visio file
of this diagram
A single shard can contain the data for several shardlets. For example, you can use list shardlets to store data for different non-contiguous tenants in the same shard. You can also mix range shardlets and list shardlets in the same shard, but then they are addressed via different maps. The following diagram shows this approach:
Download a
Visio file
of this diagram.
With elastic pools, you can add and remove shards as the volume of data grows and shrinks. Client applications can create and delete shards dynamically and transparently update the shard map manager. However, removing a shard is a destructive operation that also requires deleting all the data in that shard.
If an application needs to split a shard into two separate shards or combine shards, use the
split-merge tool
. This tool runs as an Azure web service and migrates data safely between shards.
The partitioning scheme can significantly affect the performance of your system. It can also affect the rate at which shards have to be added or removed, or that data must be repartitioned across shards. Consider the following points:
Group data that's used together in the same shard, and avoid operations that access data from multiple shards. A shard is a SQL database in its own right, and cross-database joins must be performed on the client side when operations access multiple shards.
Although SQL Database doesn't support cross-database joins, you can use Elastic Database tools to perform
multi-shard queries
. A multi-shard query sends individual queries to each database and merges the results.
Design a system that doesn't have dependencies between shards. Referential integrity constraints, triggers, and stored procedures in one database can't reference objects in another.
Consider replicating data across shards if you have reference data that's frequently used by queries. This approach can eliminate the need to join data across databases. Ideally, such data should be static or slow-moving to minimize the replication effort and reduce the chance of it becoming stale.
Use the same schema for shardlets that belong to the same shard map. This guidance isn't enforced by SQL Database, but data management and querying is complex if each shardlet has a different schema. Instead, create separate shard maps for each schema. You can store data that belongs to different shardlets in the same shard.
Store data in the same shard or implement eventual consistency if your business logic needs to perform transactions. Transactional operations are only supported for data that's in a shard, and not across shards. Transactions can span shardlets if they're part of the same shard.
Place shards close to the users that access the data in those shards. This strategy helps reduce latency.
Avoid having a combination of highly active and relatively inactive shards. Try to spread the load evenly across shards. You might have to hash the sharding keys. If you're geo-locating shards, ensure that the hashed keys map to shardlets held in shards that are stored close to the users that access that data.
Partition in Azure Blob Storage
With Blob Storage, you can store large binary objects. Use block blobs in scenarios that require you to quickly upload or download large volumes of data. Use page blobs for applications that require random, rather than serial, access to parts of the data.
Each block blob or page blob is held in a container in an Azure storage account. Use containers to group related blobs that have the same security requirements. This grouping is logical rather than physical. Inside a container, each blob has a unique name.
The partition key for a blob is the account name, the container name, and the blob name. The partition key is used to partition data into ranges. These ranges are load balanced across the system. Blobs can be distributed across many servers to scale out access to them. A single blob can only be served by a single server.
If your naming scheme uses timestamps or numerical identifiers, it can lead to excessive traffic to one partition. It prevents the system from effectively load balancing. For instance, if you have daily operations that use a blob object with a timestamp, such as
yyyy-mm-dd
, all the traffic for that operation goes to a single partition server. Instead, prefix the name with a three-digit hash. For more information, see
Partition naming convention
.
The actions of writing a single block or page are atomic, but operations that span blocks, pages, or blobs aren't. If you need to ensure consistency when write operations are performed across blocks, pages, and blobs, take out a write lock by using a blob lease.
Considerations
Data partitioning introduces some challenges and complexities that you need to consider.
Data synchronization between the partitions might become a challenge. Ensure that updates or changes to one partition are propagated to the other partitions in a timely and consistent manner.
Failover and disaster recovery processes become complex when you need to coordinate the backup and restore of multiple partitions. Data integrity issues can arise if some partitions or their backups are corrupted or unavailable.
Data partitioning can affect performance and reliability if you need to query across partitions, and when you rebalance the partitions if the data grows unevenly.
Related links
Building scalable cloud databases
Data Factory
Index Table pattern
Materialized View pattern
Moving data between scaled-out cloud databases
Multi-shard querying using elastic database tools
Partition naming
Review your data options
Scalability and performance targets for standard storage accounts
Scaling out with SQL Database
Sharding pattern
Understand data store models
Use elastic pools to manage and scale multiple databases in SQL Database
What is SQL Data Sync for Azure?
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Reliability design principles - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Reliability design principles
Article
2023-11-15
4 contributors
Feedback
In this article
Outages and malfunctions are serious concerns for all workloads. A reliable workload must survive those events and
continue to consistently provide its intended functionality
. It must be
resilient
so that it can detect, withstand, and recover from failures within an acceptable time period. It must also be
available
so that users can access the workload during the promised time period at the promised quality level.
It's not realistic to assume failures won't occur, especially when the workload is built to run on distributed systems. Some components might fail while others continue to operate. At some point, the user experience might be affected, which compromises business goals.
Workload architectures should have
reliability assurances in application code, infrastructure, and operations
. Design choices shouldn't change the intent that's specified by business requirements. Such changes should be considered significant tradeoffs.
The
design principles
are intended to provide guidance for aspects of reliability that you should consider throughout the development lifecycle. Start with the recommended approaches and
justify the benefits for a set of requirements
. After you set your strategy, drive actions by using the
Reliability checklist
.
If you don't apply these principles to your design, the workload most likely won't be prepared to
anticipate or handle problems in production
. The outcome might be service disruptions that lead to financial loss. In the case of critical workloads, failing to apply these principles could jeopardize safety.
Design for business requirements
Gather business requirements with a focus on the intended utility of the workload.
Requirements must cover user experience, data, workflows, and characteristics that are unique to the workload. The outcome of
the requirements process must clearly state the expectations
. The goals must be achievable and negotiated with the team, given a specified investment. They must be documented to drive technological choices, implementations, and operations.
Approach
Benefit
Quantify success by setting targets on indicators
for individual components, system flows, and the system as a whole.
Do those targets make user flows more reliable?
Metrics quantify expectations. They enable you to
understand complexities
and determine whether the downstream costs of those complexities are within the investment limit.
The target values indicate an ideal state. You can use the values as test thresholds that help you
detect deviations
from that state and how long it takes to return to the target state.
Compliance requirements must also have predictable outcomes for in-scope flows. Prioritizing these flows
bring attention to areas that are the most sensitive
.
Understand platform commitments.
Consider the limits, quotas, regions, and capacity constraints
for services.
Service-level agreements (SLAs) vary by service. Not all services and features are covered equally. Not all services or features are available in all regions. Most of the subscription resource limits are per region. Having a good
understanding of coverage and limits
can help you detect drift and build resiliency and recovery mechanisms.
Determine dependencies
and their effect on resiliency.
Keeping track of dependent infrastructure, services, APIs, and functions developed by other teams or third parties helps you determine
whether the workload can operate in absence of those dependencies
. It also helps you
understand cascading failures
and
improve downstream operations
.
Developers can
implement resilient design patterns
to handle potential failures when you use external services that might be susceptible to failures.
Design for resilience
The workload must continue to operate with full or reduced functionality.
You should expect that component malfunctions, platform outages, performance degradations, limited resource availability, and other faults will occur. Build resiliency in the system so that it's
fault-tolerant and can degrade gracefully
.
Approach
Benefit
Distinguish components that are on the critical path
from those that can function in a degraded state.
Not all components of the workload need to be equally reliable. Determining criticality helps you design according to the
criticality of each component
. You
won't overengineer resiliency for components
that could slightly deteriorate the user experience, as opposed to components that can cause end-to-end problems if they fail.
The design can be efficient in allocating resources to critical components. You can also implement fault isolation strategies so that if a noncritical component fails or enters a degraded state, it can be isolated to prevent cascading failures.
Identify potential failure points in the system
, especially for the critical components, and determine the effect on user flows.
You can
analyze the failure cases, blast radius, and intensity of fault
: full or partial outage. This analysis influences the design of error handling capabilities at the component level.
Build self-preservation capabilities
by using design patterns correctly and modularizing the design to isolate faults.
The system will be able to
prevent a problem from affecting downstream components
. The system will be able to mitigate transient and permanent failures, performance bottlenecks, and other problems that might affect reliability.
You'll also be able to
minimize the blast radius
.
Add the capability to scale out the critical components
(application and infrastructure) by considering the capacity constraints of services in the supported regions.
The workload will be able to
handle variable capacity spikes and fluctuations
. This capability is crucial when there's an unexpected load on the system, like a surge in valid usage. If the workload is designed to scale out over multiple regions it can even overcome potential temporary resource capacity constraints or other issues impacting in a single region.
Build redundancy in layers and resiliency on various application tiers.
Aim for redundancy in physical utilities and immediate data replication. Also aim for redundancy in the functional layer that covers services, operations, and personnel.
Redundancy helps
minimize single points of failure
. For example, if there’s a component, zonal, or regional outage, redundant deployment (in active-active or active-passive) allows you to meet uptime targets.
Adding intermediaries prevents direct dependency between components and improves buffering. Both of these benefits harden the resiliency of the system.
Overprovision to immediately mitigate individual failure
of redundant instances and to buffer against runaway resource consumption.
Higher investment in overprovisioning
increases resiliency
.
The system will continue to operate at full utility during an active failure even before scaling operations can start to
remediate the failure
. Likewise, you can reduce the risk of unexpected runaway resource consumption claiming your planned buffer, gaining critical triage time, before system faults or aggressive scaling occurs.
Design for recovery
The workload must be able to anticipate and recover from most failures, of all magnitudes, with minimal disruption to the user experience and business objectives.
Even highly resilient systems need
disaster preparedness approaches
, in both architecture design and workload operations. On the data layer, you should have strategies that can repair workload state in case of corruption.
Approach
Benefit
Have structured, tested, and documented recovery plans
that are aligned with the negotiated recovery targets. Plans must cover all components in addition to the system as a whole.
A well-defined process leads to a
quick recovery
that can prevent negative impact on the finances and reputation of your business. Conducting regular recovery drills tests the process of recovering system components, data, and failover and failback steps to
avoid confusion when time and data integrity are key
measures of success.
Ensure that you can
repair data
of all stateful components within your recovery targets.
Backups are essential to getting the
system back to a working state
by using a trusted recovery point, like the last-known good state.
Immutable and transactionally consistent backups ensure that data can't be altered, and that the restored data isn't corrupted.
Implement
automated self-healing capabilities
in the design.
This automation
reduces risks from external factors
, like human intervention, and shortens the break-fix cycle.
Replace stateless components with
immutable ephemeral units
.
Building ephemeral units that you can spin up and destroy on demand provides
repeatability and consistency
. Use side-by-side deployment models to make the transition to the new units incremental, minimizing disruptions.
Design for operations
Shift left in operations to anticipate failure conditions.
Test failures early and often
in the development lifecycle, and determine the impact of performance on reliability. For the sake of root cause analysis and postmortems, you need to have shared visibility, across teams, of dependency status and ongoing failures.
Insights, diagnostics, and alerts from observable systems are fundamental
to effective incident management and continuous improvement.
Approach
Benefit
Build observable systems
that can correlate telemetry.
Monitoring and diagnostics are crucial operations. If something fails, you need to know that it failed,
when it failed
, and
why it failed
. Observability at the component level is fundamental, but aggregated observability of components and correlated user flows provides a holistic view of health status. This data is required to enable site-reliability engineers to prioritize their efforts for remediation.
Predict potential malfunctions and anomalous behavior.
Make active reliability failures visible by using prioritized and actionable alerts.
Invest in reliable processes and infrastructure that leads to quicker triage.
Site reliability engineers can be notified immediately so that they can
mitigate ongoing live site incidents
and proactively mitigate potential failures identified by predictive alerts before they become live incidents.
Simulate failures
and run tests in production and pre-production environments.
It's beneficial to experience failures in production so you can set
realistic expectations for recovery
. This allows you to make design choices that gracefully respond to failures. Also, it enables you to test the thresholds you set for business metrics.
Build components with
automation in mind
, and automate as much as you can.
Automation
minimizes the potential for human error
, bringing
consistency
to testing, deployment, and operations.
Factor in
routine operations and their impact
on the stability of the system.
The workload might be subject to ongoing operations, like application revisions, security and compliance audits, component upgrades, and backup processes. Scrutinizing those changes ensures the
stability of the system
.
Continuously
learn from incidents in production
.
Based on the incidents, you can determine the impact and oversights in design and operations that might go unnoticed in preproduction. Ultimately, you'll be able to
drive improvements
based on real-life incidents.
Keep it simple
Avoid overengineering the architecture design, application code, and operations.
It's often what you remove rather than what you add that leads to the most reliable solutions.
Simplicity reduces the surface area for control
, minimizing inefficiencies and potential misconfigurations or unexpected interactions. On the other hand, oversimplification can introduce single points of failure. Maintain a balanced approach.
Approach
Benefit
Add components to your architecture only if they help you achieve target business values.
Keep the critical path lean
.
Designing for business requirements can lead to a straightforward solution that's
easy to implement and manage
. Avoid having too many critical components, because each one is a significant point of failure.
Establish standards
in code implementation, deployment, and processes, and document them. Identify opportunities to enforce those standards by using automated validations.
Standards provide
consistency and minimize human errors
. Approaches like standard naming conventions and code style guides can help you maintain quality and make assets easy to identify during troubleshooting.
Evaluate whether theoretical approaches translate to
pragmatic design
that applies to your use cases.
Application code that's too granular can lead to unnecessary interdependence, extra operations, and
difficult maintenance
.
Develop just enough code
.
You'll be able to prevent problems that are the result of
inefficient implementations
, like unexpected resource consumption, user or dataflow failures, and code bugs.
Conversely, reliability problems should lead to code reviews to ensure that code is resilient enough to handle the problems.
Take advantage of platform-provided features
and prebuilt assets that can help you effectively meet business targets.
This approach
minimizes development time
. It also enables you to
rely on tried and tested practices
that have been used with similar workloads.
Next steps
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing for redundancy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing for redundancy
Article
2023-11-15
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:05
Add redundancy at different levels, especially for critical flows
, to help meet your reliability targets. Consider redundant infrastructure components such as compute and network, and multiple instances of your solution.
Related guides:
Highly available multiregional design
|
Using availability zones and regions
This guide describes the recommendations for adding redundancy throughout critical flows at different workload layers, which optimizes resiliency. Meet the requirements of your defined reliability targets by applying the proper levels of redundancy to your compute, data, networking, and other infrastructure tiers. Apply this redundancy to give your workload a strong, reliable foundation to build on. When you build your workload without infrastructure redundancy, there's a high risk of extended downtime due to
potential failures
.
Definitions
Term
Definition
Redundancy
The implementation of multiple identical instances of a workload component.
Polyglot persistence
The concept of using different storage technologies by the same application or solution to take advantage of the best capabilities of each component.
Data consistency
The measure of how in sync or out of sync a given dataset is across multiple stores.
Partitioning
The process of physically dividing data into separate data stores.
Shard
A horizontal database partitioning strategy that supports multiple storage instances with a common schema. Data isn't replicated in all instances.
Key design strategies
In the context of reliability, use redundancy to contain problems that affect a single resource and ensure that those problems don't affect the reliability of the entire system. Use the information that you identified about your critical flows and reliability targets to make informed decisions that are required for each flow's redundancy.
For example, you might have multiple web server nodes running at once. The criticality of the flow that they support might require that all of them have replicas that are ready to accept traffic if there's a problem that affects the entire pool, for example a regional outage. Alternatively, because large-scale problems are rare and it's costly to deploy an entire set of replicas, you might deploy a limited number of replicas so the flow operates in a degraded state until you resolve the problem.
When you design for redundancy in the context of performance efficiency, distribute the load across multiple redundant nodes to ensure that each node performs optimally. In the context of reliability, build in spare capacity to absorb failures or malfunctions that affect one or more nodes. Ensure that the spare capacity can absorb failures for the entire time that's needed to recover the affected nodes. With this distinction in mind, both strategies need to work together. If you spread traffic across two nodes for performance and they both run at 60 percent utilization and one node fails, your remaining node is at risk of becoming overwhelmed because it can't operate at 120 percent. Spread the load out with another node to ensure that your performance and reliability targets are upheld.
Tradeoffs
:
More workload redundancy equates to more costs. Carefully consider adding redundancy and regularly review your architecture to ensure that you're managing costs, especially when you use overprovisioning. When you use overprovisioning as a resiliency strategy, balance it with a well-defined
scaling strategy
to minimize cost inefficiencies.
There can be performance tradeoffs when you build in a high degree of redundancy. For example, resources that spread across availability zones or regions can affect performance because you have to send traffic over high-latency connections between redundant resources, like web servers or database instances.
Different flows within the same workload might have different reliability requirements. Flow-specific redundancy designs can potentially introduce complexity into the overall design.
Redundant architecture design
Consider two approaches when you design a redundant architecture: active-active or active-passive. Choose your approach depending on the criticality of the user flow and system flow that the infrastructure components support. In terms of reliability, a multi-region active-active design helps you achieve the highest level of reliability possible, but it's significantly more expensive than an active-passive design. Deciding the appropriate geographic regions become the next critical choice. You can also use these design approaches for a single region by using availability zones. For more information, see
Recommendations for highly available multi-region design
.
Deployment stamps and units of scale
Whether you deploy in an active-active or active-passive model, follow the
Deployment Stamps design pattern
to ensure that you deploy your workload in a repeatable, scalable way. Deployment stamps are the groupings of resources that are required to deliver your workload to a given subset of your customers. For example, the subset might be a regional subset or a subset with all the same data privacy requirements as your workload. Think of each stamp as a
unit of scale
that you can duplicate to scale your workload horizontally or to perform blue-green deployments. Design your workload with deployment stamps to optimize your active-active or active-passive implementation for resiliency and management burden. Planning for multi-region scale out is also important to overcome potential temporary resource capacity constraints in a region.
Availability zones within Azure regions
Whether you deploy an active-active or an active-passive design, take advantage of
availability zones
within the active regions to fully optimize your resiliency. Many Azure regions provide multiple availability zones, which are separated groups of data centers within a region. Depending on the Azure service, you can take advantage of availability zones by deploying elements of your workload redundantly across zones or pinning elements to specific zones. For more information, see
Recommendations for using availability zones and regions
.
Implement zone redundancy for compute resources
Choose the appropriate
compute service
for your workload. Depending on the type of workload that you design, there might be several options available. Research the available services and understand which types of workloads work best on a given compute service. For example, SAP workloads are typically best suited for infrastructure as a service (IaaS) compute services. For a containerized application, determine the specific functionality you need to have control over to determine whether to use Azure Kubernetes Service (AKS) or a platform as a service (PaaS) solution. Your cloud platform fully manages a PaaS service.
Use PaaS compute options if your requirements allow it. Azure fully manages PaaS services, which reduces your management burden, and a documented degree of redundancy is built in.
Use Azure Virtual Machine Scale Sets if you need to deploy virtual machines (VMs). With Virtual Machine Scale Sets, you can automatically spread your compute evenly across availability zones.
Keep your compute layer
clean of any state
because individual nodes that serve requests might be deleted, faulted, or replaced at any time.
Use zone-redundant services where possible to provide higher resilience without increasing your operational burden.
Overprovision critical resources to mitigate failures of redundant instances, even before autoscaling operations begin, so the system continues to operate after a component failure. Calculate the acceptable effect of a fault when you incorporate overprovisioning into your redundancy design. As with your redundancy decision-making process, your reliability targets and financial tradeoff decisions determine the extent that you add spare capacity with overprovisioning. Overprovisioning specifically refers to
scaling out
, which means adding extra instances of a given compute resource type, rather than increasing the compute capabilities of any single instance. For example, if you change a VM from a lower-tier SKU to a higher-tier SKU.
Deploy IaaS services manually or via automation in each availability zone or region in which you intend to implement your solution. Some PaaS services have built-in capabilities that are automatically replicated across availability zones and regions.
Implement zone redundancy for data resources
Determine whether synchronous or asynchronous data replication is necessary for your workload's functionality. To help you make this determination, see
Recommendations for using availability zones and regions
.
Consider the growth rate of your data. For capacity planning, plan for data growth, data retention, and archiving to ensure your reliability requirements are met as the amount of data in your solution increases.
Distribute data geographically, as supported by your service, to minimize the effect of geographically localized failures.
Replicate data across geographical regions to provide resilience to regional outages and catastrophic failures.
Automate failover after a database instance failure. You can configure automated failover in multiple Azure PaaS data services. Automated failover isn't required for data stores that support multi-region writes, like Azure Cosmos DB. For more information, see
Recommendations for designing a disaster recovery strategy
.
Use the best
data store
for your data. Embrace polyglot persistence or solutions that use a mix of data store technologies. Data includes more than just persisted application data. It also includes application logs, events, messages, and caches.
Consider data consistency requirements and use
eventual consistency
when requirements allow it. When data is distributed, use appropriate coordination to enforce strong consistency guarantees. Coordination can reduce your throughput and make your systems tightly coupled, which can make them more brittle. For example, if an operation updates two databases, instead of putting it into a single transaction scope, it's better if the system can accommodate eventual consistency.
Partition data for availability.
Database partitioning
improves scalability and it can also improve availability. If one shard goes down, the other shards are still reachable. A failure in one shard only disrupts a subset of the total transactions.
If sharding isn't an option, you can use the
Command and Query Responsibility Segregation (CQRS) pattern
to separate your read-write and read-only data models. Add more redundant read-only database instances to provide more resilience.
Understand the built-in replication and redundancy capabilities of the stateful platform services that you use. For specific redundancy capabilities of stateful data services, see
Related links
.
Implement zone redundancy for networking resources
Decide on a reliable and scalable network topology. Use a hub-and-spoke model or an Azure Virtual WAN model to help you organize your cloud infrastructure in logical patterns that make your redundancy design easier to build and scale.
Select the appropriate
network service
to balance and redirect requests within or across regions. Use global or zone-redundant load balancing services when possible to meet your reliability targets.
Ensure that you have allocated sufficient IP address space in your virtual networks and subnets to account for planned usage, including scale-out requirements.
Ensure that the application can scale within the port limits of the chosen application hosting platform. If an application initiates several outbound TCP or UDP connections, it might exhaust all available ports and cause poor application performance.
Choose SKUs and configure networking services that can meet your bandwidth and availability requirements. A VPN gateway's throughput varies based on their SKU. Support for zone redundancy is only available for some load balancer SKUs.
Ensure that your design for handling DNS is built with a focus on resilience and supports redundant infrastructure.
Azure facilitation
The Azure platform helps you optimize the resiliency of your workload and add redundancy by:
Providing built-in redundancy with many PaaS and software as a service (SaaS) solutions, some of which are configurable.
Allowing you to design and implement intra-region redundancy by using
availability zones
and inter-region redundancy.
Offering replica-aware load balancing services like
Azure Application Gateway
,
Azure Front Door
, and
Azure Load Balancer
.
Offering easily implemented geo-replication solutions like
active geo replication
for Azure SQL Database. Implement
global distribution
and transparent replication by using Azure Cosmos DB. Azure Cosmos DB offers two options for
handling conflicting writes
. Choose the best option for your workload.
Offering point-in-time restore capabilities for many PaaS data services.
Mitigating port exhaustion via
Azure NAT Gateway
or
Azure Firewall
.
DNS-specific Azure facilitation
For internal name resolution scenarios, use Azure DNS private zones, which have built-in zone redundancy and geo redundancy. For more information, see
Azure DNS private zone resiliency
.
For external name resolution scenarios, use Azure DNS public zones, which have built-in zone redundancy and geo redundancy.
The public and private Azure DNS services are global services that are resilient to regional outages because zone data is globally available.
For hybrid name resolution scenarios between on-premises and cloud environments, use Azure DNS Private Resolver. This service supports zone redundancy if your workload is located in a region that supports availability zones. A zone-wide outage requires no action during zone recovery. The service automatically self-heals and rebalances to take advantage of the healthy zone. For more information, see
Resiliency in Azure DNS Private Resolver
.
To eliminate a single point of failure and achieve a more resilient hybrid name resolution across regions, deploy two or more Azure DNS private resolvers across different regions. DNS failover, in a conditional forwarding scenario, is achieved by assigning a resolver as your primary DNS server. Assign the other resolver in a different region as a secondary DNS server. For more information, see
Set up DNS failover by using private resolvers
.
Example
For an example of a multi-region redundant deployment, see
Baseline highly available zone-redundant web application
.
The following diagram shows another example:
Related links
To learn more about redundancy, see the following resources:
Azure regions guide
Azure Storage redundancy
Zone-redundant storage
Azure SQL Database active geo-replication
Configure replication between two managed instances
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for using availability zones and regions - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for using availability zones and regions
Article
2023-11-14
11 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:05
Add redundancy at different levels, especially for critical flows
, to help meet your reliability targets. Consider redundant infrastructure components such as compute and network, and multiple instances of your solution.
Related guides:
Highly available multiregional design
|
Redundancy
This guide describes the recommendations for determining when to deploy workloads across availability zones or regions.
When you design a solution for Azure, you need to decide whether you'll deploy across multiple availability zones in a region or deploy into multiple regions. This decision affects your solution's reliability, cost, and performance, and your team's ability to operate the solution. This guide provides information about the key business requirements that influence your decision, the approaches you can consider, the tradeoffs involved in each approach, and the effect of each approach on the core pillars of the Azure Well-Architected Framework.
The decision about the best Azure regions to use for your solution is a critical choice. The
Select Azure Regions guide
describes how to select and operate in multiple geographic regions. Your choice of how you use regions and availability zones within your solution also affects several of the pillars of the Well-Architected Framework:
Reliability
: Your choice of deployment approach can help you to mitigate various types of risks. In general, by spreading your workload across a more geographically distributed area, you can achieve higher resiliency.
Cost Optimization
: Some architectural approaches require deploying more resources than others, which can increase your resource costs. Other approaches involve sending data across geographically separated availability zones or regions, which might incur network traffic charges. It's also important to consider the ongoing cost of managing your resources, which is usually higher when you have comprehensive business requirements.
Performance Efficiency
: Availability zones are connected together through a high-bandwidth, low-latency network link, which is sufficient for most workloads to enable synchronous replication and communication across the zones. However, if your workload has been tested and is sensitive to network latency across zones, you might need to consider physically locating your workload's components close together to minimize latency when they communicate.
Operational Excellence
: A complex architecture takes more effort to deploy, configure, and manage. Additionally, for a highly available solution, you might need to plan how to fail over to a secondary set of resources. Failover, failback, and transparently redirecting your traffic can be complex, especially when manual steps are required. It's a good practice to automate your deployment and management processes. For more information, see the Operational Excellence pillar guides, including
OE:05 Infrastructure as code
,
OE:09 Task automation
,
OE:10 Automation design
, and
OE:11 Deployment practices
.
However you design your solution, the Security pillar applies. Usually, decisions about whether and how you use availability zones and regions doesn't change your security posture. Azure applies the same security rigor to every region and availability zone.
Tip
For many production workloads, a
zone-redundant deployment
provides the best balance of tradeoffs. You can extend this approach with
asynchronous data backup to another region
. If you aren't sure which approach to select, start with this type of deployment.
Consider other workload approaches when you need the specific benefits that those approaches provide, but be aware of the tradeoffs involved.
Definitions
Term
Definition
Active-active
An architecture in which multiple instances of a solution actively process requests at the same time.
Active-passive
An architecture in which one instance of a solution is designated as the
primary
and processes traffic, and one or more
secondary
instances are deployed to serve traffic if the primary is unavailable.
Asynchronous replication
A data replication approach in which data is written and committed to one location. At a later time, the changes are replicated to another location.
Availability zone
A separated group of datacenters within a region.
Each availability zone is independent of the others, with its own power, cooling, and networking infrastructure.
Many regions support availability zones.
Datacenter
A facility that contains servers, networking equipment, and other hardware to support Azure resources and workloads.
Locally redundant deployment
A deployment model in which a resource is deployed into a single region without reference to an availability zone. In a region that supports availability zones, the resource might be deployed in any of the region's availability zones.
Multi-region deployment
A deployment model in which resources are deployed into multiple Azure regions.
Paired regions
A relationship between two Azure regions.
Some Azure regions
are connected to another defined region to enable specific types of multi-region solutions.
Newer Azure regions aren't paired.
Region
A geographic perimeter that contains a set of datacenters.
Region architecture
The specific configuration of the Azure region, including the number of availability zones and whether the region is paired with another region.
Synchronous replication
A data replication approach in which data is written and committed to multiple locations. Each location must acknowledge completion of the write operation before the overall write operation is considered complete.
Zonal (pinned) deployment
A deployment model in which a resource is deployed into a specific availability zone.
Zone-redundant deployment
A deployment model in which a resource is deployed across multiple availability zones. Microsoft manages data synchronization, traffic distribution, and failover if a zone experiences an outage.
Key design strategies
Azure has a large global footprint. An Azure
region
is a geographic perimeter that contains a set of datacenters. You need to have a complete understanding of Azure regions and availability zones.
Azure regions have a variety of configurations, which are also called
region architectures
.
Many Azure regions provide
availability zones
, which are separated groups of datacenters. Within a region, availability zones are close enough to have low-latency connections to other availability zones, but they're far enough apart to reduce the likelihood that more than one will be affected by local outages or weather. Availability zones have independent power, cooling, and networking infrastructure. They're designed so that if one zone experiences an outage, then regional services, capacity, and high availability are supported by the remaining zones.
The following diagram shows several example Azure regions. Regions 1 and 2 support availability zones.
If you deploy into an
Azure region that contains availability zones
, you can use multiple availability zones together. By using multiple availability zones, you can keep separate copies of your application and data within separate physical datacenters in a large metropolitan area.
There are two ways to use availability zones in a solution:
Zonal
resources are pinned to a specific availability zone. You can combine multiple zonal deployments across different zones to meet high reliability requirements. You're responsible for managing data replication and distributing requests across zones. If an outage occurs in a single availability zone, you're responsible for failover to another availability zone.
Zone-redundant
resources are spread across multiple availability zones. Microsoft manages spreading requests across zones and the replication of data across zones. If an outage occurs in a single availability zone, Microsoft manages failover automatically.
Azure services support one or both of these approaches. Platform as a service (PaaS) services typically support zone-redundant deployments. Infrastructure as a service (IaaS) services typically support zonal deployments. For more information about how Azure services work with availability zones, see
Azure services with availability zone support
.
When Microsoft deploys updates to services, we try to use approaches that are the least disruptive to you. For example, we aim to deploy updates to a single availability zone at a time. This approach can reduce the impact that updates might have on an active workload, because the workload can continue to run in other zones while the update is in process.  However, it’s ultimately the workload team’s responsibility to ensure their workload continues to function during platform upgrades. For example, when you use
virtual machine scale sets with the flexible orchestration mode
, or most Azure PaaS services, Azure intelligently places your resources to reduce the impact of platform updates. Additionally, you might consider
overprovisioning
- deploying more instances of a resource - so that some instances remain available while other instances are upgraded. For more information about how Azure deploys updates, see
Advancing safe deployment practices
.
Many regions also have a
paired region
. Paired regions support certain types of multi-region deployment approaches. Some newer regions have
multiple availability zones and don't have a paired region
. You can still deploy multi-region solutions into these regions, but the approaches you use might be different.
For more information about how Azure uses regions and availability zones, see
What are Azure regions and availability zones?
Understand shared responsibilities
The
shared responsibility principle
describes how responsibilities are divided between the cloud provider (Microsoft) and you. Depending on the type of services you use, you might take on more or less responsibility for operating the service.
Microsoft provides availability zones and regions to give you flexibility in how you design your solution to meet your requirements. When you use managed services, Microsoft takes on more of the management responsibilities for your resources, which might even include data replication, failover, failback, and other tasks related to operating a distributed system.
Your own code needs to
recommended practices and design patterns for handling failures gracefully
. These practices are even more important during failover operations, such as those that happen when an availability zone or region failover occurs, because failover between zones or regions usually requires that your application retry connections to services.
Identify key business and workload requirements
To make an informed decision about how to use availability zones and regions in your solution, you need to understand your requirements. These requirements should be driven by discussions between solution designers and business stakeholders.
Risk tolerance
Different organizations have different degrees of risk tolerance. Even within an organization, risk tolerance is often different for each workload. Most workloads don't need extremely high availability. However, some workloads are so important that it's even worth mitigating risks that are unlikely to occur, like major natural disasters that affect a wide geographic area.
This table lists a few of the common risks that you should consider in a cloud environment:
Risk
Examples
Likelihood
Hardware outage
Problem with hard disk or networking equipment.
Host reboots.
High. Any resiliency strategy should account for these risks.
Datacenter outage
Power, cooling, or network failure across an entire datacenter.
Natural disaster in one part of a metropolitan area.
Medium
Region outage
Major natural disaster that affects a wide geographical area.
Network or service problem that makes one or more Azure services unavailable in an entire region.
Low
It would be ideal to mitigate every possible risk for every workload, but it's not practical or cost effective to do so. It's important to have an open discussion with business stakeholders so you can make informed decisions about the risks that you should mitigate.
Tip
Regardless of reliability targets, all workloads must have some mitigation for disaster recovery. If your workload demands high reliability targets, then your mitigation strategies should be comprehensive and you should reduce the risk of even low-likelihood events. For other workloads, make an informed decision on which risks you’re prepared to accept and which you need to mitigate.
Resiliency requirements
It's important to understand the resiliency requirements for your workload, including the recovery time objective (RTO) and recovery point objective (RPO). These objectives help you decide which approaches to rule out. If you don't have clear requirements, you can't make an informed decision about which approach to follow. For more information, see
Target functional and nonfunctional requirements
.
Service-level objectives
You should understand your solution's expected uptime service-level objective (SLO). For example, you might have a business requirement that your solution needs to meet 99.9% uptime.
Azure provides service level agreements (SLAs) for each service. An SLA indicates the level of uptime you should expect from the service and the conditions you need to meet to achieve that expected SLA. However, remember that the way that an Azure SLA indicates the service's availability doesn't always match the way you consider the health of your workload.
Your architectural decisions affect your solution's
composite SLO
. In general, the more redundancy you build into your solution, the higher your SLO is likely to be. Many Azure services provide higher SLAs when you deploy services in a zone-redundant or multi-region configuration. Review the SLAs for each of the Azure services you use to ensure that you understand how to maximize the resiliency and SLA of the service.
Data residency
Some organizations place restrictions on the physical locations into which their data can be stored and processed. Sometimes these requirements are based on legal or regulatory standards. In other situations, an organization might decide to adopt a data residency policy to avoid customer concerns. If you have strict data residency requirements, you might need to use a single-region deployment or use a subset of Azure regions and services.
Note
Avoid making unfounded assumptions about your data residency requirements. If you need to comply with specific regulatory standards, verify what those standards actually specify.
User location
By understanding where your users are located, you can make an informed decision about how to optimize latency and reliability for your needs. Azure provides many options to support a geographically dispersed user base.
If your users are concentrated in one area, a single-region deployment can simplify your operational requirements and reduce your costs. However, you need to consider whether a single-region deployment meets your reliability requirements. For mission-critical applications, you should still use a multi-region deployment even if your users are colocated.
If your users are geographically dispersed, it might make sense to deploy your workload across multiple regions. Azure services provide different capabilities to support a multi-region deployment, and you can use Azure's global footprint to improve your user experience and bring your applications into closer proximity to your user base. You might use the
Deployment Stamps pattern
or the
Geodes pattern
, or replicate your resources across multiple regions.
Even if your users are in different geographical areas, consider whether you need a multi-region deployment. Consider whether you can achieve your requirements within a single region by using global traffic acceleration, like the acceleration provided by
Azure Front Door
.
Budget
If you operate under a constrained budget, it's important to consider the costs involved in deploying redundant workload components. These costs can include additional resource charges, networking costs, and the operational costs of managing more resources and a more complex environment.
Complexity
It's a good practice to avoid unnecessary complexity in your solution architecture. The more complexity you introduce, the harder it becomes to make decisions about your architecture. Complex architectures are harder to operate, harder to secure, and often less performant.  Follow the
principle of simplicity
.
Azure facilitation
By providing regions and availability zones, Azure enables you to select a deployment approach that fits your needs. There are many approaches that you can choose from, each of which provides benefits and incurs costs.
To illustrate the deployment approaches that you can use, consider an example scenario. Suppose you're thinking about deploying a new solution that includes an application that writes data to some sort of storage:
This example isn't specific to any particular Azure services. It's intended to provide a simple example for illustrating fundamental concepts.
There are multiple ways to deploy this solution. Each approach provides a different set of benefits and incurs different costs. At a high level, you can consider a
locally redundant
,
zonal (pinned)
,
zone-redundant
, or
multi-region
deployment. This table summarizes some of the pillar concerns:
Pillar
Locally redundant
Zonal (pinned)
Zone-redundant
Multi-region
Reliability
Low reliability
Depends on approach
High or very high reliability
High or very high reliability
Cost Optimization
Low cost
Depends on approach
Moderate cost
High cost
Performance Efficiency
Acceptable performance (for most workloads)
High performance
Acceptable performance (for most workloads)
Depends on approach
Operational Excellence
Low operational requirements
High operational requirements
Low operational requirements
High operational requirements
This table summarizes some of the approaches you can use and how they affect your architecture:
Architectural concern
Locally redundant
Zonal (pinned)
Zone-redundant
Multi-region
Compliance with data residency
High
High
High
Depends on region
Regional availability
All regions
Regions with availability zones
Regions with availability zones
Depends on region
The rest of this article describes each of the approaches listed in the preceding table. The list of approaches isn't exhaustive. You might decide to combine multiple approaches or use different approaches in different parts of your solution.
Deployment approach 1: Locally redundant deployments
If you don't specify multiple availability zones or regions when you deploy your resources, Azure doesn't make any guarantees about whether the resources are deployed into a single datacenter or split across multiple datacenters in the region. In some situations, Azure might also move your resource between availability zones.
Most Azure resources are highly available by default, with high SLAs and built-in redundancy within a datacenter that's managed by the platform. However, from a reliability perspective, if any part of the region experiences an outage, there's a chance that your workload might be affected. If it is, your solution might be unavailable, or your data could be lost.
For highly latency-sensitive workloads, this approach might also result in lower performance. Your workload components might not be colocated in the same datacenter, so you might observe some latency for intra-region traffic. Azure might also transparently move your service instances between availability zones, which might slightly affect performance. However, this isn't a concern for most workloads.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
Low reliability.
Services are subject to outages if a datacenter fails. You can, however, build an application to be resilient to other types of failures.
Cost Optimization
Lowest cost.
You only need to have a single instance of each resource, and you don't incur any inter-region bandwidth costs.
Performance Efficiency
For most workloads:
Acceptable performance.
This approach is likely to provide satisfactory performance.
For highly latency-sensitive workloads:
Low performance.
Components aren't guaranteed to be located in the same availability zone, so you might see lower performance for highly latency-sensitive components.
Operational Excellence
High operational efficiency.
You only need to deploy and manage a single instance of each resource.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
High.
When you deploy a solution that uses this approach, data is stored in the Azure region that you select.
Regional availability
High.
This approach can be used in any Azure region.
Locally redundant deployments with backup across regions
You can extend a locally redundant deployment by performing regular backups of your infrastructure and data to a secondary region. This approach adds an extra layer of protection to mitigate against an outage in your primary region. Here's what it looks like:
When you implement this approach, you need to carefully consider your RTO and RPO:
Recovery time
: If a regional outage occurs, you might need to rebuild your solution in another Azure region, which affects your recovery time. Consider building your solution by using an infrastructure-as-code (IaC) approach so that you can quickly redeploy into another region if a major disaster occurs. Ensure that your deployment tools and processes are just as resilient as your applications so that you can use them to redeploy your solution even if there's an outage. Plan for and rehearse the steps that are required to restore your solution back to a working state.
Recovery point
: Your backup frequency determines the amount of data loss that you might experience (your recovery point). You can typically control the frequency of backups so that you can meet your RPO.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
Moderate reliability.
Services are subject to outages if a datacenter fails. Data is backed up asynchronously to a geographically separated region, which reduces the effect of a full region outage by minimizing data loss. In a full region outage, you can manually restore operations into another region. However, recovery processes can be complex, and it can take time to manually restore into the other region.
Cost Optimization
Low cost.
Typically, adding a backup to another region costs only slightly more than deploying a locally redundant resource.
Performance Efficiency
For most workloads:
Acceptable performance.
This approach is likely to provide satisfactory performance.
For highly latency-sensitive workloads:
Low performance.
Components aren't guaranteed to be located in the same availability zone, so you might see lower performance for highly latency-sensitive components.
Operational Excellence
During any outage within a region:
Low operational efficiency.
Failover is your responsibility and might require manual operations and redeployments.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
Depends on region selection.
Data is primarily stored in the Azure region that you specify. However, you need to select another region to store your backups, so it's important that you select a region that's compatible with your data residency requirements.
Regional availability
High.
You can use this approach in any Azure region.
Deployment approach 2: Zonal (pinned) deployments
In a
zonal
deployment, you specify that your resources should be deployed to a specific availability zone. This approach is sometimes called a
zone-pinned
deployment.
A zonal approach reduces the latency between your components. However, by itself, it doesn't increase the resiliency of your solution. To increase your resiliency, you need to deploy multiple instances of your components into multiple availability zones and decide how to route traffic between each instance. This example shows an
active-passive
traffic routing approach:
In the previous example, a load balancer is deployed across multiple availability zones. It's important to consider how you route traffic between instances in different availability zones, because a zone outage might also affect the networking resources deployed into that zone. You might also consider using a global load balancer, like
Azure Front Door
or
Azure Traffic Manager
, which isn't deployed into a region at all.
When you use a zonal deployment model, you take on many responsibilities:
You need to deploy resources to each availability zone, and configure and manage those resources individually.
You need to decide how and when to replicate data between the availability zones, and then configure and manage the replication.
You're responsible for distributing the requests to the correct resources, by using, for example, a load balancer. You need to ensure that the load balancer meets your resiliency requirements. You also need to decide whether to use an active-passive or an active-active request distribution model.
If an availability zone experiences an outage, you need to handle the failover to send traffic to resources in another availability zone.
An active-passive deployment across multiple availability zones is sometimes called
in-region DR
or
Metro DR
.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
When deployed in a single availability zone:
Low reliability.
A zonal deployment doesn't provide any resiliency to an outage in a datacenter or availability zone. You must deploy redundant resources across multiple availability zones to achieve high resiliency.
When deployed in multiple availability zones:
High reliability.
Services can be made resilient to a datacenter or availability zone outage.
Cost Optimization
When deployed in a single availability zone:
Low cost.
A single-zone deployment requires only a single instance of each resource.
When deployed in multiple availability zones:
High cost.
You deploy multiple instances of the resources, each of which are billed separately.
Performance Efficiency
High performance.
Latency can be very low when the components that serve a request are located in the same availability zone.
Operational Excellence
Low operational efficiency.
You need to configure and manage multiple instances of your service. You need to replicate data between availability zones. During an availability zone outage, failover is your responsibility.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
High.
When you deploy a solution that uses this approach, data is stored in the Azure region that you select.
Regional availability
Regions with availability zones.
This approach is available in any region that supports
availability zones
.
This approach is typically used for workloads that are based on virtual machines. For a complete list of services that support zonal deployments, see
Availability zone service and regional support
.
When you plan a zonal deployment, verify that the Azure services you use are supported in the availability zones you plan to use. For example, to list which virtual machine SKUs are available in each availability zone, see
Check VM SKU availability
.
Tip
When you deploy a resource into a specific availability zone, you select the zone number. The sequence of zone numbers is different for each Azure subscription. If you deploy resources across multiple Azure subscriptions, verify the zone numbers that you should use in each subscription. For more information, see
Physical and logical availability zones
.
Deployment approach 3: Zone-redundant deployments
When you use this approach, your application tier is spread across multiple availability zones. When requests arrive, a load balancer that's built into the service (which itself spans availability zones) disperses the requests across the instances in each availability zone. If an availability zone experiences an outage, the load balancer directs traffic to instances in the healthy availability zones.
Your storage tier is also spread across multiple availability zones. Copies of your application's data are distributed across multiple availability zones via
synchronous replication
. When the application makes a change to data, the storage service writes the change to multiple availability zones, and the transaction is considered complete only when all of these changes are complete. This process ensures that each availability zone always has an up-to-date copy of the data. If an availability zone experiences an outage, another availability zone can be used to access the same data.
A zone-redundant approach increases your solution's resiliency to issues like datacenter outages. Because data is replicated synchronously, however, your application has to wait for the data to be written across multiple separate locations that might be in different parts of a metropolitan area. For most applications, the latency involved in inter-zone communication is negligible. However, for some highly latency-sensitive workloads, synchronous replication across availability zones might affect the application's performance.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
High reliability.
Services are resilient to an outage of a datacenter or availability zone. Data is synchronously replicated across availability zones and with no delay.
Cost Optimization
Moderate cost.
Depending on the services you use, you might incur some costs for higher service tiers to enable zone redundancy.
Performance Efficiency
For most workloads:
Acceptable performance.
This approach is likely to provide satisfactory performance.
For highly latency-sensitive workloads:
Low performance.
Some components might be sensitive to latency due to inter-zone traffic or data replication time.
Operational Excellence
High operational efficiency.
You typically need to manage only a single logical instance of each resource. For most services, during an availability zone outage, failover is the responsibility of Microsoft and happens automatically.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
High.
When you deploy a solution that uses this approach, data is stored in the Azure region that you select.
Regional availability
Regions with availability zones.
This approach is available in any region that supports
availability zones
.
This approach is possible with many Azure services, including Azure Virtual Machine Scale Sets, Azure App Service, Azure Functions, Azure Kubernetes Service, Azure Storage, Azure SQL, Azure Service Bus, and many others. For a complete list of services that support zone redundancy, see
Availability zone service and regional support
.
Zone-redundant deployments with backup across regions
You can extend a zone-redundant deployment by performing regular backups of your infrastructure and data to a secondary region. This approach gives you the benefits of a zone-redundant approach and adds a layer of protection to mitigate the extremely unlikely event of a full region outage.
When you implement this approach, you need to carefully consider your RTO and RPO:
Recovery time
: If a regional outage does occur, you might need to rebuild your solution in another Azure region, which affects your recovery time. Consider building your solution by using an IaC approach so that you can quickly redeploy into another region during a major disaster. Ensure that your deployment tools and processes are just as resilient as your applications so that you can use them to redeploy your solution even if an outage occurs. Plan for and rehearse the steps required to restore your solution back to a working state.
Recovery point
: Your backup frequency determines the amount of data loss that you might experience (your recovery point). You can typically control the frequency of backups to meet your RPO.
Tip
This approach often provides a good balance for all architectural concerns. If you aren't sure which approach to use, start with this type of deployment.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
Very high reliability.
Services are resilient to an outage of a datacenter or availability zone. For most services, data is replicated across zones automatically and with no delay. Data is backed up asynchronously to a geographically separated region. This backup reduces the effect of a full region outage by minimizing data loss. After a full region outage, you can manually restore operations into another region. However, recovery processes can be complex, and it can take time to manually restore into the other region.
Cost Optimization
Moderate cost.
Typically, adding a backup to another region costs only slightly more than implementing zone redundancy.
Performance Efficiency
For most workloads:
Acceptable performance.
This approach is likely to provide satisfactory performance.
For highly latency-sensitive workloads:
Low performance.
Some components might be sensitive to latency due to inter-zone traffic or data replication time.
Operational Excellence
During an availability zone outage:
High operational efficiency.
Failover is the responsibility of Microsoft and happens automatically.
During a regional outage:
Low operational efficiency.
Failover is your responsibility and might require manual operations and redeployments.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
Depends on region selection.
Data is stored primarily in the Azure region that you specify, but you need to select another region to store your backups. Select a region that's compatible with your data residency requirements.
Regional availability
Regions with availability zones.
This approach is available in any region that supports
availability zones
.
Deployment approach 4: Multi-region deployments
You can use multiple Azure regions together to distribute your solution across a wide geographical area. You can use this multi-region approach to improve your solution's reliability or to support geographically distributed users. By deploying into multiple regions, you also reduce the risk that you'll encounter a temporary resource capacity constraint in a single region. If data residency is an important concern for your solution, carefully consider which regions you use to ensure that your data is stored only in locations that meet your requirements.
Active and passive regions
Multi-region architectures are complex, and there are many ways to design a multi-region solution. For some workloads, it makes sense to have multiple regions actively processing requests simultaneously (active-active deployments). For other workloads, it's better to designate one
primary region
and use one or more
secondary regions
for failover (active-passive deployments). This section focuses on the second scenario, in which one region is active and another is passive. For information about active-active multi-region solutions, see
Deployment Stamps pattern
and
Geode pattern
.
Data replication
Communicating across regions is much slower than communicating within a region. In general, a larger geographic distance between two regions incurs more network latency because of the longer physical distance that data needs to travel. See
Azure network round-trip latency statistics
for the expected network latency when you connect between two regions.
Cross-region network latency can significantly affect your solution design because you need to carefully consider how the extra latency affects data replication and other transactions. For many solutions, a cross-region architecture requires
asynchronous
replication to minimize the effect of cross-region traffic on performance.
Asynchronous data replication
When you implement asynchronous replication across regions, your application doesn't wait for all regions to acknowledge a change. After the change is committed in the primary region, the transaction is considered complete. The change is replicated to the secondary regions at a later time. This approach ensures that inter-region connection latency doesn't directly affect application performance. However, because of the delay in replication, a region-wide outage might result in some data loss. This data loss can occur because a region might experience an outage after a write is completed in the primary region but before the change could be replicated to another region.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
High reliability.
The solution is resilient to an outage of a datacenter, an availability zone, or an entire region. Data is replicated but might not be synchronous, so some data loss is possible in a failover scenario.
Cost Optimization
High cost.
You need to deploy separate resources in each region, and each resource incurs deployment and maintainenance costs. Data replication across regions might also incur significant costs.
Performance Efficiency
High performance.
Application requests don't require cross-region traffic, so traffic is typically low latency.
Operational Excellence
Low operational efficiency.
You need to deploy and manage resources across multiple regions. You're also responsible for failover between regions during a regional outage.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
Depends on region selection.
This approach requires you to select multiple regions for your workload to run in. Choose regions that are compatible with your data residency requirements.
Regional availability
Many Azure regions
are paired. Some Azure services use paired regions to replicate data automatically. If you run your workload in a
region that doesn't have a pair
, you might need to use a
different approach to replicate your data
.
Synchronous data replication
If you implement a synchronous multi-region solution, your application needs to wait for write operations to complete in each Azure region before the transaction is considered complete. The latency incurred by waiting for write operations depends on the distance between the regions. For many workloads, inter-region latency can make synchronous replication too slow to be useful.
This table summarizes some of the pillar concerns:
Pillar
Impact
Reliability
Very high reliability.
The solution is resilient to an outage of a datacenter, an availability zone, or an entire region. Data is always in sync across regions, so, even if a complete region loss occurs, your data is available and complete in another region.
Cost Optimization
High cost.
You need to deploy separate resources in each region, and each resource incurs deployment and maintainenance costs. Data replication across regions might also incur significant costs.
Performance Efficiency
Low performance.
Application requests require cross-region traffic. Depending on the distance between the regions, synchronous replication might add significant latency to requests.
Operational Excellence
Low operational efficiency.
You need to deploy and manage resources across multiple regions. You're also responsible for failover between regions during a regional outage.
This table summarizes some of the concerns from an architectural perspective:
Architectural concern
Impact
Compliance with data residency
Depends on region selection.
This approach requires you to select multiple regions for your workload to run in. Select regions that are compatible with your data residency requirements.
Regional availability
Many Azure regions
are paired. Some Azure services use paired regions to replicate data automatically. If you run your workload in a
region that doesn't have a pair
, you might need to use a
different approach to replicate your data
.
Region architectures
When you design a multi-region solution, consider whether the Azure regions you plan to use are paired.
You can create a multi-region solution even when the regions aren't paired. However, the approaches that you use to implement a multi-region architecture might be different. For example, in Azure Storage, you can use geo-redundant storage (GRS) with paired regions. If GRS isn't available, consider using features like Azure Storage
object replication
, or design your application to write to multiple regions.
Combine multi-zone and multi-region approaches
You should combine multi-zone and multi-region statements if your business requirements demand such a solution. For example, you might deploy zone-redundant components into each region and also configure replication between the regions. For some solutions, this approach provides a very high degree of reliability. However, configuring this type of approach can be complicated, and this approach can be expensive.
Important
Mission-critical workloads should use both multiple availability zones
and
multiple regions. For more information about the considerations that you should give when designing mission-critical workloads, see
Mission-critical workload documentation
.
How Azure services support deployment approaches
It's important to understand the specific details of the Azure services that you use. For example, some Azure services require that you configure their availability zone configuration when you first deploy the resource, while others support changing the deployment approach later. Similarly, some service features might not be available with every deployment approach.
To learn more about the specific deployment options and approaches to consider for each Azure service, visit the
Reliability hub
.
Examples
This section describes some common use cases and the key requirements that you typically need to consider for each workload. For each workload, one or more suggested deployment approaches are provided, based on the requirements and approaches described in this article.
Line-of-business application for an enterprise
Contoso, Ltd., is a large manufacturing company. The company is implementing a line-of-business application to manage some components of its financial processes.
Business requirements
: The information that the system manages is difficult to replace, so data needs to be persisted reliably. The architects say that the system needs to incur as little downtime and as little data loss as possible. Contoso's employees use the system throughout the workday, so high performance is important to avoid keeping team members waiting. Cost is also a concern, because the finance team has to pay for the solution.
Suggested approach
:
Zone-redundant deployment with backup across regions
provides multiple layers of resiliency with high performance.
Internal application
Fourth Coffee is a small business. The company is developing a new internal application that employees can use to submit timesheets.
Business requirements
: For this workload, cost efficiency is a primary concern. Fourth Coffee evaluated the business impact of downtime and decided that the application doesn't need to prioritize resiliency or performance. The company accepts the risk that an outage in an Azure availability zone or region might make the application temporarily unavailable.
Suggested approaches
:
Locally redundant deployment with backups across regions
has the lowest cost, but also has significant risks.
Zone-redundant deployment with backup across regions
provides better resiliency, but at a slightly higher cost.
Legacy application migration
Fabrikam, Inc., is migrating a legacy application from an on-premises datacenter to Azure. The implementation will use an IaaS approach that's based on virtual machines. The application wasn't designed for a cloud environment, and communication between the application tier and the database is very
chatty
.
Business requirements
: Performance is a priority for this application. Resiliency is also important, and the application must continue to work even if an Azure datacenter experiences an outage.
Suggested approach
:
Fabrikam should first try a
zone-redundant deployment
. They should verify the performance meets their requirements.
If the performance of the zone-redundant solution isn't acceptable, consider a
zonal (pinned) deployment, with passive deployments across multiple availability zones (in-region DR)
.
Healthcare application
Lamna Healthcare Company is implementing a new electronic health record system on Azure.
Business requirements
: Because of the nature of the data that this solution stores, data residency is critically important. Lamna operates under a strict regulatory framework that mandates that data must remain in a specific location.
Suggested approaches
:
Multi-zone multi-region deployment
, if there are multiple regions that fit Lamna's data residency requirements.
If there's only a single region that suits their needs, consider a
zone-redundant deployment
or a
zone-redundant deployment with backup across regions
provides a single-region solution
Banking system
Woodgrove Bank runs its core banking operations from a large solution that's deployed to Azure.
Business requirements
: This is a mission-critical system. Any outages can cause major financial impact for customers. As a result, Woodgrove Bank has very low risk tolerance. The system needs the highest level of reliability possible, and the architecture needs to mitigate the risk of any failures that can be mitigated.
Suggested approach
: For a mission-critical system, use a
multi-zone multi-region deployment
. Ensure that the regions fit the company's data residency requirements.
Software as a service (SaaS)
Proseware, Inc., builds software that's used by companies across the world. The company's user base is widely distributed geographically.
Business requirements
: Proseware needs to enable each of its customers to choose a deployment region that's close to the customer. Enabling this choice is important for latency and for the customers' data residency requirements.
Suggested approaches
:
A
multi-zone multi-region deployment
is typically a good choice for a SaaS provider, especially when it's used within the
Deployment Stamps pattern
.
A single-region
zone-redundant deployment
in conjunction with a global traffic acceleration solution, like
Azure Front Door
.
Related links
Following are some reference architectures and example scenarios for multi-zone and multi-region solutions:
Baseline highly available zone-redundant web application
Highly available multi-region web application
Multi-region N-tier application
Multi-tier web application built for HA/DR
Many Azure services provide guidance about how to use multiple availability zones, including the following examples:
Azure Site Recovery: Enable Azure VM disaster recovery between availability zones
Azure NetApp Files: Understand cross-zone replication of Azure NetApp Files
Azure Storage redundancy
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing a reliable scaling strategy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing a reliable scaling strategy
Article
2023-11-15
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:06
Implement a timely and reliable scaling strategy at the application, data, and infrastructure levels. Base the scaling strategy on actual or predicted usage patterns and minimize manual intervention.
Related guide:
Data partitioning
This guide describes the recommendations for designing a reliable scaling strategy.
Definitions
Term
Definition
Vertical scaling
A scaling approach that adds compute capacity to existing resources.
Horizontal scaling
A scaling approach that adds instances of a given type of resource.
Autoscaling
A scaling approach that automatically adds or removes resources when a set of conditions is met.
Note
Scaling operations can be static (regularly scheduled daily scaling to accommodate normal load patterns), automatic (an automated process in response to conditions being met), or manual (an operator performs a one-time scaling operation in reaction to an unanticipated load change). Both vertical and horizontal scaling can be performed via any of these methods. However, automatic vertical scaling requires additional custom automation development and can cause downtime depending on the resources being scaled.
Key design strategies
Design according to load patterns
To design a reliable scaling strategy for your workloads, focus on identifying load patterns for the user and system flows for each workload that leads to a scaling operation. Here are examples of the different load patterns:
Static
: Every night by 11 PM EST, the number of active users is below 100 and the CPU utilization for the app servers drops by 90% across all nodes.
Dynamic, regular, and predictable
: Every Monday morning, 1000 employees across multiple regions sign in to the ERP system.
Dynamic, irregular, and predictable
: A product launch happens on the first day of the month and there's historical data from previous launches on how the traffic increases in these situations.
Dynamic, irregular, and unpredictable
: A large scale event causes a spike in demand for a product. For example, companies manufacturing and selling dehumidifiers can experience a sudden surge in traffic after a hurricane or other flooding event when people in affected areas need to dry rooms in their home.
After you've identified these types of load patterns, you can:
Identify how the load change associated with each pattern affects your infrastructure.
Build automation to address the scaling reliably.
For the previous examples, your scaling strategies could be:
Static
: You have a scheduled scale of your compute nodes to the minimum count (2) between 11 PM and 6 AM EST.
Dynamic, regular, and predictable
: You have a scheduled scale out of your compute nodes to the normal daily capacity before the first region starts work.
Dynamic, irregular, and predictable
: You define a one-time scheduled scale up of your compute and database instances on the morning of a product launch, and you scale back down after one week.
Dynamic, irregular, and unpredictable
: You have autoscale thresholds defined to account for unplanned traffic spikes.
Automate scaling strategies
When designing your scaling automation, be sure to account for these issues:
That all components of your workload should be candidates for scaling implementation
. In most cases, global services like
Microsoft Entra ID
scale automatically and transparently to you and your customers. Be sure to understand the scaling capabilities of your networking ingress and egress controllers and your load balancing solution.
Those components that can't be scaled out
. An example would be large, relational databases that don't have sharding enabled and can't be refactored without significant impact. Document the resource limits published by your cloud provider and monitor those resources closely. Include those specific resources in your future planning for migrating to scalable services.
The time it takes to perform the scaling operation so that you properly schedule the operation to happen before the extra load hits your infrastructure
. For example, if a component like API Management takes 45 minutes to scale, adjusting the scaling threshold to 65% instead of 90% might help you scale earlier and prepare for the anticipated increase in load.
The relationship of the flow’s components in terms of order of scale operations
. Ensure that you don’t inadvertently overload a downstream component by scaling an upstream component first.
Any stateful application elements that might be interrupted by a scaling operation and any session affinity (or session stickiness) that's implemented
. Stickiness can limit your scaling ability and introduces single points of failure.
Potential bottlenecks
. Scaling out doesn't fix every performance issue. For example, if your backend database is the bottleneck, it doesn't help to add more web servers. Identify and resolve the bottlenecks in the system first before just adding more instances. Stateful parts of the system are the most likely cause of bottlenecks.
Following the
deployment stamp
design pattern helps with your overall infrastructure management. Basing your scaling design on stamps as units of scale is also beneficial. And it helps you tightly control your scaling operations across multiple workloads and subsets of workloads. Rather than managing the scaling schedules and autoscaling thresholds of many distinct resources, you can apply a limited set of scaling definitions to a deployment stamp and then mirror that across stamps as needed.
Tradeoff
: Scaling up has cost implications, so optimize your strategy to scale down as soon as possible to help keep costs under control. Ensure that the automation you're employing to scale up also has triggers to scale down.
Azure facilitation
An autoscaling feature is available in
many Azure services
. It lets you easily configure conditions to automatically scale instances horizontally. Some services have limited or no built-in functionality to automatically scale in, so be sure to document these cases and define processes to deal with scaling in.
Many Azure services offer APIs that you can use to design custom automatic scaling operations using
Azure Automation
, such as the code samples at
Autoscale your Azure IoT Hub
. You can use tools like KEDA for event-driven autoscaling, which is available in
Azure Kubernetes Service
and
Azure Container Apps
.
Azure Monitor autoscale
provides a common set of autoscaling functionality for Azure Virtual Machine Scale Sets, Azure App Service, Azure Spring Apps and more. Scaling can be performed on a schedule or based on a runtime metric, such as CPU or memory usage. See the
Azure Monitor guide
for best practices.
Tradeoffs
Autoscaling considerations
Autoscaling isn't an instant solution. Simply adding resources to a system or running more instances of a process doesn't guarantee that the performance of the system will improve. Consider the following points when designing an autoscaling strategy:
The system must be designed to be horizontally scalable. Avoid making assumptions about instance affinity. Don't design solutions that require that the code is always running in a specific instance of a process. When scaling a cloud service or website horizontally, don't assume that a series of requests from the same source are always routed to the same instance. For the same reason, design services to be stateless to avoid requiring a series of requests from an application to always be routed to the same instance of a service. When designing a service that reads messages from a queue and processes them, don't make any assumptions about which instance of the service handles a specific message. Autoscaling could start more instances of a service as the queue length grows. The
Competing Consumers pattern
describes how to handle this scenario.
If the solution implements a long-running task, design this task to support both scaling out and scaling in. Without due care, such a task could prevent an instance of a process from being shut down cleanly when the system scales in. Or, it could lose data if the process forcibly terminates. Ideally, refactor a long-running task and break up the processing that it performs into smaller, discrete chunks. The
Pipes and Filters pattern
provides an example of how you can achieve this solution.
Alternatively, you can implement a checkpoint mechanism that records state information about the task at regular intervals. You can then save this state in durable storage that can be accessed by any instance of the process running the task. In this way, if the process is shut down, the work that it was performing can be resumed from the last checkpoint by another instance. There are libraries that provide this functionality, such as NServiceBus and MassTransit. They transparently persist state, where the intervals are aligned with the processing of messages from queues in
Azure Service Bus
.
When background tasks run on separate compute instances, such as in worker roles of a cloud-services–hosted application, you might need to scale different parts of the application by using different scaling policies. For example, you might need to deploy extra user interface (UI) compute instances without increasing the number of background compute instances, or vice-versa. If you offer different levels of service, such as basic and premium service packages, you might need to scale out the compute resources for premium service packages more aggressively than for basic service packages to meet service-level agreements (SLAs).
Consider the length of the queue over which UI and background compute instances communicate. Use it as a criterion for your autoscaling strategy. This issue is one possible indicator of an imbalance or difference between the current load and the processing capacity of the background task. A slightly more complex but better attribute on which to base scaling decisions is to use the time between when a message was sent and when its processing was complete. This interval is known as the critical time. If this critical time value is below a meaningful business threshold, then it's unnecessary to scale, even if the queue length is long.
For example, there could be 50,000 messages in a queue. But the critical time of the oldest message is 500 ms, and the endpoint is dealing with integration with a third-party web service for sending out emails. Business stakeholders would likely consider that to be a period of time that wouldn't justify spending extra money for scaling.
On the other hand, there could be 500 messages in a queue, with the same 500-ms critical time, but the endpoint is part of the critical path in some real-time online game where business stakeholders defined a response time of 100 ms or less. In that case, scaling out would make sense.
To use critical time in autoscaling decisions, it's helpful to have a library automatically add the relevant information to the headers of messages while they're sent and processed. One library that provides this functionality is
NServiceBus
.
If you base your autoscaling strategy on counters that measure business processes, such as the number of orders placed per hour or the average running time of a complex transaction, ensure that you fully understand the relationship between the results from these types of counters and the actual compute capacity requirements. It might be necessary to scale more than one component or compute unit in response to changes in business process counters.
To prevent a system from attempting to scale out excessively, and to avoid the costs associated with running many thousands of instances, consider limiting the maximum number of instances that are automatically added. Most autoscaling mechanisms let you specify the minimum and maximum number of instances for a rule. In addition, consider gracefully degrading the functionality that the system provides if the maximum number of instances have been deployed and the system is still overloaded.
Keep in mind that autoscaling might not be the most appropriate mechanism to handle a sudden burst in a workload. It takes time to provision and start new instances of a service or add resources to a system, and the peak demand might pass by the time these extra resources are available. In this scenario, it might be better to throttle the service. For more information, see the
Throttling pattern
.
Conversely, if you need the capacity to process all requests when the volume fluctuates rapidly, and cost isn't a major contributing factor, consider using an aggressive autoscaling strategy that starts more instances more quickly. You can also use a scheduled policy that starts a sufficient number of instances to meet the maximum load before that load is expected.
The autoscaling mechanism should monitor the autoscaling process and log the details of each autoscaling event (what triggered it, what resources were added or removed, and when). If you create a custom autoscaling mechanism, ensure that it incorporates this capability. Analyze the information to help measure the effectiveness of the autoscaling strategy, and tune it if necessary. You can tune both in the short term, as the usage patterns become more obvious, and over the long term, as the business expands or the requirements of the application evolve. If an application reaches the upper limit defined for autoscaling, the mechanism might also alert an operator who could manually start more resources if necessary. Under these circumstances, the operator might also be responsible for manually removing these resources after the workload eases.
Example
Refer to the AKS baseline reference architecture
scaling guidance
.
Related links
Performance efficiency scaling
Best practices for autoscale
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for self-healing and self-preservation - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for self-healing and self-preservation
Article
2025-02-28
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:07
Strengthen the resiliency of your workload by implementing self-preservation and self-healing measures. Use built-in features and well-established cloud patterns to help your workload remain functional during and recover from incidents.
This guide describes the recommendations for building self-preservation and self-healing capabilities into your application architecture to optimize reliability.
Self-preservation capabilities add resilience to your workload. They reduce the likelihood of a full outage and allow your workload to operate normally, or in a degraded state, when failures occur. Self-healing capabilities help you avoid downtime by building in failure detection and automatic corrective actions to respond to failures.
Definitions
Term
Definition
Self-healing
The ability of your workload to automatically resolve issues by recovering affected components and if needed, failing over to redundant infrastructure.
Self-preservation
The ability of your workload to be resilient against potential problems.
Key design strategies
Design for redundancy
One of the most effective strategies to protect your workload from malfunctions is to build redundancy into all of its components and avoid single points of failure. Being able to fail components or the entire workload over to redundant resources provides an efficient way to handle most faults in your system.
Build redundancy at different levels, consider redundant infrastructure components such as compute, network, and storage; and consider deploying multiple instances of your solution. Depending on your business requirements, you can build redundancy within a single region or across regions. You can also decide whether you need an active-active or an active-passive design to meet your recovery requirements. See the
redundancy
,
regions and availability zones
, and
highly available multi-region design
Reliability articles for in-depth guidance on this strategy.
Design for self-preservation
To design your workload for self-preservation, follow infrastructure and application architecture design patterns to optimize your workload's resiliency. To minimize the chance of experiencing a full application outage, increase the resiliency of your solution by eliminating single points of failure and minimizing the blast radius of failures. The design approaches in this article provide several options to strengthen the resilience of your workload and meet your workload's defined
reliability targets
.
Infrastructure design guidance and patterns
At the infrastructure level, a
redundant architecture design
should support your critical flows, with resources deployed across
availability zones
or
regions
. Implement
autoscaling
when possible. Autoscaling helps protect your workload against unanticipated bursts in activity, further reinforcing your infrastructure.
Use the Deployment Stamps pattern or the Bulkhead pattern to minimize the blast radius when problems arise. These patterns help to keep your workload available if an individual component is unavailable. Use the following application design patterns in combination with your autoscaling strategy.
Deployment Stamps pattern
: Provision, manage, and monitor a varied group of resources to host and operate multiple workloads or tenants. Each individual copy is called a
stamp
, or sometimes a
service unit
,
scale unit
, or
cell
.
Bulkhead pattern
: Partition service instances into different groups, known as
pools
, based on the consumer load and availability requirements. This design helps to isolate failures and allows you to sustain service functionality for some consumers, even during a failure.
Application design guidance and patterns
Avoid building monolithic applications in your application design. Use loosely coupled services or microservices that communicate with each other via well-defined standards to reduce the risk of extensive problems when malfunctions happen to a single component. For example, you may standardize the use of a service bus to handle all asynchronous communication. Standardizing communication protocols ensures that applications design is consistent and simplified, which makes the workload more reliable and easier to troubleshoot when malfunctions happen. When practical, prefer asynchronous communication between components over synchronous communication to minimize timeout issues, like dead-lettering.
Use industry-proven patterns to help you develop your design standards and simplify aspects of the architecture. Design patterns that can help support reliability can be found in the
Reliability patterns
article.
Design for self-healing
To design your workload for self-healing, implement failure detection so automatic responses are triggered and critical flows gracefully recover. Enable logging to provide operational insights about the nature of the failure and the success of the recovery. The approaches that you take to achieve self-healing for a critical flow depend on the
reliability targets
that are defined for that flow and the flow's components and dependencies.
Infrastructure design guidance
At the infrastructure level, your critical flows should be supported by a redundant architecture design, with automated failover enabled for components that support it. You can enable automated failover for the following types of services:
Compute resources
: Azure Virtual Machine Scale Sets and most platform as a service (PaaS) compute services can be configured for automatic failover.
Databases
: Relational databases can be configured for automatic failover with solutions like Azure SQL failover clusters, Always On availability groups, or built-in capabilities with PaaS services. NoSQL databases have similar clustering capabilities and built-in capabilities for PaaS services.
Storage
: Use
redundant storage options
with automatic failover.
Application design guidance
In addition to using
design patterns
that support reliability, other strategies that can help you develop self-healing mechanisms include:
Use checkpoints for long-running transactions
: Checkpoints can provide resiliency if a long-running operation fails. When the operation restarts, for example if it's picked up by another virtual machine, it can resume from the last checkpoint. Consider implementing a mechanism that records state information about the task at regular intervals. Save this state in durable storage that can be accessed by any instance of the process running the task. If the process is shut down, the work that it was performing can be resumed from the last checkpoint by using another instance. There are libraries that provide this functionality, such as
NServiceBus
and
MassTransit
. They transparently persist state, where the intervals are aligned with the processing of messages from queues in Azure Service Bus.
Implement automated self-healing actions:
Use automated actions that are triggered by your monitoring solution when pre-determined health status changes are detected. For example, if your monitoring detects that a web app isn't responding to requests, you can build automation through a PowerShell script to restart the app service. Depending on your team's skill set and preferred development technologies, use a webhook or function to build more complex automation actions. See the
Event-based cloud automation
reference architecture for an example of using a function to respond to database throttling. Using automated actions can help you recover quickly and minimize the necessity of human intervention.
Implement a graceful degradation mode
Despite your self-preservation and self-healing mechanisms, you may still encounter situations where one or more components malfunction to the extent that they become unavailable for some amount of time. In these cases, ideally, your workload can maintain enough functionality for business to continue in a degraded state. To ensure that this is possible, design and implement a graceful degradation mode. This is a distinct workflow that is enabled in reaction to failed components. Considerations for the design and implementation include:
Failure detection and automated initiation:
Your monitoring and alerting systems should detect degraded and failed components, so use those signals to build a workflow that determines when switching to your graceful degradation mode is necessary. The workflow should then automatically reroute calls to and from affected components to alternative components, or other similar actions.
Implement a degraded user experience:
Include a notification mechanism for users in your graceful degradation mode to ensure that they know what functionality remains and what has changed. This typically is reflected in messages tied to different functions of the workload, like a pop-up when adding items to a cart, for example.
Build alternatives paths to complete your workload's essential functions:
Reflect on your workload's
critical flows
and determine how you can maintain those flows when core components are unavailable. For example, if a database is down, the application might switch to a read-only mode using cached data. To further illustrate this example, if a payment gateway is down, using cached data might allow users to save their cart and complete the purchase later.
Implement mechanisms for handling transient faults
Transient faults
, like network timeouts, are a common issue for cloud workloads, so having mechanisms in place to handle them can minimize downtime and troubleshooting efforts as you operate your workload in production. Since most operations that fail due to a transient fault will succeed if sufficient time is allowed before retrying the operation, using a retry mechanism is the most common approach for dealing with transient faults. When designing your retry strategy, consider the following:
Refer to the
Transient faults
design guide for a full review of recommendations and considerations.
Implement background jobs
Background jobs are an effective way to enhance the reliability of a system by decoupling tasks from the user interface (UI). Implement a task as a background job if it doesn't require user input or feedback and if it doesn't affect UI responsiveness.
Common examples of background jobs are:
CPU-intensive jobs, such as performing complex calculations or analyzing structural models.
I/O-intensive jobs, such as running multiple storage operations or indexing large files.
Batch jobs, such as updating data regularly or processing tasks at a specific time.
Long-running workflows, such as completing an order or provisioning services and systems.
Refer to the
background jobs
design guide for detailed guidance for a full review of recommendations and considerations.
Azure facilitation
Most Azure services and client SDKs include a retry mechanism. But they differ because each service has different characteristics and requirements, so each retry mechanism is tuned to a specific service. For more information, see
Recommendations for transient fault handling
.
Use
Azure Monitor action groups
for notifications, like email, voice or SMS, and to trigger automated actions. When you're notified of a failure, trigger an Azure Automation runbook, Azure Event Hubs, an Azure function, a logic app, or a webhook to perform an automated healing action.
Example
For example use cases of some patterns, see the
reliable web app pattern for .NET
. Follow
these steps to deploy a reference implementation
.
Related links
Reliability patterns
Handle transient faults
Develop background jobs
Cloud design patterns
Design for self-healing
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing for simplicity and efficiency - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing for simplicity and efficiency
Article
2023-12-01
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:01
Focus your workload design on simplicity and efficiency.
Use a practical approach to avoid unnecessary complexity while meeting your business goals and requirements.
This guide describes the recommendations for minimizing unnecessary complexity and overhead to keep your workloads simple and efficient. Choose the best components to perform the necessary workload tasks to optimize the reliability of your workload. To lessen your development and management burdens, take advantage of efficiencies that platform-provided services offer. This design helps you create a workload architecture that's resilient, repeatable, scalable, and manageable.
Definitions
Term
Definition
Workload
A discrete capability or computing task that you can logically separate from other tasks.
Key design strategies
A key tenet of designing for reliability is to keep things simple and efficient. Focus your workload design on meeting business requirements to reduce the risk of unnecessary complexity or excess overhead. Consider the recommendations in this article to help you make decisions about your design to create a lean, efficient, and reliable workload. Different workloads might have different requirements for availability, scalability, data consistency, and disaster recovery.
You must justify every design decision with a business requirement. This design principle might seem obvious, but it's crucial for workload design. Does your application support millions of users, or a few thousand? Are there large traffic bursts, or a steady workload? What level of application outage is acceptable? Business requirements drive these design considerations.
Tradeoff
: A complex solution can offer more features and flexibility, but it might affect the reliability of the workload because it requires more coordination, communication, and management of components. Alternatively, a simpler solution might not fully meet user expectations, or it might have a negative effect on scalability and extensibility as the workload evolves.
Collaborate with stakeholders on design exercises
Work with stakeholders to:
Define and assign a criticality level to your workload's user flows and system flows
. Focus your design on
critical flows
to help you determine the required components and the best approach to achieve the required resiliency level.
Define functional and nonfunctional requirements
. Consider functional requirements to determine whether an application performs a task. Consider nonfunctional requirements to determine how well the application performs a task. Ensure that you understand nonfunctional requirements like scalability, availability, and latency. These requirements influence design decisions and technology choices.
Decompose workloads into components
. Prioritize simplicity, efficiency, and reliability in your design. Determine the components that you need to support your flows. Some components support multiple flows. Identify which challenge a component conceptually addresses, and consider removing a component from individual flows to simplify the overall design while still providing full functionality. For more information, see
Recommendations for performing failure mode analysis
.
Use failure mode analysis
to identify single points of failure and potential risks. Consider whether you need to account for unlikely situations, for example a geographic area that experiences a major natural disaster that affects all the availability zones in the region. It's expensive and involves significant tradeoffs to mitigate these uncommon risks. Clearly understand your business's tolerance for risk. For more information, see
Recommendations for performing failure mode analysis
.
Define availability and recovery targets
for your flows to inform your workload's architecture. Business metrics include service-level objectives (SLOs), service-level agreements (SLAs), mean time to recover (MTTR), mean time between failure (MTBF), recovery time objectives (RTOs), and recovery point objectives (RPOs). Define target values for these metrics. This exercise might require compromise and mutual understanding between technology and business teams to ensure that each team's goals meet business objectives and are realistic. For more information, see
Recommendations for defining reliability targets
.
Favor simpler design choices
You can perform the following recommendations without stakeholder engagement:
Strive for simplicity and clarity
in your design. Use the appropriate level of abstraction and granularity for your components and services. Avoid overengineering or under-engineering your solution. For example, if you break down your code into multiple small functions, it's hard to understand, test, and maintain.
Concede that all successful applications change over time
, whether to fix bugs, implement new features or technologies, or make existing systems more scalable and resilient.
Use platform as a service (PaaS) options
instead of infrastructure as a service (IaaS) when possible. IaaS is like having a box of parts. You can build anything, but you have to assemble it yourself. PaaS options are easier to configure and administer. You don't need to set up virtual machines (VMs) or virtual networks. You also don't have to perform maintenance tasks, such as installing patches and updates.
Use asynchronous messaging
to decouple the message producer from the consumer.
Abstract infrastructure away from domain logic
. Ensure that domain logic doesn't interfere with infrastructure-related functionality, such as messaging or persistence.
Offload cross-cutting concerns to a separate service
. Minimize the need to duplicate code across different functions, prefer reusing services with well-defined interfaces that can be easily consumed by different components. For example, if several services need to authenticate requests, you can move this functionality into its own service. Then you can evolve the authentication service. For example, you can add a new authentication flow without touching any of the services that use it.
Evaluate the suitability of common patterns and practices
for your needs. Avoid following trends or recommendations that might not be best for your context or requirements. For example, microservices aren't the best option for every application because they can introduce complexity, overhead, and dependency issues.
Develop just enough code
The principles of simplicity, efficiency, and reliability also apply to your development practices. In a loosely coupled, componentized workload, determine the functionality that a component provides. Develop your flows to take advantage of that functionality. Consider these recommendations for your development practices:
Use platform capabilities when they meet your business requirements. For example, to offload development and management, use low-code, no-code, or serverless solutions that your cloud provider offers.
Use libraries and frameworks.
Introduce pair programming or dedicated code review sessions as a development practice.
Implement an approach to identify
dead code
. Be skeptical of the code that your automated tests don't cover.
Select the right data store
In the past, many organizations stored all their data in large relational SQL databases. Relational databases provide atomic, consistent, isolated, and durable (ACID) guarantees for relational data transactions. But these databases come with disadvantages:
Queries can require expensive joins.
You need to normalize the data and restructure it for schema on write.
Lock contention can affect performance.
Alternatives to relational databases
In a large solution, a single data store technology likely doesn't meet all your needs. Alternatives to relational databases include:
Key-value stores
Document databases
Search engine databases
Time series databases
Column family databases
Graph databases
Each option has pros and cons. Different data types are better suited for different data store types. Pick the storage technology that's the best fit for your data and how you use it.
For example, you might store a product catalog in a document database, such as Azure Cosmos DB, which supports a flexible schema. Each product description is a self-contained document. For queries over the entire catalog, you might index the catalog and store the index in Azure Cognitive Search. Product inventory might go into a SQL database because that data requires ACID guarantees.
Recommendations
Consider other data stores. Relational databases aren't always appropriate. For more information, see
Understand data store models
.
Remember that data includes more than just persisted application data. It also includes application logs, events, messages, and caches.
Embrace polyglot persistence or solutions that use a combination of data store technologies.
Consider the type of data that you have. For example, store:
Transactional data in a SQL database.
JSON documents in a document database.
Telemetry in a time series database.
Application logs in Azure Cognitive Search.
Blobs in Azure Blob Storage.
Prioritize availability over consistency. The CAP theorem implies that you have to make tradeoffs between availability and consistency in a distributed system. You can't completely avoid network partitions, which is the other component of the CAP theorem. But you can adopt an eventual consistency model to achieve higher availability.
Consider the skill set of your development team. There are advantages to using polyglot persistence, but it's possible to go overboard. It requires new skill sets to adopt a new data storage technology. To get the most out of the technology, your development team must:
Optimize queries.
Tune for performance.
Work with the appropriate usage patterns.
Consider these factors when you choose a storage technology:
Use compensating transactions. With polyglot persistence, a single transaction might write data to multiple stores. If there's a failure, use compensating transactions to undo any steps that have finished.
Consider bounded contexts, which is a domain-driven design concept. A bounded context is an explicit boundary around a domain model. A bounded context defines which parts of the domain that the model applies to. Ideally, a bounded context maps to a subdomain of the business domain. Consider polyglot persistence for bounded contexts in your system. For example, products might appear in the product catalog subdomain and the product inventory subdomain. But most likely, these two subdomains have different requirements for storing, updating, and querying products.
Azure facilitation
Azure offers the following services:
Azure Functions
is a serverless compute service that you can use to build orchestration with minimal code.
Azure Logic Apps
is a serverless workflow integration platform that you can use to build orchestration with a GUI or by editing a configuration file.
Azure Event Grid
is a highly scalable, fully managed publish-subscribe message distribution service that offers flexible message consumption patterns that use the MQTT and HTTP protocols. With Event Grid, you can build data pipelines with device data, build event-driven serverless architectures, and integrate applications.
For more information, see:
Choose an Azure compute service
Choose a compute option for microservices
Review your data options
Example
For an example workload that determines components and their features based on requirements, see
Reliable Web App pattern
.
Related links
Azure serverless
Cloud-native applications
Types of databases on Azure
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for designing a reliability testing strategy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for designing a reliability testing strategy
Article
2023-11-15
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Reliability checklist recommendation:
RE:08
Test for resiliency and availability scenarios by applying the principles of chaos engineering.
Ensure that your graceful degradation implementation and scaling strategies are effective by performing active malfunction and simulated load testing.
This guide describes the recommendations for designing a reliability testing strategy to validate and optimize the reliability of your workload. Reliability testing focuses on the resiliency and availability of your workload, specifically the critical flows that you identify when you design your solution. This guide provides general testing guidance and guidance that's specific to fault injection and chaos engineering.
Definitions
Term
Definition
Availability
The amount of time that an application workload runs in a healthy state without significant downtime.
Chaos engineering
The practice of subjecting applications and services to real-world stresses and failures. The goal of chaos engineering is to build and validate resilience to unreliable conditions and missing dependencies.
Fault injection
The act of introducing an error to a system to test the resiliency of the system.
Recoverability
A synonym for resiliency.
Resiliency
An application workload's ability to withstand and recover from failure modes.
Key design strategies
Test reliability preparedness
Routinely perform testing to validate existing thresholds, targets, and assumptions. When a major change occurs in your workload, run regular testing. Perform most testing in testing and staging environments. It's also beneficial to run a subset of tests against the production system. Plan a one-to-one parity of key test environments with the production environment.
Automate testing to help ensure consistent test coverage and reproducibility. Automate common testing tasks and integrate them into your build processes. Manually testing software is tedious and susceptible to error, but you can conduct manual exploratory testing. For cases in which you need to develop automated testing, use manual testing to determine the scope of the tests to develop.
Adopt a shift-left testing approach to perform resiliency and availability testing early in the development cycle.
Adapt a simple documentation format, so it's easy for everyone to understand the process and the results of every regular test.
Share the documented results with the appropriate teams, like operational teams, technology leadership, business stakeholders, and disaster recovery stakeholders. The results should inform the refinement of reliability targets, such as service-level objectives (SLOs), service-level agreements (SLAs), recovery time objectives (RTOs), and recovery point objectives (RPOs).
Create a regular testing cadence for your backups. Restore the data to isolated systems to help ensure that the backups are valid and that restores are functional.
Document and share recovery time metrics with your disaster recovery stakeholders to ensure that expectations for recovery are appropriate.
Use industry standard
deployment testing procedures
to help ensure that you have an automated, predictable, and efficient deployment process.
Test your workload's ability to withstand transient failures. For more information, see
Recommendations for handling transient faults
.
Test your workload's ability to respond to changes in load patterns and spikes in usage. Use this information to help you test your
scaling strategy
. For information about load and stress testing, see
Recommendations for testing
.
Test how your workload handles failures in dependent services or other dependencies by using fault injection.
Test and validate how your
self-healing and self-preservation design
responds to malfunctions. Test automated and manual recovery operations.
Test your
disaster recovery plan
to respond to catastrophic failures and other major incidents.
Test your workload's ability to degrade gracefully and minimize the blast radius of component malfunction by using fault injection.
Take advantage of planned and unplanned outages
When your workload is offline due to planned maintenance or an unplanned outage, you have a unique opportunity to perform testing and improve your understanding of your workload. The following sections provide recommendations for each scenario.
Planned maintenance
When you have planned maintenance windows for updates or patches, you can test components and flows that aren't involved in the maintenance work. Perform tests without the potential risk of unexpectedly degrading the workload or taking it offline altogether. If you have enough time during your maintenance window, you can also test the components and flows that are involved in the maintenance after the maintenance work is complete.
Unplanned outage
Use every outage incident as an opportunity to learn more about your workload and improve its resiliency by following these steps, ordered by priority:
Get the workload back online for your customers. To do so, you might perform a workaround for the issue, resolve the issue, or initiate the recovery processes.
Determine the root cause of the outage and address it. If you can fix the root cause as part of the investigation, document the root cause and the measures that you took to fix it. If the issue requires taking an additional maintenance window at a later time, ensure that your mitigation measures can handle the expected load by thoroughly testing it. Ensure that you have set up sufficient monitoring to cover your mitigation measures.
If applicable, look for the same issue, or configuration weaknesses that might be affected by similar issues, across all the components in your workload. Use this opportunity to proactively address those components. Consult your incident history to detect patterns of similar issues across your workload.
Use your findings to improve your testing strategy. Ensure that you have successfully addressed the root cause and similar problems by directly testing the same failure.
Use fault injection and chaos engineering
Fault-injection testing follows the principles of chaos engineering by highlighting the workload's ability to react to component failures. Perform fault-injection testing in pre-production and production environments. Apply testing to infrastructure and application layers. Apply the information that you learned
Recommendations for performing failure mode analysis
to ensure that you test only faults that you prioritize and that you have mitigation strategies that address faults. The key guidelines of chaos engineering are:
Be proactive.
Don't wait for failures to happen. Try to anticipate failures by conducting chaos experiments to discover and fix issues before they affect your production environment.
Embrace failure.
Accept and learn from the failures that occur in your system. See failures as a natural part of complex systems and use them as opportunities to learn and improve your system's reliability.
Break the system.
Deliberately inject faults or stress into your system to test its resilience. Simulate real-world failures or disruptions to test and improve your workload's recovery capabilities.
Identify and address single points of failure early.
As you test, consult and update your
failure mode analysis
to validate and address faults in your documentation. Apply reliability approaches, like redundancy and segmentation, to increase your workload's availability and minimize downtime.
Install guardrails and graceful mitigation.
Implement safety measures, like the Circuit Breaker pattern or the Throttling pattern, to increase availability. Implement graceful degradation approaches that enable business continuity during failures.
Minimize the blast radius.
Implement fault isolation strategies to help ensure that, even if a failure occurs, its scope is limited. The system continues to function with minimal effect on your customers.
Build immunity.
Use chaos engineering experiments to improve your workload's ability to prevent and recover from failures.
Chaos engineering is an integral part of workload team culture and an ongoing practice, not a short-term tactical effort in response to a single outage. Follow this standard method when you design your chaos experiments:
Start with a hypothesis. Each experiment should have a clear goal, like testing a given flow's ability to withstand the loss of a particular component.
Measure baseline behavior. Ensure that you have consistent reliability and performance metrics for the flow and components involved in a given experiment to compare with the degraded state when running your experiment.
Inject a fault or faults. The experiment should intentionally target specific components that can be recovered quickly and you should have an informed expectation of the effect that the fault injection will cause to help control the experiment's blast radius.
Monitor the resulting behavior. Gather telemetry about the individual flow components and the end-to-end flow behavior that the experiment targets to properly understand the effects of the fault. Compare the metrics that you gather with the baseline metrics for a full picture of the fault injection results.
Document the process and observations. Keeping detailed records of your experiments will inform the future decisions about the workload design, ensuring that you address the gaps that have been revealed over time.
Identify and act on the result. Plan for remediation steps that can be added to your workload backlog as improvements. Ensure that design improvement plans are reviewed and tested in nonproduction environments according to the same processes as other deployments.
Periodically validate your process, architecture choices, and code to quickly detect technical debt, integrate new technologies, and adapt to changing requirements.
When you conduct fault-injection experiments, you:
Confirm that monitoring is in place and alerts are set up.
Validate your process of assigning a directly responsible individual (DRI) to take ownership of an incident.
Ensure that your documentation and investigation processes are up to date.
Integrate the following recommendations and considerations to optimize your chaos testing strategy:
Challenge system assumptions. With testing, you try to improve the resiliency of your workload and your workload design strategies. Look for opportunities to inject faults into components and flows that you assume are reliable based on past experiences. They might not be reliable in your new workload.
Validate change, such as the topology, platform, and resources. Without thorough testing, including fault-injection testing, you might have an incomplete picture of your workload after changes are made. For example, you might inadvertently introduce new dependencies or broken existing dependencies in ways that aren't immediately apparent.
Use SLA buffers. Limit chaos testing to stay within your SLAs and avoid potential reputation or financial effects from outages. Your flow and component recovery targets help define the scope of your testing.
Establish an error budget as an investment in chaos and fault injection. Your error budget is the difference between achieving 100 percent of the SLO and achieving the agreed upon SLO.
Stop the experiment if it goes beyond scope. Unknown results are an expected outcome of chaos experiments. Strive to achieve balance between collecting substantial result data and affecting as few production users as possible.
Work closely with development teams to ensure the relevance of the injected failures. Use past incidents or issues as a guide. Examine dependencies and evaluate the results when you remove those dependencies.
Identify and document previously undiscovered dependencies between different components within your workload that are revealed through chaos testing.
Adjust recovery plans as necessary to account for dependencies that are discovered during chaos testing.
Use the results from your experiments and tests as the basis for new experiments and tests. As unexpected behaviors arise, new tests might target those behaviors directly and give you the opportunity to design remediation strategies for them.
Tradeoff
: Fault-injection testing in production can be disruptive and can potentially cause downtime. Be transparent with stakeholders about this possibility and ensure that you have safeguards in place to terminate experiments and roll back plans to quickly reverse the failures that you introduce. To guard against unintended outages in production, ensure that you plan for sufficient
redundancy
and that your stakeholders understand the cost tradeoff.
Azure facilitation
Azure Test Plans
is an easy-to-use, browser-based test management solution that provides all the capabilities required for planned manual testing, user acceptance testing, exploratory testing, and gathering feedback from stakeholders.
Azure Chaos Studio
is a managed service that uses chaos engineering to help you measure, understand, and improve your cloud application and service resilience. Azure Chaos Studio reached general availability at Ignite 2023 and has lots of features to help you get started with Fault injection and resiliency testing for your application using Azure infrastructure.
Related links
Backup and disaster recovery for Azure applications
Checklist for reliability testing
Test applications for availability and resiliency
Reliability checklist
Refer to the complete set of recommendations.
Reliability checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Reliability tradeoffs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Reliability tradeoffs
Article
2024-10-10
5 contributors
Feedback
In this article
A reliable workload consistently meets its defined reliability objectives. It should reach established resiliency targets, ideally by circumventing events that affect reliability. Realistically, however, a workload must tolerate and control the impact of such events and maintain operations at a predetermined level during active malfunction. Even during a disaster, a reliable workload must recover to a specific state within a given period of time, both of which are agreed upon among the stakeholders. An incident response plan that enables you to achieve rapid detection and recovery is vital.
During the design phase of a workload, you need to consider how decisions based on the
Reliability design principles
and the recommendations in the
Design review checklist for Reliability
might influence the goals and optimizations of other pillars. Certain decisions might benefit some pillars but constitute a tradeoff for others. This article describes example tradeoffs that a workload team might encounter when designing workload architecture and operations for reliability.
Reliability tradeoffs with Security
Tradeoff: Increased workload surface area.
The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and reduce the management of security controls.
Reliability is often obtained through replication. Replication can occur at the component level, at the data level, or even at a geographic level. Replicas, by design, increase the surface area of a workload. From a security perspective, a reduced and contained surface area is preferred to minimize potential attack vectors and streamline the management of security controls.
Similarly, disaster recovery solutions, like backups, increase a workload's surface area. However, they're often isolated from the workload's runtime. These solutions require the implementation of additional security controls, which might be specific to the disaster recovery approach.
For the sake of reliability goals, additional components might be needed for the architecture, which increases the surface area. For example, a message bus might be added to make requests resilient through decoupling. This increased complexity increases the surface area of the workload by adding new components that need to be secured, possibly in ways that aren't already used in the system. Typically, these components are accompanied by additional code and libraries to support their use or general reliability patterns, which also increases application surface area.
Tradeoff: Security control bypass.
The Security pillar recommends that all controls remain active in both normal and stressed systems.
When a workload is experiencing a reliability event that's being addressed under active incident response, urgency might create pressure for workload teams to bypass security controls that are optimized for routine access.
Troubleshooting activities can cause the team to temporary disable security protocols, leaving an already stressed system potentially exposed to additional security risks. There's also a risk that the security protocols won't be reestablished promptly.
Granular implementations of security controls, like custom role-based access control assignments or narrow firewall rules, introduce configuration complexity and sensitivity, increasing the chance for misconfiguration. Mitigating this potential reliability impact by using broad rules erodes all three Zero Trust architecture principles.
Tradeoff: Old software versions.
The Security pillar encourages a "get current, stay current" approach to vendor security patches.
Applying security patches or software updates can potentially disrupt the target component, causing unavailability during the software change. Delaying or avoiding patching might avoid the potential reliability risks, but it leaves the system unprotected against evolving threats.
The preceding consideration also applies to the workload's code. For example, it applies to application code that uses old libraries and containers that use old base images. If updating and deploying application code is viewed as an unmitigated reliability risk, the application is exposed to additional security risks over time.
Reliability tradeoffs with Cost Optimization
Tradeoff: Increased implementation redundancy or waste.
A cost-optimized workload minimizes underutilized resources and avoids over-provisioning resources.
Replication is a key strategy for reliability. Specifically, the strategy is to have enough replication to handle a given number of concurrent node failures. The tolerance for more concurrent node failures requires a higher replica count, which leads to increased costs.
Over-provisioning is another technique for absorbing unexpected load on a system, such as during a failover event, that could otherwise lead to a reliability issue. Any excess capacity that's not utilized is considered wasteful.
If a workload uses a disaster recovery solution that excessively satisfies the workload's recovery point and time objectives, the excess leads to higher costs because of waste.
Workload deployments themselves are a potential source for reliability impact, and that impact is often mitigated by redundancy at deployment time via a deployment strategy like blue/green. This transient duplication of resources during safe deployment typically increases the overall cost of the workload during those periods. Costs increase with frequency of deployments.
Tradeoff: Increased investment in operations that aren't aligned with functional requirements.
One approach to cost optimization is evaluating the value that's provided by any deployed solution.
To achieve reliability, a system requires observability. Monitoring systems require observability data transfer and collection. As monitoring capabilities increase, the frequency and volume of data increase, leading to additional costs.
Reliability affordances in workloads necessitate testing and drills. Designing and running tests takes time and potentially specialized tooling, which incurs costs.
Workloads with high reliability targets often have a rapid response process that requires technical team members to be part of a formal on-call rotation. This process incurs additional personnel costs and lost opportunity costs because of attention that could be directed elsewhere. It also incurs potential tooling costs for management of the process.
Support contracts with technology providers are a key component of a reliable workload. Support contracts that aren't utilized because the level of support is over-provisioned incur waste.
Reliability tradeoffs with Operational Excellence
Tradeoff: Increased operational complexity.
Operational Excellence, like Reliability itself, prioritizes simplicity.
Reliability usually increases the complexity of a workload. As the complexity of a workload increases, the operational elements of the workload can also increase to support the added components and processes in terms of deployment coordination and configuration surface area.
Having a comprehensive monitoring strategy for a workload is a key part of operational excellence. Introducing additional components into an architecture to implement reliability design patterns results in more data sources to manage, increasing the complexity of implementing distributed tracing and observability.
Using multiple regions to overcome single region resource capacity constraints and/or implement an active/active architecture increases the complexity of the workload's operational management. This complexity is introduced by the need to manage multiple regions and the need to manage the data replication between them.
Tradeoff: Increased effort to generate team knowledge and awareness.
The Operational Excellence pillar recommends keeping and maintaining a documentation repository for procedures and topologies.
As a workload becomes more robust through the addition of reliability components and patterns, it takes more time to maintain operational procedures and artifact documentation.
Training becomes more complex as the number of components in the workload increases. This complexity affects the time required for onboarding. The complexity also increases the knowledge that's needed to track product roadmaps and  the latest service-level guidance.
Reliability tradeoffs with Performance Efficiency
Tradeoff: Increased latency.
Performance Efficiency requires a system to achieve performance targets for user and data flows.
Reliability patterns often incorporate data replication to survive replica malfunction. Replication introduces additional latency for reliable data-write operations, which consumes a part of the performance budget for a specific user or data flow.
Reliability sometimes employs various forms of resource balancing to distribute or redistribute load to healthy replicas. A dedicated component that's used for balancing usually affects the performance of the request or process that's being balanced.
Distributing components across geographical boundaries or availability zones to survive a scoped impact introduces network latency in the communication between components that span those availability boundaries.
Extensive processes are used to observe the health of a workload. Although monitoring is critical for reliability, instrumentation can affect system performance. As observability increases, performance might decrease.
Tradeoff: Increased over-provisioning.
The Performance Efficiency pillar discourages over-provisioning, instead recommending the use of just enough resources to satisfy demand.
Automatic scaling operations aren't instantaneous and therefore can't reliably handle a sudden and dramatic spike in demand that can't be shaped or smoothed. Therefore, over-provisioning via either larger instances or more instances is a critical reliability tactic to account for the lag between demand signal and supply creation to help absorb bursts. Unused capacity counters the goals of performance efficiency.
Sometimes a component can't be scaled in reaction to demand, and that demand isn't fully predictable. Using large instances to cover the worst case leads to over-provisioning waste in situations that are outside that use case.
Related links
Explore the tradeoffs for the other pillars:
Security tradeoffs
Cost Optimization tradeoffs
Operational Excellence tradeoffs
Performance Efficiency tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025