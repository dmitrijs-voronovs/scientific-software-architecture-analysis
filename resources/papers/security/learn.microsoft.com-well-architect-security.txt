Recommendations for protecting application secrets - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for protecting application secrets
Article
2023-11-14
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:09
Protect application secrets by hardening their storage and restricting access and manipulation and by auditing those actions. Run a reliable and regular rotation process that can improvise rotations for emergencies.
This guide describes the recommendations for securing sensitive information in applications. Proper management of secrets is crucial for maintaining the security and integrity of your application, workload, and associated data. Improper handling of secrets can lead to data breaches, service disruption, regulatory violations, and other issues.
Credentials, such as API keys, Open Authorization (OAuth) tokens, and Secure Shell (SSH) keys are secrets. Some credentials, such as client-side OAuth tokens, can be dynamically created at runtime. Dynamic secrets still need to be safeguarded despite their temporary nature. Noncredential information, like certificates and digital signature keys, can also be sensitive. Compliance requirements might cause configuration settings that aren't typically considered secret to be treated as application secrets.
Definitions
Term
Definition
Certificates
Digital files that hold the public keys for encryption or decryption.
Credentials
Information that's used to verify the identity of the publisher or consumer in a communication channel.
Credential scanning
The process of validating source code to make sure secrets aren't included.
Encryption
The process by which data is made unreadable and locked with a secret code.
Key
A secret code that's used to lock or unlock encrypted data.
Least-privilege access
A Zero Trust principle that aims at minimizing a set of permissions to complete a job function.
Managed identity
An identity that's assigned to resources and managed by Azure.
Nonsecret
Information that doesn't jeopardize the security posture of the workload if it's leaked.
Rotation
The process of regularly updating secrets so that, if they're compromised, they're available only for a limited time.
Secret
A confidential component of the system that facilitates communication between workload components. If leaked, secrets can cause a breach.
X.509
A standard that defines the format of public key certificates.
Important
Don't treat nonsecrets like secrets.
Secrets require operational rigor that's unnecessary for nonsecrets and that might result in extra costs.
Application configuration settings, such as URLs for APIs that the application uses, are an example of nonsecrets. This information shouldn't be stored with the application code or application secrets. Consider using a dedicated configuration management system such as Azure App Configuration to manage these settings. For more information, see
What is Azure App Configuration?
.
Key design strategies
Your secret management strategy should minimize secrets as much as possible and integrate them into the environment by taking advantage of platform features. For example, if you use a managed identity for your application, access information isn't embedded in connection strings and it's safe to store the information in a configuration file. Consider the following areas of concern before storing and managing secrets:
Created secrets should be kept in secure storage with strict access controls.
Secret rotation is a proactive operation, whereas revocation is reactive.
Only trusted identities should have access to secrets.
You should maintain an audit trail to inspect and validate access to secrets.
Build a strategy around these points to help prevent identity theft, avoid repudiation, and minimize unnecessary exposure to information.
Manage workload secrets
If possible, avoid creating secrets. Find ways to
delegate responsibility to the platform
. For example, use the platform's built-in managed identities to handle credentials. Fewer secrets result in reduced surface area and less time spent on secret management.
We recommend that keys have three distinct roles: user, administrator, and auditor. Role distinction helps to ensure that only trusted identities have access to secrets with the appropriate level of permission. Educate developers, administrators, and other relevant personnel about the importance of secret management and security best practices.
Preshared keys
You can control access by creating distinct keys for each consumer.
For example, a client communicates with a third-party API using a preshared key. If another client needs to access the same API, they must use another key. Don't share keys even if two consumers have the same access patterns or roles. Consumer scopes might change over time, and you can't independently update permissions or distinguish usage patterns after a key is shared. Distinct access also makes revocation easier. If a consumer's key is compromised, it's easier to revoke or rotate that key without affecting other consumers.
This guidance applies to different environments. The same key shouldn't be used for both preproduction and production environments. If you're responsible for creating preshared keys, make sure you create multiple keys to support multiple clients.
For more information, see
Recommendations for identity and access management
.
Secret storage
Use a secret management system
, like Azure Key Vault, to store secrets in a hardened environment, encrypt at-rest and in-transit, and audit access and changes to secrets. If you need to store application secrets, keep them outside the source code for easy rotation.
Certificates should only be stored in Key Vault or in the OS's certificate store. For example, storing an X.509 certificate in a PFX file or on a disk isn't recommended. If you need a higher level of security, choose systems that have hardware security module (HSM) capabilities instead of software-based secret stores.
Tradeoff
: HSM solutions are offered at a higher cost. You might also see an effect on application performance due to added layers of security.
A dedicated secret management system makes it easy to store, distribute, and control access to application secrets. Only authorized identities and services should have access to secret stores. Access to the system can be restricted via permissions. Always apply the least-privilege approach when assigning permissions.
You also need to control access at the secret level.
Each secret should only have access to a single resource scope. Create isolation boundaries so that a component is only able to use secrets that it needs. If an isolated component is compromised, it can't gain control of other secrets and potentially the entire workload. One way to isolate secrets is to use multiple key vaults. There's no added costs for creating extra key vaults.
Implement auditing and monitoring for secret access.
Log who accesses secrets and when to identify unauthorized or suspicious activity. For information about logging from a security perspective, see
Recommendations on security monitoring and threat detection
.
Secret rotation
Have a process in place that maintains secret hygiene.
The longevity of a secret influences the management of that secret. To reduce attack vectors, secrets should be retired and replaced with new secrets as frequently as possible.
Handle OAuth access tokens carefully, taking into consideration their time to live. Consider if the exposure window needs to be adjusted to a shorter period. Refresh tokens must be stored securely with limited exposure to the application. Renewed certificates should also use a new key. For information about refresh tokens, see
Secure OAuth 2.0 On-Behalf-Of refresh tokens
.
Replace secrets after they reach their end of life, are no longer used by the workload, or if they've been compromised.
Conversely, don't retire active secrets unless it's an emergency. You can determine a secret's status by viewing access logs. Secret rotation processes shouldn't affect the reliability or performance of the workload. Use strategies that build redundancy in secrets, consumers, and access methods for smooth rotation.
For more information on how Azure Storage handles rotation, see
Manage account access keys
.
Rotation processes should be automated and deployed without any human interaction. Storing secrets in a secret management store that natively supports rotation concepts can simplify this operational task.
Use workload secrets safely
As a secret generator or operator, you should be able to distribute secrets in a safe manner. Many organizations use tools to securely share secrets both within the organization and externally to partners. In absence of a tool, have a process for properly  handing off credentials to authorized recipients. Your disaster recovery plans should include secret recovery procedures. Have a process for situations where a key is compromised or leaked and needs to be regenerated on demand. Consider the following best practices for safety when using secrets:
Prevent hardcoding
Don't hard code secrets as static text
in code artifacts such as application code, configuration files, and build-deployment pipelines. This high-risk practice makes the code vulnerable because secrets are exposed to everyone with read access.
You can avoid this situation by using managed identities to eliminate the need to store credentials. Your application uses its assigned identity to authenticate against other resources via the identity provider (IdP). Test in nonproduction environments with fake secrets during development to prevent accidental exposure of real secrets.
Use tools that periodically detect exposed secrets
in your application code and build artifacts. You can add these tools as Git precommit hooks that scan for credentials before source code commits deploy. Review and sanitize application logs regularly to help ensure that no secrets are inadvertently recorded. You can also reinforce detection via peer reviews.
Note
If the scanning tools discover a secret, that secret must be considered compromised. It should be revoked.
Respond to secret rotation
As a workload owner, you need to
understand the secret rotation plan and policies so that you can incorporate new secrets with minimal disruption to users.
When a secret is rotated, there might be a window when the old secret isn't valid, but the new secret hasn't been placed. During that window, the component that the application is trying to reach doesn't acknowledge requests. You can minimize these issues by building retry logic into the code. You can also use concurrent access patterns that allow you to have multiple credentials that can be safely changed without affecting each other.
Work with the operations team and be part of the change management process.
You should let credential owners know when you decommission a part of the application that uses credentials that are no longer needed.
Integrate secret retrieval and configuration into your automated deployment pipeline.
Secret retrieval helps to ensure secrets are automatically fetched during deployment. You can also use secret injection patterns to insert secrets into application code or configuration at runtime, which prevents secrets from being accidentally exposed to logs or version control.
Azure facilitation
Store secrets by using Key Vault.
Store secrets in the Azure secret management system, Key Vault, Azure Managed HSM, and other locations. For more information, see
How to choose the right key management solution
.
Integrate identity-based access control.
Microsoft Entra ID and managed identities help minimize the need for secrets. Microsoft Entra ID offers a highly secure and usable experience for access control with built-in mechanisms for handling key rotation, for anomalies, and more.
Use Azure role-based access control (RBAC) to assign permissions to users, groups, and applications at a certain scope.
Use an access model to control key vaults, permissions, and secrets. For more information, see
Access model overview
.
Implement secret exposure detection.
Integrate processes in your workload that detect suspicious activity and periodically check for exposed keys in your application code. Some options include:
Azure DevOps Credential Scanner task
Defender for Cloud secret scanning
Microsoft Defender for Key Vault
GitHub Secret Scanner
Don't store keys and secrets for any environment type in application configuration files or continuous integration and continuous delivery (CI/CD) pipelines. Developers should use
Visual Studio Connected Services
or local-only files to access credentials.
Related links
Access model overview
Azure DevOps Credential Scanner task
Configure the Microsoft Security DevOps Azure DevOps extension
Configure GitHub Advanced Security for Azure DevOps
Defender for Cloud secret scanning
How to choose the right key management solution
Manage account access keys
Microsoft Defender for Key Vault
Recommendations on security monitoring and threat detection
Recommendations for identity and access management
Secure OAuth 2.0 On-Behalf-Of refresh tokens for web services
Visual Studio Connected Services
Community links
GitHub secret scanner
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Design review checklist for Security - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Design review checklist for Security
Article
2023-11-14
2 contributors
Feedback
In this article
This checklist presents a set of security recommendations to help you ensure your workload is secure and aligned with the Zero Trust model. If you haven't checked the following boxes and considered the tradeoffs, then your design might be at risk. Carefully consider all of the points covered in the checklist to gain confidence in your workload's security.
Checklist
Code
Recommendation
☐
SE:01
Establish a security baseline
that's aligned to compliance requirements, industry standards, and platform recommendations. Regularly measure your workload architecture and operations against the baseline to sustain or improve your security posture over time.
☐
SE:02
SE:02
Maintain a secure development lifecycle
by using a hardened, mostly automated, and auditable software supply chain. Incorporate a secure design by using threat modeling to safeguard against security-defeating implementations.
☐
SE:03
Classify and consistently apply sensitivity and information type labels
on all workload data and systems involved in data processing. Use classification to influence workload design, implementation, and security prioritization.
☐
SE:04
Create intentional segmentation and perimeters
in your architecture design and in the workload's footprint on the platform. The segmentation strategy must include networks, roles and responsibilities, workload identities, and resource organization.
☐
SE:05
Implement strict, conditional, and auditable identity and access management (IAM)
across all workload users, team members, and system components. Limit access exclusively to
as necessary
. Use modern industry standards for all authentication and authorization implementations. Restrict and rigorously audit access that's not based on identity.
☐
SE:06
Isolate, filter, and control network traffic
across both ingress and egress flows. Apply defense-in-depth principles by using localized network controls at all available network boundaries across both east-west and north-south traffic.
☐
SE:07
Encrypt data by using modern, industry-standard methods
to guard confidentiality and integrity. Align the encryption scope with data classifications, and prioritize native platform encryption methods.
☐
SE:08
Harden all workload components
by reducing extraneous surface area and tightening configurations to increase attacker cost.
☐
SE:09
Protect application secrets
by hardening their storage and restricting access and manipulation and by auditing those actions. Run a reliable and regular rotation process that can improvise rotations for emergencies.
☐
SE:10
Implement a holistic monitoring strategy
that relies on modern threat detection mechanisms that can be integrated with the platform. Mechanisms should reliably alert for triage and send signals into existing SecOps processes.
☐
SE:11
Establish a comprehensive testing regimen
that combines approaches to prevent security issues, validate threat prevention implementations, and test threat detection mechanisms.
☐
SE:12
Define and test effective incident response procedures
that cover a spectrum of incidents, from localized issues to disaster recovery. Clearly define which team or individual runs a procedure.
Next steps
We recommend that you review the Security tradeoffs to explore other concepts.
Security tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Data classification recommendations - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for data classification
Article
2023-11-15
5 contributors
Feedback
In this article
Applies to Azure Well-Architected Framework Security checklist recommendation:
SE:03
Classify and consistently apply sensitivity labels on all workload data and systems involved in data processing. Use classification to influence workload design, implementation, and security prioritization.
This guide describes the recommendations for data classification. Most workloads store various types of data. Not all data is equally sensitive. Data classification helps you categorize data based on its sensitivity level, information type, and scope of compliance so you can apply the correct level of protection. Protection includes access controls, retention policies for different information types, and so on. While the actual security controls based on data classification are out of scope for this article, it provides recommendations for categorizing data based on the preceding criteria set by your organization.
Definitions
Term
Definition
Classification
A process to categorize workload assets by sensitivity levels, information type, compliance requirements, and other criteria provided by the organization.
Metadata
An implementation for applying taxonomy to assets.
Taxonomy
A system to organize classified data by using an agreed upon structure. Typically, a hierarchical depiction of data classification. It has named entities that indicate categorization criteria.
Key design strategies
Data classification is a crucial exercise that often drives building a system of record and its function. Classification also helps you correctly size security assurances and helps the triage team expediate discovery during incident response. A prerequisite to the design process is to clearly understand whether data should be treated as confidential, restricted, public, or any other sensitivity classification. It's also essential to determine the locations where data is stored, because the data might be distributed across multiple environments.
Data discovery is necessary to locate the data. Without that knowledge, most designs adopt a middle-ground approach, which might or might not serve the security requirements. Data can be overprotected, resulting in cost and performance inefficiencies. Or it might not be protected enough, which adds to the attack surface.
Data classification is often a cumbersome exercise. There are tools available that can discover data assets and suggest classifications. But don't just rely on tooling. Have a process in place where team members diligently do the exercises. Then use tooling to automate when that's practical.
Along with these best practices, see
Create a well-designed data classification framework
.
Understand organization-defined taxonomy
Taxonomy
is a hierarchical depiction of data classification. It has named entities that indicate the categorization criteria.
In general, there isn't a universal standard for classification or for defining taxonomy. It's driven by an organization's motivation for protecting data. Taxonomy might capture compliance requirements, promised features for the workload users, or other criteria driven by business needs.
Here are some example classification labels for sensitivity levels, information type, and scope of compliance.
Sensitivity
Information type
Scope of compliance
Public, General, Confidential, Highly Confidential, Secret, Top Secret, Sensitive
Financial, Credit Card, Name, Contact Info, Credentials, Banking, Networking, SSN, Health fields, Date of Birth, Intellectual Property, personal data
HIPAA, PCI, CCPA, SOX, RTB
As a workload owner, rely on your organization to provide you with a well-defined taxonomy. All workload roles must have a shared understanding of the structure, nomenclature, and definition of the sensitivity levels. Don't define your own classification system.
Define the classification scope
Most organizations have a diverse set of labels.
Clearly identify which data assets and components are in-scope and out-of-scope for each sensitivity level. You should have a clear objective on the outcome. The objective could be quicker triage, accelerated disaster recovery, or regulatory audits. When you clearly understand the objectives, it ensures you correctly size your classification efforts.
Start with these simple questions and expand as necessary based on your system complexity:
What's the origin of data and information type?
What's the expected restriction based on access? For example, is it public information data, regulatory, or other expected use cases?
What's the data footprint? Where is data stored? How long should the data be retained?
Which components of the architecture interact with the data?
How does the data move through the system?
What information is expected in the audit reports?
Do you need to classify preproduction data?
Take inventory of your data stores
If you have an existing system, take inventory of all data stores and components that are in scope. On the other hand, if you're designing a new system, create a data flow dimension of the architecture and have an initial categorization per taxonomy definitions. Classification applies to the system as a whole. It's distinctly different from classifying configuration secrets and nonsecrets.
Define your scope
Be granular and explicit when defining the scope. Suppose your data store is a tabular system. You want to classify sensitivity at the table level or even the columns within the table. Also, be sure to extend classification to nondata store components that might be related or have a part in processing the data. For example, have you classified the backup of your highly sensitive data store? If you're caching user-sensitive data, is the caching data store in scope? If you use analytical data stores, how is the aggregated data classified?
Design according to classification labels
Classification should influence your architectural decisions. The most obvious area is your segmentation strategy, which should consider the varied classification labels.
For example, the labels influence the traffic isolation boundaries. There might be critical flows where end-to-end transport layer security (TLS) is required, while other packets can be sent over HTTP. If there are messages transmitted over a message broker, certain messages might need to be signed.
For data at rest, the levels will affect the encryption choices
. You might choose to protect highly sensitive data through double encryption. Different application secrets might even require control with varied levels of protection. You might be able to justify storing secrets in a hardware security module (HSM) store, which offers higher restrictions. Compliance labels also dictate decisions about the right protection standards. For example, The PCI-DSS standard mandates the use of FIPS 140-2 Level 3 protection, which is available only with HSMs. In other cases, it might be acceptable for other secrets to be stored in a regular secret management store.
If you need to protect data in use, you might want to incorporate confidential computing in the architecture.
Classification information should move with the data as it transitions through the system
and across components of the workload. Data labeled as confidential should be treated as confidential by all components that interact with it. For example, be sure to protect personal data by removing or obfuscating it from any kind of application logs.
Classification impacts the design of your report
in the way data should be exposed. For example, based on your information type labels, do you need to apply a data masking algorithm for obfuscation as a result of the information type label? Which roles should have visibility into the raw data versus masked data? If there are any compliance requirements for reporting, how is data mapped to regulations and standards? When you have this understanding, it's easier to demonstrate compliance with specific requirements and generate reports for auditors.
It also impacts the data lifecycle management operations, such as data retention and decommissioning schedules.
Apply taxonomy for querying
There are many ways to apply taxonomy labels to the identified data. Using a classification schema with metadata is the most common way to indicate the labels. Standardization through schema makes sure that reporting is accurate, minimizes chances of variation, and avoids the creation of custom queries. Build automated checks to catch invalid entries.
You can apply labels manually, programmatically, or use a combination of both. The architecture design process should include design of the schema. Whether you have an existing system or are building a new one, when applying labels, maintain consistency in the key/value pairs.
Keep in mind that not all data can be clearly classified. Make an explicit decision about how the data that can't be classified should be represented in reporting.
The actual implementation depends on the type of resources. Certain Azure resources have built-in classification systems. For example, Azure SQL Server has a classification engine, supports dynamic masking, and can generate reports based on metadata. Azure Service Bus supports including a message schema that can have attached metadata. When you design your implementation, evaluate the features supported by the platform and take advantage of them. Make sure metadata used for classification is isolated and stored separately from the data stores.
There are also specialized classification tools that can detect and apply labels automatically. These tools are connected to your data sources. Microsoft Purview has autodiscover capabilities. There are also third-party tools that offer similar capabilities. The discovery process should be validated through manual verification.
Review data classification regularly
. Classification maintenance should be built into operations, otherwise stale metadata can lead to erroneous results for the identified objectives and compliance issues.
Tradeoff
: Be mindful of the cost tradeoff on tooling. Classification tools require training and can be complex.
Ultimately, classification must roll up to the organization through central teams. Get input from them about the expected report structure. Also, take advantage of centralized tools and processes to have organizational alignment and also alleviate operational costs.
Azure facilitation
Microsoft Purview unifies Azure Purview and Microsoft Purview solutions to provide visibility into data assets throughout your organization. For more information, see
What is Microsoft Purview?
Azure SQL Database, Azure SQL Managed Instance, and Azure Synapse Analytics offer built-in classification features. Use these tools to discover, classify, label, and report the sensitive data in your databases. For more information, see
Data discovery and classification
.
Example
This example builds on the Information Technology (IT) environment established in the
security baseline (SE:01)
. The example diagram below shows data stores where data is classified.
Data stored on databases and disks should only be accessible to a few users, such as Administrators, Database administrators. Then, it's usual that common users or customers' final clients have access only to layers that are exposed to the internet, such as applications or jump boxes.
Applications communicate with the databases or data stored on disks, such as object storage or file servers.
In some cases, data might be stored in an on-premises environment and the public cloud. Both need to be classified consistently.
In an operator use case, remote administrators need access jump boxes on the cloud or a virtual machine running the workload. Access permissions should be given as per the data classification labels.
Data moves through the virtual machines to the backend databases and data should be treated with the same level of confidentiality throughout the traversal points.
Workloads store data directly in virtual machine disks. Those disks are in scope for classification.
In a hybrid environment, different personas may access workloads on-premises through different mechanisms to connect to different data storage technologies or databases. Access must be granted as per the classification labels.
The on-premises servers connect to important data that need to be classified and protected such as file servers, object storage, and different types of databases, such as relational, no-SQL, and data warehouse.
Microsoft Purview Compliance provides a solution to classify files and emails.
Microsoft Defender for Cloud provides a solution that helps your company to track compliance in your environment, including many of your services used to store data, mentioned in these se cases above.
Related links
Data classification and sensitivity label taxonomy - Microsoft Service Assurance
Create a well-designed data classification framework - Microsoft Service Assurance
Next step
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cloud design patterns that support security - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Cloud design patterns that support security
Article
2024-10-10
3 contributors
Feedback
In this article
When you design workload architectures, you should use industry patterns that address common challenges. Patterns can help you make intentional tradeoffs within workloads and optimize for your desired outcome. They can also help mitigate risks that originate from specific problems, which can affect reliability, performance, cost, and operations. Those risks might be indicative of lack of security assurances, if left unattended can pose significant risks to the business. These patterns are backed by real-world experience, are designed for cloud scale and operating models, and are inherently vendor agnostic. Using well-known patterns as a way to standardize your workload design is a component of operational excellence.
Many design patterns directly support one or more architecture pillars. Design patterns that support the Security pillar prioritize concepts like segmentation and isolation, strong authorization, uniform application security, and modern protocols.
Design patterns for security
The following table summarizes cloud design patterns that support the goals of security.
Pattern
Summary
Ambassador
Encapsulates and manages network communications by offloading cross-cutting tasks that are related to network communication. The resulting helper services initiate communication on behalf of the client. This mediation point provides an opportunity to augment security on network communications.
Backends for Frontends
Individualizes the service layer of a workload by creating separate services that are exclusive to a specific frontend interface. Because of this separation, the security and authorization in the service layer that support one client can be tailored to the functionality provided by that client, potentially reducing the surface area of an API and lateral movement among different backends that might expose different capabilities.
Bulkhead
Introduces intentional and complete segmentation between components to isolate the blast radius of malfunctions. You can also use this strategy to contain security incidents to the compromised bulkhead.
Claim Check
Separates data from the messaging flow, providing a way to separately retrieve the data related to a message. This pattern supports keeping sensitive data out of message bodies, instead keeping it managed in a secured data store. This configuration enables you to establish stricter authorization to support access to the sensitive data from services that are expected to use the data, but remove visibility from ancillary services like queue monitoring solutions.
Federated Identity
Delegates trust to an identity provider that's external to the workload for managing users and providing authentication for your application. By externalizing user management and authentication, you can get evolved capabilities for identity-based threat detection and prevention without needing to implement these capabilities in your workload. External identity providers use modern interoperable authentication protocols.
Gatekeeper
Offloads request processing that's specifically for security and access control enforcement before and after forwarding the request to a backend node. Adding a gateway into the request flow enables you to centralize security functionality like web application firewalls, DDoS protection, bot detection, request manipulation, authentication initiation, and authorization checks.
Gateway Aggregation
Simplifies client interactions with your workload by aggregating calls to multiple backend services in a single request. This topology often reduces the number of touch points a client has with a system, which reduces the public surface area and authentication points. The aggregated backends can stay fully network-isolated from clients.
Gateway Offloading
Offloads request processing to a gateway device before and after forwarding the request to a backend node. Adding a gateway into the request flow enables you to centralize security functionality like web application firewalls and TLS connections with clients. Any offloaded functionality that's platform-provided already offers enhanced security.
Publisher/Subscriber
Decouples components in an architecture by replacing direct client-to-service communication with communication via an intermediate message broker or event bus. This replacement introduces an important security segmentation boundary that enables queue subscribers to be network-isolated from the publisher.
Quarantine
Ensures external assets meet a team-agreed quality level before being authorized to consume them in the workload. This check serves as a first security validation of external artifacts. The validation on an artifact is conducted in a segmented environment before it's used within the secure development lifecycle (SDL).
Sidecar
Extends the functionality of an application by encapsulating nonprimary or cross-cutting tasks in a companion process that exists alongside the main application. By encapsulating these tasks and deploying them out-of-process, you can reduce the surface area of sensitive processes to only the code that's needed to accomplish the task. You can also use sidecars to add cross-cutting security controls to an application component that's not natively designed with that functionality.
Throttling
Imposes limits on the rate or throughput of incoming requests to a resource or component. You can design the limits to help prevent resource exhaustion that could result from automated abuse of the system.
Valet Key
Grants security-restricted access to a resource without using an intermediary resource to proxy the access. This pattern enables a client to directly access a resource without needing long-lasting or standing credentials. All access requests start with an auditable transaction. The granted access is then limited in both scope and duration. This pattern also makes it easier to revoke the granted access.
Next steps
Review the cloud design patterns that support the other Azure Well-Architected Framework pillars:
Cloud design patterns that support reliability
Cloud design patterns that support cost optimization
Cloud design patterns that support operational excellence
Cloud design patterns that support performance efficiency
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Encryption strategy recommendations - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for data encryption
Article
2024-02-05
7 contributors
Feedback
In this article
Applies to Well-Architected Framework Security checklist recommendation:
SE:07
Encrypt data by using modern industry-standard methods to guard confidentiality and integrity. Align encryption scope with data classifications; prioritize native platform encryption methods.
If your data isn't protected, it can be maliciously modified, which leads to loss of integrity and confidentiality.
This guide describes the recommendations for encrypting and protecting your data. Encryption is the process of using cryptography algorithms to
make the data unreadable and lock the data with a key
. In the encrypted state, data can't be deciphered. It can only be decrypted by using a key that's paired with the encryption key.
Definitions
Terms
Definition
Certificates
Digital files that hold the public keys for encryption or decryption.
Cipher suite
A set of algorithms that are used to encrypt and decrypt information to secure a network connection over Transport Layer Security (TLS).
Confidential computing
Confidential Computing is the protection of data in use by performing computation in a hardware-based, attested Trusted Execution Environment.
Decryption
The process in which encrypted data is unlocked with a secret code.
Double encryption
The process of encrypting data by using two or more independent layers of encryption.
Encryption
The process by which data is made unreadable and locked with a secret code.
Hashing
The process of transforming data to text or numbers with the intent of hiding information.
Keys
A secret code that's used to lock or unlock encrypted data.
Signature
An encrypted stamp of authentication on data.
Signing
The process of verifying data's authenticity by using a signature.
X.509
A standard that defines the format of public key certificates.
Key design strategies
Organizational mandates or regulatory requirements might enforce encryption mechanisms. For example, there might be a requirement that data must remain only in the selected region, and copies of the data are maintained in that region.
These requirements are often the base minimum. Strive for a higher level of protection. You're responsible for
preventing confidentiality leaks and tampering of sensitive data
, whether it's external user data or employee data.
Encryption mechanisms likely need to secure the data in three stages:
Data at rest
is all information that's kept in storage objects.
An example of securing data at rest is using BitLocker to encrypt data that's saved to storage on a disk.
Data in transit
is information that's transferred between components, locations, or programs.
An example of securing data in transit is encrypting data with TLS so packets that move over public and private networks are secure.
Data in use
is data that's actively being worked on in memory.
An example of securing data in use is encrypting with confidential computing to protect data as it's processed.
The preceding choices aren't mutually exclusive. They're often used together in the context of the entire solution. One stage might act as a compensating control. For example, you might need to isolate data to prevent tampering when data is read from memory.
Determine encryption requirements
Classify data by its purpose and sensitivity level
to determine what data you need to encrypt. For data that should be encrypted, determine the required level of protection. Do you need end-to-end TLS encryption for all data in transit? For data at rest, which Azure features can meet your requirements? Do you need to double encrypt data at every storage point? How do you implement information protection?
It's important to balance your encryption decisions because there are significant tradeoffs.
Tradeoff
: Every encryption hop can introduce performance latency. Operational complexities can occur in relation to troubleshooting and observability. Recovery can be a challenge.
Scope these tradeoffs. Anticipate tradeoffs for data that's classified as sensitive. Requirements might even determine the tradeoffs, for example if a certain type of data must be encrypted and stored within certain thresholds.
There are cases when encryption isn't possible because of technical limitations, investment, or other reasons. Ensure that those reasons are clear, valid, and documented.
Strong encryption mechanisms shouldn't be your only form of defense. Implement data theft prevention processes, proper testing methods, and anomaly detection.
For information about classification, see
Recommendations on data classification
.
Use native encryption mechanisms
Most Azure services provide a base level of encryption.
Explore platform-provided encryption options
.
It's highly recommended that you don't disable platform capabilities to develop your own functionality. Platform encryption features use modern industry standards, are developed by experts, and are highly tested.
For rare occasions, if you need to replace the platform-provided encryption, evaluate the pros and cons and use industry-standard cryptographic algorithms.
Developers should use cryptography APIs that are built into the operating system rather than nonplatform cryptography libraries. For .NET, follow the
.NET cryptography model
.
Choose an encryption keys approach
By default, Azure services use Microsoft-managed encryption keys to encrypt and decrypt data. Azure is responsible for key management.
You can opt for
customer-managed keys
. Azure still uses your keys, but you're accountable for key operations.
You have the flexibility to change keys
when you want. Decryption is a compelling reason to use customer-managed keys.
You should
pair strong encryption with strong decryption
. From a security perspective, protecting a decryption key is important because rotation is a common way to control the blast radius if a key is compromised. Monitor access to detect anomalous access and activities.
Store keys separate from encrypted data
. This decoupling helps ensure that the compromise of one entity doesn't affect the other. If you use customer-managed keys, store them in a key store. Store highly sensitive data in a managed hardware security module (HSM).
Both stores are protected with identity-based access. This feature enables you to deny access, even to the platform.
Use standard encryption algorithms
Use cryptography algorithms that are well-established and follow industry standards
instead of creating custom implementations.
Industry standards for algorithms require encryption schemes to have a certain level of entropy. The entropy sources are injected during encryption. Entropy makes the algorithm strong and makes it difficult for an attacker to extract information.
Determine the tolerable thresholds of entropy
. Encryption procedures are processor-intensive. Find the right balance so that you're maximizing the compute cycles that are spent on the encryption, relative to the overall performance targets of the compute request.
Tradeoff
: If you choose an algorithm that's highly complex or injects more than a reasonable amount of entropy, it degrades your system's performance.
Use hashes and checksums
Typically, hashing is an error detection technique. You can also use hashing for security because it
detects changes to data that might be caused by tampering
. Hash functions are based on cryptography, but they don't use keys. Hash functions use algorithms to produce checksums. Checksums can compare data to verify the integrity of it.
Applications should use the SHA-2 family of hash algorithms, such as SHA-256, SHA-384, or SHA-512.
Encrypt data at rest
Classify and protect information storage objects in accordance with the internal and external compliance requirements. See the following recommendations:
Encrypt data by using native options
that are provided for storage services, data stores, and other resources that are used to persist data. Encrypt this data even if you store data in these storage services or resources only temporarily. Also encrypt your backup data to maintain the same level of security as the original source.
For more information, see
Data at rest protection
.
Use double encryption
. If your business requirements call for higher assurance, you can perform double encryption. Encrypt data in two or more layers by using independent customer-managed keys. Store the data in a managed HSM. To read the data, you need access to both keys. If one key is compromised, the other key still protects the data. This technique aims to increase attacker costs.
You can also use platform-provided encryption to double encrypt data. Platform-provided encryption protects the storage media at the infrastructure level, and you apply another layer of encryption at the data level. For example, a message broker service has platform-provided encryption via Microsoft-managed keys that protects the message pipe. This method allows you to encrypt the messages with customer-managed keys.
Use more than one encryption key. Use a key encryption key (KEK) to protect your data encryption key (DEK).
Use identity-based access controls to control access to data
. Add network firewalls to provide an extra layer of security that blocks unexpected and unsafe access.
For more information, see
Recommendations for identity and access management
.
Store keys in a managed HSM
that has least-privilege access control. Separate the data from the keys to the data.
Store limited amount of data
so that you only encrypt what's necessary. Your data shouldn't live longer than your encryption cycle. When data is no longer needed, delete the encrypted data without spending decryption cycles.
Encrypt data in transit
Use secure protocols for client-server communication
. Transport protocols have a built-in layer of security. TLS is the industry standard for exchanging data between client and server endpoints.
Don't use versions lower than TLS 1.2. Migrate solutions to support TLS 1.2, and use this version by default. All Azure services support TLS 1.2 on public HTTPS endpoints.
Risk
: Older clients that don't support TLS 1.2 might not work properly if backward compatibility isn't supported.
All website communication should use HTTPS, regardless of the sensitivity of the transferred data. During a client-server handshake, negotiate the use of the HTTP Strict Transport Security (HSTS) policy so that HTTPS transport is maintained and doesn't drop to HTTP during communication. This policy protects against man-in-the-middle attacks.
Support for HSTS is for newer versions. You might break backward compatibility with older browsers.
Note
You can also encrypt protocols to establish secure connections for databases. For example, Azure SQL Database supports the Tabular Data Stream (TDS) protocol, which integrates a TLS handshake.
A cipher suite is a set of algorithms that are used to standardize the handshake between the client and the server. The ciphers ensure that the exchange is encrypted and authenticated. The choice of ciphers depends on the TLS version that the server uses. For some services, such as Azure Application Gateway, you can choose the version of TLS and the cipher suites that you want to support. Implement cipher suites that use the Advanced Encryption Standard (AES) as a symmetric block cipher. AES-128, AES-192, and AES-256 are acceptable.
Manage the lifecycle of certificates
. Certificates have a predetermined lifespan. Don't keep long-lived certificates, and don't let them expire on their own. Implement a process that renews certificates at an acceptable frequency. You can automate the process for renewals that occur at short intervals.
Note
If you use
certificate pinning
, familiarize yourself with the agility and certificate management limitations.
Your workflow shouldn't allow invalid certificates to be accepted in the environment. The certificate pinning process should validate certificates and enforce that validation check. You should monitor access logs to ensure that the signing key is used with proper permissions.
If a key is compromised, the certificate must be revoked immediately. A certificate authority (CA) provides a certificate revocation list (CRL) that indicates the certificates that are invalidated before their expiration. Your validation check should account for CRLs.
Tradeoff
: The certification validation process can be cumbersome and usually involves a CA. Determine the data that you must encrypt with certificates. For other types of communication, determine if you can implement localized compensating controls to add security.
One way of localizing controls is with mutual TLS (mTLS). It establishes trust in both directions between the client and the server. Both the client and the server have their own certificates, and each certificate is authenticated with their public or private key pair. With mTLS, you're not dependent on the external CA. The tradeoff is the added complexity of managing two certificates.
Double encrypt VPN connections if needed
. Perform double encryption to add defense in depth to your VPN tunnel. When you use two VPN servers, you can hide the IP address between the servers, and also hide the IP address between the server and the destination. During this process, data in transit is also encrypted twice.
Tradeoff
: Compared to single VPN setups, double VPN setups are often more expensive, and connections are often slower.
Implement logging and monitoring processes
. Keep track of access sign-in resources that store information about clients, like their source IP, port, and protocol. Use this information to detect anomalies.
Encrypt data in use
For high security workloads, segmentation, isolation and least-priviledge are recommended design patterns.
In the context of in-use protection, hardware boundaries may require encryption of data while it's in use in the physical CPU and memory to ensure isolation of VMs, host management code and other components. Encryption and decryption of data must only be done within those isolation boundaries.
More stringent security or regulatory requirements may also require hardware based, cryptographically signed evidence that data is being encrypted while in-use, this can be obtained through
attestation
.
Confidential computing
is one such technology that supports the requirement. Specific services in Azure offer the ability to protect data while it's being computed-upon. For more information, see
Azure Facilitation: Azure Confidential Compute
.
Consider the end-end lifecycle of data you are protecting
data often moves through multiple systems in its lifetime, take care to ensure that all component parts of a solution can provide the required levels of protection, or ensure that your data management strategy provides appropriate segmentation or masking.
Azure facilitation
The following sections describe Azure services and features that you can use to encrypt your data.
Customer-managed keys
Store customer-managed keys in Azure Key Vault or in a Key Vault-managed HSM.
Key Vault treats the keys like any other secret. Azure role-based access controls (RBAC) access the keys via a permission model. This identity-based control must be used with Key Vault access policies.
For more information, see
Provide access to Key Vault keys, certificates, and secrets by using RBAC
.
Azure Key Vault Premium and Managed-HSM further enhances the offering by including confidential computing capabilites and
Secure Key Release
which supports a policy to ensure that a key is only ever released to a workload that can cryptographically prove it is executing inside a Trusted Execution Environment (TEE).
Data-at-rest protection
Azure Storage
automatically encrypts your data with block ciphers when the data is persisted to a storage account. For Azure Blob Storage and Azure Queue Storage, Storage also provides client-side encryption via libraries.
For more information, see
Storage encryption
.
Azure Virtual Machines
has disk files that serve as virtual storage volumes. You can encrypt the virtual disk files so the contents can't be accessed.
Managed disks can be exported from the portal. Server-side encryption and encryption at host can protect data only after it's exported. However, you should protect data during the export process. You can use
Azure Disk Encryption
to protect and safeguard your data during the export process.
Azure offers several encryption options for managed disks. For more information, see
Overview of managed disk encryption options
.
SQL Database
offers a
transparent data encryption
feature that's used to encrypt a database file at the page level.
Data-in-transit protection
With
Key Vault
, you can provision, manage, and deploy public and private Secure Sockets Layer (SSL) or TLS certificates. You can use the certificates with Azure and with your internal connected resources.
Data-in-use protection
Specific services in Azure
offer the ability to protect data while being computed within the physical CPU and memory of a host using Azure confidential computing.
Confidential Virtual Machines
offer an entire
virtual machine running inside a TEE
, the memory and executing CPU contents of the virtual machine are encrypted offering a simple 'lift & shift' approach for moving unmodified applications with high security requirements to Azure. Each Azure confidential VM has its own dedicated virtual
Trust Platform Module (TPM)
. Encryption is performed while the operating system components securely boot.
Confidential AKS worker nodes, Confidential Containers on AKS or Confidential Containers on Azure Container Instances (ACI)
offer the ability to
run and manage unmodified containers inside a TEE
which enables customers to benefit from in-use protection. Container offerings are built-upon Confidential Virtual Machines and benefit from the same protections.
Application Enclave
solutions are specially built applications taking advantage of specific CPU extensions offered by virtual machine SKUs that support Intel Software Guard Extensions (SGX), these offer a very granular
Trusted Compute Base (TCB)
but require applications to be specifically coded to take advantage of the features.
Secure Key Release
can be
combined with these technologies
to ensure that encrypted data is only ever decrypted inside a TEE which proves it provides the required level of protection through a process known as
Attestation
.
Secret management
You can use
Key Vault
to securely store and control access to tokens, passwords, certificates, API keys, and other secrets. Use Key Vault as a key and certificate management solution. Premium SKU supports HSMs.
Example
The following example shows encryption solutions that you can use to manage keys, certificates, and secrets.
Related links
.NET cryptography model
Azure Disk Encryption
Storage encryption for data at rest
Certificate pinning in Azure services
Provide access to Key Vault keys, certificates, and secrets by using RBAC
Overview of managed disk encryption options
Transparent data encryption
Trust Platform Module overview
Azure confidential computing
Community links
Key Vault overview
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for establishing a security baseline - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for establishing a security baseline
Article
2023-11-14
5 contributors
Feedback
In this article
Applies to Azure Well-Architected Framework Security checklist recommendation:
SE:01
Establish a security baseline aligned to compliance requirements, industry standards, and platform recommendations. Regularly measure your workload architecture and operations against the baseline to sustain or improve your security posture over time.
This guide describes the recommendations for establishing a security baseline. A security baseline is a document that specifies your organization's bare minimum security requirements and expectations across a range of areas. A good security baseline helps you:
Keep your data and systems secure.
Comply with regulatory requirements.
Minimize risk of oversight.
Reduce the likelihood of breaches and subsequent business effects.
Security baselines should be published widely throughout your organization so that all stakeholders are aware of the expectations.
This guide provides recommendations about setting a security baseline that's based on internal and external factors. Internal factors include business requirements, risks, and asset evaluation. External factors include industry benchmarks and regulatory standards.
Definitions
Term
Definition
Baseline
The minimum level of security affordances that a workload must have to avoid being exploited.
Benchmark
A standard that signifies the security posture that the organization aspires to. It's evaluated, measured, and improved over time.
Controls
Technical or operational controls on the workload that help prevent attacks and increase attacker costs.
Regulatory requirements
A set of business requirements, driven by industry standards, that laws and authorities impose.
Key design strategies
A security baseline is a structured document that defines a set of security criteria and capabilities that the workload must fulfill in order to increase security. In a more mature form, you can extend a baseline to include a set of policies that you use to set guardrails.
The baseline should be considered the standard for measuring your security posture. The goal should always be full attainment while keeping a broad scope.
Your security baseline should never be an ad-hoc effort. Industry standards, compliance (internal or external) or regulatory requirements, regional requirements, and the cloud platform benchmarks are main drivers for the baseline. Examples include Center for Internet Security (CIS) Controls, National Institute of Standards and Technology (NIST), and platform-driven standards, such as Microsoft cloud security benchmark (MCSB). All of these standards are considered a starting point for your baseline. Build the foundation by incorporating security requirements from the business requirements.
For links to the preceding assets, see
Related links
.
Create the baseline by gaining consensus among business and technical leaders. The baseline shouldn't be restricted to technical controls. It should also include the operational aspects of managing and maintaining the security posture. So, the baseline document also serves as the organization's commitment to investment toward workload security. The security baseline document should be distributed widely within your organization to ensure there's awareness about the workload's security posture.
As the workload grows and the ecosystem evolves, it's vital to keep your baseline in synch with the changes to ensure the fundamental controls are still effective.
Creating a baseline is a methodical process. Here are some recommendations about the process:
Asset inventory
. Identify stakeholders of workload assets and the security objectives for those assets. In the asset inventory, classify by security requirements and criticality. For information about data assets, see
Recommendations on data classification
.
Risk assessment
. Identity potential risks associated with each asset and prioritize them.
Compliance requirements
. Baseline any regulatory or compliance for those assets and apply industry best practices.
Configuration standards
. Define and document specific security configurations and settings for each asset. If possible, templatize or find a repeatable, automated way to apply the settings consistently across the environment.
Access control and authentication
. Specify the role-based access control (RBAC) and multifactor authentication (MFA) requirements. Document what
just enough access
means at the asset level. Always start with the principle of least privilege.
Patch management
. Apply latest versions on all the resource types to strengthen against attack.
Documentation and communication
. Document all configurations, policies, and procedures. Communicate the details to the relevant stakeholders.
Enforcement and accountability
. Establish clear enforcement mechanisms and consequences for noncompliance with the security baseline. Hold individuals and teams accountable for maintaining security standards.
Continuous monitoring
. Assess the effectiveness of the security baseline through observability and make improvements overtime.
Define the baseline
Here are some common categories that should be part of a baseline. The following list isn't exhaustive. It's intended as an overview of the document's scope.
Regulatory compliance
A workload might be subject to regulatory compliance for specific industry segments, there might be some geographic restrictions, and so on. It's key to understand the requirements as given in the regulatory specifications because those influence the design choices and in some cases must be included in the architecture.
The baseline should include regular evaluation of the workload against regulatory requirements. Take advantage of the platform-provided tools, such as Microsoft Defender for Cloud, which can identify areas of noncompliance. Work with the organization's compliance team to make sure all requirements are met and maintained.
Architecture components
The baseline needs prescriptive recommendations for the main components of the workload. These usually include technical controls for networking, identity, compute, and data. Reference the security baselines provided by the platform and add the missing controls to the architecture.
Refer to
Example
.
Development processes
The baseline must have recommendations about:
System classification.
The approved set of resource types.
Tracking the resources.
Enforcing policies for using or configuring resources.
The development team needs to have a clear understanding of the scope for security checks. For example, threat modeling is a requirement in making sure that potential threats are identified in code and in deployment pipelines. Be specific about static checks and vulnerability scanning in your pipeline and how regularly the team needs to perform those scans.
For more information, see
Recommendations on threat analysis
.
The development process should also set standards on various testing methodologies and their cadence. For more information, see
Recommendations on security testing
.
Operations
The baseline must set standards on using threat detection capabilities and raising alerts on anomalous activities that indicate actual incidents. Threat detection needs to include all layers of the workload, including all the endpoints that are reachable from hostile networks.
The baseline should include recommendations for setting up incident response processes, including communication and a recovery plan, and which of those processes can be automated to expedite detection and analysis. For examples, see
Security baselines for Azure overview
.
The incident response should also include a recovery plan and the requirements for that plan, such as resources for regularly taking and protecting backups.
You develop data breach plans by using industry standards and recommendations provided by the platform. The team then has a comprehensive plan to follow when a breach is discovered. Also, check with your organization to see if there's coverage through cyberinsurance.
Training
Develop and maintain a security training program to ensure the workload team is equipped with the appropriate skills to support the security goals and requirements. The team needs fundamental security training, but use what you can from your organization to support specialized roles. Role-based security training compliance and participation in drills are part of your security baseline.
Apply the baseline
Use the baseline to drive initiatives, such as:
Preparedness toward design decisions
. Create the security baseline and publish it before you start the architecture design process. Ensure team members are fully aware of your organization's expectations early, which avoids costly rework caused by a lack of clarity. You can use baseline criteria as workload requirements that the organization has committed to and design and validate controls against those constraints.
Measure your design
. Grade the current decisions against the current baseline. The baseline sets actual thresholds for criteria. Document any deviations that are deferred or deemed long-term acceptable.
Drive improvements
. While the baseline sets attainable goals, there are always gaps. Prioritize the gaps in your backlog and remediate based on prioritization.
Track your progress against the baseline
. Continuous monitoring of security measures against a set baseline is essential. Trend analysis is a good way of reviewing security progress over time and can reveal consistent deviations from the baseline. Use automation as much as possible, pulling data from various sources, internal and external, to address current issues and prepare for future threats.
Set guardrails
. Where possible, your baseline criteria must have guardrails. Guardrails enforce required security configurations, technologies, and operations, based on internal factors and external factors. Internal factors include business requirements, risks, and asset evaluation. External factors include benchmarks, regulatory standards, and threat environment. Guardrails help minimize the risk of inadvertent oversight and punitive fines for noncompliance.
Explore Azure Policy for custom options or use built-in initiatives like CIS benchmarks or Azure Security Benchmark to enforce security configurations and compliance requirements. Consider creating Azure Policies and initiatives out of baselines.
Evaluate the baseline regularly
Continuously improve security standards incrementally towards the ideal state to ensure continual risk reduction. Conduct periodic reviews to ensure that the system is up-to-date and in compliance with external influences. Any change to the baseline must be formal, agreed upon, and sent through proper change management processes.
Measure the system against the new baseline and prioritize remediations based on their relevance and effect on the workload.
Ensure that the security posture doesn't degrade over time by instituting auditing and monitoring compliance with organizational standards.
Azure facilitation
The Microsoft cloud security benchmark (MCSB) is a comprehensive security best practice framework that you can use as a starting point for your security baseline. Use it along with other resources that provide input to your baseline.
For more information, see
Introduction to the Microsoft cloud security benchmark
.
Use the Microsoft Defender for Cloud (MDC) regulatory compliance dashboard to track those baselines and be alerted if a pattern outside of a baseline is detected. For more information, see the
Customize the set of standards in your regulatory compliance dashboard
.
Other features that help in establishing and improving the baseline:
Create custom Azure security policies
Understand security policies, initiatives, and recommendations
Regulatory compliance checks
Example
This logical diagram shows an example security baseline for architectural components that encompass network, infrastructure, endpoint, application, data, and identity to demonstrate how a common IT environment may be securely protected. Other recommendation guides build on this example.
Infrastructure
A common IT environment, with an on-premises layer with basic resources.
Azure Security services
Azure security services and features by the types of resources they protect.
Azure security monitoring services
The monitoring services available on Azure that go beyond simple monitoring services, including  security information event management (SIEM) and security orchestration automated response (SOAR) solutions and Microsoft Defender for Cloud.
Threats
This layer brings a recommendation and reminder that threats may be mapped according to your organization's concerns regarding threats, regardless of the methodology or matrix-like Mitre Attack Matrix or Cyber Kill chain.
Related links
Microsoft compliance
Security baselines for Azure overview
What is incident response? Plan and steps
Azure Security benchmarks
Community links
CIS Microsoft Azure Foundations Benchmark
Cybersecurity framework | NIST
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for hardening resources - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for hardening resources
Article
2023-11-15
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:08
Harden all workload components by reducing extraneous surface area and tightening configurations to increase attacker cost.
This guide describes the recommendations for hardening resources by developing localized controls within a workload and maintaining them to withstand repeated attacks.
Security hardening is an intentional self-preservation exercise. The goal is to
reduce an attack surface
and
increase attackers' costs in other areas
, which limits opportunities for malicious actors to exploit vulnerabilities. To protect your workload, implement security best practices and configurations.
Security hardening is an ongoing process
that requires continuous monitoring and adaptation to evolving threats and vulnerabilities.
Definitions
Term
Definition
Hardening
The practice of reducing an attack surface area by removing extraneous resources or adjusting configurations.
Privileged access workstation (PAW)
A dedicated and secure machine that you use to perform sensitive tasks, which reduces the risk of compromise.
Secure administrative workstation (SAW)
A specialized PAW that's used by critical impact accounts.
Surface area
A logical footprint of a workload that contains vulnerabilities.
Key design strategies
Security hardening is a highly localized exercise that
strengthens controls at the component level
, whether it's resources or processes. When you tighten the security of each component, it improves the aggregate security assurance of your workload.
Security hardening doesn't consider the functionality of the workload, and it doesn't detect threats or perform automated scanning.
Security hardening focuses on configuration tuning with an assume-breach and defense-in-depth mentality.
The goal is to make it difficult for an attacker to gain control of a system. Hardening shouldn't alter the intended utility of a workload or its operations.
Build an inventory of workload assets
The first step of the hardening process is to gather a comprehensive inventory of all hardware, software, and data assets. Keep your inventory records up to date by adding new assets and removing decommissioned assets. For all assets in your inventory, consider the following best practices:
Reduce the footprint
. Remove extraneous surface area or reduce the scope.
Eliminate easy targets
, or cheap and well-established attack vectors, such as unpatched software exploits and brute force attacks. Prior to the production deployment, you should clean identities, build components, and other nonrequired assets from the source tree.
Fine-tune configurations
. Evaluate and
tighten the remaining surface area
. When resources are hardened, tried and tested methods that attackers use are no longer successful. It forces attackers to acquire and use advanced or untested attack methods, which increases their costs.
Maintain defenses
. Maintain protective measures by performing
continuous threat detection
to help ensure that hardening efforts are dependable over time.
Also consider the following factors.
Trusted source.
Part of the hardening exercise involves the software supply chain. This guidance assumes that
all components are obtained from trusted sources
. Your organization must approve software that's procured from third-party vendors. This approval applies to sources of the operating system, images, and other third-party tools. Without trusted resources, hardening can be an infinite drain of security assurances on untrusted sources.
For recommendations about security for your supply chain, see
Recommendations for securing a development lifecycle
.
Training.
Hardening is a specialized skill. It's methodical and requires a high level of competency. You need to understand the functionality of a component and how changes affect the component. A team member must be able to discern the guidance that's from industry experts and the platform to distinguish it from guidance from uncertain sources. Educate your team members in creating a security-aware culture. Ensure that your team is
proficient in security best practices, has awareness of potential threats, and learns from post-incident retrospectives
.
Documentation.
Document and publish hardening requirements, decisions, and defined methods. For transparency, also
document exceptions or deviations
from those requirements.
Hardening can be cumbersome, but it's a crucial security exercise that you must document. Harden the core components first, and then expand to other areas, such as automated processes and human processes, to tighten up potential gaps. Be meticulous about changes. For example, a necessary step is to disable the default settings because changes to default values can affect the stability of the system. Even if the replacement configuration is the same as the default, it must be defined. The following sections describe common targets for hardening. Evaluate key design areas of your workload and follow the key strategies to harden at a component level.
Harden networking components
Divide the network into segments
to isolate critical assets and sensitive data from less secure assets, which reduces lateral movements by attackers. In those segments, apply a
deny-by-default
approach. Only add access to the allowlist if it's justified.
Disable ports and protocols that aren't actively used
. For example, on Azure App Service, if you don't need to deploy via FTP, you can disable it. Or if you perform management operations via an internal network, you can disable administrative access from the internet.
Remove or disable legacy protocols
. Attackers exploit systems that use old versions. Use an Azure detection service to review logs and determine protocol usage. It might be difficult to remove protocols because it can disrupt the functionality of the system. Test all changes before implementation to mitigate the risk of operational interruption.
Treat public IP (PIP) addresses as high-risk assets
because they're easy to access and have a broad worldwide reach. To reduce exposure, remove unnecessary internet access to the workload. Use shared public IP addresses that Microsoft services, like Azure Front Door, provide. These services are designed to be internet-facing, and they block access to disallowed protocols. Many such services perform initial checks on incoming requests at the network edge. With a dedicated PIP, you're responsible for managing its security aspects, allowing or blocking ports, and scanning incoming requests to ensure their validity.
For internet-facing applications,
restrict access by adding a layer-7
service that can filter invalid traffic. Explore native services that enforce distributed denial-of-service (DDoS) protection, have web application firewalls, and provide protection at the edge before traffic reaches the application tier.
Domain Name System (DNS) hardening is another network security practice. To ensure that the DNS infrastructure is secure, we recommend that you
use trusted DNS resolvers
. To validate information from DNS resolvers and provide an extra layer of security, when possible, use a DNS security protocol for highly sensitive DNS zones. To prevent attacks such as DNS cache poisoning, DDoS attacks, and amplification attacks, explore other DNS-related security controls such as query rate limiting, response rate limiting, and DNS cookies.
Harden identity access controls
Remove unused or default accounts.
Disable unused authentication and authorization methods.
Disable legacy authentication methods
because they're frequently attack vectors. Old protocols often lack attack-counter measures, such as account lockouts. Externalize your authentication requirements to your identity provider (IdP), such as Microsoft Entra ID.
Prefer federation over creating duplicate identities.
If an identity is compromised, it's easier to revoke its access when it's centrally managed.
Understand platform capabilities
for enhanced authentication and authorization. Harden access controls by taking advantage of multifactor authentication, passwordless authentication, Conditional Access, and other features that Microsoft Entra ID offers to verify identity. You can add extra protection around sign-in events and reduce the scope in which an attacker can make a request.
Use managed identities
and workload identities with no credentials where possible. Credentials can be leaked. For more information, see
Recommendations for protecting application secrets
.
Use the least-privilege approach for your management processes.
Remove unnecessary role assignments and perform regular Microsoft Entra access reviews. Use role assignment descriptions to keep a paper trail of justifications, which is crucial for audits.
Harden cloud resource configurations
The preceding hardening recommendations for networking and identity apply to individual cloud services. For networking, pay special attention to
service-level firewalls
, and evaluate their inbound rules.
Discover and disable unused capabilities
or features, such as unused data plane access and product features, that other components might cover. For example, App Service supports Kudu, which provides FTP deployments, remote debugging, and other features. If you don't need those features, turn them off.
Always
keep up with the Azure roadmap and the workload roadmap
. Apply patching and versioning updates that Azure services offer. Allow platform-provided updates, and subscribe to automated update channels.
Risk
: Cloud resources often have requirements for allowances or must run in documented configurations to be considered
supported
. Some hardening techniques, such as aggressively blocking outbound traffic, can cause a service to fall outside a supported configuration, even if the service operates normally. Understand each cloud resource's runtime requirements from your platform to ensure that you maintain support for that resource.
Harden code assets
Evaluate areas where your application might inadvertently leak information. For example, suppose you have an API that retrieves user information. A request might have a valid user ID, and your application returns a 403 error. But with an invalid customer ID, the request returns a 404 error. Then you're effectively leaking information about your user IDs.
There might be more subtle cases. For example, the response latency with a valid user ID is higher than an invalid customer ID.
Consider implementing application hardening in the following areas:
Input validation and sanitization
: Prevent injection attacks such as SQL injection and cross-site scripting (XSS) by validating and sanitizing all user inputs. Automate input sanitization by using input validation libraries and frameworks.
Session management
: Protect session identifiers and tokens from theft or session fixation attacks by using secure session management techniques. Implement session timeouts, and enforce reauthentication for sensitive actions.
Error management
: Implement custom error handling to minimize exposing sensitive information to attackers. Securely log errors and monitor these logs for suspicious activity.
HTTP security headers
: Mitigate common web vulnerabilities by utilizing security headers in HTTP responses, such as the Content Security Policy (CSP), X-Content-Type-Options, and X-Frame-Options.
API security
: Secure your APIs with proper authentication and authorization mechanisms. To further enhance security, implement rate limiting, request validation, and access controls for API endpoints.
Follow secure coding practices when you develop and maintain applications. Regularly conduct code reviews and scan applications for vulnerabilities. For more information, see
Recommendations for securing a development lifecycle
.
Harden management operations
Also harden other non-runtime resources. For example,
reduce your build operations footprint
by taking an inventory of all assets and removing unused assets from your pipeline. Then,
pull in tasks that are published by trusted sources
, and only run tasks that are validated.
Determine if you need Microsoft-hosted or self-hosted build agents.
Self-hosted build agents need extra management and must be hardened
.
From an observability perspective,
implement a process for reviewing logs
for potential breaches. Regularly review and update access control rules based on access logs. Work with central teams to analyze security information event management (SIEM) and security orchestration automated response (SOAR) logs to detect anomalies.
Consider requiring PAWs or SAWs for privileged management operations. PAWs and SAWs are hardened physical devices that offer significant security advantages, but their implementation requires careful planning and management. For more information, see
Securing devices as part of the privileged access story
.
Azure facilitation
Microsoft Defender for Cloud offers several hardening capabilities:
Server hardening
Adaptive network hardening
Docker host hardening
The Center for Internet Security (CIS) offers hardened images in Azure Marketplace.
You can use Azure VM Image Builder to build a repeatable process for hardened OS images. Common Base Linux-Mariner is a hardened Linux distribution that's developed by Microsoft that follows security standards and industry certifications. You can use it with Azure infrastructure products to build workload implementations.
Example
The following procedure is an example of how to harden an operating system:
Reduce the footprint
. Remove unnecessary components in an image. Install only what you need.
Fine-tune configurations
. Disable unused accounts. The default configuration of operating systems has extra accounts that are linked to security groups. If you don't use those accounts, disable or remove them from the system. Extra identities are threat vectors that can be used to gain access to the server.
Disable unnecessary access to the file system. Encrypt the file system and fine-tune access controls for identity and networking.
Run only what's needed. Block applications and services that run by default. Approve only applications and services that are needed for workload functionality.
Maintain defenses
. Regularly update operating system components with the latest security updates and patches to mitigate known vulnerabilities.
Related links
Adaptive network hardening
Recommendations for protecting application secrets
Recommendations for securing a development lifecycle
Securing devices as part of the privileged access story
Server hardening
Community links
CIS benchmarks
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for identity and access management - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for identity and access management
Article
2023-11-15
9 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:05
Implement strict, conditional, and auditable identity and access management (IAM) across all workload users, team members, and system components. Limit access exclusively to
as necessary
. Use modern industry standards for all authentication and authorization implementations. Restrict and rigorously audit access that's not based on identity.
This guide describes the recommendations for authenticating and authorizing identities that are attempting to access your workload resources.
From a technical control perspective,
identity is always the primary perimeter
. This scope doesn't just include the edges of your workload. It also includes individual components that are inside your workload. Typical identities include:
Humans
. Application users, admins, operators, auditors, and bad actors.
Systems
. Workload identities, managed identities, API keys, service principals, and Azure resources.
Anonymous
. Entities who haven't provided any evidence about who they are.
Definitions
Terms
Definition
Authentication (AuthN)
A process that verifies that an identity is who or what it says it is.
Authorization (AuthZ)
A process that verifies whether an identity has permission to perform a requested action.
Conditional access
A set of rules that allows actions based on specified criteria.
IdP
An identity provider, like Microsoft Entra ID.
Persona
A job function or a title that has a set of responsibilities and actions.
Preshared keys
A type of secret that's shared between a provider and consumer and used through a secure and agreed upon mechanism.
Resource identity
An identity defined for cloud resources that's managed by the platform.
Role
A set of permissions that define what a user or group can do.
Scope
Different levels of organizational hierarchy where a role is permitted to operate. Also a group of features in a system.
Security principal
An identity that provides permissions. It can be a user, a group, or a service principal. Any group members get the same level of access.
User identity
An identity for a person, like an employee or an external user.
Workload identity
A system identity for an application, service, script, container, or other component of a workload that's used to authenticate itself to other services and resources.
Note
An identity can be grouped with other, similar identities under a parent called a
security principal
. A security group is an example of a security principal. This hierarchical relationship simplifies maintenance and improves consistency. Because identity attributes aren't handled at the individual level, chances of errors are also reduced. In this article, the term
identity
is inclusive of security principals.
The role of an identity provider
An identity provider (IdP) is a cloud-hosted service that stores and manages users as digital identities.
Take advantage of the capabilities provided by a trusted IdP
for your identity and access management. Don't implement custom systems to replace an IdP. IdP systems are improved frequently based on the latest attack vectors by capturing billions of signals across multiple tenants each day. Microsoft Entra ID is the IdP for Azure cloud platform.
Authentication
Authentication is a process that verifies identities. The requesting identity is required to provide some form of verifiable identification. For example:
A user name and password.
A preshared secret, like an API key that grants access.
A shared access signature (SAS) token.
A certificate that's used in TLS mutual authentication.
As much as possible, the verification process should be handled by your IdP.
Authorization
Authorization is a process that allows or denies actions that are requested by the verified identity. The action might be operational or related to resource management.
Authorization requires that you assign permissions to the identities, which you need to do by using the functionality provided by your IdP.
Key design strategies
To get a holistic view of the identity needs for a workload, you need to catalog the flows, workload assets, and personas, and the actions the assets and personas will perform. Your strategy must cover all use cases that handle
the flows that reach the workload or its components (outside-in access) and flows that reach out from the workload to other sources (inside-out access)
.
Each use case will probably have its own set of controls that you need to design with an assume-breach mindset. Based on the identity requirements of the use case or the personas, identify the conditional choices. Avoid using one solution for all use cases. Conversely, the controls shouldn't be so granular that you introduce unnecessary management overhead.
You need to log the identity access trail. Doing so helps validate the controls, and you can use the logs for compliance audits.
Determine all identities for authentication
Outside-in access
. Your identity design must authenticate all users that access the workload for various purposes. For example, an end user who accesses the application by calling APIs.
At a granular level, components of the workload might also need access from outside. For example, an operator who needs access through the portal or access to the compute to run commands.
Both are examples of
user identities
that have different personas.
Inside-out access
. Your application will need to access other resources. For example, reading from or writing to the data platform, retrieving secrets from the secret store, and logging telemetry to monitoring services. It might even need to access third-party services. These access needs require
workload identity
, which enables the application to authenticate itself against the other resources.
The concept applies at the component level. In the following example, the container might need access to deployment pipelines to get its configuration. These access needs require
resource identity
.
All these identities should be authenticated by your IdP.
Here's an example of how identity can be implemented in an architecture:
Determine actions for authorization
Next, you need to know what each authenticated identity is trying to do so that those actions can be authorized. The actions can be divided by the type of access that they require:
Data plane access
. Actions that take place in the data plane cause data transfer for inside-out or outside-in access. For example, an application reading data from a database and writing data to a database, fetching secrets, or writing logs to a monitoring sink. At the component level, compute that's pulling or pushing images to or from a registry are considered data plane operations.
Control plane access
. Actions that take place in the control plane cause an Azure resource to be created, modified, or deleted. For example, changes to resource properties.
Applications typically target data plane operations, while operations often access both control and data planes. To identify authorization needs, note the operational actions that can be performed on the resource. For information about the permitted actions for each resource, see
Azure resource provider operations
.
Provide role-based authorization
Based on the responsibility of each identity, authorize actions that should be permitted.
An identity must not be allowed to do more than it needs to do
. Before you set authorization rules, you need to have a clear understanding of who or what is making requests, what that role is allowed to do, and to what extent it can do it. Those factors lead to choices that combine identity, role, and scope.
Consider a workload identity as an example. The application must have data plane access to the database, so read and write actions to the data resource must be allowed. However, does the application need control plane access to the secret store? If the workload identity is compromised by a bad actor, what would the impact to the system be, in terms of confidentiality, integrity, and availability?
Role assignment
A role is a
set of permissions
that's assigned to an identity. Assign roles that only allow the identity to complete the task, and no more. When user's permissions are restricted to their job requirements, it's easier to identify suspicious or unauthorized behavior in the system.
Ask questions like these:
Is read-only access enough?
Does the identity need permissions to delete resources?
Limiting the level of access that users, applications, or services have to Azure resources reduces the potential attack surface.
If you grant only the minimum permissions that are required to perform specific tasks, the risk of a successful attack or unauthorized access is significantly reduced. For example, security teams only need read-only access to security attributes for all technical environments. That level is enough to assess risk factors, identify potential mitigations, and report on the risks.
There are scenarios in which users need more access because of the organizational structure and team organization. There might be an overlap between various roles, or single users might perform multiple standard roles. In this case, use multiple role assignments that are based on the business function instead of creating a custom role for each of these users. Doing so makes the roles easier to manage.
Avoid permissions that specifically reference individual resources or users.
Granular and custom permissions create complexity and confusion because they don't pass on the intention to new resources that are similar. This can create  a complex legacy configuration that's difficult to maintain and negatively impact both security and reliability.
Tradeoff
: A granular access control approach enables better auditing and monitoring of user activities.
A role also has an
associated scope
. The role can operate at the allowed management group, subscription, resource group, or resource scope, or at another custom scope. Even if the identity has a limited set of permissions, widening the scope to include resources that are outside the identity's job function is risky. For example, read access to all source code and data can be dangerous and must be controlled.
You assign roles to identities by using role-based access control (RBAC).
Always use IdP-provided RBAC
to take advantage of features that enable you to apply access control consistently and revoke it rigorously.
Use built-in roles.
They're designed to cover most use cases. Custom roles are powerful and sometimes useful, but you should reserve them for scenarios in which built-in roles won't work. Customization leads to complexity that increases confusion and makes automation more complex, challenging, and fragile. These factors all negatively impact security.
Grant roles that start with least privilege and add more based your operational or data access needs
. Your technical teams must have clear guidance to implement permissions.
If you want fine-grained control on RBAC, add conditions on the role assignment based on context, such as actions and attributes.
Make conditional access choices
Don't give all identities the same level of access. Base your decisions on two main factors:
Time
. How long the identity can access your environment.
Privilege
. The level of permissions.
Those factors aren't mutually exclusive. A compromised identity that has more privileges and unlimited duration of access can gain more control over the system and data or use that access to continue to change the environment. Constrain those access factors both as a preventive measure and to control the blast radius.
Just in Time (JIT)
approaches provide the required privileges only when they're needed.
Just Enough Access (JEA)
provides only the required privileges.
Although time and privilege are the primary factors, there are other conditions that apply. For example, you can also use the device, network, and location from which the access originated to set policies.
Use strong controls that filter, detect, and block unauthorized access
, including parameters like user identity and location, device health, workload context, data classification, and anomalies.
For example, your workload might need to be accessed by third-party identities like vendors, partners, and customers. They need the appropriate level of access rather than the default permissions that you provide to full-time employees. Clear differentiation of external accounts makes it easier to prevent and detect attacks that come from these vectors.
Your choice of IdP must be able to provide that differentiation, provide built-in features that grant permissions based on the least privilege, and provide built-in threat intelligence. This includes monitoring of access requests and sign-ins. The Azure IdP is Microsoft Entra ID. For more information, see the
Azure facilitation section
of this article.
Protect critical impact accounts
Administrative identities introduce some of the highest impact security risks because the tasks they perform require privileged access to a broad set of these systems and applications. Compromise or misuse can have a detrimental effect on your business and its information systems. Security of administration is one of the most critical security areas.
Protecting privileged access against determined adversaries requires you to take a complete and thoughtful approach to isolate these systems from risks. Here are some strategies:
Minimize the number of critical impact accounts.
Use separate roles
instead of elevating privileges for existing identities.
Avoid permanent or standing access
by using the JIT features of your IdP. For break glass situations, follow an emergency access process.
Use modern access protocols
like passwordless authentication or multifactor authentication. Externalize those mechanisms to your IdP.
Enforce key security attributes by using
conditional access policies
.
Decommission administrative accounts
that aren't being used.
Use a single identity across environments and associate a single identity with the user or principal. Consistency of identities across cloud and on-premises environments reduces human errors and the resulting security risks. Teams in both environments that manage resources need a consistent, authoritative source in order to meet security assurances. Work with your central identity team to ensure that identities in hybrid environments are synchronized.
Risk
: There's a risk associated with synchronizing high privilege identities. An attacker can get full control of on-premises assets, and this can lead to a successful compromise of a cloud account. Evaluate your synchronization strategy by filtering out accounts that can add to the attack surface.
Establish processes to manage the identity lifecycle
Access to identities must not last longer than the resources that the identities access.
Ensure that you have a process for disabling or deleting identities when there are changes in team structure or software components.
This guidance applies to source control, data, control planes, workload users, infrastructure, tooling, the monitoring of data, logs, metrics, and other entities.
Establish an identity governance process
to manage the lifecycle of digital identities, high-privileged users, external/guest users, and workload users. Implement access reviews to ensure that when identities leave the organization or the team, their workload permissions are removed.
Protect nonidentity based secrets
Application secrets like preshared keys should be considered vulnerable points in the system. In the two-way communication, if the provider or consumer is compromised, significant security risks can be introduced. Those keys can also be burdensome because they introduce operational processes.
When you can, avoid using secrets
and consider using identity-based authentication for user access to the application itself, not just to its resources.
The following list provides a summary of guidance. For more information, see
Recommendations for application secrets
.
Treat these secrets as entities that can be dynamically pulled from a secret store. They shouldn't be hard coded in your application code, IaC scripts, deployment pipelines, or in any other artifact.
Be sure that you have the
ability to revoke secrets
.
Apply operational practices that handle tasks like
key rotation and expiration
.
For information about rotation policies, see
Automate the rotation of a secret for resources that have two sets of authentication credentials
and
Tutorial: Updating certificate auto-rotation frequency in Key Vault
.
Keep development environments safe
All code and scripts, pipeline tooling, and source control systems should be considered workload assets.
Access to writes should be gated
with automation and peer review.
Read access to source code should be limited
to roles on a need-to-know basis. Code repositories must have versioning, and
security code reviews
by peers must be a regular practice that's integrated with the development lifecycle. You need to have a process in place that
scans resources regularly
and identifies the latest vulnerabilities.
Use workload identities to grant access to resources from deployment environments, such as GitHub.
Maintain an audit trail
One aspect of identity management is ensuring that the system is auditable. Audits validate whether assume-breach strategies are effective. Maintaining an audit trail helps you:
Verify that identity is authenticated with strong authentication.
Any action must be traceable
to prevent repudiation attacks.
Detect weak or missing authentication protocols
and get visibility into and insights about user and application sign-ins.
Evaluate access from identities to the workload based on security and
compliance requirements
and consider user account risk, device status, and other criteria and policies that you set.
Track progress or deviation
from compliance requirements.
Most resources have data plane access. You need to know the identities that access resources and the actions that they perform. You can use that information for security diagnostics.
For more information, see
Recommendations on security monitoring and threat analysis
.
Azure facilitation
We recommend that you always use modern authentication protocols that take into account all available data points and use conditional access.
Microsoft Entra ID provides identity and access management in Azure
. It covers the management plane of Azure and is integrated with the data planes of most Azure services. Microsoft Entra ID is the tenant that's associated with the workload subscription. It tracks and manages identities and their allowed permissions and simplifies overall management to minimize the risk of oversight or human error.
These capabilities natively integrate into the same Microsoft Entra identity and permission model for user segments:
Microsoft Entra ID
. Employees and enterprise resources.
Microsoft Entra External ID
. Partners.
Azure AD B2C
. Customers.
Microsoft Entra federation compatibility list
. Third-party federation solutions.
You can use Microsoft Entra ID for authentication and authorization of custom applications via Microsoft Authentication Library (MSAL) or platform features, like authentication for web apps. It covers the management plane of Azure, the data planes of most of Azure services, and integration capabilities for your applications.
You can stay current by visiting
What's new in Microsoft Entra ID
.
Tradeoff
: Microsoft Entra ID is a single point of failure just like any other foundational service. There's no workaround until the outage is fixed by Microsoft. However, the rich feature set of Microsoft Entra outweighs the risk of using custom solutions.
Azure supports open protocols like OAuth2 and OpenID Connect. We recommend that you use these standard authentication and authorization mechanisms instead of designing your own flows.
Azure RBAC
Azure RBAC represents security principals in Microsoft Entra ID. All role assignments are done via Azure RBAC. Take advantage of built-in roles that provide most of the permissions that you need. For more information, see
Microsoft Entra built-in roles
.
Here are some use cases:
By assigning users to roles, you can control access to Azure resources. For more information, see
Overview of role-based access control in Microsoft Entra ID
.
You can use Privileged Identity Management to provide time-based and approval-based role activation for roles that are associated with high-impact identities. For more information, see
What is Privileged Identity Management?
.
For more information about RBAC, see
Best practices for Azure RBAC
.
For information about attribute-based controls, see
What is Azure ABAC?
.
Workload identity
Microsoft Entra ID can handle your application's identity.
The service principal that's associated with the application can dictate its access scope.
For more information, see
What are workload identities?
.
The service principal is also abstracted when you use a managed identity.
The advantage is that Azure manages all credentials for the application.
Not all services support managed identities. If you can't use managed identities, you can use service principals. However, using service principals increases your management overhead. For more information, see
What are managed identities for Azure resources?
.
Resource identity
The concept of
managed identities can be extended to Azure resources
. Azure resources can use managed identities to authenticate themselves to other services that support Microsoft Entra authentication. For more information, see
Azure services that can use managed identities to access other services
.
Conditional access policies
Conditional access describes your policy
for an access decision. To use conditional access, you need to understand the restrictions that are required for the use case. Configure Microsoft Entra Conditional Access by setting up an access policy for that's based on your operational needs.
For more information, see
Conditional access: Users, groups, and workload identities
.
Group access management
Instead of granting permissions to specific users, assign access to groups in Microsoft Entra ID. If a group doesn't exist, work with your identity team to create one. You can then add and remove group members outside of Azure and make sure that permissions are current. You can also use the group for other purposes, like mailing lists.
For more information, see
Secure access control using groups in Microsoft Entra ID
.
Threat detection
Microsoft Entra ID Protection can help you detect, investigate, and remediate identity-based risks. For more information, see
What is Identity Protection?
.
Threat detection can take the form of reacting to an alert of suspicious activity or proactively searching for anomalous events in activity logs. User and Entity Behavior Analytics (UEBA) in Microsoft Sentinel makes it easy to detect suspicious activities. For more information, see
Identify advanced threats with UEBA
.
Hybrid systems
On Azure,
don't synchronize accounts to Microsoft Entra ID that have high privileges in your existing Active Directory
. This synchronization is blocked in the default Microsoft Entra Connect Sync configuration, so you only need to confirm that you haven't customized this configuration.
For information about filtering in Microsoft Entra ID, see
Microsoft Entra Connect Sync: Configure filtering
.
Identity logging
Enable diagnostic settings on Azure resources
to emit information that you can use as an audit trail. The diagnostic information shows which identities attempt to access which resources and the outcome of those attempts. The collected logs are sent to Azure Monitor.
Tradeoff
: Logging incurs costs because of the data storage that's used to store the logs. It also might cause a performance impact, especially on the code and on logging solutions that you add to the application.
Example
The following example shows an identity implementation. Different types of identities are used together to provide the required levels of access.
Identity components
System-managed identities
. Microsoft Entra ID provides access to service data planes that don't face users, like Azure Key Vault and data stores. These identities also control access, via RBAC, to the Azure management plane for workload components, deployment agents, and team members.
Workload identities
. The application services in the Azure Kubernetes Service (AKS) cluster use workload identities to authenticate themselves to other components in the solution.
Managed identities
. System components in the client role use system-managed identities, including build agents.
Human identities
. User and operator authentication is delegated to Microsoft Entra ID or Microsoft Entra ID (native, B2B, or B2C).
The security of preshared secrets is critical for any application. Azure Key Vault provides a secure storage mechanism for these secrets, including Redis and third-party secrets.
A rotation mechanism is used to help ensure that secrets aren't compromised. Tokens for the Microsoft identity platform implementation of OAuth 2 and OpenID Connect are used to authenticate users.
Azure Policy is used to ensure that identity components like Key Vault use RBAC instead of access policies. JIT and JEA provide traditional standing permissions for human operators.
Access logs are enabled across all components via Azure Diagnostics, or via code for code components.
Related links
Tutorial: Automate the rotation of a secret for resources that have two sets of authentication credentials
Tutorial: Updating certificate auto-rotation frequency in Key Vault
What's new in Microsoft Entra ID?
Microsoft Entra built-in roles
Overview of role-based access control in Microsoft Entra ID
What are workload identities?
What are managed identities for Azure resources?
Conditional access: Users, groups, and workload identities
Microsoft Entra Connect Sync: Configure filtering
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for security incident response - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for security incident response
Article
2023-11-14
5 contributors
Feedback
In this article
Applies to Azure Well-Architected Framework Security checklist recommendation:
SE:12
Define and test effective incident response procedures that cover a spectrum of incidents, from localized issues to disaster recovery. Clearly define which team or individual runs a procedure.
This guide describes the recommendations for implementing a security incident response for a workload. If there's a security compromise to a system, a systematic incident response approach helps to reduce the time that it takes to identify, manage, and mitigate security incidents. These incidents can threaten the confidentiality, integrity, and availability of software systems and data.
Most enterprises have a central security operation team (also known as Security Operations Center (SOC), or SecOps). The responsibility of the security operation team  is to rapidly detect, prioritize, and triage potential attacks. The team also monitors security-related telemetry data and investigates security breaches.
However, you also have a responsibility to protect your workload. It's important that any communication, investigation, and hunting activities are a collaborative effort between workload team and SecOps team.
This guide provides recommendations for you and your workload team to help you rapidly detect, triage, and investigate attacks.
Definitions
Term
Definition
Alert
A notification that contains information about an incident.
Alert fidelity
The accuracy of the data that determines an alert. High-fidelity alerts contain the security context that's needed to take immediate actions. Low-fidelity alerts lack information or contain noise.
False positive
An alert that indicates an incident that didn't happen.
Incident
An event that indicates unauthorized access to a system.
Incident response
A process that detects, responds to, and mitigates risks that are associated with an incident.
Triage
An incident response operation that analyzes security issues and prioritizes their mitigation.
Key design strategies
You and your team perform incident response operations when there's a signal or alert for a potential compromise. High-fidelity alerts contain ample security context that makes it easy for analysts to make decisions. High-fidelity alerts result in a low number of false positives. This guide assumes that an alerting system filters low-fidelity signals and focuses on high-fidelity alerts that might indicate a real incident.
Designate incident notification contacts
Security alerts need to reach the appropriate people on your team and in your organization. Establish a designated point of contact on your workload team to receive incident notifications. These notifications should include as much information as possible about the resource that's compromised and the system. The alert must include the next steps, so your team can expedite actions.
We recommend that you log and manage incident notifications and actions by using specialized tooling that keeps an audit trail. By using standard tools, you can preserve evidence that might be required for potential legal investigations. Look for opportunities to implement automation that can send notifications based on the responsibilities of accountable parties. Keep a clear chain of communication and reporting during an incident.
Take advantage of security information event management (SIEM) solutions and security orchestration automated response (SOAR) solutions that your organization provides. Alternatively, you can procure incident management tools and encourage your organization to standardize them for all workload teams.
Investigate with a triage team
The team member that receives an incident notification is responsible for setting up a triage process that involves the appropriate people based on the available data. The triage team, often called the
bridge team
, must agree on the mode and process of communication. Does this incident require asynchronous discussions or bridge calls? How should the team track and communicate the progress of investigations?  Where can the team access incident assets?
Incident response is a crucial reason to keep documentation up to date, like the architectural layout of the system, information at a component level, privacy or security classification, owners, and key points of contact. If the information is inaccurate or outdated, the bridge team wastes valuable time trying to understand how the system works, who's responsible for each area, and what the effect of the event might be.
For further investigations, involve the appropriate people. You might include an incident manager, security officer, or workload-centric leads. To keep the triage focused, exclude people that are outside of the scope of the problem. Sometimes separate teams investigate the incident. There might be a team that initially investigates the issue and tries to mitigate the incident, and another specialized team that might perform forensics for a deep investigation to ascertain wide issues. You can quarantine the workload environment to enable the forensics team to do their investigations. In some cases, the same team might handle the entire investigation.
In the initial phase, the triage team is responsible for determining the potential vector and its effect on the confidentiality, integrity, and availability (also called the
CIA
) of the system.
Within the categories of CIA, assign an initial severity level that indicates the depth of the damage and the urgency of remediation. This level is expected to change over time as more information is discovered in the levels of triage.
In the discovery phase, it's important to determine an immediate course of action and communication plans. Are there any changes to the running state of the system? How can the attack be contained to stop further exploitation? Does the team need to send out internal or external communication, such as a responsible disclosure? Consider detection and response time. You might be legally obligated to report some types of breaches to a regulatory authority within a specific time period, which is often hours or days.
If you decide to shut down the system, the next steps lead to the workload's disaster recovery (DR) process.
If you don't shut down the system, determine how to remediate the incident without affecting the functionality of the system.
Recover from an incident
Treat a security incident like a disaster. If the remediation requires complete recovery, use proper DR mechanisms from a security perspective. The recovery process must prevent chances of recurrence. Otherwise, recovery from a corrupted backup reintroduces the issue. Redeploying a system with the same vulnerability leads to the same incident. Validate failover and failback steps and processes.
If the system remains functioning, assess the effect on the running parts of the system. Continue to monitor the system to ensure that other reliability and performance targets are met or readjusted by implementing proper degradation processes. Don't compromise privacy due to mitigation.
Diagnosis is an interactive process until the vector, and a potential fix and fallback, is identified. After diagnosis, the team works on remediation, which identifies and applies the required fix within an acceptable period.
Recovery metrics measure how long it takes to fix an issue. In the event of a shutdown, there might be an urgency regarding the remediation times. To stabilize the system, it takes time to apply fixes, patches, and tests, and deploy updates. Determine containment strategies to prevent further damage and the spread of the incident. Develop eradication procedures to completely remove the threat from the environment.
Tradeoff
: There's a tradeoff between reliability targets and remediation times. During an incident, it's likely that you don't meet other nonfunctional or functional requirements. For example, you might need to disable parts of your system while you investigate the incident, or you might even need to take the entire system offline until you determine the scope of the incident. Business decision-makers need to explicitly decide what the acceptable targets are during the incident. Clearly specify the person that's accountable for that decision.
Learn from an incident
An incident uncovers gaps or vulnerable points in a design or implementation. It's an improvement opportunity that's driven by lessons in technical design aspects, automation, product development processes that include testing, and the effectiveness of the incident response process. Maintain detailed incident records, including actions taken, timelines, and findings.
We highly recommended that you conduct structured post-incident reviews, such as root-cause analysis and retrospectives. Track and prioritize the outcome of those reviews, and consider using what you learn in future workload designs.
Improvement plans should include updates to security drills and testing, like business continuity and disaster recovery (BCDR) drills. Use security compromise as a scenario for performing a BCDR drill. Drills can validate how the documented processes work. There shouldn't be multiple incident response playbooks. Use a single source that you can adjust based on the size of the incident and how widespread or localized the effect is. Drills are based on hypothetical situations. Conduct drills in a low-risk environment, and include the learning phase in the drills.
Conduct post-incident reviews, or postmortems, to identify weaknesses in the response process and areas for improvement. Based on the lessons you learn from the incident, update the incident response plan (IRP) and the security controls.
Define a communication plan
Implement a communication plan to notify users of a disruption and to inform internal stakeholders about the remediation and improvements. Other people in your organization need to be notified of any changes to the workload's security baseline to prevent future incidents.
Generate incident reports for internal use and, if necessary, for regulatory compliance or legal purposes. Also, adopt a standard format report (a document template with defined sections) that the SOC team uses for all incidents. Ensure that every incident has a report associated with it before you close the investigation.
Azure facilitation
Microsoft Sentinel
is an SIEM and SOAR solution. It's a single solution for alert detection, threat visibility, proactive hunting, and threat response. For more information, see
What's Microsoft Sentinel?
Ensure that the Azure enrollment portal includes administrator contact information so security operations can be notified directly via an internal process. For more information, see
Update notification settings
.
To learn more about establishing a designated point of contact that receives Azure incident notifications from Microsoft Defender for Cloud, see
Configure email notifications for security alerts
.
Organizational alignment
Cloud Adoption Framework for Azure provides guidance about incident response planning and security operations. For more information, see
Security operations
.
Related links
Automatically create incidents from Microsoft security alerts
Conduct end-to-end threat hunting by using the hunts feature
Configure email notifications for security alerts
Incident response overview
Microsoft Azure incident readiness
Navigate and investigate incidents in Microsoft Sentinel
Security control: Incident response
SOAR solutions in Microsoft Sentinel
Training: Introduction to Azure incident readiness
Update Azure portal notification settings
What's an SOC?
What's Microsoft Sentinel?
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Security quick links - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Read in English
Table of contents
Read in English
Edit
Share via
Facebook
x.com
LinkedIn
Email
Table of contents
Security quick links
Apply security guidance to your architecture to help ensure the confidentiality, integrity, and availability of your data and systems.
Learn key points
Quickstart
Design principles
Checklist
Tradeoffs
Security patterns
Azure Well-Architected Review assessment
Training
Security
video
Defense in depth security in Azure
Review design principles
Concept
Plan your security readiness
Design to protect confidentiality
Design to protect integrity
Design to protect availability
Sustain and evolve your security posture
Create a security foundation
How-To Guide
Establish a security baseline
Improve the security of your development lifecycle
Classify data
Monitor workload security
Model threats
Protect workload assets
How-To Guide
Segment components
Manage identities and access
Protect the network
Use encryption
Harden resources
Guard application secrets
Validate and improve security
How-To Guide
Perform security testing
Respond to incidents
Explore related resources
Reference
Microsoft Defender for Cloud: Azure security recommendations
Microsoft Defender for Cloud: AWS recommendations
Microsoft Defender for Cloud: Google Cloud recommendations
Azure security documentation
Microsoft cloud security benchmark
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for monitoring and threat detection - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for monitoring and threat detection
Article
2024-02-13
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:10
Implement a holistic monitoring strategy that relies on modern threat detection mechanisms that can be integrated with the platform. Mechanisms should reliably alert for triage and send signals into existing SecOps processes.
This guide describes the recommendations for monitoring and threat detection. Monitoring is fundamentally a process of
getting information about events that have already occurred
. Security monitoring is a practice of capturing information at different altitudes of the workload (infrastructure, application, operations) to
gain awareness of suspicious activities
. The goal is to predict incidents and learn from past events. Monitoring data provides the basis of post-incident analysis of what occurred to help incident response and forensic investigations.
Monitoring is an Operational Excellence approach that's applied across all Well-Architected Framework pillars. This guide provides recommendations only from a security perspective. General concepts of monitoring, like code instrumentation, data collection, and analysis, are out of scope for this guide. For information about core monitoring concepts, see
Recommendations for designing and building an observability framework
.
Definitions
Term
Definition
Audit logs
A record of activities in a system.
Security information and event management (SIEM)
An approach that uses built-in threat detection and intelligence capabilities based on data that's aggregated from multiple sources.
Threat detection
A strategy for detecting deviations from expected actions by using collected, analyzed, and correlated data.
Threat intelligence
A strategy for interpreting threat detection data to detect suspicious activity or threats by examining patterns.
Threat prevention
Security controls that are placed in a workload at various altitudes to protect its assets.
Key design strategies
The main purpose of security monitoring is
threat detection
. The primary objective is to prevent potential security breaches and maintain a secure environment. However, it's equally important to recognize that not all threats can be preemptively blocked. In such instances, monitoring also serves as a mechanism to identify the cause of a security incident that has occurred despite the prevention efforts.
Monitoring can be approached from various perspectives:
Monitor at various altitudes.
Observing from
various altitudes
is the process of getting information about user flows, data access, identity, networking, and even the operating system. Each of these areas offers unique insights that can help you identify deviations from expected behaviors that are established against the security baseline. Conversely, continuously monitoring a system and applications over time can
help establish that baseline posture
. For example, you might typically see around 1,000 sign-in attempts in your identity system every hour. If your monitoring detects a spike of 50,000 sign-in attempts during a short period, an attacker might be trying to gain access to your system.
Monitor at various scopes of impact.
It's critical to
observe the application and the platform
. Assume an application user accidentally gets escalated privileges or a security breach occurs. If the user performs actions beyond their designated scope, the impact might be confined to actions that other users can perform.
However, if an internal entity compromises a database, the extent of the potential damage is uncertain.
If a compromise occurs on the Azure resource side, the impact could be global, affecting all entities that interact with the resource.
The blast radius or impact scope could be significantly different, depending on which of these scenarios occurs.
Use specialized monitoring tools.
It's critical to invest in
specialized tools
that can continuously scan for anomalous behavior that might indicate an attack. Most of these tools have
threat intelligence capabilities
that can perform predictive analysis based on a large volume of data and known threats. Most tools aren't stateless and incorporate a deep understanding of telemetry in a security context.
The tools need to be platform-integrated or at least platform-aware to get deep signals from the platform and make predictions with high fidelity. They must be able to generate alerts in a timely manner with enough information to conduct proper triage. Using too many diverse tools can lead to complexity.
Use monitoring for incident response.
Aggregated data, transformed into actionable intelligence,
enables swift and effective reactions
to incidents. Monitoring
helps with post-incident activities
. The goal is to collect enough data to analyze and understand what happened. The process of monitoring captures information on past events to enhance reactive capabilities and potentially predict future incidents.
The following sections provide recommended practices that incorporate the preceding monitoring perspectives.
Capture data to keep a trail of activities
The objective is to maintain a
comprehensive audit trail
of events that are significant from a security perspective. Logging is the most common way to capture access patterns. Logging must be performed for the application and the platform.
For an audit trail, you need to
establish the
what
,
when
, and
who
that's associated with actions
. You need to identify the specific timeframes when actions are performed. Make this assessment in your threat modeling. To counteract a repudiation threat, you should establish strong logging and auditing systems that result in a  record of activities and transactions.
The following sections describe use cases for some common altitudes of a workload.
Application user flows
Your application should be designed to provide runtime visibility when events occur.
Identify critical points within your application and establish logging for these points.
For example, when a user logs into the application, capture the user's identity, source location, and other relevant information. It's important to acknowledge any escalation in user privileges, the actions performed by the user, and whether the user accessed sensitive information in a secure data store. Keep track of activities for the user and the user session.
To facilitate this tracking, code should be
instrumented via structured logging
. Doing so enables easy and uniform querying and filtering of the logs.
Important
You need to enforce responsible logging to maintain the confidentiality and integrity of your system. Secrets and sensitive data must not appear in logs.  Be aware of leaking personal data and other compliance requirements when you capture this log data.
Identity and access monitoring
Maintain a thorough
record of access patterns for the application and modifications to platform resources
. Have robust activity logs and threat detection mechanisms, particularly for identity-related activities, because attackers often attempt to manipulate identities to gain unauthorized access.
Implement comprehensive logging by
using all available data points
. For example, include the client IP address to differentiate between regular user activity and potential threats from unexpected locations. All logging events should be timestamped by the server.
Record all resource access activities
, capturing who's doing what and when they're doing it. Instances of privilege escalation are a significant data point that should be logged. Actions related to account creation or deletion by the application must also be recorded. This recommendation extends to application secrets. Monitor who accesses secrets and when they're rotated.
Although logging successful actions is important,
recording failures is necessary from a security perspective
. Document any violations, like a user attempting an action but encountering an authorization failure, access attempts for nonexistent resources, and other actions that seem suspicious.
Network monitoring
By monitoring network packets and their sources, destinations, and structures, you gain visibility into access patterns at the network level.
Your segmentation design should
enable observation points at the boundaries
to monitor what crosses them and log that data. For example, monitor subnets that have network security groups that generate flow logs. Also monitor firewall logs that show the flows that were allowed or denied.
There are access logs for inbound connection requests. These logs record the source IP addresses that initiate the requests, the type of request (GET, POST), and all other information that's part of the requests.
Capturing DNS flows is a significant requirement for many organizations. For instance,
DNS logs can help identify which user or device initiated a particular DNS query
. By correlating DNS activity with user/device authentication logs, you can track activities to individual clients. This responsibility often extends to the workload team, especially if they deploy anything that makes DNS requests part of their operation. DNS traffic analysis is a key aspect of platform security observability.
It's important to monitor unexpected DNS requests or DNS requests that are directed toward known command and control endpoints.
Tradeoff
:
Logging all network activities can result in a large amount of data.
Every request from layer 3 can be recorded in a flow log, including every transaction that crosses a subnet boundary. Unfortunately, it's not possible to capture only adverse events because they can only be identified after they occur. Make strategic decisions about the type of events to capture and how long to store them. If you're not careful, managing the data can be overwhelming. There's also a tradeoff on the cost of storing that data.
Because of the tradeoffs, you should consider whether the benefit of network monitoring of your workload is sufficient to justify the costs. If you have a web application solution with a high request volume and your system makes extensive use of managed Azure resources, the cost might outweigh the benefits. On the other hand, if you have a solution that's designed to use virtual machines with various ports and applications, it might be important to capture and analyze network logs.
Capture system changes
To maintain the integrity of your system, you should have an accurate and up-to-date record of system state. If there are changes, you can use this record to promptly address any issues that arise.
Build processes should also emit telemetry.
Understanding the security context of events is key. Knowing what triggered the build process, who triggered it, and when it was triggered can provide valuable insights.
Track
when resources are created and when they're decommissioned
. This information must be extracted from the platform. This information provides valuable insights for resource management and accountability.
Monitor
drift in resource configuration
. Document any change to an existing resource. Also keep track of changes that don't complete as part of a rollout to a fleet of resources. Logs must capture the specifics of the change and the exact time it occurred.
Have a comprehensive view, from a patching perspective, of whether the system is up-to-date and secure.
Monitor routine update processes
to verify that they complete as planned. A security patching process that doesn't complete should be considered a vulnerability. You should also maintain an inventory that records the patch levels and any other required details.
Change detection also applies to the operating system.
This involves tracking whether services are added or turned off. It also includes monitoring for the addition of new users to the system. There are tools that are designed to target an operating system. They help with context-less monitoring in the sense that they don't target the functionality of the workload. For example, file integrity monitoring is a critical tool that enables you to track changes in system files.
You should set up alerts for these changes, particularly if you don't expect them to occur often.
Important
When you roll out to production, be sure that alerts are configured to catch anomalous activity that's detected on the application resources and build process.
In your test plans,
include the validation of logging and alerting
as prioritized test cases.
Store, aggregate, and analyze data
Data collected from these monitoring activities must be stored in data sinks where it can be thoroughly
examined, normalized, and correlated
. Security data should be persisted outside the system's own data stores. Monitoring sinks, whether they're localized or central, must outlive the data sources. The
sinks can't be ephemeral
because sinks are the source for intrusion detection systems.
Networking logs can be verbose and take up storage.
Explore different tiers in storage systems
. Logs can naturally transition to colder storage over time. This approach is beneficial because older flow logs typically aren't used actively and are only needed on demand. This method ensures efficient storage management while also ensuring  that you can access historical data when you need to.
The flows of your workload are typically a composite of multiple logging sources. Monitoring data must be
analyzed intelligently across all those sources
. For example, your firewall will only block traffic that reaches it. If you have a network security group that has already blocked certain traffic, that traffic isn't visible to the firewall. To reconstruct the sequence of events, you need to aggregate data from all components that are in flow and then aggregate data from all flows. This data is particularly useful in a post-incident response scenario when you're trying to understand what happened. Accurate timekeeping is essential. For security purposes, all systems need to use a network time source so that they're always in sync.
Centralized threat detection with correlated logs
You can use a system like security information and event management (SIEM) to
consolidate security data in a central location
where it can be correlated across various services. These systems have
built-in threat detection
mechanisms. They can
connect to external feeds
to obtain threat intelligence data. Microsoft, for example, publishes threat intelligence data that you can use. You can also buy threat intelligence feeds from other providers, like Anomali and FireEye. These feeds can provide valuable insights and enhance your security posture. For threat insights from Microsoft, see
Security Insider
.
A SIEM system can
generate alerts
based on correlated and normalized data. These alerts are a significant resource during an incident response process.
Tradeoff
: SIEM systems can be expensive, complex, and require specialized skills. However, if you don't have one, you might need to correlate data on your own. This can be a time-consuming and complex process.
SIEM systems are usually managed by an organization's central teams. If your organization doesn't have one, consider advocating for it. It could alleviate the burden of manual log analysis and correlation to allow more efficient and effective security management.
Some cost-effective options are provided by Microsoft. Many Microsoft Defender products provide the alerting functionality of a SIEM system, but without a data-aggregation feature.
By combining several smaller tools, you can emulate some functions of a SIEM system. However, you need to know that these makeshift solutions might not be able to perform correlation analysis. These alternatives can be useful, but they might not fully replace the functionality of a dedicated SIEM system.
Detect abuse
Be proactive about threat detection
and be vigilant for signs of abuse, like identity brute force attacks on an SSH component or an RDP endpoint. Although external threats might generate a lot of noise, especially if the application is exposed to the internet,
internal threats are often a greater concern
. An unexpected brute force attack from a trusted network source or an inadvertent misconfiguration, for instance, should be investigated immediately.
Keep up with your hardening practices.
Monitoring isn't a substitute for proactively hardening your environment. A larger surface area is prone to more attacks. Tighten controls as much as practice. Detect and disable unused accounts, remove unused ports, and use a web application firewall, for example. For more information about hardening techniques, see
Recommendations on security hardening
.
Signature-based detection
can inspect a system in detail. It involves looking for signs or correlations between activities that might indicate a potential attack. A detection mechanism might identify certain characteristics that are indicative of a specific type of attack. It might not always be possible to directly detect the command-and-control mechanism of an attack. However, there are often hints or patterns associated with a particular command-and-control process. For example, an attack might be indicated by a certain flow rate from a request perspective, or it might frequently access domains that have specific endings.
Detect
anomalous user access patterns
so that you can identify and investigate deviations from expected patterns. This involves comparing current user behavior with past behavior to spot anomalies. Although it might not be feasible to perform this task manually, you can use threat intelligence tools to do it. Invest in
User and Entity Behavior Analytics (UEBA) tools
that collect user behavior from monitoring data and analyze it. These tools can often perform predictive analysis that maps suspicious behaviors to potential types of attack.
Detect threats during pre-deployment and post-deployment stages.
During the predeployment phase, incorporate vulnerability scanning into pipelines and take necessary actions based on the results. Post-deployment, continue to conduct vulnerability scanning. You can use tools like Microsoft Defender for Containers, which scans container images. Include the results in the collected data. For information about secure development practices, see
Recommendations for using safe deployment practices
.
Take advantage of platform-provided detection mechanisms and measures.
For example, Azure Firewall can analyze traffic and block connections to untrusted destinations. Azure also provides ways to detect and protect against distributed denial-of-service (DDoS) attacks.
Azure facilitation
Azure Monitor
provides observability across your entire environment. With no configuration, you automatically get platform metrics, activity logs, and diagnostics logs from most of your Azure resources. The activity logs provide detailed diagnostic and auditing information.
Note
Platform logs aren't available indefinitely. You need to keep them so that you can review them later for auditing purposes or offline analysis. Use Azure storage accounts for long-term/archival storage. In Azure Monitor, specify a retention period when you enable diagnostic settings for your resources.
Set up alerts based on predefined or custom metrics and logs to get notifications when specific security-related events or anomalies are detected.
For more information, see
Azure Monitor documentation
.
Microsoft Defender for Cloud
provides built-in capabilities for threat detection. It operates on collected data and analyzes logs. Because it's aware of the types of logs generated, it can use built-in rules to make informed decisions. For example, it checks lists of potentially compromised IP addresses and generates alerts.
Enable built-in threat protection services for Azure resources. For example, enable Microsoft Defender for Azure resources, like virtual machines, databases, and containers, to detect and protect against known threats.
Defender for Cloud provides cloud workload protection platform (CWPP) capabilities for threat detection of all workload resources.
For more information, see
What is Microsoft Defender for Cloud?
.
Alerts generated by Defender can also feed into SIEM systems.
Microsoft Sentinel
is the native offering. It uses AI and machine learning to detect and respond to security threats in real time. It provides a centralized view of security data and facilitates proactive threat hunting and investigation.
For more information, see
What is Microsoft Sentinel?
.
Microsoft Sentinel can also use threat intelligence feeds from various sources. For more information, see
Threat intelligence integration in Microsoft Sentinel
.
Microsoft Sentinel can analyze user behavior from monitoring data. For more information, see
Identify advanced threats with User and Entity Behavior Analytics (UEBA) in Microsoft Sentinel
.
Defender and Microsoft Sentinel work together, despite some overlap in functionality. This collaboration enhances your overall security posture by helping to ensure comprehensive threat detection and response.
Take advantage of
Azure Business Continuity Center
to identify gaps in your business continuity estate and defend against threats like ransomware attacks, malicious activities, and rogue-administrator incidents. For more information, see
What is Azure Business Continuity Center?
.
Networking
Review all logs, including raw traffic, from your network devices.
Security group logs. Review
flow logs
and diagnostic logs.
Azure Network Watcher. Take advantage of the
packet capture
feature to set alerts and gain access to real-time performance information at the packet level.
Packet capture tracks traffic in and out of virtual machines. You can use it to run proactive captures based on defined network anomalies, including information about network intrusions.
For an example, see
Monitor networks proactively with alerts and Azure Functions using Packet Capture
.
Identity
Monitor identity-related risk events on potentially compromised identities and remediate those risks. Review the reported risk events in these ways:
Use Microsoft Entra ID reporting. For more information, see
What is Identity Protection?
and
Identity Protection
.
Use Identity Protection risk detection API members to get programmatic access to security detections via Microsoft Graph. For more information, see
riskDetection
and
riskyUser
.
Microsoft Entra ID uses adaptive machine learning algorithms, heuristics, and known compromised credentials (user name and password pairs) to detect suspicious actions that are related to your user accounts. These user name and password pairs are surfaced by monitoring the public and dark web and by working with security researchers, law enforcement, security teams at Microsoft, and others.
Azure Pipelines
DevOps advocates change management of workloads via continuous integration and continuous delivery (CI/CD). Be sure to add security validation in the pipelines. Follow the guidance described in
Securing Azure Pipelines
.
Related links
Recommendations for designing and creating an observability framework
Security Insider
Recommendations for hardening resources
Recommendations for using safe deployment practices
Azure Monitor documentation
What is Microsoft Defender for Cloud?
What is Microsoft Sentinel?
Threat intelligence integration in Microsoft Sentinel
Identify advanced threats with User and Entity Behavior Analytics (UEBA) in Microsoft Sentinel
Tutorial: Log network traffic to and from a virtual machine using the Azure portal
Packet capture
Monitor networks proactively with alerts and Azure Functions using Packet Capture
What is Identity Protection?
Identity Protection
riskDetection
riskyUser
Learn how to add continuous security validation to your CI/CD pipeline
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for networking and connectivity - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for networking and connectivity
Article
2023-11-15
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:06
Isolate, filter, and control network traffic across both ingress and egress flows. Apply defense in depth principles by using localized network controls at all available network boundaries across both east-west and north-south traffic.
This guide describes the recommendations for network design. The focus is on
security controls that can filter, block, and detect adversaries crossing network boundaries
at various depths of your architecture.
You can strengthen your identity controls by implementing network-based access control measures. Along with identity-based access control, network security is a high priority for protecting assets. Proper network security controls can provide a defense-in-depth element that can help detect and contain threats, and prevent attackers from gaining entry into your workload.
Definitions
Term
Definition
East-west traffic
Network traffic that moves within a trusted boundary.
Egress flow
Outbound workload traffic.
Hostile network
A network that isn't deployed as part of your workload. A hostile network is considered a threat vector.
Ingress flow
Inbound workload traffic.
Network filtering
A mechanism that allows or blocks network traffic based on specified rules.
Network segmentation or isolation
A strategy that divides a network into small, isolated segments, with security controls applied at the boundaries. This technique helps protect resources from hostile networks, such as the internet.
Network transformation
A mechanism that mutates network packets to obscure them.
North-south traffic
Network traffic that moves from a trusted boundary to external networks that are potentially hostile, and vice versa.
Key design strategies
Network security uses
obscurity to protect workload assets from hostile networks
. Resources that are behind a network boundary are hidden until the boundary controls mark the traffic as safe to move forward. Network security design is built on three main strategies:
Segment
. This technique
isolates traffic on separate networks by adding boundaries
. For example, traffic to and from an application tier passes a boundary to communicate with other tiers, which have different security requirements. Layers of segmentation actualize the defense-in-depth approach.
The foremost security boundary is the
networking edge between your application and public networks
. It's important to clearly define this perimeter so that you establish a boundary for isolating hostile networks. The controls on this edge must be highly effective, because this boundary is your first line of defense.
Virtual networks provide a logical boundary. By design, a virtual network can't communicate with another virtual network unless the boundary has been intentionally broken through peering. Your architecture should take advantage of this strong, platform-provided security measure.
You can also use other logical boundaries, such as carved-out
subnets within a virtual network
. A benefit of subnets is that you can use them to group together resources that are within an isolation boundary and have similar security assurances. You can then configure controls on the boundary to filter traffic.
Filter
. This strategy helps ensure that
traffic that enters a boundary is expected, allowed, and safe
. From a Zero-Trust perspective, filtering explicitly verifies all available data points at the network level. You can place rules on the boundary to check for specific conditions.
For example, at the header level, the rules can verify that the traffic originates from an expected location or has an expected volume. But these checks aren't sufficient. Even if the traffic exhibits expected characteristics, the payload might not be safe. Validation checks might reveal an SQL injection attack.
Transform
.
Mutate packets at the boundary as a security measure.
For example, you can remove HTTP headers to eliminate the risk of exposure. Or you can turn off Transport Layer Security (TLS) at one point and reestablish it at another hop with a certificate that's managed more rigorously.
Classify the traffic flows
The first step in classifying flows is to study a schematic of your workload architecture. From the schematic,
determine the intent and characteristics of the flow
with respect to the functional utility and operational aspects of your workload. Use the following questions to help classify the flow:
If the workload needs to communicate with external networks, what should the required level of proximity to those networks be?
What are the network characteristics of the flow, such as the expected protocol and the source and shape of the packets? Are there any compliance requirements at the networking level?
There are many ways to classify traffic flows. The following sections discuss commonly used criteria.
Visibility from external networks
Public
. A workload is public facing if its application and other components are reachable from the public internet. The application is exposed through one or more public IP addresses and public Domain Name System (DNS) servers.
Private
. A workload is private if it can only be accessed through a private network such as a virtual private network (VPN). It's exposed only through one or more private IP addresses and potentially through a private DNS server.
In a private network, there's no line of sight from the public internet to the workload. For the gateway, you can use a load balancer or firewall. These options can provide security assurances.
Even with public workloads,
strive to keep as much of the workload private as possible
. This approach forces packets to cross through a private boundary when they arrive from a public network. A gateway in that path can function as a transition point by acting as a reverse proxy.
Traffic direction
Ingress
. Ingress is inbound traffic that flows toward a workload or its components. To help secure ingress, apply the preceding set of key strategies. Determine what the traffic source is and whether it's expected, allowed, and safe. Attackers who scan public cloud provider IP address ranges can successfully penetrate your defenses if you don't check ingress or implement basic network security measures.
Egress
. Egress is outbound traffic that flows away from a workload or its components. To check egress, determine where the traffic is headed and whether the destination is expected, allowed, and safe. The destination might be malicious or associated with data exfiltration risks.
You can also
determine your level of exposure by considering your workload's proximity to the public internet
. For example, the application platform typically serves public IP addresses. The workload component is the face of the solution.
Scope of influence
North-south
. Traffic that flows between a workload network and external networks is north-south traffic. This traffic crosses the edge of your network. External networks can be the public internet, a corporate network, or any other network that's outside your scope of control.
Ingress and egress can both be north-south traffic.
As an example, consider the egress flow of a hub-spoke network topology. You can define the networking edge of your workload so that the hub is an external network. In that case, outbound traffic from the virtual network of the spoke is north-south traffic. But if you consider the hub network within your sphere of control, north-south traffic is extended to the firewall in the hub, because the next hop is the internet, which is potentially hostile.
East-west
. Traffic that flows within a workload network is east-west traffic. This type of traffic results when components in your workload communicate with each other. An example is traffic between the tiers of an
n
-tier application. In microservices, service-to-service communication is east-west traffic.
To provide defense in depth, maintain
end-to-end control of security affordances that are included in each hop or that you use when packets cross internal segments
. Different risk levels require different risk remediation methods.
The preceding diagram illustrates network defense in depth in the private cloud. In this diagram, the border between the public and private IP address spaces is significantly farther from the workload than in the public cloud diagram. Multiple layers separate the Azure deployments from the public IP address space.
Note
Identity is always the primary perimeter. Access management must be applied to networking flows. Use managed identities when you use Azure role-based access control (RBAC) between components of your network.
After you classify flows, perform a segmentation exercise to identify firewall injection points on the communication paths of your network segments. When you
design your network defense in depth across all segments and all traffic types, assume a breach at all points
. Use a combination of various localized network controls at all available boundaries. For more information, see
Segmentation strategies
.
Apply firewalls at the edge
Internet edge traffic is north-south traffic and includes ingress and egress. To detect or block threats, an edge strategy must mitigate as many attacks as possible to and from the internet.
For egress,
send all internet-bound traffic through a single firewall
that provides enhanced oversight, governance, and control of traffic. For ingress, force all traffic from the internet to go through a network virtual appliance (NVA) or a web application firewall.
Firewalls are usually singletons that are deployed per region in an organization. As a result, they're shared among workloads and owned by a central team. Make sure that any NVAs that you use are configured to support the needs of your workload.
We recommend that you use Azure native controls as much as possible.
In addition to native controls, you can also consider partner NVAs that provide advanced or specialized features. Partner firewall and web application firewall vendor products are available in Azure Marketplace.
The decision to use native features as opposed to partner solutions should be based on your organization's experience and requirements.
Tradeoff
: Partner capabilities often provide advanced features that can protect against sophisticated, but typically uncommon, attacks. The configuration of partner solutions can be complex and fragile, because these solutions don't integrate with the cloud's fabric controllers. From a cost perspective, native control is preferred because it's cheaper than partner solutions.
Any technological options that you consider should provide security controls and monitoring for both ingress and egress flows. To see options that are available for Azure, see the
Edge security
section in this article.
Design virtual network and subnet security
The primary objective of a private cloud is to obscure resources from the public internet. There are several ways of achieving this goal:
Move to private IP address spaces
, which you can accomplish by using virtual networks. Minimize network line of sight even within your own private networks.
Minimize the number of public DNS entries that you use
to expose less of your workload.
Add ingress and egress network flow control
. Don't allow traffic that's not trusted.
Segmentation strategy
To minimize network visibility,
segment your network and start with least-privilege network controls
. If a segment isn't routable, it can't be accessed. Broaden the scope to include only segments that need to communicate with each other through network access.
You can segment virtual networks by creating subnets. The criteria for division should be intentional. When you collocate services inside a subnet, make sure that those services can see each other.
You can base your segmentation on many factors. For example, you can place different application tiers in dedicated segments. Another approach is to plan your subnets based on common roles and functions that use well-known protocols.
For more information, see
Segmentation strategies
.
Subnet firewalls
It's important to inspect each subnet's inbound and outbound traffic. Use the three main strategies discussed earlier in this article, in
Key design strategies
. Check whether the flow is expected, allowed, and safe. To verify this information,
define firewall rules that are based on the protocol, source, and destination
of the traffic.
On Azure, you set firewall rules in network security groups. For more information, see the
Network security groups
section in this article.
For an example of a subnet design, see
Azure Virtual Network subnets
.
Use controls at the component level
After you minimize the visibility of your network, map out your Azure resources from a network perspective and evaluate the flows. The following types of flows are possible:
Planned traffic
, or intentional communication between services according to your architecture design. For example, you have planned traffic when your architecture recommends that Azure Functions pulls messages from Azure Service Bus.
Management traffic
, or communication that happens as part of the service's functionality. This traffic isn't part of your design, and you have no control over it. An example of managed traffic is the communication between the Azure services in your architecture and the Azure management plane.
Distinguishing between planned and management traffic helps you build localized, or service-level, controls. Have a good understanding of the source and destination at each hop. Especially understand how your data plane is exposed.
As a starting point, determine whether each service is exposed to the internet. If it is, plan how to restrict access. If it isn't, place it in a virtual network.
Service firewalls
If you expect a service to be exposed to the internet,
take advantage of the service-level firewall that's available for most Azure resources
. When you use this firewall, you can set rules based on access patterns. For more information, see the
Azure service firewalls
section in this article.
Note
When your component isn't a service, use a host-based firewall in addition to network-level firewalls. A virtual machine (VM) is an example of a component that's not a service.
Connectivity to platform as a service (PaaS) services
Consider using
private endpoints to help secure access to PaaS services
. A private endpoint is assigned a private IP address from your virtual network. The endpoint allows other resources in the network to communicate with the PaaS service over the private IP address.
Communication with a PaaS service is achieved by using the service's public IP address and DNS record. That communication occurs over the internet. You can make that communication private.
A tunnel from the PaaS service into one of your subnets creates a private channel. All communication takes place from the component's private IP address to a private endpoint in that subnet, which then communicates with the PaaS service.
In this example, the image on the left shows the flow for publicly exposed endpoints. On the right, that flow is secured by using private endpoints.
For more information, see the
Private endpoints
section in this article.
Note
We recommend that you use private endpoints in conjunction with service firewalls. A service firewall blocks incoming internet traffic and then exposes the service privately to internal users who use the private endpoint.
Another advantage of using private endpoints is that you don't need to open the ports on the firewall for outbound traffic.
Private endpoints lock down all outbound traffic on the port for the public internet.
Connectivity is limited to resources within the network.
Tradeoff
: Azure Private Link is a paid service that has meters for inbound and outbound data that's processed. You're also charged for private endpoints.
Protect against distributed denial of service (DDoS) attacks
A DDoS attack attempts to exhaust an application's resources to make the application unavailable to legitimate users. DDoS attacks can target any endpoint that's publicly reachable through the internet.
A DDoS attack is usually a massive, widespread, geographically dispersed abuse of your system's resources that makes it hard to pinpoint and block the source.
For Azure support to help protect against these attacks, see the
Azure DDoS Protection
section in this article.
Azure facilitation
You can use the following Azure services to add defense-in-depth capabilities to your network.
Azure Virtual Network
Virtual Network
helps your Azure resources securely communicate with each other, the internet, and on-premises networks.
By default, all resources in a virtual network can engage in outbound communication with the internet. But inbound communication is restricted by default.
Virtual Network offers features for filtering traffic. You can restrict access at the virtual-network level by using a user-defined route (UDR) and a firewall component. At the subnet level, you can filter traffic by using network security groups.
Edge security
By default, ingress and egress both flow over public IP addresses. Depending on the service or topology, either you set these addresses or Azure assigns them. Other ingress and egress possibilities include passing traffic through a load balancer or network address translation (NAT) gateway. But these services are intended for traffic distribution and not necessarily for security.
The following technology choices are recommended:
Azure Firewall
. You can use Azure Firewall at the network edge and in popular network topologies, such as hub-spoke networks and virtual WANs. You typically
deploy Azure Firewall as an egress firewall
that acts as the final security gate before traffic goes to the internet. Azure Firewall can route traffic that uses non-HTTP and non-HTTPS protocols, such as Remote Desktop Protocol (RDP), Secure Shell Protocol (SSH), and File Transfer Protocol (FTP). The feature set of Azure Firewall includes:
Destination network address translation (DNAT), or port forwarding.
Intrusion detection and prevention system (IDPS) signature detection.
Strong layer 3, layer 4, and fully qualified domain name (FQDN) network rules.
Note
Most organizations have a forced tunneling policy that forces traffic to flow through an NVA.
If you don't use a virtual WAN topology,
you must deploy a UDR
with a
NextHopType
of
Internet
to your NVA's private IP address. UDRs are applied at the subnet level. By default, subnet-to-subnet traffic doesn't flow through the NVA.
You can also use Azure Firewall simultaneously for ingress. It can route HTTP and HTTPS traffic. In higher-tiered SKUs, Azure Firewall offers TLS termination so that you can implement payload-level inspections.
The following practices are recommended:
Enable diagnostics settings
in Azure Firewall to collect traffic flow logs, IDPS logs, and DNS request logs.
Be as specific as possible in rules.
Where it's practical, avoid FQDN service tags. But when you use them, use the regional variant, which allows communication with all endpoints of the service.
Use IP groups to define sources that must share the same rules over the life of the IP group. IP groups should reflect your segmentation strategy.
Override the infrastructure FQDN allow rule only if your workload requires absolute egress control. Overriding this rule comes with a reliability tradeoff, because Azure platform requirements change on services.
Tradeoff
: Azure Firewall can impact your performance. Rule order, quantity, TLS inspection, and other factors can cause significant latency.
There can also be an impact on the reliability of your workload. It might experience source network address translation (SNAT) port exhaustion. To help overcome this problem, add public IP addresses as needed.
Risk
: For egress traffic, Azure assigns a public IP address. This assignment can have a downstream impact on your external security gate.
Azure Web Application Firewall
. This service supports inbound filtering and only targets HTTP and HTTPS traffic.
It offers basic security for common attacks, such as threats that the Open Worldwide Application Security Project (OWASP) identifies in the OWASP Top 10 document. Azure Web Application Firewall also provides other security features that are focused on layer 7, such as rate limiting, SQL-injection rules, and cross-site scripting.
With Azure Web Application Firewall, TLS termination is required, because most checks are based on payloads.
You can integrate Azure Web Application Firewall with routers, such as Azure Application Gateway or Azure Front Door. Azure Web Application Firewall implementations for those kinds of routers can vary.
Azure Firewall and Azure Web Application Firewall aren't mutually exclusive choices. For your edge security solution, various options are available. For examples, see
Firewall and Application Gateway for virtual networks
.
Network security groups
A
network security group
is a layer 3 and layer 4 firewall that you apply at the subnet or network interface card (NIC) level. Network security groups aren't created or applied by default.
Network security group rules act as a firewall
to stop traffic that flows in and out at the perimeter of a subnet. A network security group has a default rule set that's overly permissive. For example, the default rules don't set a firewall from the egress perspective. For ingress, no inbound internet traffic is allowed.
To create rules, start with the default rule set:
For
inbound
traffic, or ingress:
Virtual network traffic from direct, peered, and VPN gateway sources is allowed.
Azure Load Balancer health probes are allowed.
All other traffic is blocked.
For
outbound
traffic, or egress:
Virtual network traffic to direct, peered, and VPN gateway destinations is allowed.
Traffic to the internet is allowed.
All other traffic is blocked.
Then consider the following five factors:
Protocol
Source IP address
Source port
Destination IP address
Destination port
The lack of support for FQDN limits network security group functionality. You need to provide specific IP address ranges for your workload, and they're hard to maintain.
But for Azure services, you can use
service tags
to summarize source and destination IP address ranges. A security benefit of service tags is that they're
opaque to the user, and the responsibility is offloaded to Azure
. You can also assign an application security group as a destination type to route traffic to. This type of named group contains resources that have similar inbound or outbound access needs.
Risk
: Service tag ranges are very broad so that they accommodate the widest possible range of customers. Updates to service tags lag behind changes in the service.
In the preceding image, network security groups are applied at the NIC. Internet traffic and subnet-to-subnet traffic are denied. The network security groups are applied with the
VirtualNetwork
tag. So in this case, the subnets of peered networks have a direct line of sight. The broad definition of the
VirtualNetwork
tag can have a significant security impact.
When you use service tags, use regional versions when possible, such as
Storage.WestUS
instead of
Storage
. By taking this approach, you limit the scope to all endpoints in a particular region.
Some tags are exclusively for
inbound
or
outbound
traffic. Others are for
both
types.
Inbound
tags usually allow traffic from all hosting workloads, such as
AzureFrontDoor.Backend
, or from Azure to support service runtimes, such as
LogicAppsManagement
. Similarly,
outbound
tags allow traffic to all hosting workloads or from Azure to support service runtimes.
Scope the rules as much as possible. In the following example, the rule is set to specific values. Any other type of traffic is denied.
Information
Example
Protocol
Transmission Control Protocol (TCP), UDP
Source IP address
Allow ingress to the subnet from <source-IP-address-range>: 4575/UDP
Source port
Allow ingress to the subnet from <service-tag>: 443/TCP
Destination IP address
Allow egress from the subnet to <destination-IP-address-range>: 443/TCP
Destination port
Allow egress from the subnet to <service-tag>: 443/TCP
To summarize:
Be precise when you create rules
. Only allow traffic that's necessary for your application to function. Deny everything else. This approach limits the network line of sight to network flows that are needed to support the operation of the workload.
Supporting more network flows than necessary leads to unnecessary attack vectors and extends the surface area.
Restricting traffic doesn't imply that allowed flows are beyond the scope of an attack. Because network security groups work at layers 3 and 4 on the Open Systems Interconnection (OSI) stack, they only contain shape and direction information. For example, if your workload needs to allow DNS traffic to the internet, you would use a network security group of
Internet:53:UDP
. In this case, an attacker might be able to exfiltrate data through UDP on port 53 to some other service.
Understand that network security groups can differ slightly from one another. It's easy to overlook the intent of the differences.
To have granular filtering, it's safer to create extra network security groups.
Set up at least one network security group.
Adding a network security group unlocks many diagnostics tools, such as flow logs and network traffic analytics.
Use Azure Policy to help control traffic in subnets that don't have network security groups.
If a subnet supports network security groups, add a group, even if it's minimally impactful.
Azure service firewalls
Most Azure services offer a service-level firewall. This feature inspects ingress traffic to the service from specified classless inter-domain routing (CIDR) ranges. These firewalls offer benefits:
They provide a
basic level of security
.
There's a
tolerable performance impact
.
Most services offer these firewalls at
no extra cost
.
The firewalls emit logs through Azure diagnostics, which can be useful for analyzing access patterns.
But there are also security concerns associated with these firewalls, and there are limitations associated with providing parameters. For example, if you use Microsoft-hosted build agents, you have to open the IP address range for all Microsoft-hosted build agents. The range is then open to your build agent, other tenants, and adversaries who might abuse your service.
If you have access patterns for the service, which can be configured as service firewall rule sets, you should enable the service. You can use Azure Policy to enable it. Make sure you don't enable the trusted Azure services option if it isn't enabled by default. Doing so brings in all dependent services that are in the scope of the rules.
For more information, see the product documentation of individual Azure services.
Private endpoints
Private Link
provides a way for you to give a PaaS instance a private IP address. The service is then unreachable over the internet.
Private endpoints
aren't supported for all SKUs.
Keep the following recommendations in mind when you use private endpoints:
Configure services that are bound to virtual networks to
contact PaaS services through private endpoints
, even if those PaaS services also need to offer public access.
Promote the use of
network security groups for private endpoints to restrict access
to private endpoint IP addresses.
Always
use service firewalls when you use private endpoints
.
When possible, if you have a service that's only accessible via private endpoints, remove the DNS configuration for its public endpoint.
Consider runtime
line-of-sight concerns
when you implement private endpoints. But also consider
DevOps and monitoring concerns
.
Use Azure Policy to
enforce resource configuration
.
Tradeoff
: Service SKUs with private endpoints are expensive. Private endpoints can complicate operations because of network obscurity. You need to add self-hosted agents, jump boxes, a VPN, and other components to your architecture.
DNS management can be complex in common network topologies. You might have to introduce DNS forwarders and other components.
Virtual network injection
You can use the
virtual network injection process
to deploy some Azure services into your network. Examples of such services include Azure App Service, Functions, Azure API Management, and Azure Spring Apps. This process
isolates the application
from the internet, systems in private networks, and other Azure services. Inbound and outbound traffic from the application is allowed or denied based on network rules.
Azure Bastion
You can use
Azure Bastion
to connect to a VM by using your browser and the Azure portal. Azure Bastion
enhances the security of RDP and SSH connections
. A typical use case includes connecting to a jump box in the same virtual network or a peered virtual network. Using Azure Bastion removes the need for the VM to have a public IP address.
Azure DDoS Protection
Every property in Azure is protected by Azure DDoS infrastructure protection at no extra cost and with no added configuration. The level of protection is basic, but the protection has high thresholds. It also doesn't provide telemetry or alerting, and it's workload-agnostic.
Higher-tiered SKUs of DDoS Protection are available but aren't free. The scale and capacity of the globally deployed Azure network offers protection against common network-layer attacks. Technologies like always-on traffic monitoring and real-time mitigation provide this capability.
For more information, see
Azure DDoS Protection overview
.
Example
Here are some examples that demonstrate the use of network controls recommended in this article.
IT environment
This example builds on the Information Technology (IT) environment established in the
security baseline (SE:01)
. This approach provides a broad understanding of network controls applied at various perimeters to restrict traffic.
Network attack personas
. Several personas may be considered in a network attack, including Admins, employees, customer’s clients and anonymous attackers.
VPN access
. A bad actor might access the on-premises environment through a VPN or an Azure environment that's  connected to the on-premises environment through a VPN. Configure with IPSec protocol to enable secure communication.
Public access to the application
. Have a web application firewall (WAF) in front of the application to protect it on Layer 7 of the network OSI layer.
Operator access
. Remote access through Layer 4 of network OSI layers must be secured. Consider using Azure Firewall with IDP/IDS features.
DDoS protection
. Have DDoS protection for your entire VNet.
Network topology
. A network topology such as hub-spoke, is more secure, and optimize costs. The hub network provides centralized firewall protection to all the peered spokes.
Private endpoints
: Consider adding publically exposed services into your private network by using private endpoints. These create a Network Card (NIC) in your private VNet and bind with the Azure service.
TLS communication
. Protect data in transit by communicating over TLS.
Network Security Group (NSG)
: Protect segments within a VNet with NSG, a free resource that filters TCP/UDP inbound and outbound communication considering IP and port ranges. Part of NSG is the Application Security Group (ASG) that allows you to create tags for traffic rules for easier management.
Log Analytics
. Azure resources emit telemetry that's  ingested in Log Analytics then used with a SIEM solution like Microsoft Sentinel for analysis.
Microsoft Sentinel Integration
. Log Analytics is integrated with Microsoft Sentinel and other solutions like Microsoft Defender for Cloud.
Microsoft Defender for Cloud
. Microsoft Defender for Cloud delivers many workload protection solutions, including Network recommendations for your environment.
Traffic Analytics
: Monitor your network controls with Traffic Analytics. This is configured through Network Watcher, part of Azure Monitor, and aggregates inbound and outbound hits in your subnets collected by NSG.
Architecture for a containerized workload
This example architecture combines the network controls that are described in this article. The example doesn't show the complete architecture. Instead, it focuses on ingress controls on the private cloud.
Application Gateway is a web traffic load balancer
that you can use to manage traffic to your web applications. You deploy Application Gateway in a dedicated subnet that has network security group controls and web application firewall controls in place.
Communication with all PaaS services is conducted through
private endpoints
. All endpoints are placed in a dedicated subnet. DDoS Protection helps protect all public IP addresses that are configured for a basic or higher level of firewall protection.
Management traffic is restricted through Azure Bastion
, which helps provide secure and seamless RDP and SSH connectivity to your VMs directly from the Azure portal over TLS. Build agents are placed in the virtual network so that they have a network view to workload resources such as compute resources, container registries, and databases. This approach helps provide a secure and isolated environment for your build agents, which boosts protection for your code and artifacts.
Network security groups at the subnet level of the compute resources restrict egress traffic. Forced tunneling is used to route all traffic through Azure Firewall. This approach helps provide a secure and isolated environment for your compute resources, which boosts protection for your data and applications.
Related links
Recommendations for designing segmentation strategies
Azure Virtual Network subnets
Azure Virtual Network
Azure Firewall
Azure Web Application Firewall
Firewall and Application Gateway for virtual networks
Network security groups
Service tags
Azure Private Link
Private endpoints
Azure Bastion
Azure DDoS Protection overview
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Security design principles - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Security design principles
Article
2023-11-15
4 contributors
Feedback
In this article
A Well-Architected workload must be built with a zero-trust approach. A secure workload is
resilient to attacks
and incorporates the interrelated security
principles of confidentiality, integrity, and availability
(also known as the
CIA triad
) in addition to meeting business goals. Any security incident has the potential to become a major breach that damages the brand and reputation of the workload or organization. To measure the security efficacy of your overall strategy for a workload, start with these questions:
Do your defensive investments provide meaningful cost and friction to prevent attackers from compromising your workload?
Will your security measures be effective in restricting the blast radius of an incident?
Do you understand how controlling the workload could be valuable for an attacker? Do you understand the impact to your business if the workload and its data are stolen, unavailable, or tampered with?
Can the workload and operations quickly detect, respond to, and recover from disruptions?
As you design your system, use the Microsoft Zero Trust model as the compass to mitigate security risks:
Verify explicitly
so that
only trusted identities
perform
intended and allowed actions
that originate from
expected locations
. This safeguard makes it harder for attackers to impersonate legitimate users and accounts.
Use least-privilege access
for the
right identities
, with the
right set of permissions
, for the
right duration
, and to the
right assets
. Limiting permissions helps keep attackers from abusing permissions that legitimate users don't even need.
Assume breach
of security controls and design compensating controls that
limit risk and damage
if a primary layer of defense fails. Doing so helps you to defend your workload better by thinking like an attacker who's interested in success (regardless of how they get it).
Security isn't a one-time effort. You must implement this guidance on a recurring basis. Continuously improve your defenses and security knowledge to help keep your workload safe from attackers who are constantly gaining access to innovative attack vectors as they're developed and added to automated attack kits.
The design principles are intended to establish an ongoing security mindset to help you continuously improve the security posture of your workload as the attempts of attackers continuously evolve. These principles should guide the security of your architecture, design choices, and operational processes. Start with the recommended approaches and
justify the benefits for a set of security requirements
. After you set your strategy, drive actions by using the
Security checklist
as your next step.
If these principles aren't applied properly, a negative impact on business operations and revenue can be expected. Some consequences might be obvious, like penalties for regulatory workloads. Others might not be so obvious and could lead to ongoing security problems before they're detected.
In many mission-critical workloads, security is the primary concern, alongside reliability, given that some attack vectors, like data exfiltration, don't affect reliability. Security and reliability can pull a workload in opposite directions because security-focused design can introduce points of failure and increase operational complexity. The effect of security on reliability is often indirect, introduced by way of operational constraints. Carefully consider tradeoffs between security and reliability.
By following these principles, you can improve security effectiveness, harden workload assets, and build trust with your users.
Plan your security readiness
Strive to adopt and implement security practices in architectural design decisions and operations with minimal friction.
As a workload owner, you have a shared responsibility with the organization to protect assets. Create a
security readiness plan
that's aligned with business priorities. It will lead to well-defined processes, adequate investments, and appropriate accountabilities. The plan should provide the workload requirements to the organization, which also shares responsibility for protecting assets. Security plans should factor into your strategy for reliability, health modeling, and self-preservation.
In addition to organizational assets, the workload itself needs to be protected from intrusion and exfiltration attacks. All facets of Zero Trust and the CIA triad should be factored into the plan.
Functional and non-functional requirements, budget constraints, and other considerations shouldn't restrict security investments or dilute assurances. At the same time, you need to engineer and plan security investments with those constraints and restrictions in mind.
Approach
Benefit
Use segmentation as a strategy to plan security boundaries
in the workload environment, processes, and team structure to
isolate access and function
.
Your segmentation strategy should be driven by business requirements. You can base it on criticality of components, division of labor, privacy concerns, and other factors.
You'll be able to
minimize operational friction
by defining roles and establishing
clear lines of responsibility
. This exercise also helps you
identify the level of access
for each role, especially for critical-impact accounts.
Isolation enables you to
limit exposure of sensitive flows
to only roles and assets that need access. Excessive exposure could inadvertently lead to information flow disclosure.
To summarize, you'll be able to
right-size security efforts
based on the needs of each segment.
Continuously
build skills
through
role-based security training
that meets the requirements of the organization and the use cases of the workload.
A highly skilled team can design, implement, and monitor
security controls that remain effective
against attackers, who constantly look for new ways to exploit the system.
Organization-wide training typically focuses on developing a broader skill set for securing the common elements. However, with role-based training, you focus on
developing deep expertise
in the platform offerings and security features that address workload concerns.
You need to implement both approaches to defend against adversaries through
good design and effective operations
.
Make sure there's an incident response plan
for your workload.
Use industry frameworks that define the standard operating procedure for preparedness, detection, containment, mitigation, and post-incident activity.
At the time of crisis, confusion must be avoided.
If you have a well-documented plan, responsible roles can
focus on execution
without wasting time on uncertain actions. Also, a comprehensive plan can help you ensure that
all remediation requirements are fulfilled
.
Strengthen your security posture by understanding the security compliance requirements
that are imposed by influences outside the workload team, like organizational policies, regulatory compliance, and industry standards.
Clarity about compliance requirements will help you
design for the right security assurances
and
prevent non-compliance
issues, which could lead to penalties.
Industry standards can provide a baseline and influence your choice of tools, policies, security safeguards, guidelines, risk-management approaches, and training.
If you know that the workload adheres to compliance, you'll be able to
instill confidence
in your user base.
Define and enforce team-level security standards
across the lifecycle and operations of the workload.
Strive for consistent practices
in operations like coding, gated approvals, release management, and data protection and retention.
Defining good security practices can
minimize negligence
and the surface area for potential errors. The team will
optimize efforts and the outcome will be predictable
because approaches are made more consistent.
Observing security standards over time will enable you to
identify opportunities for improvement, possibly including automation
, which will streamline efforts further and increase consistency.
Align your incident response with the
Security Operation Center (SOC) centralized function
in your organization.
Centralizing incident response functions enables you to take advantage of specialized IT professionals who can detect incidents in real time to address potential threats as quickly as possible.
Design to protect confidentiality
Prevent exposure to privacy, regulatory, application, and proprietary information through access restrictions and obfuscation techniques.
Workload data can be classified by user, usage, configuration, compliance, intellectual property, and more. That data can't be shared or accessed beyond the established trust boundaries. Efforts to protect confidentiality should focus on access controls, opacity, and keeping an audit trail of activities that pertain to data and the system.
Approach
Benefit
Implement
strong access controls
that grant access only on a need-to-know basis.
Least privilege
.
The workload will be protected from
unauthorized access
and prohibited activities. Even when access is from trusted identities, the
access permissions and exposure time will be minimized
because the communication path is open for a limited period.
Classify data based on its type, sensitivity, and potential risk
. Assign a confidentiality level for each.
Include system components that are in scope for the identified level.
Verify explicitly
.
This evaluation helps you right-size security measures.
You'll also be able to identify data and components that have a
high potential impact
and/or exposure to risk. This exercise adds
clarity
to your information protection strategy and helps ensure
agreement
.
Safeguard your data at rest, in transit, and during processing by using
encryption
. Base your strategy on the assigned confidentiality level.
Assume breach
.
Even if an attacker gets access, they
won't be able to read properly encrypted
sensitive data.
Sensitive data includes configuration information that's used to gain further access inside the system. Data encryption can help you
contain risks
.
Guard against exploits
that might cause unwarranted exposure of information.
Verify explicitly
.
It's crucial to minimize vulnerabilities in authentication and authorization implementations, code, configurations, operations, and those that stem from the social habits of the system's users.
Up-to-date security measures enable you to
block known security vulnerabilities
from entering the system. You can also
mitigate new vulnerabilities
that can appear over time by implementing routine operations throughout the development cycle, continuously improving security assurances.
Guard against data exfiltration
that results from malicious or inadvertent access to data.
Assume breach
.
You'll be able to contain blast radius by
blocking unauthorized data transfer
. Additionally, controls applied to networking, identity, and encryption will protect data at various layers.
Maintain the level of confidentiality
as data flows through various components of the system.
Assume breach
.
Enforcing confidentiality levels throughout the system enables you to provide a consistent level of hardening. Doing so can
prevent vulnerabilities
that might result from moving data to a lower security tier.
Maintain an
audit trail
of all types of access activities.
Assume breach
.
Audit logs support
faster detection and recovery
in case of incidents and help with ongoing security monitoring.
Design to protect integrity
Prevent corruption of design, implementation, operations, and data to avoid disruptions that can stop the system from delivering its intended utility or cause it to operate outside the prescribed limits. The system should provide information assurance throughout the workload lifecycle.
The key is to implement controls that prevent tampering of business logic, flows, deployment processes, data, and even the lower stack components, like the operating system and boot sequence. Lack of integrity can introduce vulnerabilities that can lead to breaches in confidentiality and availability.
Approach
Benefit
Implement strong access controls that authenticate and authorize access to the system.
Minimize access based on privilege, scope, and time.
Least privilege
.
Depending on the strength of the controls, you'll be able to
prevent or reduce risks from unapproved modifications
. This helps ensure that data is consistent and trustworthy.
Minimizing access limits the extent of potential corruption.
Continuously protect against vulnerabilities and detect them in your supply chain
to block attackers from injecting software faults into your infrastructure, build system, tools, libraries, and other dependencies.
Supply chain should scan for vulnerabilities during
build time and runtime
.
Assume breach
.
Knowing the origin of software and verifying its authenticity throughout the lifecycle will
provide predictability
. You'll
know about vulnerabilities well in advance
so that you can proactively remediate them and keep the system secure in production.
Establish trust and verify by using cryptography techniques
like attestation, code signing, certificates, and encryption.
Protect those mechanisms by allowing reputable decryption.
Verify explicitly
,
least privilege.
You'll know that changes to data or access to the system
is verified by a trusted source
.
Even if encrypted data is intercepted in transit by a malicious actor, the actor won't be able to unlock or decipher the content. You can use digital signatures to ensure that the data wasn't tampered with during transmission.
Ensure backup data is immutable and encrypted
when data is replicated or transferred.
Verify explicitly.
You'll be able to recover data with confidence that backup
data wasn't changed at rest
, inadvertently or maliciously.
Avoid or mitigate system implementations that allow your workload to operate outside its intended limits and purposes.
Verify explicitly.
When your system has strong safeguards that check whether usage aligns with its intended limits and purposes, the scope for potential abuse or tampering of your compute, networking, and data stores is reduced.
Design to protect availability
Prevent or minimize system and workload downtime and degradation in the event of a security incident by using strong security controls. You must maintain data integrity during the incident and after the system recovers.
You need to balance availability architecture choices with security architecture choices. The system should have availability guarantees to ensure that users have access to data and that data is reachable. From a security perspective, users should operate within the allowed access scope, and the data must be trusted. Security controls should block bad actors, but they shouldn't block legitimate users from accessing the system and data.
Approach
Benefit
Prevent compromised identities from misusing access
to gain control of the system.
Check for
overly pervasive scope and time limits
to minimize risk exposure.
Least privilege
.
This strategy
mitigates the risks of excessive, unnecessary, or misused access permissions
on crucial resources. Risks include unauthorized modifications and even the deletion of resources. Take advantage of the platform-provided just-in-time (JIT), just-enough-access (JEA), and time-based security modes to replace standing permissions wherever possible.
Use security controls and design patterns to
prevent attacks and code flaws from causing resource exhaustion
and blocking access.
Verify explicitly
.
The
system won't experience downtime
caused by malicious actions, like distributed denial of service (DDoS) attacks.
Implement
preventative measures for attack vectors that exploit vulnerabilities
in application code, networking protocols, identity systems, malware protection, and other areas.
Assume breach
.
Implement code scanners, apply the latest security patches, update software, and protect your system with effective antimalware on an ongoing basis.
You'll be able to reduce the attack surface to ensure business continuity.
Prioritize
security controls on the
critical components and flows
in the system that are susceptible to risk.
Assume breach
,
verify explicitly
.
Regular detection and prioritization exercises can help you
apply security expertise to the critical aspects
of the system. You'll be able to focus on the most likely and damaging threats and start your risk mitigation in areas that need the most attention.
Apply at least the same level of
security rigor in your recovery resources and processes
as you do in the primary environment, including security controls and frequency of backup.
Assume breach
.
You should have a preserved safe system state available in disaster recovery. If you do, you can fail over to a secure secondary system or location and restore backups that won't introduce a threat.
A well-designed process can prevent a security incident from hindering the recovery process. Corrupted backup data or encrypted data that can't be deciphered can slow down recovery.
Sustain and evolve your security posture
Incorporate continuous improvement and apply vigilance to stay ahead of attackers who are continuously evolving their attack strategies.
Your security posture must not degrade over time. You must continually improve security operations so that new disruptions are handled more efficiently. Strive to align improvements with the phases defined by industry standards. Doing so leads to better preparedness, reduced time to incident detection, and effective containment and mitigation. Continuous improvement should be based on lessons learned from past incidents.
It's important to measure your security posture, enforce policies to maintain that posture, and regularly validate your security mitigations and compensating controls in order to continuously improve your security posture in the face of evolving threats.
Approach
Benefit
Create and maintain a comprehensive asset inventory
that includes classified information about resources, locations, dependencies, owners, and other metadata that's relevant to security.
As much as possible,
automate
inventory to derive data from the system.
A well-organized inventory provides a
holistic view of the environment
, which puts you in an advantageous position against attackers, especially during post-incident activities.
It also creates a business rhythm to drive communication, upkeep of critical components, and the decommissioning of orphaned resources.
Perform threat modeling
to identify and mitigate potential threats.
You'll have a
report of attack vectors
prioritized by their severity level. You'll be able to identify threats and vulnerabilities quickly and set up countermeasures.
Regularly
capture data to quantify your current state
against your established security baseline and
set priorities for remediations
.
Take advantage of platform-provided features for
security posture management
and
the enforcement of compliance
imposed by external and internal organizations.
You need accurate reports that bring clarity and consensus to focus areas. You'll be able to immediately
execute technical remediations
, starting with the highest priority items. You'll also
identify gaps
, which provide opportunities for improvement.
Implementing enforcement helps prevent violations and regressions, which preserves your security posture.
Run periodic security tests
that are conducted by experts external to the workload team who attempt to ethically hack the system.
Perform routine and integrated
vulnerability scanning
to detect exploits in infrastructure, dependencies, and application code.
These tests enable you to validate security defenses by
simulating real-world attacks
by using techniques like penetration testing.
Threats can be introduced as part of your change management. Integrating scanners into the deployment pipelines enables you to automatically detect vulnerabilities and even quarantine usage until the vulnerabilities are removed.
Detect, respond, and recover
with swift and effective security operations.
The primary benefit of this approach is that it enables you to
preserve or restore the security assurances of the CIA triad
during and after an attack.
You need to be alerted as soon as a threat is detected so that you can start your investigations and take appropriate actions.
Conduct post-incident activities
like root-cause analyses, postmortems, and incident reports.
These activities provide insight into the impact of the breach and into resolution measures, which drives improvements in defenses and operations.
Get current, and stay current.
Stay current on updates, patching, and security fixes.
Continuously evaluate the system and improve it based on audit reports, benchmarking, and lessons from testing activities. Consider automation, as appropriate.
Use threat intelligence powered by security analytics for dynamic detection of threats.
At regular intervals, review the workload's conformance to Security Development Lifecycle (SDL) best practices.
You'll be able to ensure that your
security posture doesn't degrade over time
.
By integrating findings from real-world attacks and testing activities, you'll be able to combat attackers who continuously improve and exploit new categories of vulnerabilities.
Automation of repetitive tasks
decreases the chance of human error
that can create risk.
SDL reviews bring clarity around security features. SDL can help you maintain an inventory of workload assets and their security reports, which cover origin, usage, operational weaknesses, and other factors.
Next steps
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for securing a development lifecycle - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for securing a development lifecycle
Article
2024-08-30
5 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:02
Maintain a secure development lifecycle by using a hardened, mostly automated, and auditable software supply chain. Incorporate a secure design by using threat modeling to safeguard against security-defeating implementations.
Related guide
:
Threat analysis
This guide describes the
recommendations for hardening your code, development environment, and software supply chain
by applying security best practices throughout the development cycle. To understand this guidance, you should have knowledge of DevSecOps.
DevSecOps integrates security into DevOps processes by:
Automating security testing and validation.
Implementing tools like security pipelines to scan code and infrastructure as code (IaC) for vulnerabilities.
At the core of a workload is the application code that implements business logic. The code and the process of developing code must be
free of security defects
to ensure confidentiality, integrity, and availability.
It's not enough to secure just the infrastructure plane by using controls on identity and networking and other measures.
Prevent bad implementation of code or a compromised code block
to strengthen your overall security posture. The usage plane, that is, the application code, must also be hardened. The process of integrating security into your development lifecycle is essentially a hardening process. Like resource hardening, tightening up code development is also context-agnostic. The focus is on enhancing security and not the functional requirements of the application. For information related to hardening, see
Recommendations for hardening resources
.
Definitions
Term
Definition
Security Development Lifecycle (SDL)
A set of practices provided by Microsoft that supports security assurance and compliance requirements.
Software development lifecycle (SDLC)
A multistage, systematic process for developing software systems.
Key design strategies
Security measures should be integrated at multiple points into your existing Software Development Lifecycle (SDLC) to ensure:
Design choices don't lead to security gaps.
Application code and configuration don't create vulnerabilities because of exploitable implementation and improper coding practices.
Software acquired via the supply chain doesn't introduce security threats.
Application code, build, and deployment processes aren't tampered with.
Vulnerabilities revealed through incidents are mitigated.
Unused assets are properly decommissioned.
Compliance requirements aren't compromised or reduced.
Audit logging is implemented in developer environments.
The following sections provide security strategies for the commonly practiced phases of SDLC.
Collect and document the security requirements
The goal of the requirements phase is to
gather and analyze the functional and non-functional requirements
for an application or a new feature of an application. This phase is important because it facilitates the creation of guardrails that are tailored to the objectives of the application. Protecting the data and integrity of your application should be a core requirement throughout every phase of the development lifecycle.
For example, consider an application that needs to support critical user flows that enable the user to upload and manipulate data. The security design choices should cover assurances for the user's interaction with the application, like authenticating and authorizing the user identity, allowing only permitted actions on the data, and preventing SQL injection. Similarly, cover non-functional requirements like availability, scalability, and maintainability. Security choices should include segmentation boundaries, firewall ingress and egress, and other cross-cutting security concerns.
All these decisions should lead to a good definition of the security posture of the application.
Document the security requirements in an agreed-upon specification
and reflect it in the backlog. It should explicitly state the security investments and the tradeoffs and risks that the business is willing to take on if the investments aren't approved by business stakeholders. For example, you might document the need to use a web application firewall (WAF) in front of your application, like Azure Front Door or Azure Application Gateway. If business stakeholders aren't prepared to accept the additional cost of running a WAF, they need to accept the risk that application-layer attacks might be directed toward the application.
Security requirement gathering is a critical part of this phase. Without this effort, the design and implementation phases will be based on unstated choices, which can lead to security gaps. You might need to change the implementation later to accommodate security, which can be expensive.
Translate security requirements to technical requirements
During the design phase,
the security requirements are converted to technical requirements
. In your technical specification, document all design decisions to prevent ambiguity during implementation. Here are some typical tasks:
Define the security dimension of the system architecture
Overlay the architecture with security controls. For example, controls that are practical on the isolation boundaries per your
segmentation strategy
, the types of identities needed for the components of the application, and the type of encryption methods to use. For some example architectures, see the illustrations in the Example sections of the
Identity and access management
and
Networking
articles.
Evaluate platform-provided affordances
It's important to understand the
division of responsibility between you and the cloud provider
. Avoid overlap with Azure native security controls, for example. You'll get better security coverage and be able to reallocate development resources to the needs of the application.
For example, if your design calls for a web application firewall on ingress, you can offload that responsibility to a load balancer like Application Gateway or Azure Front Door. Avoid replicating features as custom code in your application.
Choose only trusted frameworks, libraries, and supply chain software.
Your design should also specify secure version control. Application dependencies should be sourced from trusted parties.
Third-party vendors should be able to meet your security requirements
and share their responsible disclosure plan. Any security incident should be promptly reported so that you can take necessary actions. Also, certain libraries might be prohibited by your organization. For example, software might be secure from vulnerabilities but still disallowed because of licensing restrictions.
To ensure that this guidance is followed by all contributors to the software,
maintain a list of approved and/or unapproved frameworks, libraries, and vendors
. When possible, place guardrails in the development pipelines to support the list. As much as possible,
automate the use of tools to scan dependencies
for vulnerabilities.
Determine the security design patterns that the application code should implement.
Patterns can support security concerns like segmentation and isolation, strong authorization, uniform application security, and modern protocols. Some operational patterns, such as the Quarantine pattern, can help verify and block the use of software that could potentially introduce security vulnerabilities.
For more information, see
Cloud design patterns that support security
.
Store application secrets securely
Securely implement the use of application secrets and pre-shared keys that your application uses.
Credentials and application secrets should never be stored in the source code tree.
Use external resources like Azure Key Vault to ensure that, if your source code becomes available to a potential attacker, no further access can be obtained. In general, find ways to avoid secrets. Using managed identities, when possible, is one way to achieve that goal. For more information, see
Recommendations for managing application secrets
.
Define test plans
Define clear test cases for security requirements. Evaluate whether you can
automate those tests in your pipelines
. If your team has processes for manual testing, include security requirements for those tests.
Note
Perform threat modeling during this phase. Threat modeling can confirm that design choices are aligned with security requirements and expose gaps that you should mitigate. If your workload handles highly sensitive data, invest in security experts who can help you conduct threat modelling.
The initial threat modeling exercise should occur during the design phase when the software's architecture and high-level design are being defined. Doing it during that phase helps you to identify potential security issues before they're incorporated into the system's structure. However, this exercise isn't a one-time activity. It's a continuous process that should continue throughout the software's evolution.
For more information, see
Recommendations for threat analysis
.
Secure development and testing practices
During the development and testing phase, the goal is to
prevent security defects
and tampering in code, build, and deployment pipelines.
Be well-trained in secure code practices
The development team should
have formal and specialized training in secure coding practices
. For example, web and API developers might need specific training to protect against cross-site scripting attacks, and back-end developers can benefit from in-depth training to avoid database-level attacks like SQL injection attacks.
Developers should be required to complete this training before they can gain access to production source code.
You should also perform internal peer code reviews to promote continuous learning.
Use security test tools
Perform threat modeling to evaluate the security of the application's architecture.
Use
static application security testing (SAST)
to analyze code for vulnerabilities. Integrate this methodology into the developer environment to detect vulnerabilities in real time.
Use
dynamic application security testing (DAST)
during runtime. This tool chain can check for errors in security domains and simulate a set of attacks to test the application's security resilience. When possible, integrate this tool into your build pipelines.
Follow industry standards for secure coding practices. For more information, see the
Community resources
section of this article.
Use linters and code analyzers to prevent credentials from getting pushed to the source code repository. For example, .NET Compiler Platform (Roslyn) Analyzers inspect your application code.
During the build process,
use pipeline add-ons to catch credentials in the source code
. Scan all dependencies, like third-party libraries and framework components, as part of the continuous integration process. Investigate vulnerable components that are flagged by the tool. Combine this task with other code scanning tasks that inspect code churn, test results, and coverage.
Use a combination of tests. For information about security testing in general, see
Recommendations for security testing
.
Write just enough code
When you reduce your code footprint, you also reduce the chances of security defects.
Reuse code and libraries that are already in use and have been through security validations
instead of duplicating code.
Taking advantage of Azure features is another way to prevent unnecessary code. One way is to use managed services. For more information, see
Use platform as a service (PaaS) options
.
Write code with a deny-all approach by default.
Create allowlists only for entities that need access.  For example, if you have code that needs to determine whether a privileged operation should be allowed, you should write it so that the
deny
outcome is the default case and the
allow
outcome  occurs only when specifically permitted by code.
Protect developer environments
Developer workstations need to be protected
with strong network and identity controls to prevent exposure. Make sure security updates are applied diligently.
Build agents are highly privileged and have access to the build server and the code. They must be protected with the same rigor as your workload components. This means that
access to build agents must be authenticated and authorized
, they should be network-segmented with firewall controls, they should be subject to vulnerability scanning, and so on. Microsoft-hosted build agents should be preferred over self-hosted build agents. Microsoft-hosted agents provide benefits like clean virtual machines for each run of a pipeline.
Custom build agents add management complexity and can become an attack vector.
Build machine credentials must be stored securely
, and you need to regularly remove any temporary build artifacts from the file system. You can achieve network isolation by only allowing outgoing traffic from the build agent, because it's using the pull model of communication with Azure DevOps.
The source code repository must be safeguarded
as well. Grant access to code repositories on a need-to-know basis and reduce exposure of vulnerabilities as much as possible to avoid attacks.
Have a thorough process to review code
for security vulnerabilities. Use security groups for that purpose, and implement an approval process that's based on business justifications.
Protect code in deployment pipelines
It's not enough to just secure code. If it runs in exploitable pipelines, all security efforts are futile and incomplete.
Build and release environments must also be protected
because you want to prevent bad actors from running malicious code in your pipeline.
Maintain an up-to-date inventory of every component that's integrated into your application
Every new component that's integrated into an application increases the attack surface. To ensure proper accountability and alerting when new components are added or updated, you should have an inventory of these components. Store it outside of the build environment.
On a regular basis, check that your manifest matches what's in your build process.
Doing so helps ensure that no new components that contain back doors or other malware are added unexpectedly.
Pipeline tasks
Pull tasks in your pipeline from trusted sources
, like Azure Marketplace. Run tasks that are written by your pipeline vendor. We recommend GitHub tasks or GitHub Actions. If you use GitHub workflows, prefer Microsoft-authored tasks. Also, validate tasks because they run in the security context of your pipeline.
Pipeline secrets.
Deployment assets that run inside a pipeline have access to all the secrets in that pipeline.
Have proper segmentation in place for different stages of the pipeline
to avoid unnecessary exposure. Use secret stores that are built into the pipeline. Remember that you can avoid using secrets in some situations. Explore the use of workload identities (for pipeline authentication) and managed identities (for service-to-service authentication).
Keep different environments separate
Data used in different environments must be kept separate.
Production data shouldn't be used in lower environments
because those environments might not have the strict security controls that production has. Avoid connecting from a non-production application to a production database, and avoid connecting non-production components to production networks.
Progressive exposure
Use progressive exposure to
release features to a subset of users
based on chosen criteria. If there are issues, the impact is minimized to those users. This approach is a common risk mitigation strategy because it reduces surface area. As the feature matures and you have more confidence in security assurances, you can gradually release it to a broader set of users.
Protect code in production
The production phase presents the
last responsible opportunity to fix security gaps
. Keep a record of the golden image that's released in production.
Keep versioned artifacts
Keep a catalog of all deployed assets and their versions.
This information is useful during incident triage, when you're mitigating issues, and when you're getting the system back to working state. Versioned assets can also be compared against published Common Vulnerabilities and Exposures (CVE) notices. You should use automation to perform these comparisons.
Emergency fixes
Your automated pipeline design should have the flexibility to
support both regular and emergency deployments
. This flexibility is important to support rapid and responsible security fixes.
A release is typically associated with multiple approval gates. Consider creating an emergency process to accelerate security fixes. The process might involve communication among teams. The pipeline should allow for quick roll-forward and rollback deployments that address security fixes, critical bugs, and code updates that occur outside of the regular deployment lifecycle.
Note
Always prioritize security fixes over convenience. A security fix shouldn't introduce a regression or bug. If you want to accelerate the fix through an emergency pipeline, carefully consider which automated tests can be bypassed. Evaluate the value of each test against the execution time. For example, unit tests usually complete quickly. Integration or end-to-end tests can run for a long time.
Maintain code security throughout its lifecycle
The goal of this phase is to
make sure security posture doesn't decay over time
. SDLC is an ongoing agile process. Concepts covered in the preceding phases apply to this phase because requirements change over time.
Patch management.
Keep software, libraries, and infrastructure components up to date with security patches and updates.
Continuous improvement.
Continuously assess and improve the security of the software development process by taking into account code reviews, feedback, lessons learned, and evolving threats.
Decommission legacy assets
that are stale or no longer in use. Doing so reduces the surface area of the application.
Maintenance also includes incident fixes. If issues are found in production, they need to be promptly integrated back into the process so that they don't recur.
Continuously improve your secure coding practices to keep up with the threat landscape.
Azure facilitation
Microsoft Security Development Lifecycle (SDL) recommends secure practices that you can apply to your development lifecycle. For more information, see
Microsoft Security Development Lifecycle
.
Defender for DevOps and the SAST tools are included as part of GitHub Advanced Security or Azure DevOps. These tools can help you track a security score for your organization.
Follow the Azure security recommendations that are described in these resources:
Design secure applications on Azure
Develop secure applications on Azure
Deploy secure applications on Azure
Secure development best practices on Azure
Training: Learn how Microsoft supports secure software development as part of a cybersecurity solution
Community links
To find credentials in source code, consider using tools like
GitHub Advanced Security
and
OWASP source code analysis tools
.
Validate the security of any open-source code in your application. These free tools and resources can help you with your assessment:
Mend Bolt
npm-audit
OWASP Dependency-Check
GitHub Dependabot
Microsoft Security DevOps Azure DevOps extension
OWASP Secure Coding Practices
OWASP Top Ten
Related links
Cloud design patterns that support security
Design secure applications on Azure
Deploy secure applications on Azure
Develop secure applications on Azure
Microsoft Security Development Lifecycle
Recommendations for building a segmentation strategy
Recommendations for hardening resources
Recommendations for managing application secrets
Recommendations for security testing
Recommendations for threat analysis
Secure development best practices on Azure
Training: Learn how Microsoft supports secure software development as part of a cybersecurity solution
Use platform as a service (PaaS) options
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for building a segmentation strategy - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for building a segmentation strategy
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to Well-Architected Framework Security checklist recommendation:
SE:04
Create intentional segmentation and perimeters in your architecture design and the workload’s footprint on the platform. The segmentation strategy must include networks, roles and responsibilities, workload identities, and resource organization.
A segment is a logical section of your solution that needs to be secured as one unit. A segmentation strategy defines how one unit should be separated from other units with its own set of security requirements and measures.
This guide describes the recommendations for
building a unified segmentation strategy
. Using perimeters and isolation boundaries in workloads, you can design a security approach that works for you.
Definitions
Term
Definition
Containment
A technique to contain the blast radius if an attacker gains access to a segment.
Least-privilege access
A Zero Trust principle that aims at minimizing a set of permissions to complete a job function.
Perimeter
The trust boundary around a segment.
Resource organization
A strategy to group related resources by flows within a segment.
Role
A set of permissions needed to complete a job function.
Segment
A logical unit that's isolated from other entities and protected by a set of security measures.
Key design strategies
The concept of segmentation is commonly used for networks. However, the same underlying principle can be used throughout a solution, including segmenting resources for management purposes and access control.
Segmentation helps you
design a security approach that applies defense in depth
based on the principles of the Zero Trust model. Ensure that an attacker who breaches one network segment can't gain access to another by segmenting workloads with different identity controls. In a secure system, identity and network attributes block unauthorized access and hide the assets from being exposed. Here are some examples of segments:
Subscriptions that isolate workloads of an organization
Resource groups that isolate workload assets
Deployment environments that isolate deployment by stages
Teams and roles that isolate job functions related to workload development and management
Application tiers that isolate by workload utility
Microservices that isolate one service from another
Consider these key elements of segmentation to make sure you're building a comprehensive defense in depth strategy:
The
boundary or perimeter
is the entry edge of a segment where you apply security controls. Perimeter controls should block access to the segment unless explicitly allowed. The goal is to prevent an attacker from breaking through the perimeter and gaining control of the system. For example, an application tier might accept an end user's access token when it processes a request. But the
data
tier might require a different access token that has a specific permission, which only the application tier can request.
Containment
is the exit edge of a segment that prevents lateral movement in the system. The goal of containment is to minimize the effect of a breach. For example, an Azure virtual network might be used to configure routing and network security groups to only allow traffic patterns that you expect, avoiding traffic to arbitrary network segments.
Isolation
is the practice of grouping entities with similar assurances together to protect them with a boundary. The goal is ease of management and the containment of an attack within an environment. For example, you might group the resources that relate to a specific workload into one Azure subscription, and then apply access control so that only specific workload teams can access the subscription.
It's important to note the distinction between perimeters and isolation. Perimeter refers to the points of location that should be checked. Isolation is about grouping. Actively contain an attack by using these concepts together.
Isolation doesn't mean creating silos in the organization.
A unified segmentation strategy provides alignment between the technical teams and sets clear lines of responsibility.
Clarity reduces the risk of human error and automation failures that can lead to security vulnerabilities, operational downtime, or both. Suppose a security breach is detected in a component of a complex enterprise system. It's important that everyone understands who's responsible for that resource so that the appropriate person is included in the triage team. The organization and stakeholders can quickly identify how to respond to different kinds of incidents by creating and documenting a good segmentation strategy.
Tradeoff
: Segmentation introduces complexity because there's overhead in management. There's also a tradeoff in cost. For example, more resources are provisioned when deployment environments that run side by side are segmented.
Risk
: Micro-segmentation beyond a reasonable limit loses the benefit of isolation. When you create too many segments, it becomes difficult to identify points of communication or to allow for valid communication paths within the segment.
Establish identity as the primary security perimeter
Various identities such as people, software components, or devices access workload segments. Identity is a perimeter that should be the primary line of defense to
authenticate and authorize access across isolation boundaries
, regardless of where the access request originates. Use identity as a perimeter to:
Assign access by role.
Identities only need access to the segments required to do their job. Minimize anonymous access by understanding the roles and responsibilities of the requesting identity so that you know the entity that's requesting access to a segment and for what purpose.
An identity might have different access scopes in different segments. Consider a typical environment setup, with separate segments for each stage. Identities associated with the developer role have read-write access to the development environment. As the deployment moves to staging, those permissions are curbed. By the time the workload is promoted to production, scope for developers is reduced to read-only access.
Consider application and management identities separately.
In most solutions, users have a different level of access than developers or operators. In some applications, you might use different identity systems or directories for each type of identity. Consider using access scopes and creating separate roles for each identity.
Assign least-privilege access.
If the identity is allowed access, determine the level of access. Start with the least privilege for each segment and broaden that scope only when needed.
By applying the least privilege, you limit the negative effects if the identity is ever compromised. If access is limited by time, the attack surface is reduced further. Time-limited access is especially applicable to critical accounts, such as administrators or software components that have a compromised identity.
Tradeoff
: The performance of the workload can be affected by identity perimeters. Verifying each request explicitly requires extra compute cycles and extra network IO.
Role-based access control (RBAC) also results in management overhead. Keeping track of identities and their access scopes can become complex in role assignments. The workaround is to assign roles to security groups instead of individual identities.
Risk
: Identity settings can be complex. Misconfigurations can affect the reliability of the workload. For example, suppose there's a misconfigured role assignment that's denied access to a database. The requests start failing, eventually causing reliability issues that can't otherwise be detected until runtime.
For information about identity controls, see
Identity and access management
.
In contrast to network access controls, identity validates access control at access time. It's highly recommended to conduct regular access review and require an approval workflow to obtain privileges for critical impact accounts. For example, see
Identity segmentation patterns
.
Enhance with networking as a perimeter
Identity perimeters are network agnostic while network perimeters augment identity but never replace it. Network perimeters are established to control blast radius, block unexpected, prohibited, and unsafe access, and obfuscate workload resources.
While the primary focus of the identity perimeter is least privilege, you should assume there will be a breach when you're designing the network perimeter.
Create software-defined perimeters in your networking footprint using Azure services and features. When a workload (or parts of a given workload) is placed into separate segments, you
control traffic from or to those segments to secure communication paths
. If a segment is compromised, it's contained and prevented from laterally spreading through the rest of your network.
Think like an attacker to achieve a foothold within the workload and establish controls to minimize further expansion. The controls should detect, contain, and stop attackers from gaining access to the entire workload. Here are some examples of network controls as a perimeter:
Define your edge perimeter between public networks and the network where your workload is placed. Restrict line of sight from public networks to your network as much as possible.
Implement demilitarized zones (DMZs) in front of the application with proper controls via firewalls.
Create micro-segmentation within your private network by grouping parts of the workload into separate segments. Establish secure communication paths between them.
Create boundaries based on intent. For example, segment workload functional networks from operational networks.
For common patterns related to networking segmentation, see
Networking segmentation patterns
.
Tradeoff
: Network security controls are often expensive because they're included with the premium SKUs. Configuring rules on firewalls often results in overwhelming complexity requiring broad exceptions.
Private connectivity changes architectural design, often adding more components such as jump boxes for private access to compute nodes.
Because network perimeters are based on control points, or hops, on the network, each hop can be a potential point of failure. These points can have an effect on the reliability of the system.
Risk
: Network controls are rule-based and there's a significant chance of misconfiguration, which is a reliability concern.
For information about network controls, see
Networking and connectivity
.
Define roles and clear lines of responsibility
Segmentation that prevents confusion and security risks is achieved by
clearly defining lines of responsibility
within a workload team.
Document and share roles and functions to create consistency and facilitate communication. Designate groups or individual roles that are responsible for key functions. Consider the built-in roles in Azure before creating custom roles for objects.
Consider consistency while accommodating several organizational models when assigning permissions for a segment. These models can range from a single centralized IT group to mostly independent IT and DevOps teams.
Risk
: Membership of groups can change over time as employees join or leave teams or change roles. Management of roles across segments can result in management overhead.
Organize resources to promote segmentation
Segmentation allows you to
isolate workload resources from other parts of the organization
or even within the team. Azure constructs, such as management groups, subscriptions, environments, and resource groups, are ways of organizing your resources that promote segmentation. Here are some examples of resource-level isolation:
Polyglot persistence involves a combination of data storing technologies instead of a single database system to support segmentation. Use polyglot persistence for separation by various data models, separation of functionalities such as data storage and analytics, or to separate by access patterns.
Allocate one service for each server when organizing your compute. This level of isolation minimizes complexity and can help contain an attack.
Azure provides built-in isolation for some services, for example separation of compute from storage. For other examples, see
Isolation in the Azure public cloud
.
Tradeoff
: Resource isolation might result in an increase in total cost of ownership (TCO). For data stores, there might be added complexity and coordination during disaster recovery.
Azure facilitation
Certain Azure services are available for use in implementing a segmentation strategy, as outlined in the following sections.
Identity
Azure RBAC supports segmentation by isolating access by job function. Only certain actions are allowed for certain roles and scopes. For example, job functions that only need to observe the system can be assigned reader permissions versus contributor permissions that allow the identity to manage resources.
For more information, see
Best practices for RBAC
.
Networking
Virtual networks
: Virtual networks provide network-level containment of resources without adding traffic between two virtual networks. Virtual networks are created in private address spaces within a subscription
Network security groups (NSG): An access control mechanism for controlling traffic between resources in virtual networks and external networks, such as the internet. Implement user-defined routes (UDR) to control the next hop for traffic. NSGs can take your segmentation strategy to a granular level by creating perimeters for a subnet, a virtual machine (VM), or a group of VMs. For information about possible operations with subnets in Azure, see
Subnets
.
Application security groups (ASGs)
: ASGs allow you to group a set of VMs under an application tag and define traffic rules that are then applied to each of the underlying VMs.
Azure Firewall
: A cloud-native service, which can be deployed in your virtual network or in
Azure Virtual WAN
hub deployments. Use Azure Firewall to filter traffic flowing between cloud resources, the internet, and on-premises resources. Use Azure Firewall or
Azure Firewall Manager
to create rules or policies that allow or deny traffic using layer 3 to layer 7 controls. Filter internet traffic using Azure Firewall and third parties by directing traffic through third-party security providers for advanced filtering and user protection. Azure supports network virtual appliance deployment, which helps segmentation from third-party firewalls.
Example
Here are some common patterns for segmenting a workload in Azure. Choose a pattern based on your needs.
This example builds on the Information Technology (IT) environment established in the
security baseline (SE:01)
. The diagram below shows segmentation at the management group level done by an organization.
Identity segmentation patterns
Pattern 1: Job title-based grouping
One way to organize security groups is by job title like software engineer, database administrator, site reliability engineer, quality assurance engineer, or security analyst. This approach involves
creating security groups for your workload team
based on their roles, without considering the work that needs to be accomplished. Grant security groups RBAC permissions, standing or just in time (JIT), according to their responsibilities in the workload. Assign human and service principles to security groups based on their as-needed access.
Membership is highly visible at the role assignment level, making it easy to see what a
role
has access to. Each person is usually a member of only one security group, which makes onboarding and offboarding easy. However, unless job titles overlap perfectly with responsibilities, title-based grouping isn't ideal for least-privilege implementation. You might end up combining implementation with function-based grouping.
Pattern 2: Function-based grouping
Function-based grouping is a security group organization method that reflects discrete work that needs to be accomplished, not taking into account your team structure. With this pattern, you
grant security groups RBAC permissions, standing or JIT as needed
, according to their required function in the workload.
Assign human and service principles to security groups based on their as-needed access. Where possible, use existing homogeneous groups as members of the function-based groups, such as those groups from pattern 1. Examples of function-based groups include:
Production database operators
Preproduction database operators
Production certificate rotation operators
Preproduction certificate rotation operators
Production live-site/triage
Preproduction all access
This approach maintains the strictest least-privilege access and provides security groups where scope is evident, which makes it easy to audit memberships relative to job duties performed. Often a built-in Azure role exists to match this job function.
However, membership is abstracted at least one layer, forcing you to go to the identity provider to understand who's in the group when looking from the resource perspective. Additionally, one person needs to have multiple memberships maintained for complete coverage. The matrix of overlapping security groups can be complex.
Pattern 2 is recommended to make the access patterns the focus, not the organization chart. Organization charts and member roles sometimes change. Capturing your workload's identity and access management from a functional perspective allows you to abstract your team organization from the secure management of the workload.
Networking segmentation patterns
Pattern 1: Segmentation within a workload (soft boundaries)
In this pattern, the workload is placed in a single virtual network using subnets to mark boundaries.
Segmentation is achieved using two subnets
, one for database and one for web workloads. You must configure NSGs that allow Subnet 1 to only communicate with Subnet 2 and Subnet 2 to only communicate with the internet. This pattern provides layer 3 level control.
Pattern 2: Segmentation within a workload
This pattern is an example of platform-level segmentation. Workload c
omponents are spread across multiple networks without peering between them
. All communication is routed through an intermediary that serves as a public access point. The workload team owns all networks.
Pattern 2 provides containment but has the added complexity of virtual network management and sizing. Communication between the two networks takes place over the public internet, which can be a risk. There's also latency with public connections. However, the two networks can be peered, breaking segmentation by connecting them to create a larger segment. Peering should be done when no other public endpoints are needed.
Considerations
Pattern 1
Pattern 2
Connectivity and routing: How each segment communicates
System routing provides default connectivity to workload components. No external component can communicate with the workload.
Within the virtual network, same as pattern 1.
Between networks, the traffic goes over the public internet. There's no direct connectivity between the networks.
Network-level traffic filtering
Traffic between the segments is allowed by default. Use NSGs or ASGs to filter traffic.
Within the virtual network, same as pattern 1.
Between the networks, you can filter both ingress and egress traffic through a firewall.
Unintended open public endpoints
Network interface cards (NICs) don't get public IPs. Virtual networks aren't exposed to internet API management.
Same as pattern 1. Intended open public endpoint on one virtual network, which can be misconfigured to accept more traffic.
Resource organization
Organize Azure resources based on ownership responsibility
Consider an Azure estate that contains multiple workloads and shared service components like hub virtual networks, firewalls, identity services, and security services like Microsoft Sentinel. Components throughout the estate should be grouped based on their functional areas, workloads, and ownership. For example, shared networking resources should be grouped together into a single subscription and managed by a networking team. Components that are dedicated to individual workloads should be in their own segment and might be further divided based on application tiers or other organizational principles.
Grant access to manage resources within individual segments by creating RBAC role assignments
. For example, the cloud networking team might be granted administrative access to the subscription that contains their resources, but not to individual workload subscriptions.
A good segmentation strategy makes it possible to easily identify the owners of each segment. Consider using Azure resource tags to annotate resource groups or subscriptions with the owner team.
Configure and review access control
Grant appropriate access based on need by clearly defining segments for your resources.
Consider the principle of least privilege when you define access control policies. It's important to distinguish between
control plane operations
(management of the resource itself) and
data plane operations
(access to the data stored by the resource). For example, suppose you have a workload that contains a database with sensitive information about employees. You might grant management access to some users that need to configure settings like database backups or users that monitor the performance of the database server. However, these users shouldn't be able to query the sensitive data stored in the database. Select permissions that grant the minimum scope needed for users to perform their duties. Regularly review role assignments for each segment and remove access that's no longer required.
Note
Some highly privileged roles, like the owner role in RBAC, give users the ability to grant other users access to a resource. Limit how many users or groups are assigned the owner role, and regularly review audit logs to ensure they only perform valid operations.
Related links
Isolation in the Azure public cloud
Recommendations for RBAC
Virtual networks overview
ASGs
Azure Firewall
Firewall Manager overview
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for security testing - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for security testing
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:11
Establish a comprehensive testing regimen that combines approaches to prevent security issues, validate threat prevention implementations, and test threat detection mechanisms.
Rigorous testing is the foundation of good security design. Testing is a tactical form of validation to make sure controls are working as intended. Testing is also a proactive way to detect vulnerabilities in the system.
Establish testing rigor through cadence and verification from multiple perspectives. You should include inside-out viewpoints that test platform and infrastructure and outside-in evaluations that test the system like an external attacker.
This guide provides recommendations for testing the security posture of your workload. Implement these testing methods to improve your workload's resistance to attacks and maintain confidentiality, integrity, and availability of resources.
Definitions
Term
Definition
Application security testing (AST)
A Microsoft Security Development Lifecycle (SDL) technique that uses white-box and black-box testing methodologies to check for security vulnerabilities in code.
Black-box testing
A testing methodology that validates the externally visible application behavior without knowledge of the internals of the system.
Blue team
A team that defends against the attacks of the red team in a war game exercise.
Penetration testing
A testing methodology that uses ethical hacking techniques to validate the security defenses of a system.
Red team
A team that plays the role of an adversary and attempts to hack the system in a war game exercise.
Security Development Lifecycle (SDL)
A set of practices provided by Microsoft that supports security assurance and compliance requirements.
Software development lifecycle (SDLC)
A multistage, systematic process for developing software systems.
White-box testing
A testing methodology where the structure of the code is known to the practitioner.
Key design strategies
Testing is a nonnegotiable strategy, especially for security. It allows you to proactively discover and address security issues before they can be exploited and to verify that the security controls that you implemented are functioning as designed.
The scope of testing must include the application, infrastructure, and automated and human processes.
Note
This guidance makes a distinction between testing and incident response. Although testing is a detection mechanism that ideally fixes issues prior to production, it shouldn't be confused with the remediation or investigation that's done as part of incident response. The aspect of recovering from security incidents is described in
Incident Response recommendations
.
SDL includes several types of tests that catch vulnerabilities in code, verify runtime components, and use ethical hacking to test the security resilience of the system. SDL is a key shift-left activity. You should run tests like static code analysis and automated scanning of infrastructure as code (IaC) as early in the development process as possible.
Be involved in test planning.
The workload team might not design the test cases. That task is often centralized in the enterprise or completed by external security experts. The workload team should be involved in that design process to ensure that security assurances integrate with the application's functionality.
Think like an attacker.
Design your test cases with the assumption that the system has been attacked. That way, you can uncover the potential vulnerabilities and prioritize the tests accordingly.
Run tests in a structured manner and with a repeatable process.
Build your testing rigor around cadence, types of tests, driving factors, and intended outcomes.
Use the right tool for the job.
Use tools that are configured to work with the workload. If you don't have a tool, buy the tool. Don't build it. Security tools are highly specialized, and building your own tool might introduce risks. Take advantage of the expertise and tools offered by central SecOps teams or by external means if the workload team doesn't have that expertise.
Set up separate environments.
Tests can be classified as destructive or nondestructive. Nondestructive tests aren't invasive. They indicate there's a problem, but they don't alter functionality in order to remediate the problem. Destructive tests are invasive and might damage functionality by deleting data from a database.
Testing in production environments gives you the best information but causes the most disruption. You tend to do only nondestructive tests in production environments. Testing in nonproduction environments is typically less disruptive but might not accurately represent the production environment's configuration in ways that are important to security.
If you deploy by using IaC and automation, consider whether you can create an isolated clone of your production environment for testing. If you have a continuous process for routine tests, we recommend using a dedicated environment.
Always evaluate the test results.
Testing is a wasted effort if the results aren't used to prioritize actions and make improvements upstream. Document the security guidelines, including best practices, that you uncover. Documentation that captures results and remediation plans educates the team about the various ways that attackers might try to breach security. Conduct regular security training for developers, admins, and testers.
When you design your test plans, think about the following questions:
How often do you expect the test to run, and how does it affect your environment?
What are the different test types that you should run?
Test the workload regularly
Test the workload regularly to make sure changes don't introduce security risks and that there aren't any regressions. The team must also be ready to respond to organizational security validations that might be conducted at any time. There are also tests that you can run in response to a security incident. The following sections provide recommendations on the frequency of tests.
Routine tests
Routine tests are conducted at a regular cadence, as part of your standard operating procedures and to meet compliance requirements. Various tests might be run at different cadences, but the key is that they're conducted periodically and on a schedule.
You should integrate these tests into your SDLC because they provide defense in depth at each stage. Diversify the test suite to verify assurances for identity, data storage and transmission, and communication channels. Conduct the same tests at different points in the lifecycle to ensure that there aren't any regressions. Routine tests help establish an initial benchmark. However that's just a starting point. As you uncover new issues at the same points of the lifecycle, you add new test cases. The tests also improve with repetition.
At each stage, these tests should validate code that's added or removed or configuration settings that have changed in order to detect the security impact of those changes. You should improve the tests' efficacy with automation, balanced with peer reviews.
Consider running security tests as part of an automated pipeline or scheduled test run. The sooner you discover security issues, the easier it is to find the code or configuration change that causes them.
Don't rely only on automated tests. Use manual testing to detect vulnerabilities that only human expertise can catch. Manual testing is good for exploratory use cases and finding unknown risks.
Improvised tests
Improvised tests provide point-in-time validation of security defenses. Security alerts that might affect the workload at that time trigger these tests. Organizational mandates might require a pause-and-test mindset to verify the effectiveness of defense strategies if the alert escalates to an emergency.
The benefit of improvised tests is preparedness for a real incident. These tests can be a forcing function to do user acceptance testing (UAT).
The security team might audit all workloads and run these tests as needed. As a workload owner, you need to facilitate and collaborate with security teams. Negotiate enough lead time with security teams so that you can prepare. Acknowledge and communicate to your team and stakeholders that these disruptions are necessary.
In other cases, you might be required to run tests and report the security state of the system against the potential threat.
Tradeoff
: Because improvised tests are disruptive events, expect to reprioritize tasks, which may delay other planned work.
Risk
: There's risk of the unknown. Improvised tests might be one-time efforts without established processes or tools. But the predominant risk is the potential interruption of the rhythm of business. You need to evaluate those risks relative to the benefits.
Security incident tests
There are tests that detect the cause of a security incident at its source. These security gaps must be resolved to make sure the incident isn't repeated.
Incidents also improve test cases over time by uncovering existing gaps. The team should apply the lessons learned from the incident and routinely incorporate improvements.
Employ a variety of tests
Tests can be categorized by
technology
and by
testing methodologies
. Combine those categories and approaches within those categories to get complete coverage.
By adding multiple tests and types of tests, you can uncover:
Gaps in security controls or compensating controls.
Misconfigurations.
Gaps in observability and detection methods.
A good threat modeling exercise can point to key areas to ensure test coverage and frequency. For recommendations on threat modeling, see
Recommendations for securing a development lifecycle
.
Most tests described in these sections can be run as routine tests. However, repeatability can incur costs in some cases and cause disruption. Consider those tradeoffs carefully.
Tests that validate the technology stack
Here are some examples of types of tests and their focus areas. This list isn't exhaustive. Test the entire stack, including the application stack, front end, back end, APIs, databases, and any external integrations.
Data security: Test the effectiveness of data encryption and access controls to ensure data is properly protected from unauthorized access and tampering.
Network and connectivity: Test your firewalls to ensure they only allow expected, allowed, and safe traffic to the workload.
Application: Test source code through application security testing (AST) techniques to make sure that you follow secure coding practices and to catch runtime errors like memory corruption and privilege issues. For details, see these
community links
.
Identity: Evaluate whether the role assignments and conditional checks work as intended.
Test methodology
There are many perspectives on testing methodologies. We recommend tests that enable threat hunting by simulating real-world attacks. They can identify potential threat actors, their techniques, and their exploits that pose a threat to the workload. Make the attacks as realistic as possible. Use all the potential threat vectors that you identify during threat modeling.
Here are some advantages of testing through real-world attacks:
When you make these attacks a part of routine testing, you use an outside-in perspective to check the workload and make sure the defense can withstand an attack.
Based on the lessons they learned, the team upgrades their knowledge and skill level. The team improves situational awareness and can self-assess their readiness to respond to incidents.
Risk
: Testing in general can affect performance. There might be business continuity problems if destructive tests delete or corrupt data. There are also risks associated with information exposure; make sure to maintain the confidentiality of data. Ensure the integrity of data after you complete testing.
Some examples of simulated tests include black-box and white-box testing, penetration testing, and war game exercises.
Black-box and white-box testing
These test types offer two different perspectives. In black-box tests, the internals of the system aren't visible. In white-box tests, the tester has a good understanding of the application and even has access to code, logs, resource topology, and configurations for conducting the experiment.
Risk
: The difference between the two types is upfront cost. White-box testing can be expensive in terms of time taken to understand the system. In some cases, white-box testing requires you to purchase specialized tools. Black-box testing doesn't need ramp-up time, but it might not be as effective. You might need to put in extra effort to uncover issues. It's a time investment tradeoff.
Tests that simulate attacks through penetration testing
Security experts who aren't part of the organization's IT or application teams conduct penetration testing, or
pentesting
. They look at the system in the way that malicious actors scope an attack surface. Their goal is to find security gaps by gathering information, analyzing vulnerabilities, and reporting the results.
Tradeoff
: Penetration tests are improvised and can be expensive in terms of disruptions and monetary investment because pentesting is typically a paid offering by third-party practitioners.
Risk
: A pentesting exercise might affect the runtime environment and might disrupt the availability for normal traffic.
The practitioners might need access to sensitive data in the entire organization. Follow the rules of engagement to ensure that access isn't misused. See the resources listed in
Related links
.
Tests that simulate attacks through war game exercises
In this methodology of simulated attacks, there are two teams:
The
red
team is the adversary attempting to model real-world attacks. If they're successful, you find gaps in your security design and evaluate the blast radius containment of their breaches.
The
blue
team is the workload team that defends against the attacks. They test their ability to detect, respond, and remediate the attacks. They validate the defenses that have been implemented to protect workload resources.
If they're conducted as routine tests, war game exercises can provide ongoing visibility and assurance that your defenses work as designed. War game exercises can potentially test across levels within your workloads.
A popular choice to simulate realistic attack scenarios is the Microsoft Defender for Office 365
Attack simulation training
.
For more information, see
Insights and reports for Attack simulation training
.
For information about red-team and blue-team setup, see
Microsoft Cloud Red Teaming
.
Azure facilitation
Microsoft Sentinel is a native control that combines security information event management (SIEM) and security orchestration automated response (SOAR) capabilities. It analyzes events and logs from various connected sources. Based on data sources and their alerts, Microsoft Sentinel creates incidents and performs threat analysis for early detection. Through intelligent analytics and queries, you can proactively hunt for security issues. If there's an incident, you can automate workflows. Also, with workbook templates, you can quickly gain insights through visualization.
For product documentation, see
Hunting capabilities in Microsoft Sentinel
.
Microsoft Defender for Cloud offers vulnerability scanning for various technology areas. For details, see
Enable vulnerability scanning with Microsoft Defender Vulnerability Management - Microsoft Defender for Cloud
.
The practice of DevSecOps integrates security testing as part of an ongoing and continuous improvement mindset. War game exercises are a common practice that's integrated into the rhythm of business at Microsoft. For more information, see
Security in DevOps (DevSecOps)
.
Azure DevOps supports third-party tools that can be automated as part of the continuous integration/continuous deployment pipelines. For details, see
Enable DevSecOps with Azure and GitHub - Azure DevOps
.
Related links
Follow the rules of engagement to make sure that access isn't misused. For guidance about planning and executing simulated attacks, see the following articles:
Penetration Testing Rules of Engagement
Penetration testing
You can simulate denial of service (DoS) attacks in Azure. Be sure to follow the policies laid out in
Azure DDoS Protection simulation testing
.
Community links
Application security testing: Tools, types, and best practices - GitHub Resources
describes the types of testing methodologies that can test the build-time and runtime defenses of the application.
Penetration Testing Execution Standard (PTES)
provides guidelines about common scenarios and the activities required to establish a baseline.
OWASP Top Ten | OWASP Foundation
provides security best practices for applications and test cases that cover common threats.
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Application threat analysis - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for threat analysis
Article
2024-06-18
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Security checklist recommendation:
SE:02
Maintain a secure development lifecycle by using a hardened, mostly automated, and auditable software supply chain. Incorporate a secure design by using threat modeling to safeguard against security-defeating implementations.
Related guide
:
Recommendations for securing a development lifecycle
A comprehensive analysis to identify threats, attacks, vulnerabilities, and counter measures is crucial during the design phase of a workload.
Threat modeling
is an engineering exercise that includes defining security requirements, identifying and mitigating threats, and validating those mitigations. You can use this technique at any stage of application development or production, but it's most effective during the design stages of new functionality.
This guide describes the recommendations for doing threat modeling so that you can identify security gaps quickly and design your security defenses.
Definitions
Term
Definition
Software development lifecycle (SDLC)
A multistage, systematic process for developing software systems.
STRIDE
A Microsoft-defined taxonomy for categorizing types of threats.
Threat modeling
A process for identifying potential security vulnerabilities in the application and system, mitigating risks, and validating security controls.
Key design strategies
Threat modeling is a crucial process that an organization should integrate into its SDLC. Threat modeling is not solely a developer's task. It's a shared responsibility between:
The workload team, which is responsible for the technical aspects of the system.
Business stakeholders, who understand the business outcomes and have a vested interest in security.
There's often a disconnect between organizational leadership and technical teams regarding business requirements for critical workloads. This disconnect can lead to unwanted outcomes, particularly for security investments.
When the workload team is doing a threat modeling exercise, it should consider both business and technical requirements. The workload team and business stakeholders must agree on security-specific needs of the workload so that they can make adequate investments in the countermeasures.
The security requirements serve as guide for the entire process of threat modeling. To make it an effective exercise, the workload team should have a security mindset and be trained in threat modeling tools.
Understand the scope of the exercise
A clear understanding of the scope is crucial for effective threat modeling. It helps focus efforts and resources on the most critical areas. This strategy involves defining the boundaries of the system, taking inventory of the assets that need to be protected, and understanding the level of investment that's required in security controls.
Gather information about each component
A workload architecture diagram is a starting point for gathering information because it provides a visual representation of the system. The diagram highlights technical dimensions of the system. For example, it shows user flows, how data moves through the network, data sensitivity levels and information types, and identity access paths.
This detailed analysis can often provide insight into potential vulnerabilities in the design. It's important to understand the functionality of each component and its dependencies.
Evaluate the potential threats
Analyze each component from an outside-in perspective. For example, how easily can an attacker gain access to sensitive data? If attackers gain access to the environment, can they move laterally and potentially access or even manipulate other resources? These questions help you understand how an attacker might exploit workload assets.
Classify the threats by using an industry methodology
One methodology for classifying threats is
STRIDE
, which the Microsoft Security Development Lifecycle uses. Classifying threats helps you understand the nature of each threat and use appropriate security controls.
Mitigate the threats
Document all the identified threats. For each threat, define security controls and the response to an attack if those controls fail. Define a process and timeline that minimize exposure to any identified vulnerabilities in the workload, so that those vulnerabilities can't be left unaddressed.
Use the
assume breach
approach. It can help identify controls needed in the design to mitigate risk if a primary security control fails. Evaluate how likely it is for the primary control to fail. If it does fail, what is the extent of the potential organizational risk? Also, what is the effectiveness of the compensating control? Based on the evaluation, apply defense-in-depth measures to address potential failures of security controls.
Here's an example:
Ask this question
To determine controls that...
Are connections authenticated through Microsoft Entra ID, Transport Layer Security (TLS) with mutual authentication, or another modern security protocol that the security team approved:
- Between users and the application?
- Between application components and services?
Prevent unauthorized access to the application components and data.
Are you limiting access to only accounts that need to write or modify data in the application?
Prevent unauthorized data tampering or alteration.
Is the application activity logged and fed into a security information and event management (SIEM) system through Azure Monitor or a similar solution?
Detect and investigate attacks quickly.
Is critical data protected with encryption that the security team approved?
Prevent unauthorized copying of data at rest.
Are inbound and outbound network traffic encrypted through TLS?
Prevent unauthorized copying of data in transit.
Is the application protected against distributed denial of service (DDoS) attacks through services such as Azure DDoS Protection?
Detect attacks designed to overload the application so it can't be used.
Does the application store sign-in credentials or keys to access other applications, databases, or services?
Identify whether an attack can use your application to attack other systems.
Do the application controls allow you to fulfill regulatory requirements?
Protect users' private data and avoid compliance fines.
Track threat modeling results
We highly recommend that you use a
threat modeling tool
. Tools can automate the process of identifying threats and produce a comprehensive report of all identified threats. Be sure to communicate the results to all interested teams.
Track the results as part of the workload team's backlog to allow for accountability in a timely way. Assign tasks to individuals who are responsible for mitigating a particular risk that threat modeling identified.
As you add new features to the solution, update the threat model and integrate it into the code management process. If you find a security problem, make sure there's a process to triage the problem based on severity. The process should help you determine when and how to remediate the problem (for example, in the next release cycle or in a faster release).
Review business-critical workload requirements regularly
Meet regularly with executive sponsors to define requirements. These reviews provide an opportunity to align expectations and ensure operational resource allocation to the initiative.
Azure facilitation
The Microsoft Security Development Lifecycle provides a threat modeling tool to assist with the threat modeling process. This tool is available at no additional cost. For more information, see the
Threat Modeling page
.
Example
This example builds on the Information Technology (IT) environment established in the
security baseline (SE:01)
. This approach provides a broad understanding of the threat landscape across different IT scenarios.
Development Lifecycle personas
. There are many personas involved in a development life cycle, including developers, testers, final users, and administrators. All of them may be compromised and put your environment at risk through vulnerabilities or threats created intentionally.
Potential attackers
. Attackers consider a wide range of tools available easily to be used at any time to explore your vulnerabilities and start an attack.
Security controls
. As part of threat analysis, identify Azure security services to be used to protect your solution and how effective those solutions are.
Log collection
. Logs from Azure resources and some on-premises components may be sent to Azure Log Analytics so you may understand the behavior of your solution developed and try to capture initial vulnerabilities.
Security information event management (SIEM) solution
. Microsoft Sentinel may be added even in an early stage of the solution so you can  build some analytics queries to mitigate threats and vulnerabilities, anticipating your security environment when you are in production.
Microsoft Defender for Cloud
might make some security recommendations to improve the security posture.
Related links
STRIDE
Threat Modeling
Community links
Open Web Application Security Project (OWASP)
has documented a threat modeling approach for applications.
Security checklist
Refer to the complete set of recommendations.
Security checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Security tradeoffs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Security tradeoffs
Article
2024-10-10
3 contributors
Feedback
In this article
Security provides confidentiality, integrity, and availability assurances of a workload's system and its users' data. Security controls are required for the workload and for the software development and operational components of the system. When teams design and operate a workload, they can almost never compromise on security controls.
During the design phase of a workload, it's important to consider how decisions based on the
Security design principles
and the recommendations in the
Design review checklist for Security
might influence the goals and optimizations of other pillars. Certain security decisions might benefit some pillars but constitute tradeoffs for others. This article describes example tradeoffs that a workload team might encounter when establishing security assurances.
Security tradeoffs with Reliability
Tradeoff: Increased complexity.
The Reliability pillar prioritizes simplicity and recommends that points of failure are minimized.
Some security controls can increase the risk of misconfiguration, which can lead to service disruption. Examples of security controls that can introduce misconfiguration include network traffic rules, identity providers, virus scanning exclusions, and role-based or attribute-based access control assignments.
Increased segmentation usually results in a more complex environment in terms of resource and network topology and operator access. This complexity can lead to more points of failure in processes and in workload execution.
Workload security tooling is often incorporated into many layers of a workload's architecture, operations, and runtime requirements. These tools might affect resiliency, availability, and capacity planning. Failure to account for limitations in the tooling can lead to a reliability event, like SNAT port exhaustion on an egress firewall.
Tradeoff:  Increased critical dependencies.
The Reliability pillar recommends minimizing critical dependencies. A workload that minimizes critical dependencies, especially external ones, has more control over its points of failure.
The Security pillar requires a workload to explicitly verify identities and actions. Verification occurs via critical dependencies on key security components. If those components aren't available or if they malfunction, verification might not complete. This failure puts the workload in a degraded state. Some examples of these critical single-point-of-failure dependencies are:
Ingress and egress firewalls.
Certificate revocation lists.
Accurate system time provided by a Network Time Protocol (NTP) server.
Identity providers, like Microsoft Entra ID.
Tradeoff:  Increased complexity of disaster recovery.
A workload must reliably recover from all forms of disaster.
Security controls might affect recovery time objectives. This effect can be caused by the additional steps that are needed to decrypt backed up data or by operational access delays created by site reliability triage.
Security controls themselves, for example secret vaults and their contents or edge DDoS protection, need to be part of the disaster recovery plan of the workload and must be validated via recovery drills.
Security or compliance requirements might limit data residency options or access control restrictions for backups, potentially further complicating recovery by segmenting even offline replicas.
Tradeoff: Increased rate of change.
A workload that experiences runtime change is exposed to more risk of reliability impact due to that change.
Stricter patching and update policies lead to more changes in a workload's production environment. This change comes from sources like these:
Application code being released more frequently because of updates to libraries or updates to base container images
Increased routine patching of operating systems
Staying current with versioned applications or data platforms
Applying vendor patches to software in the environment
Rotation activities for keys, service principal credentials, and certificates increase the risk of transient issues due to the timing of the rotation and clients using the new value.
Security tradeoffs with Cost Optimization
Tradeoff: Additional infrastructure.
One approach to cost optimizing a workload is to look for ways to reduce the diversity and number of components and increase density.
Some workload components or design decisions exist only to protect the security (confidentiality, integrity, and availability) of systems and data. These components, although they enhance the security of the environment, also increase costs. They must also be subject to cost optimization themselves. Some example sources for these security-centric additional resources or licensing costs are:
Compute, network, and data segmentation for isolation, which sometimes involves running separate instances, preventing co-location and reducing density.
Specialized observability tooling, like a SIEM that can perform aggregation and threat intelligence.
Specialized networking appliances or capabilities, like firewalls or distributed denial-of-service prevention.
Data classification tools that are required for capturing sensitivity and information-type labels.
Specialized storage or compute capabilities to support encryption at rest and in transit, like an HSM or confidential-compute functionality.
Dedicated testing environments and testing tools to validate that security controls are functioning and to uncover previously undiscovered gaps in coverage.
The preceding items often also exist outside of production environments, in preproduction and disaster recovery resources.
Tradeoff: Increased demand on infrastructure.
The Cost Optimization pillar prioritizes driving down demand on resources to enable the use of cheaper SKUs, fewer instances, or reduced consumption.
Premium SKUs
: Some security measures in cloud and vendor services that can benefit the security posture of a workload might only be found in more expensive SKUs or tiers.
Log storage
: High fidelity security monitoring and audit data that provide broad coverage increase storage costs. Security observability data is also often stored for longer periods of time than would typically be needed for operational insights.
Increased resource consumption
: In-process and on-host security controls can introduce additional demand for resources. Encryption for data at rest and in transit can also increase demand. Both scenarios can require higher instance counts or larger SKUs.
Tradeoff: Increased process and operational costs.
Personnel process costs are part of the overall total cost of ownership and are factored into a workload's return on investment. Optimizing these costs is a recommendation of the Cost Optimization pillar.
A more comprehensive and strict patch management regime leads to an increase in time and money spent on these routine tasks. This increase is often coupled with the expectation of investing in preparedness for ad hoc patching for zero-day exploits.
Stricter access controls to reduce the risk of unauthorized access can lead to more complex user management and operational access.
Training and awareness for security tools and processes take up employee time and also incur costs for materials, instructors, and possibly training environments.
Complying with regulations might necessitate additional investments for audits and generating compliance reporting.
Planning for and conducting drills for security-incident response preparedness takes time.
Time needs to be allocated for designing and performing routine and ad hoc processes that are associated with security, like key or certificate rotation.
The security validation of the SDLC usually requires specialized tools. Your organization might need to pay for these tools. Prioritizing and remediating issues found during testing also takes time.
Hiring third-party security practitioners to perform white-box testing or testing that's performed without the knowledge of a system's internal workings (sometimes known as
black-box testing
), including penetration testing, incurs costs.
Security tradeoffs with Operational Excellence
Tradeoff: Complications in observability and serviceability.
Operational Excellence requires architectures to be serviceable and observable. The most serviceable architectures are those that are the most transparent to everyone involved.
Security benefits from extensive logging that provides high fidelity insight into the workload for alerting on deviations from baselines and for incident response. This logging can generate a significant volume of logs, which can make it harder to provide insights that are targeted at reliability or performance.
When compliance guidelines for data masking are followed, specific segments of logs or even large amounts of tabular data are redacted to protect confidentiality. The team needs to evaluate how this observability gap might affect alerting or hinder incident response.
Strong resource segmentation increases the complexity of observability by requiring additional cross-service distributed tracing and correlation for capturing flow traces. The segmentation also increases the surface area of compute and data to service.
Some security controls impede access by design. During incident response, these controls can slow down workload operators' emergency access. Therefore, incident response plans need to include more emphasis on planning and drills in order to reach acceptable efficacy.
Tradeoff: Decreased agility and increased complexity.
Workload teams measure their velocity so that they can improve the quality, frequency, and efficiency of delivery activities over time. Workload complexity factors into the effort and risk involved in operations.
Stricter change control and approval policies to reduce the risk of introducing security vulnerabilities can slow down the development and safe deployment of new features. However, the expectation of addressing security updates and patching can increase demand for more frequent deployments. Additionally, human-gated approval policies in operational processes can make it more difficult to automate those processes.
Security testing results in findings that need to be prioritized, potentially blocking planned work.
Routine, ad hoc, and emergency processes might require audit logging to meet compliance requirements. This logging increases the rigidity of running the processes.
Workload teams might increase the complexity of identity management activities as the granularity of role definitions and assignments is increased.
An increased number of routine operational tasks that are associated with security, like certificate management, increases the number of processes to automate.
Tradeoff: Increased coordination efforts.
A team that minimizes external points of contact and review can control their operations and timeline more effectively.
As external compliance requirements from the larger organization or from external entities increase, the complexity of achieving and proving compliance with auditors also increases.
Security requires specialized skills that workload teams don't typically have. Those proficiencies are often sourced from the larger organization or from third parties. In both cases, coordination of effort, access, and responsibility needs to be established.
Compliance or organizational requirements often require maintained communication plans for responsible disclosure of breaches. These plans must be factored into security coordination efforts.
Security tradeoffs with Performance Efficiency
Tradeoff: Increased latency and overhead.
A performant workload reduces latency and overhead.
Inspection security controls, like firewalls and content safety filters, are located in the flows that they secure. Those flows are therefore subject to additional verification, which adds latency to requests. In highly decoupled architecture the distributed nature can lead to these inspections happening multiple times for a single user or data flow transaction.
Identity controls require each invocation of a controlled component to be verified explicitly. This verification consumes compute cycles and might require network traversal for authorization.
Encryption and decryption require dedicated compute cycles. These cycles increase the time and resources consumed by those flows. This increase is usually correlated with the complexity of the algorithm and the generation of high-entropy and diverse initialization vectors (IVs).
As the extensiveness of logging increases, the impact on system resources and network bandwidth for streaming those logs can also increase.
Resource segmentation frequently introduces network hops in a workload's architecture.
Tradeoff: Increased chance of misconfiguration.
Reliably meeting performance targets depends on predictable implementations of the design.
A misconfiguration or overextension of security controls can impact performance because of inefficient configuration. Examples of security control configurations that can affect performance include:
Firewall rule ordering, complexity, and quantity (granularity).
Failing to exclude key files from file integrity monitors or virus scanners. Neglecting this step can lead to lock contention.
Web application firewalls performing deep packet inspection for languages or platforms that are irrelevant for the components that are being protected.
Related links
Explore the tradeoffs for the other pillars:
Reliability tradeoffs
Cost Optimization tradeoffs
Operational Excellence tradeoffs
Performance Efficiency tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025