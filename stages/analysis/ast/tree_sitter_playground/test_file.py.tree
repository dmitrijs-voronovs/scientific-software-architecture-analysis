module: b'import json\r\nimport os\r\nimport subprocess\r\nfrom typing import List\r\n\r\n"""Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n"""\r\n\r\n\'\'\'22222Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n\'\'\'\r\n\r\nfrom services.git import clone_repo, clone_tag, get_abs_parent_dir\r\n\r\n# WORDS = "1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")\r\nany_book = 1\r\nMY_FAVORITE_BOOK = "Garfield"\r\nWORDS = "1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")\r\n\r\ntype Book = List[int]\r\n\r\n\r\n# --------------------------------------------------------------------------------\r\n# Graph stuff\r\n# --------------------------------------------------------------------------------\r\n\r\ndef read(\r\n        filename: str,\r\n):\r\n    """\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``\'r\'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``\'r+\'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``\' \'``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast \'h5ad\' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    """\r\n    filekey = str(filename)\r\n    return filekey\r\n\r\n\r\nclass BaseReader:\r\n    """\r\n    Base class for reading books\r\n    """\r\n\r\n    def __init__(self, book: Book):\r\n        self.book = book\r\n\r\n    def read(self, page: int) -> int:\r\n        return self.book[page]\r\n\r\n    @classmethod\r\n    def create_class(cls):\r\n        return BaseReader([1, 23])\r\n\r\n    @staticmethod\r\n    def read_all_words(cls):\r\n        return ",".join(str(word) for word in cls.book)\r\n\r\n    def read_all(self):\r\n        return self.book\r\n\r\n\r\nclass WordReader(BaseReader):\r\n    """\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    """\r\n    instances = 0\r\n    new_books: List[Book]\r\n\r\n    def read(self, page: int):\r\n        return self.book[page]\r\n\r\n    def read_all(self):\r\n        return self.book\r\n\r\n    def read_all_words(self):\r\n        return ",".join(str(word) for word in self.book)\r\n\r\n\r\nclass Writer():\r\n    def write(self, word: str):\r\n        print(word)\r\n\r\n\r\nclass Manager(BaseReader, Writer):\r\n    def test(self):\r\n        pass\r\n\r\n\r\ndef run_gumtree_diff(author: str, repo_name, repo_path, tag1, tag2) -> dict:\r\n    # Clone the repository twice and checkout the respective tags\r\n    path1 = clone_tag(author, repo_name, repo_path, tag1)\r\n    path2 = clone_tag(author, repo_name, repo_path, tag2)\r\n\r\n    root_dir = get_abs_parent_dir()\r\n\r\n    # Run GumTree on the entire project\r\n    cmd = [\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]\r\n    print(" ".join(cmd))\r\n    result = subprocess.run(cmd, capture_output=True, text=True)\r\n\r\n    return json.loads(result.stdout)\r\n\r\n\r\ndef generate_metadata(author, repo_name, tag1, tag2):\r\n    os.makedirs(\'./.tmp/source\', exist_ok=True)\r\n    repo_path = clone_repo(author, repo_name)\r\n\r\n    metadata = {\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }\r\n\r\n    return metadata\r\n\r\n\r\ndef main():\r\n    def sub_fun():\r\n        pass\r\n\r\n    # author = input("Enter GitHub repository author: ")\r\n    # repo_name = input("Enter GitHub repository name: ")\r\n    # tag1 = input("Enter first tag: ")\r\n    # tag2 = input("Enter second tag: ")\r\n\r\n    author = "scverse"\r\n    repo_name = "scanpy"\r\n    tag1 = "1.10.1"\r\n    tag2 = "1.10.2"\r\n\r\n    metadata = generate_metadata(author, repo_name, tag1, tag2)\r\n\r\n    with open("diff_metadata.json", "w") as f:\r\n        json.dump(metadata, f, indent=2)\r\n\r\n    print("Metadata has been saved to diff_metadata.json")\r\n\r\n\r\nif __name__ == "__main__":\r\n    main()\r\n'
  import_statement: b'import json'
    import: b'import'
    dotted_name: b'json'
      identifier: b'json'
  import_statement: b'import os'
    import: b'import'
    dotted_name: b'os'
      identifier: b'os'
  import_statement: b'import subprocess'
    import: b'import'
    dotted_name: b'subprocess'
      identifier: b'subprocess'
  import_from_statement: b'from typing import List'
    from: b'from'
    dotted_name: b'typing'
      identifier: b'typing'
    import: b'import'
    dotted_name: b'List'
      identifier: b'List'
  expression_statement: b'"""Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n"""'
    string: b'"""Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n"""'
      string_start: b'"""'
      string_content: b'Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n'
      string_end: b'"""'
  expression_statement: b"'''22222Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n'''"
    string: b"'''22222Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n'''"
      string_start: b"'''"
      string_content: b'22222Utility functions and classes\r\n\r\nThis file largely consists of the old _utils.py file. Over time, these functions\r\nshould be moved of this file.\r\n'
      string_end: b"'''"
  import_from_statement: b'from services.git import clone_repo, clone_tag, get_abs_parent_dir'
    from: b'from'
    dotted_name: b'services.git'
      identifier: b'services'
      .: b'.'
      identifier: b'git'
    import: b'import'
    dotted_name: b'clone_repo'
      identifier: b'clone_repo'
    ,: b','
    dotted_name: b'clone_tag'
      identifier: b'clone_tag'
    ,: b','
    dotted_name: b'get_abs_parent_dir'
      identifier: b'get_abs_parent_dir'
  comment: b'# WORDS = "1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")\r'
  expression_statement: b'any_book = 1'
    assignment: b'any_book = 1'
      identifier: b'any_book'
      =: b'='
      integer: b'1'
  expression_statement: b'MY_FAVORITE_BOOK = "Garfield"'
    assignment: b'MY_FAVORITE_BOOK = "Garfield"'
      identifier: b'MY_FAVORITE_BOOK'
      =: b'='
      string: b'"Garfield"'
        string_start: b'"'
        string_content: b'Garfield'
        string_end: b'"'
  expression_statement: b'WORDS = "1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")'
    assignment: b'WORDS = "1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")'
      identifier: b'WORDS'
      =: b'='
      call: b'"1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split(",")'
        attribute: b'"1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20".split'
          string: b'"1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20"'
            string_start: b'"'
            string_content: b'1,2,31,4124,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20'
            string_end: b'"'
          .: b'.'
          identifier: b'split'
        argument_list: b'(",")'
          (: b'('
          string: b'","'
            string_start: b'"'
            string_content: b','
            string_end: b'"'
          ): b')'
  type_alias_statement: b'type Book = List[int]'
    type: b'type'
    type: b'Book'
      identifier: b'Book'
    =: b'='
    type: b'List[int]'
      generic_type: b'List[int]'
        identifier: b'List'
        type_parameter: b'[int]'
          [: b'['
          type: b'int'
            identifier: b'int'
          ]: b']'
  comment: b'# --------------------------------------------------------------------------------\r'
  comment: b'# Graph stuff\r'
  comment: b'# --------------------------------------------------------------------------------\r'
  function_definition: b'def read(\r\n        filename: str,\r\n):\r\n    """\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``\'r\'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``\'r+\'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``\' \'``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast \'h5ad\' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    """\r\n    filekey = str(filename)\r\n    return filekey'
    def: b'def'
    identifier: b'read'
    parameters: b'(\r\n        filename: str,\r\n)'
      (: b'('
      typed_parameter: b'filename: str'
        identifier: b'filename'
        :: b':'
        type: b'str'
          identifier: b'str'
      ,: b','
      ): b')'
    :: b':'
    block: b'"""\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``\'r\'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``\'r+\'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``\' \'``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast \'h5ad\' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    """\r\n    filekey = str(filename)\r\n    return filekey'
      expression_statement: b'"""\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``\'r\'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``\'r+\'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``\' \'``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast \'h5ad\' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    """'
        string: b'"""\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``\'r\'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``\'r+\'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``\' \'``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast \'h5ad\' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    """'
          string_start: b'"""'
          string_content: b"\\\r\n    Read file and return :class:`~anndata.AnnData` object.\r\n\r\n    To speed up reading, consider passing ``cache=True``, which creates an hdf5\r\n    cache file.\r\n\r\n    Parameters\r\n    ----------\r\n    filename\r\n        If the filename has no file extension, it is interpreted as a key for\r\n        generating a filename via ``sc.settings.writedir / (filename +\r\n        sc.settings.file_format_data)``.  This is the same behavior as in\r\n        ``sc.read(filename, ...)``.\r\n    backed\r\n        If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead\r\n        of fully loading it into memory (`memory` mode). If you want to modify\r\n        backed attributes of the AnnData object, you need to choose ``'r+'``.\r\n    sheet\r\n        Name of sheet/table in hdf5 or Excel file.\r\n    ext\r\n        Extension that indicates the file type. If ``None``, uses extension of\r\n        filename.\r\n    delimiter\r\n        Delimiter that separates data within text file. If ``None``, will split at\r\n        arbitrary number of white spaces, which is different from enforcing\r\n        splitting at any single white space ``' '``.\r\n    first_column_names\r\n        Assume the first column stores row names. This is only necessary if\r\n        these are not strings: strings in the first column are automatically\r\n        assumed to be row names.\r\n    backup_url\r\n        Retrieve the file from an URL if not present on disk.\r\n    cache\r\n        If `False`, read from source, if `True`, read from fast 'h5ad' cache.\r\n    cache_compression\r\n        See the h5py :ref:`dataset_compression`.\r\n        (Default: `settings.cache_compression`)\r\n    kwargs\r\n        Parameters passed to :func:`~anndata.read_loom`.\r\n\r\n    Returns\r\n    -------\r\n    An :class:`~anndata.AnnData` object\r\n    "
            escape_sequence: b'\\\r\n'
          string_end: b'"""'
      expression_statement: b'filekey = str(filename)'
        assignment: b'filekey = str(filename)'
          identifier: b'filekey'
          =: b'='
          call: b'str(filename)'
            identifier: b'str'
            argument_list: b'(filename)'
              (: b'('
              identifier: b'filename'
              ): b')'
      return_statement: b'return filekey'
        return: b'return'
        identifier: b'filekey'
  class_definition: b'class BaseReader:\r\n    """\r\n    Base class for reading books\r\n    """\r\n\r\n    def __init__(self, book: Book):\r\n        self.book = book\r\n\r\n    def read(self, page: int) -> int:\r\n        return self.book[page]\r\n\r\n    @classmethod\r\n    def create_class(cls):\r\n        return BaseReader([1, 23])\r\n\r\n    @staticmethod\r\n    def read_all_words(cls):\r\n        return ",".join(str(word) for word in cls.book)\r\n\r\n    def read_all(self):\r\n        return self.book'
    class: b'class'
    identifier: b'BaseReader'
    :: b':'
    block: b'"""\r\n    Base class for reading books\r\n    """\r\n\r\n    def __init__(self, book: Book):\r\n        self.book = book\r\n\r\n    def read(self, page: int) -> int:\r\n        return self.book[page]\r\n\r\n    @classmethod\r\n    def create_class(cls):\r\n        return BaseReader([1, 23])\r\n\r\n    @staticmethod\r\n    def read_all_words(cls):\r\n        return ",".join(str(word) for word in cls.book)\r\n\r\n    def read_all(self):\r\n        return self.book'
      expression_statement: b'"""\r\n    Base class for reading books\r\n    """'
        string: b'"""\r\n    Base class for reading books\r\n    """'
          string_start: b'"""'
          string_content: b'\r\n    Base class for reading books\r\n    '
          string_end: b'"""'
      function_definition: b'def __init__(self, book: Book):\r\n        self.book = book'
        def: b'def'
        identifier: b'__init__'
        parameters: b'(self, book: Book)'
          (: b'('
          identifier: b'self'
          ,: b','
          typed_parameter: b'book: Book'
            identifier: b'book'
            :: b':'
            type: b'Book'
              identifier: b'Book'
          ): b')'
        :: b':'
        block: b'self.book = book'
          expression_statement: b'self.book = book'
            assignment: b'self.book = book'
              attribute: b'self.book'
                identifier: b'self'
                .: b'.'
                identifier: b'book'
              =: b'='
              identifier: b'book'
      function_definition: b'def read(self, page: int) -> int:\r\n        return self.book[page]'
        def: b'def'
        identifier: b'read'
        parameters: b'(self, page: int)'
          (: b'('
          identifier: b'self'
          ,: b','
          typed_parameter: b'page: int'
            identifier: b'page'
            :: b':'
            type: b'int'
              identifier: b'int'
          ): b')'
        ->: b'->'
        type: b'int'
          identifier: b'int'
        :: b':'
        block: b'return self.book[page]'
          return_statement: b'return self.book[page]'
            return: b'return'
            subscript: b'self.book[page]'
              attribute: b'self.book'
                identifier: b'self'
                .: b'.'
                identifier: b'book'
              [: b'['
              identifier: b'page'
              ]: b']'
      decorated_definition: b'@classmethod\r\n    def create_class(cls):\r\n        return BaseReader([1, 23])'
        decorator: b'@classmethod'
          @: b'@'
          identifier: b'classmethod'
        function_definition: b'def create_class(cls):\r\n        return BaseReader([1, 23])'
          def: b'def'
          identifier: b'create_class'
          parameters: b'(cls)'
            (: b'('
            identifier: b'cls'
            ): b')'
          :: b':'
          block: b'return BaseReader([1, 23])'
            return_statement: b'return BaseReader([1, 23])'
              return: b'return'
              call: b'BaseReader([1, 23])'
                identifier: b'BaseReader'
                argument_list: b'([1, 23])'
                  (: b'('
                  list: b'[1, 23]'
                    [: b'['
                    integer: b'1'
                    ,: b','
                    integer: b'23'
                    ]: b']'
                  ): b')'
      decorated_definition: b'@staticmethod\r\n    def read_all_words(cls):\r\n        return ",".join(str(word) for word in cls.book)'
        decorator: b'@staticmethod'
          @: b'@'
          identifier: b'staticmethod'
        function_definition: b'def read_all_words(cls):\r\n        return ",".join(str(word) for word in cls.book)'
          def: b'def'
          identifier: b'read_all_words'
          parameters: b'(cls)'
            (: b'('
            identifier: b'cls'
            ): b')'
          :: b':'
          block: b'return ",".join(str(word) for word in cls.book)'
            return_statement: b'return ",".join(str(word) for word in cls.book)'
              return: b'return'
              call: b'",".join(str(word) for word in cls.book)'
                attribute: b'",".join'
                  string: b'","'
                    string_start: b'"'
                    string_content: b','
                    string_end: b'"'
                  .: b'.'
                  identifier: b'join'
                generator_expression: b'(str(word) for word in cls.book)'
                  (: b'('
                  call: b'str(word)'
                    identifier: b'str'
                    argument_list: b'(word)'
                      (: b'('
                      identifier: b'word'
                      ): b')'
                  for_in_clause: b'for word in cls.book'
                    for: b'for'
                    identifier: b'word'
                    in: b'in'
                    attribute: b'cls.book'
                      identifier: b'cls'
                      .: b'.'
                      identifier: b'book'
                  ): b')'
      function_definition: b'def read_all(self):\r\n        return self.book'
        def: b'def'
        identifier: b'read_all'
        parameters: b'(self)'
          (: b'('
          identifier: b'self'
          ): b')'
        :: b':'
        block: b'return self.book'
          return_statement: b'return self.book'
            return: b'return'
            attribute: b'self.book'
              identifier: b'self'
              .: b'.'
              identifier: b'book'
  class_definition: b'class WordReader(BaseReader):\r\n    """\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    """\r\n    instances = 0\r\n    new_books: List[Book]\r\n\r\n    def read(self, page: int):\r\n        return self.book[page]\r\n\r\n    def read_all(self):\r\n        return self.book\r\n\r\n    def read_all_words(self):\r\n        return ",".join(str(word) for word in self.book)'
    class: b'class'
    identifier: b'WordReader'
    argument_list: b'(BaseReader)'
      (: b'('
      identifier: b'BaseReader'
      ): b')'
    :: b':'
    block: b'"""\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    """\r\n    instances = 0\r\n    new_books: List[Book]\r\n\r\n    def read(self, page: int):\r\n        return self.book[page]\r\n\r\n    def read_all(self):\r\n        return self.book\r\n\r\n    def read_all_words(self):\r\n        return ",".join(str(word) for word in self.book)'
      expression_statement: b'"""\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    """'
        string: b'"""\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    """'
          string_start: b'"""'
          string_content: b'\\\r\n    Functionality for generic grouping and aggregating.\r\n\r\n    There is currently support for count_nonzero, sum, mean, and variance.\r\n\r\n    **Implementation**\r\n\r\n    Moments are computed using weighted sum aggregation of data by some feature\r\n    via multiplication by a sparse coordinate matrix A.\r\n\r\n    Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero)\r\n    entries in X with multiplicity the number of group memberships for that entry.\r\n    This is `O(data)` for partitions (each observation belonging to exactly one group),\r\n    independent of the number of groups.\r\n    '
            escape_sequence: b'\\\r\n'
          string_end: b'"""'
      expression_statement: b'instances = 0'
        assignment: b'instances = 0'
          identifier: b'instances'
          =: b'='
          integer: b'0'
      expression_statement: b'new_books: List[Book]'
        assignment: b'new_books: List[Book]'
          identifier: b'new_books'
          :: b':'
          type: b'List[Book]'
            generic_type: b'List[Book]'
              identifier: b'List'
              type_parameter: b'[Book]'
                [: b'['
                type: b'Book'
                  identifier: b'Book'
                ]: b']'
      function_definition: b'def read(self, page: int):\r\n        return self.book[page]'
        def: b'def'
        identifier: b'read'
        parameters: b'(self, page: int)'
          (: b'('
          identifier: b'self'
          ,: b','
          typed_parameter: b'page: int'
            identifier: b'page'
            :: b':'
            type: b'int'
              identifier: b'int'
          ): b')'
        :: b':'
        block: b'return self.book[page]'
          return_statement: b'return self.book[page]'
            return: b'return'
            subscript: b'self.book[page]'
              attribute: b'self.book'
                identifier: b'self'
                .: b'.'
                identifier: b'book'
              [: b'['
              identifier: b'page'
              ]: b']'
      function_definition: b'def read_all(self):\r\n        return self.book'
        def: b'def'
        identifier: b'read_all'
        parameters: b'(self)'
          (: b'('
          identifier: b'self'
          ): b')'
        :: b':'
        block: b'return self.book'
          return_statement: b'return self.book'
            return: b'return'
            attribute: b'self.book'
              identifier: b'self'
              .: b'.'
              identifier: b'book'
      function_definition: b'def read_all_words(self):\r\n        return ",".join(str(word) for word in self.book)'
        def: b'def'
        identifier: b'read_all_words'
        parameters: b'(self)'
          (: b'('
          identifier: b'self'
          ): b')'
        :: b':'
        block: b'return ",".join(str(word) for word in self.book)'
          return_statement: b'return ",".join(str(word) for word in self.book)'
            return: b'return'
            call: b'",".join(str(word) for word in self.book)'
              attribute: b'",".join'
                string: b'","'
                  string_start: b'"'
                  string_content: b','
                  string_end: b'"'
                .: b'.'
                identifier: b'join'
              generator_expression: b'(str(word) for word in self.book)'
                (: b'('
                call: b'str(word)'
                  identifier: b'str'
                  argument_list: b'(word)'
                    (: b'('
                    identifier: b'word'
                    ): b')'
                for_in_clause: b'for word in self.book'
                  for: b'for'
                  identifier: b'word'
                  in: b'in'
                  attribute: b'self.book'
                    identifier: b'self'
                    .: b'.'
                    identifier: b'book'
                ): b')'
  class_definition: b'class Writer():\r\n    def write(self, word: str):\r\n        print(word)'
    class: b'class'
    identifier: b'Writer'
    argument_list: b'()'
      (: b'('
      ): b')'
    :: b':'
    block: b'def write(self, word: str):\r\n        print(word)'
      function_definition: b'def write(self, word: str):\r\n        print(word)'
        def: b'def'
        identifier: b'write'
        parameters: b'(self, word: str)'
          (: b'('
          identifier: b'self'
          ,: b','
          typed_parameter: b'word: str'
            identifier: b'word'
            :: b':'
            type: b'str'
              identifier: b'str'
          ): b')'
        :: b':'
        block: b'print(word)'
          expression_statement: b'print(word)'
            call: b'print(word)'
              identifier: b'print'
              argument_list: b'(word)'
                (: b'('
                identifier: b'word'
                ): b')'
  class_definition: b'class Manager(BaseReader, Writer):\r\n    def test(self):\r\n        pass'
    class: b'class'
    identifier: b'Manager'
    argument_list: b'(BaseReader, Writer)'
      (: b'('
      identifier: b'BaseReader'
      ,: b','
      identifier: b'Writer'
      ): b')'
    :: b':'
    block: b'def test(self):\r\n        pass'
      function_definition: b'def test(self):\r\n        pass'
        def: b'def'
        identifier: b'test'
        parameters: b'(self)'
          (: b'('
          identifier: b'self'
          ): b')'
        :: b':'
        block: b'pass'
          pass_statement: b'pass'
            pass: b'pass'
  function_definition: b'def run_gumtree_diff(author: str, repo_name, repo_path, tag1, tag2) -> dict:\r\n    # Clone the repository twice and checkout the respective tags\r\n    path1 = clone_tag(author, repo_name, repo_path, tag1)\r\n    path2 = clone_tag(author, repo_name, repo_path, tag2)\r\n\r\n    root_dir = get_abs_parent_dir()\r\n\r\n    # Run GumTree on the entire project\r\n    cmd = [\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]\r\n    print(" ".join(cmd))\r\n    result = subprocess.run(cmd, capture_output=True, text=True)\r\n\r\n    return json.loads(result.stdout)'
    def: b'def'
    identifier: b'run_gumtree_diff'
    parameters: b'(author: str, repo_name, repo_path, tag1, tag2)'
      (: b'('
      typed_parameter: b'author: str'
        identifier: b'author'
        :: b':'
        type: b'str'
          identifier: b'str'
      ,: b','
      identifier: b'repo_name'
      ,: b','
      identifier: b'repo_path'
      ,: b','
      identifier: b'tag1'
      ,: b','
      identifier: b'tag2'
      ): b')'
    ->: b'->'
    type: b'dict'
      identifier: b'dict'
    :: b':'
    comment: b'# Clone the repository twice and checkout the respective tags\r'
    block: b'path1 = clone_tag(author, repo_name, repo_path, tag1)\r\n    path2 = clone_tag(author, repo_name, repo_path, tag2)\r\n\r\n    root_dir = get_abs_parent_dir()\r\n\r\n    # Run GumTree on the entire project\r\n    cmd = [\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]\r\n    print(" ".join(cmd))\r\n    result = subprocess.run(cmd, capture_output=True, text=True)\r\n\r\n    return json.loads(result.stdout)'
      expression_statement: b'path1 = clone_tag(author, repo_name, repo_path, tag1)'
        assignment: b'path1 = clone_tag(author, repo_name, repo_path, tag1)'
          identifier: b'path1'
          =: b'='
          call: b'clone_tag(author, repo_name, repo_path, tag1)'
            identifier: b'clone_tag'
            argument_list: b'(author, repo_name, repo_path, tag1)'
              (: b'('
              identifier: b'author'
              ,: b','
              identifier: b'repo_name'
              ,: b','
              identifier: b'repo_path'
              ,: b','
              identifier: b'tag1'
              ): b')'
      expression_statement: b'path2 = clone_tag(author, repo_name, repo_path, tag2)'
        assignment: b'path2 = clone_tag(author, repo_name, repo_path, tag2)'
          identifier: b'path2'
          =: b'='
          call: b'clone_tag(author, repo_name, repo_path, tag2)'
            identifier: b'clone_tag'
            argument_list: b'(author, repo_name, repo_path, tag2)'
              (: b'('
              identifier: b'author'
              ,: b','
              identifier: b'repo_name'
              ,: b','
              identifier: b'repo_path'
              ,: b','
              identifier: b'tag2'
              ): b')'
      expression_statement: b'root_dir = get_abs_parent_dir()'
        assignment: b'root_dir = get_abs_parent_dir()'
          identifier: b'root_dir'
          =: b'='
          call: b'get_abs_parent_dir()'
            identifier: b'get_abs_parent_dir'
            argument_list: b'()'
              (: b'('
              ): b')'
      comment: b'# Run GumTree on the entire project\r'
      expression_statement: b'cmd = [\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]'
        assignment: b'cmd = [\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]'
          identifier: b'cmd'
          =: b'='
          list: b'[\r\n        "gumtree", "textdiff",\r\n        "-f", "JSON",\r\n        os.path.join(root_dir, path1),\r\n        os.path.join(root_dir, path2),\r\n        "-o", f"{repo_path}_{tag1}..{tag2}.diff.json"\r\n    ]'
            [: b'['
            string: b'"gumtree"'
              string_start: b'"'
              string_content: b'gumtree'
              string_end: b'"'
            ,: b','
            string: b'"textdiff"'
              string_start: b'"'
              string_content: b'textdiff'
              string_end: b'"'
            ,: b','
            string: b'"-f"'
              string_start: b'"'
              string_content: b'-f'
              string_end: b'"'
            ,: b','
            string: b'"JSON"'
              string_start: b'"'
              string_content: b'JSON'
              string_end: b'"'
            ,: b','
            call: b'os.path.join(root_dir, path1)'
              attribute: b'os.path.join'
                attribute: b'os.path'
                  identifier: b'os'
                  .: b'.'
                  identifier: b'path'
                .: b'.'
                identifier: b'join'
              argument_list: b'(root_dir, path1)'
                (: b'('
                identifier: b'root_dir'
                ,: b','
                identifier: b'path1'
                ): b')'
            ,: b','
            call: b'os.path.join(root_dir, path2)'
              attribute: b'os.path.join'
                attribute: b'os.path'
                  identifier: b'os'
                  .: b'.'
                  identifier: b'path'
                .: b'.'
                identifier: b'join'
              argument_list: b'(root_dir, path2)'
                (: b'('
                identifier: b'root_dir'
                ,: b','
                identifier: b'path2'
                ): b')'
            ,: b','
            string: b'"-o"'
              string_start: b'"'
              string_content: b'-o'
              string_end: b'"'
            ,: b','
            string: b'f"{repo_path}_{tag1}..{tag2}.diff.json"'
              string_start: b'f"'
              interpolation: b'{repo_path}'
                {: b'{'
                identifier: b'repo_path'
                }: b'}'
              string_content: b'_'
              interpolation: b'{tag1}'
                {: b'{'
                identifier: b'tag1'
                }: b'}'
              string_content: b'..'
              interpolation: b'{tag2}'
                {: b'{'
                identifier: b'tag2'
                }: b'}'
              string_content: b'.diff.json'
              string_end: b'"'
            ]: b']'
      expression_statement: b'print(" ".join(cmd))'
        call: b'print(" ".join(cmd))'
          identifier: b'print'
          argument_list: b'(" ".join(cmd))'
            (: b'('
            call: b'" ".join(cmd)'
              attribute: b'" ".join'
                string: b'" "'
                  string_start: b'"'
                  string_content: b' '
                  string_end: b'"'
                .: b'.'
                identifier: b'join'
              argument_list: b'(cmd)'
                (: b'('
                identifier: b'cmd'
                ): b')'
            ): b')'
      expression_statement: b'result = subprocess.run(cmd, capture_output=True, text=True)'
        assignment: b'result = subprocess.run(cmd, capture_output=True, text=True)'
          identifier: b'result'
          =: b'='
          call: b'subprocess.run(cmd, capture_output=True, text=True)'
            attribute: b'subprocess.run'
              identifier: b'subprocess'
              .: b'.'
              identifier: b'run'
            argument_list: b'(cmd, capture_output=True, text=True)'
              (: b'('
              identifier: b'cmd'
              ,: b','
              keyword_argument: b'capture_output=True'
                identifier: b'capture_output'
                =: b'='
                true: b'True'
              ,: b','
              keyword_argument: b'text=True'
                identifier: b'text'
                =: b'='
                true: b'True'
              ): b')'
      return_statement: b'return json.loads(result.stdout)'
        return: b'return'
        call: b'json.loads(result.stdout)'
          attribute: b'json.loads'
            identifier: b'json'
            .: b'.'
            identifier: b'loads'
          argument_list: b'(result.stdout)'
            (: b'('
            attribute: b'result.stdout'
              identifier: b'result'
              .: b'.'
              identifier: b'stdout'
            ): b')'
  function_definition: b'def generate_metadata(author, repo_name, tag1, tag2):\r\n    os.makedirs(\'./.tmp/source\', exist_ok=True)\r\n    repo_path = clone_repo(author, repo_name)\r\n\r\n    metadata = {\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }\r\n\r\n    return metadata'
    def: b'def'
    identifier: b'generate_metadata'
    parameters: b'(author, repo_name, tag1, tag2)'
      (: b'('
      identifier: b'author'
      ,: b','
      identifier: b'repo_name'
      ,: b','
      identifier: b'tag1'
      ,: b','
      identifier: b'tag2'
      ): b')'
    :: b':'
    block: b'os.makedirs(\'./.tmp/source\', exist_ok=True)\r\n    repo_path = clone_repo(author, repo_name)\r\n\r\n    metadata = {\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }\r\n\r\n    return metadata'
      expression_statement: b"os.makedirs('./.tmp/source', exist_ok=True)"
        call: b"os.makedirs('./.tmp/source', exist_ok=True)"
          attribute: b'os.makedirs'
            identifier: b'os'
            .: b'.'
            identifier: b'makedirs'
          argument_list: b"('./.tmp/source', exist_ok=True)"
            (: b'('
            string: b"'./.tmp/source'"
              string_start: b"'"
              string_content: b'./.tmp/source'
              string_end: b"'"
            ,: b','
            keyword_argument: b'exist_ok=True'
              identifier: b'exist_ok'
              =: b'='
              true: b'True'
            ): b')'
      expression_statement: b'repo_path = clone_repo(author, repo_name)'
        assignment: b'repo_path = clone_repo(author, repo_name)'
          identifier: b'repo_path'
          =: b'='
          call: b'clone_repo(author, repo_name)'
            identifier: b'clone_repo'
            argument_list: b'(author, repo_name)'
              (: b'('
              identifier: b'author'
              ,: b','
              identifier: b'repo_name'
              ): b')'
      expression_statement: b'metadata = {\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }'
        assignment: b'metadata = {\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }'
          identifier: b'metadata'
          =: b'='
          dictionary: b'{\r\n        "repo": f"{author}/{repo_name}",\r\n        "tag1": tag1,\r\n        "tag2": tag2,\r\n        "changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)\r\n    }'
            {: b'{'
            pair: b'"repo": f"{author}/{repo_name}"'
              string: b'"repo"'
                string_start: b'"'
                string_content: b'repo'
                string_end: b'"'
              :: b':'
              string: b'f"{author}/{repo_name}"'
                string_start: b'f"'
                interpolation: b'{author}'
                  {: b'{'
                  identifier: b'author'
                  }: b'}'
                string_content: b'/'
                interpolation: b'{repo_name}'
                  {: b'{'
                  identifier: b'repo_name'
                  }: b'}'
                string_end: b'"'
            ,: b','
            pair: b'"tag1": tag1'
              string: b'"tag1"'
                string_start: b'"'
                string_content: b'tag1'
                string_end: b'"'
              :: b':'
              identifier: b'tag1'
            ,: b','
            pair: b'"tag2": tag2'
              string: b'"tag2"'
                string_start: b'"'
                string_content: b'tag2'
                string_end: b'"'
              :: b':'
              identifier: b'tag2'
            ,: b','
            pair: b'"changes": run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)'
              string: b'"changes"'
                string_start: b'"'
                string_content: b'changes'
                string_end: b'"'
              :: b':'
              call: b'run_gumtree_diff(author, repo_name, repo_path, tag1, tag2)'
                identifier: b'run_gumtree_diff'
                argument_list: b'(author, repo_name, repo_path, tag1, tag2)'
                  (: b'('
                  identifier: b'author'
                  ,: b','
                  identifier: b'repo_name'
                  ,: b','
                  identifier: b'repo_path'
                  ,: b','
                  identifier: b'tag1'
                  ,: b','
                  identifier: b'tag2'
                  ): b')'
            }: b'}'
      return_statement: b'return metadata'
        return: b'return'
        identifier: b'metadata'
  function_definition: b'def main():\r\n    def sub_fun():\r\n        pass\r\n\r\n    # author = input("Enter GitHub repository author: ")\r\n    # repo_name = input("Enter GitHub repository name: ")\r\n    # tag1 = input("Enter first tag: ")\r\n    # tag2 = input("Enter second tag: ")\r\n\r\n    author = "scverse"\r\n    repo_name = "scanpy"\r\n    tag1 = "1.10.1"\r\n    tag2 = "1.10.2"\r\n\r\n    metadata = generate_metadata(author, repo_name, tag1, tag2)\r\n\r\n    with open("diff_metadata.json", "w") as f:\r\n        json.dump(metadata, f, indent=2)\r\n\r\n    print("Metadata has been saved to diff_metadata.json")'
    def: b'def'
    identifier: b'main'
    parameters: b'()'
      (: b'('
      ): b')'
    :: b':'
    block: b'def sub_fun():\r\n        pass\r\n\r\n    # author = input("Enter GitHub repository author: ")\r\n    # repo_name = input("Enter GitHub repository name: ")\r\n    # tag1 = input("Enter first tag: ")\r\n    # tag2 = input("Enter second tag: ")\r\n\r\n    author = "scverse"\r\n    repo_name = "scanpy"\r\n    tag1 = "1.10.1"\r\n    tag2 = "1.10.2"\r\n\r\n    metadata = generate_metadata(author, repo_name, tag1, tag2)\r\n\r\n    with open("diff_metadata.json", "w") as f:\r\n        json.dump(metadata, f, indent=2)\r\n\r\n    print("Metadata has been saved to diff_metadata.json")'
      function_definition: b'def sub_fun():\r\n        pass'
        def: b'def'
        identifier: b'sub_fun'
        parameters: b'()'
          (: b'('
          ): b')'
        :: b':'
        block: b'pass'
          pass_statement: b'pass'
            pass: b'pass'
      comment: b'# author = input("Enter GitHub repository author: ")\r'
      comment: b'# repo_name = input("Enter GitHub repository name: ")\r'
      comment: b'# tag1 = input("Enter first tag: ")\r'
      comment: b'# tag2 = input("Enter second tag: ")\r'
      expression_statement: b'author = "scverse"'
        assignment: b'author = "scverse"'
          identifier: b'author'
          =: b'='
          string: b'"scverse"'
            string_start: b'"'
            string_content: b'scverse'
            string_end: b'"'
      expression_statement: b'repo_name = "scanpy"'
        assignment: b'repo_name = "scanpy"'
          identifier: b'repo_name'
          =: b'='
          string: b'"scanpy"'
            string_start: b'"'
            string_content: b'scanpy'
            string_end: b'"'
      expression_statement: b'tag1 = "1.10.1"'
        assignment: b'tag1 = "1.10.1"'
          identifier: b'tag1'
          =: b'='
          string: b'"1.10.1"'
            string_start: b'"'
            string_content: b'1.10.1'
            string_end: b'"'
      expression_statement: b'tag2 = "1.10.2"'
        assignment: b'tag2 = "1.10.2"'
          identifier: b'tag2'
          =: b'='
          string: b'"1.10.2"'
            string_start: b'"'
            string_content: b'1.10.2'
            string_end: b'"'
      expression_statement: b'metadata = generate_metadata(author, repo_name, tag1, tag2)'
        assignment: b'metadata = generate_metadata(author, repo_name, tag1, tag2)'
          identifier: b'metadata'
          =: b'='
          call: b'generate_metadata(author, repo_name, tag1, tag2)'
            identifier: b'generate_metadata'
            argument_list: b'(author, repo_name, tag1, tag2)'
              (: b'('
              identifier: b'author'
              ,: b','
              identifier: b'repo_name'
              ,: b','
              identifier: b'tag1'
              ,: b','
              identifier: b'tag2'
              ): b')'
      with_statement: b'with open("diff_metadata.json", "w") as f:\r\n        json.dump(metadata, f, indent=2)'
        with: b'with'
        with_clause: b'open("diff_metadata.json", "w") as f'
          with_item: b'open("diff_metadata.json", "w") as f'
            as_pattern: b'open("diff_metadata.json", "w") as f'
              call: b'open("diff_metadata.json", "w")'
                identifier: b'open'
                argument_list: b'("diff_metadata.json", "w")'
                  (: b'('
                  string: b'"diff_metadata.json"'
                    string_start: b'"'
                    string_content: b'diff_metadata.json'
                    string_end: b'"'
                  ,: b','
                  string: b'"w"'
                    string_start: b'"'
                    string_content: b'w'
                    string_end: b'"'
                  ): b')'
              as: b'as'
              as_pattern_target: b'f'
                identifier: b'f'
        :: b':'
        block: b'json.dump(metadata, f, indent=2)'
          expression_statement: b'json.dump(metadata, f, indent=2)'
            call: b'json.dump(metadata, f, indent=2)'
              attribute: b'json.dump'
                identifier: b'json'
                .: b'.'
                identifier: b'dump'
              argument_list: b'(metadata, f, indent=2)'
                (: b'('
                identifier: b'metadata'
                ,: b','
                identifier: b'f'
                ,: b','
                keyword_argument: b'indent=2'
                  identifier: b'indent'
                  =: b'='
                  integer: b'2'
                ): b')'
      expression_statement: b'print("Metadata has been saved to diff_metadata.json")'
        call: b'print("Metadata has been saved to diff_metadata.json")'
          identifier: b'print'
          argument_list: b'("Metadata has been saved to diff_metadata.json")'
            (: b'('
            string: b'"Metadata has been saved to diff_metadata.json"'
              string_start: b'"'
              string_content: b'Metadata has been saved to diff_metadata.json'
              string_end: b'"'
            ): b')'
  if_statement: b'if __name__ == "__main__":\r\n    main()'
    if: b'if'
    comparison_operator: b'__name__ == "__main__"'
      identifier: b'__name__'
      ==: b'=='
      string: b'"__main__"'
        string_start: b'"'
        string_content: b'__main__'
        string_end: b'"'
    :: b':'
    block: b'main()'
      expression_statement: b'main()'
        call: b'main()'
          identifier: b'main'
          argument_list: b'()'
            (: b'('
            ): b')'
