from typing import Literal

import pandas as pd
from pydantic import BaseModel

from cfg.LLMHost import LLMHost
from processing_pipeline.s0_noise_filtering.IStageVerification import IStageVerification
from processing_pipeline.s0_noise_filtering.NoiseFiltering import NoiseFilteringStage


class OllamaFormatValidityResponse(BaseModel):
    correctness: Literal["correct", "partially correct", "incorrect"]
    reasoning: str


class NoiseFilteringStageVerification(IStageVerification):
    data_model = OllamaFormatValidityResponse
    stage_name = 's0_v'

    @classmethod
    def to_prompt(cls, x: pd.Series) -> str:
        return f"""
You are a meticulous and expert evaluator of AI model outputs. Your goal is to review and verify a classification made by another AI model based on a set of fixed instructions.

You will be provided with:
1.  The **Original Prompt** the first AI was supposed to follow, containing the **Content** it analyzed.
2.  The **Output** (decision and reasoning) it produced.

Your task is to judge if the AI's output was `correct`, `partially correct`, or `incorrect` (field `correctness`) and provide a justification for your judgment (field `reasoning`).

---

## 1. Original Task (Prompt Given to the First AI)

This is the entire prompt, including instructions and the specific content the first AI was asked to analyze.
{x['s0_prompt']}

---

## 2. AI Output to be Verified

This is the output generated by the first AI after processing the prompt above.

- `to_eliminate`: {x['s0_to_eliminate']}
- `reasoning`: {x['s0_reasoning']}

---

## 3. Your Evaluation Task

Based **only** on the instructions in the **Original Task (Section 1)**, evaluate the **AI Output (Section 2)**. You must use the following strict definitions for your judgment:

- **`correct`**: The AI's decision is perfectly aligned with the instructions in the original prompt, AND the `reasoning` accurately and logically justifies that decision based on those instructions.
- **`partially correct`**: The AI's decision is correct, but the `reasoning` is weak, flawed, imprecise, or irrelevant to the instructions. This also applies if the reasoning is missing when it was required, or when the reasoning is correct, but the AI's decision is incorrect.
- **`incorrect`**: Both the AI's decision and reasoning are wrong, directly contradicting the instructions provided in the original prompt.
"""


def main():
    NoiseFilteringStageVerification(hostname=LLMHost.RADU_SERVER, batch_size_override=10).execute(
        [NoiseFilteringStage.stage_name])


if __name__ == "__main__":
    main()
