id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:46206,Modifiability,variab,variable,46206,"the type table. TYPE_CODE_PPC_FP128 Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[PPC_FP128]``. The ``PPC_FP128`` record (code 15) adds a ``ppc_fp128`` (128-bit floating point); type to the type table. TYPE_CODE_METADATA Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[METADATA]``. The ``METADATA`` record (code 16) adds a ``metadata`` type to the type table. TYPE_CODE_X86_MMX Record; ^^^^^^^^^^^^^^^^^^^^^^^^. ``[X86_MMX]``. The ``X86_MMX`` record (code 17) adds an ``x86_mmx`` type to the type table. TYPE_CODE_STRUCT_ANON Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_ANON, ispacked, ...eltty...]``. The ``STRUCT_ANON`` record (code 18) adds a literal struct type to the type; table. The operand fields are. * *ispacked*: Non-zero if the type represents a packed structure. * *eltty*: Zero or more type indices representing the element types of the; structure. TYPE_CODE_STRUCT_NAME Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_NAME, ...string...]``. The ``STRUCT_NAME`` record (code 19) contains a variable number of values; representing the bytes of a struct name. The next ``OPAQUE`` or; ``STRUCT_NAMED`` record will use this name. TYPE_CODE_STRUCT_NAMED Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_NAMED, ispacked, ...eltty...]``. The ``STRUCT_NAMED`` record (code 20) adds an identified struct type to the; type table, with a name defined by a previously encountered ``STRUCT_NAME``; record. The operand fields are. * *ispacked*: Non-zero if the type represents a packed structure. * *eltty*: Zero or more type indices representing the element types of the; structure. TYPE_CODE_FUNCTION Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[FUNCTION, vararg, retty, ...paramty... ]``. The ``FUNCTION`` record (code 21) adds a function type to the type table. The; operand fields are. * *vararg*: Non-zero if the type represents a varargs function. * *retty*: The type index of the function's return type. * *paramty*: Zero or more type indices representing the parameter types of the; function. TYPE_CODE_X86_AMX ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:904,Performance,optimiz,optimizations,904,".. role:: raw-html(raw); :format: html. ========================; LLVM Bitcode File Format; ========================. .. contents::; :local:. Abstract; ========. This document describes the LLVM bitstream file format and the encoding of the; LLVM IR into it. Overview; ========. What is commonly known as the LLVM bitcode file format (also, sometimes; anachronistically known as bytecode) is actually two things: a `bitstream; container format`_ and an `encoding of LLVM IR`_ into the container format. The bitstream format is an abstract encoding of structured data, very similar to; XML in some ways. Like XML, bitstream files contain tags, and nested; structures, and you can parse the file without having to understand the tags.; Unlike XML, the bitstream format is a binary encoding, and unlike XML it; provides a mechanism for the file to self-describe ""abbreviations"", which are; effectively size optimizations for the content. LLVM IR files may be optionally embedded into a `wrapper`_ structure, or in a; `native object file`_. Both of these mechanisms make it easy to embed extra; data along with LLVM IR files. This document first describes the LLVM bitstream format, describes the wrapper; format, then describes the record structure used by LLVM IR files. .. _bitstream container format:. Bitstream Format; ================. The bitstream format is literally a stream of bits, with a very simple; structure. This structure consists of the following concepts:. * A ""`magic number`_"" that identifies the contents of the stream. * Encoding `primitives`_ like variable bit-rate integers. * `Blocks`_, which define nested content. * `Data Records`_, which describe entities within the file. * Abbreviations, which specify compression optimizations for the file. Note that the :doc:`llvm-bcanalyzer <CommandGuide/llvm-bcanalyzer>` tool can be; used to dump and inspect arbitrary bitstreams, which is very useful for; understanding the encoding. .. _magic number:. Magic Numbers; -------------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:1742,Performance,optimiz,optimizations,1742," Unlike XML, the bitstream format is a binary encoding, and unlike XML it; provides a mechanism for the file to self-describe ""abbreviations"", which are; effectively size optimizations for the content. LLVM IR files may be optionally embedded into a `wrapper`_ structure, or in a; `native object file`_. Both of these mechanisms make it easy to embed extra; data along with LLVM IR files. This document first describes the LLVM bitstream format, describes the wrapper; format, then describes the record structure used by LLVM IR files. .. _bitstream container format:. Bitstream Format; ================. The bitstream format is literally a stream of bits, with a very simple; structure. This structure consists of the following concepts:. * A ""`magic number`_"" that identifies the contents of the stream. * Encoding `primitives`_ like variable bit-rate integers. * `Blocks`_, which define nested content. * `Data Records`_, which describe entities within the file. * Abbreviations, which specify compression optimizations for the file. Note that the :doc:`llvm-bcanalyzer <CommandGuide/llvm-bcanalyzer>` tool can be; used to dump and inspect arbitrary bitstreams, which is very useful for; understanding the encoding. .. _magic number:. Magic Numbers; -------------. The first four bytes of a bitstream are used as an application-specific magic; number. Generic bitcode tools may look at the first four bytes to determine; whether the stream is a known stream type. However, these tools should *not*; determine whether a bitstream is valid based on its magic number alone. New; application-specific bitstream formats are being developed all the time; tools; should not reject them just because they have a hitherto unseen magic number. .. _primitives:. Primitives; ----------. A bitstream literally consists of a stream of bits, which are read in order; starting with the least significant bit of each byte. The stream is made up of; a number of primitive values that encode a stream of unsigned inte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:3453,Performance,optimiz,optimizing,3453,"erto unseen magic number. .. _primitives:. Primitives; ----------. A bitstream literally consists of a stream of bits, which are read in order; starting with the least significant bit of each byte. The stream is made up of; a number of primitive values that encode a stream of unsigned integer values.; These integers are encoded in two ways: either as `Fixed Width Integers`_ or as; `Variable Width Integers`_. .. _Fixed Width Integers:; .. _fixed-width value:. Fixed Width Integers; ^^^^^^^^^^^^^^^^^^^^. Fixed-width integer values have their low bits emitted directly to the file.; For example, a 3-bit integer value encodes 1 as 001. Fixed width integers are; used when there are a well-known number of options for a field. For example,; boolean values are usually encoded with a 1-bit wide integer. .. _Variable Width Integers:; .. _Variable Width Integer:; .. _variable-width value:. Variable Width Integers; ^^^^^^^^^^^^^^^^^^^^^^^. Variable-width integer (VBR) values encode values of arbitrary size, optimizing; for the case where the values are small. Given a 4-bit VBR field, any 3-bit; value (0 through 7) is encoded directly, with the high bit set to zero. Values; larger than N-1 bits emit their bits in a series of N-1 bit chunks, where all; but the last set the high bit. For example, the value 30 (0x1E) is encoded as 62 (0b0011'1110) when emitted as; a vbr4 value. The first set of four bits starting from the least significant; indicates the value 6 (110) with a continuation piece (indicated by a high bit; of 1). The next set of four bits indicates a value of 24 (011 << 3) with no; continuation. The sum (6+24) yields the value 30. .. _char6-encoded value:. 6-bit characters; ^^^^^^^^^^^^^^^^. 6-bit characters encode common characters into a fixed 6-bit field. They; represent the following characters with the following 6-bit values:. ::. 'a' .. 'z' --- 0 .. 25; 'A' .. 'Z' --- 26 .. 51; '0' .. '9' --- 52 .. 61; '.' --- 62; '_' --- 63. This encoding is only suitable for enco",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:24216,Performance,load,load,24216,"e format; version. Versions 0, 1 and 2 are supported at this time. The difference between; version 0 and 1 is in the encoding of instruction operands in; each `FUNCTION_BLOCK`_. In version 0, each value defined by an instruction is assigned an ID; unique to the function. Function-level value IDs are assigned starting from; ``NumModuleValues`` since they share the same namespace as module-level; values. The value enumerator resets after each function. When a value is; an operand of an instruction, the value ID is used to represent the operand.; For large functions or large modules, these operand values can be large. The encoding in version 1 attempts to avoid large operand values; in common cases. Instead of using the value ID directly, operands are; encoded as relative to the current instruction. Thus, if an operand; is the value defined by the previous instruction, the operand; will be encoded as 1. For example, instead of. .. code-block:: none. #n = load #n-1; #n+1 = icmp eq #n, #const0; br #n+1, label #(bb1), label #(bb2). version 1 will encode the instructions as. .. code-block:: none. #n = load #1; #n+1 = icmp eq #1, (#n+1)-#const0; br #1, label #(bb1), label #(bb2). Note in the example that operands which are constants also use; the relative encoding, while operands like basic block labels; do not use the relative encoding. Forward references will result in a negative value.; This can be inefficient, as operands are normally encoded; as unsigned VBRs. However, forward references are rare, except in the; case of phi instructions. For phi instructions, operands are encoded as; `Signed VBRs`_ to deal with forward references. In version 2, the meaning of module records ``FUNCTION``, ``GLOBALVAR``,; ``ALIAS``, ``IFUNC`` and ``COMDAT`` change such that the first two operands; specify an offset and size of a string in a string table (see `STRTAB_BLOCK; Contents`_), the function name is removed from the ``FNENTRY`` record in the; value symbol table, and the top-level `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:24362,Performance,load,load,24362,"s in; each `FUNCTION_BLOCK`_. In version 0, each value defined by an instruction is assigned an ID; unique to the function. Function-level value IDs are assigned starting from; ``NumModuleValues`` since they share the same namespace as module-level; values. The value enumerator resets after each function. When a value is; an operand of an instruction, the value ID is used to represent the operand.; For large functions or large modules, these operand values can be large. The encoding in version 1 attempts to avoid large operand values; in common cases. Instead of using the value ID directly, operands are; encoded as relative to the current instruction. Thus, if an operand; is the value defined by the previous instruction, the operand; will be encoded as 1. For example, instead of. .. code-block:: none. #n = load #n-1; #n+1 = icmp eq #n, #const0; br #n+1, label #(bb1), label #(bb2). version 1 will encode the instructions as. .. code-block:: none. #n = load #1; #n+1 = icmp eq #1, (#n+1)-#const0; br #1, label #(bb1), label #(bb2). Note in the example that operands which are constants also use; the relative encoding, while operands like basic block labels; do not use the relative encoding. Forward references will result in a negative value.; This can be inefficient, as operands are normally encoded; as unsigned VBRs. However, forward references are rare, except in the; case of phi instructions. For phi instructions, operands are encoded as; `Signed VBRs`_ to deal with forward references. In version 2, the meaning of module records ``FUNCTION``, ``GLOBALVAR``,; ``ALIAS``, ``IFUNC`` and ``COMDAT`` change such that the first two operands; specify an offset and size of a string in a string table (see `STRTAB_BLOCK; Contents`_), the function name is removed from the ``FNENTRY`` record in the; value symbol table, and the top-level ``VALUE_SYMTAB_BLOCK`` may only contain; ``FNENTRY`` records. MODULE_CODE_TRIPLE Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[TRIPLE, ...string...]``. The ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:17909,Safety,safe,safe,17909,"side ``BLOCKINFO`` blocks, but; unlike their occurrence in normal blocks, the abbreviation is defined for blocks; matching the block ID we are describing, *not* the ``BLOCKINFO`` block; itself. The abbreviations defined in ``BLOCKINFO`` blocks receive abbreviation; IDs as described in `DEFINE_ABBREV`_. The ``BLOCKNAME`` record (code 2) can optionally occur in this block. The; elements of the record are the bytes of the string name of the block.; llvm-bcanalyzer can use this to dump out bitcode files symbolically. The ``SETRECORDNAME`` record (code 3) can also optionally occur in this block.; The first operand value is a record ID number, and the rest of the elements of; the record are the bytes for the string name of the record. llvm-bcanalyzer can; use this to dump out bitcode files symbolically. Note that although the data in ``BLOCKINFO`` blocks is described as ""metadata,""; the abbreviations they contain are essential for parsing records from the; corresponding blocks. It is not safe to skip them. .. _wrapper:. Bitcode Wrapper Format; ======================. Bitcode files for LLVM IR may optionally be wrapped in a simple wrapper; structure. This structure contains a simple header that indicates the offset; and size of the embedded BC file. This allows additional information to be; stored alongside the BC file. The structure of this file header is:. :raw-html:`<tt><blockquote>`; [Magic\ :sub:`32`, Version\ :sub:`32`, Offset\ :sub:`32`, Size\ :sub:`32`, CPUType\ :sub:`32`]; :raw-html:`</blockquote></tt>`. Each of the fields are 32-bit fields stored in little endian form (as with the; rest of the bitcode file fields). The Magic number is always ``0x0B17C0DE`` and; the version is currently always ``0``. The Offset field is the offset in bytes; to the start of the bitcode stream in the file, and the Size field is the size; in bytes of the stream. CPUType is a target-specific value that can be used to; encode the CPU of the target. .. _native object file:. Native Object",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:23911,Safety,avoid,avoid,23911,"O`_; * `PARAMATTR_BLOCK`_; * `PARAMATTR_GROUP_BLOCK`_; * `TYPE_BLOCK`_; * `VALUE_SYMTAB_BLOCK`_; * `CONSTANTS_BLOCK`_; * `FUNCTION_BLOCK`_; * `METADATA_BLOCK`_. .. _MODULE_CODE_VERSION:. MODULE_CODE_VERSION Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[VERSION, version#]``. The ``VERSION`` record (code 1) contains a single value indicating the format; version. Versions 0, 1 and 2 are supported at this time. The difference between; version 0 and 1 is in the encoding of instruction operands in; each `FUNCTION_BLOCK`_. In version 0, each value defined by an instruction is assigned an ID; unique to the function. Function-level value IDs are assigned starting from; ``NumModuleValues`` since they share the same namespace as module-level; values. The value enumerator resets after each function. When a value is; an operand of an instruction, the value ID is used to represent the operand.; For large functions or large modules, these operand values can be large. The encoding in version 1 attempts to avoid large operand values; in common cases. Instead of using the value ID directly, operands are; encoded as relative to the current instruction. Thus, if an operand; is the value defined by the previous instruction, the operand; will be encoded as 1. For example, instead of. .. code-block:: none. #n = load #n-1; #n+1 = icmp eq #n, #const0; br #n+1, label #(bb1), label #(bb2). version 1 will encode the instructions as. .. code-block:: none. #n = load #1; #n+1 = icmp eq #1, (#n+1)-#const0; br #1, label #(bb1), label #(bb2). Note in the example that operands which are constants also use; the relative encoding, while operands like basic block labels; do not use the relative encoding. Forward references will result in a negative value.; This can be inefficient, as operands are normally encoded; as unsigned VBRs. However, forward references are rare, except in the; case of phi instructions. For phi instructions, operands are encoded as; `Signed VBRs`_ to deal with forward references. In versi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:39016,Safety,safe,safestack,39016,"; * code 7: ``naked``; * code 8: ``nest``; * code 9: ``noalias``; * code 10: ``nobuiltin``; * code 11: ``nocapture``; * code 12: ``nodeduplicate``; * code 13: ``noimplicitfloat``; * code 14: ``noinline``; * code 15: ``nonlazybind``; * code 16: ``noredzone``; * code 17: ``noreturn``; * code 18: ``nounwind``; * code 19: ``optsize``; * code 20: ``readnone``; * code 21: ``readonly``; * code 22: ``returned``; * code 23: ``returns_twice``; * code 24: ``signext``; * code 25: ``alignstack(<n>)``; * code 26: ``ssp``; * code 27: ``sspreq``; * code 28: ``sspstrong``; * code 29: ``sret``; * code 30: ``sanitize_address``; * code 31: ``sanitize_thread``; * code 32: ``sanitize_memory``; * code 33: ``uwtable``; * code 34: ``zeroext``; * code 35: ``builtin``; * code 36: ``cold``; * code 37: ``optnone``; * code 38: ``inalloca``; * code 39: ``nonnull``; * code 40: ``jumptable``; * code 41: ``dereferenceable(<n>)``; * code 42: ``dereferenceable_or_null(<n>)``; * code 43: ``convergent``; * code 44: ``safestack``; * code 45: ``argmemonly``; * code 46: ``swiftself``; * code 47: ``swifterror``; * code 48: ``norecurse``; * code 49: ``inaccessiblememonly``; * code 50: ``inaccessiblememonly_or_argmemonly``; * code 51: ``allocsize(<EltSizeParam>[, <NumEltsParam>])``; * code 52: ``writeonly``; * code 53: ``speculatable``; * code 54: ``strictfp``; * code 55: ``sanitize_hwaddress``; * code 56: ``nocf_check``; * code 57: ``optforfuzzing``; * code 58: ``shadowcallstack``; * code 59: ``speculative_load_hardening``; * code 60: ``immarg``; * code 61: ``willreturn``; * code 62: ``nofree``; * code 63: ``nosync``; * code 64: ``sanitize_memtag``; * code 65: ``preallocated``; * code 66: ``no_merge``; * code 67: ``null_pointer_is_valid``; * code 68: ``noundef``; * code 69: ``byref``; * code 70: ``mustprogress``; * code 74: ``vscale_range(<Min>[, <Max>])``; * code 75: ``swiftasync``; * code 76: ``nosanitize_coverage``; * code 77: ``elementtype``; * code 78: ``disable_sanitizer_instrumentation``; * code 79: `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:28205,Testability,log,logarithm,28205,"VAR`` record (code 7) marks the declaration or definition of a; global variable. The operand fields are:. * *strtab offset*, *strtab size*: Specifies the name of the global variable.; See `STRTAB_BLOCK Contents`_. * *pointer type*: The type index of the pointer type used to point to this; global variable. * *isconst*: Non-zero if the variable is treated as constant within the module,; or zero if it is not. * *initid*: If non-zero, the value index of the initializer for this variable,; plus 1. .. _linkage type:. * *linkage*: An encoding of the linkage type for this variable:. * ``external``: code 0; * ``weak``: code 1; * ``appending``: code 2; * ``internal``: code 3; * ``linkonce``: code 4; * ``dllimport``: code 5; * ``dllexport``: code 6; * ``extern_weak``: code 7; * ``common``: code 8; * ``private``: code 9; * ``weak_odr``: code 10; * ``linkonce_odr``: code 11; * ``available_externally``: code 12; * deprecated : code 13; * deprecated : code 14. * alignment*: The logarithm base 2 of the variable's requested alignment, plus 1. * *section*: If non-zero, the 1-based section index in the table of; `MODULE_CODE_SECTIONNAME`_ entries. .. _visibility:. * *visibility*: If present, an encoding of the visibility of this variable:. * ``default``: code 0; * ``hidden``: code 1; * ``protected``: code 2. .. _bcthreadlocal:. * *threadlocal*: If present, an encoding of the thread local storage mode of the; variable:. * ``not thread local``: code 0; * ``thread local; default TLS model``: code 1; * ``localdynamic``: code 2; * ``initialexec``: code 3; * ``localexec``: code 4. .. _bcunnamedaddr:. * *unnamed_addr*: If present, an encoding of the ``unnamed_addr`` attribute of this; variable:. * not ``unnamed_addr``: code 0; * ``unnamed_addr``: code 1; * ``local_unnamed_addr``: code 2. .. _bcdllstorageclass:. * *dllstorageclass*: If present, an encoding of the DLL storage class of this variable:. * ``default``: code 0; * ``dllimport``: code 1; * ``dllexport``: code 2. * *comdat*: An encodi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:30881,Testability,log,logarithm,30881,"The operand fields are:. * *strtab offset*, *strtab size*: Specifies the name of the function.; See `STRTAB_BLOCK Contents`_. * *type*: The type index of the function type describing this function. * *callingconv*: The calling convention number:; * ``ccc``: code 0; * ``fastcc``: code 8; * ``coldcc``: code 9; * ``anyregcc``: code 13; * ``preserve_mostcc``: code 14; * ``preserve_allcc``: code 15; * ``swiftcc`` : code 16; * ``cxx_fast_tlscc``: code 17; * ``tailcc`` : code 18; * ``cfguard_checkcc`` : code 19; * ``swifttailcc`` : code 20; * ``x86_stdcallcc``: code 64; * ``x86_fastcallcc``: code 65; * ``arm_apcscc``: code 66; * ``arm_aapcscc``: code 67; * ``arm_aapcs_vfpcc``: code 68. * isproto*: Non-zero if this entry represents a declaration rather than a; definition. * *linkage*: An encoding of the `linkage type`_ for this function. * *paramattr*: If nonzero, the 1-based parameter attribute index into the table; of `PARAMATTR_CODE_ENTRY`_ entries. * *alignment*: The logarithm base 2 of the function's requested alignment, plus; 1. * *section*: If non-zero, the 1-based section index in the table of; `MODULE_CODE_SECTIONNAME`_ entries. * *visibility*: An encoding of the `visibility`_ of this function. * *gc*: If present and nonzero, the 1-based garbage collector index in the table; of `MODULE_CODE_GCNAME`_ entries. * *unnamed_addr*: If present, an encoding of the; :ref:`unnamed_addr<bcunnamedaddr>` attribute of this function. * *prologuedata*: If non-zero, the value index of the prologue data for this function,; plus 1. * *dllstorageclass*: An encoding of the; :ref:`dllstorageclass<bcdllstorageclass>` of this function. * *comdat*: An encoding of the COMDAT of this function. * *prefixdata*: If non-zero, the value index of the prefix data for this function,; plus 1. * *personalityfn*: If non-zero, the value index of the personality function for this function,; plus 1. * *preemptionspecifier*: If present, an encoding of the :ref:`runtime preemption specifier<bcpreemptionspec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:35765,Testability,log,logarithm,35765,". .. note::; This is a legacy encoding for attributes, produced by LLVM versions 3.2 and; earlier. It is guaranteed to be understood by the current LLVM version, as; specified in the :ref:`IR backwards compatibility` policy. ``[ENTRY, paramidx0, attr0, paramidx1, attr1...]``. The ``ENTRY`` record (code 1) contains an even number of values describing a; unique set of function parameter attributes. Each *paramidx* value indicates; which set of attributes is represented, with 0 representing the return value; attributes, 0xFFFFFFFF representing function attributes, and other values; representing 1-based function parameters. Each *attr* value is a bitmap with the; following interpretation:. * bit 0: ``zeroext``; * bit 1: ``signext``; * bit 2: ``noreturn``; * bit 3: ``inreg``; * bit 4: ``sret``; * bit 5: ``nounwind``; * bit 6: ``noalias``; * bit 7: ``byval``; * bit 8: ``nest``; * bit 9: ``readnone``; * bit 10: ``readonly``; * bit 11: ``noinline``; * bit 12: ``alwaysinline``; * bit 13: ``optsize``; * bit 14: ``ssp``; * bit 15: ``sspreq``; * bits 16-31: ``align n``; * bit 32: ``nocapture``; * bit 33: ``noredzone``; * bit 34: ``noimplicitfloat``; * bit 35: ``naked``; * bit 36: ``inlinehint``; * bits 37-39: ``alignstack n``, represented as the logarithm; base 2 of the requested alignment, plus 1. .. _PARAMATTR_GROUP_BLOCK:. PARAMATTR_GROUP_BLOCK Contents; ------------------------------. The ``PARAMATTR_GROUP_BLOCK`` block (id 10) contains a table of entries; describing the attribute groups present in the module. These entries can be; referenced within ``PARAMATTR_CODE_ENTRY`` entries. .. _PARAMATTR_GRP_CODE_ENTRY:. PARAMATTR_GRP_CODE_ENTRY Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[ENTRY, grpid, paramidx, attr0, attr1, ...]``. The ``ENTRY`` record (code 3) contains *grpid* and *paramidx* values, followed; by a variable number of values describing a unique group of attributes. The; *grpid* value is a unique key for the attribute group, which can be referenced; within ``PARAMAT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:1402,Usability,simpl,simple,1402," bytecode) is actually two things: a `bitstream; container format`_ and an `encoding of LLVM IR`_ into the container format. The bitstream format is an abstract encoding of structured data, very similar to; XML in some ways. Like XML, bitstream files contain tags, and nested; structures, and you can parse the file without having to understand the tags.; Unlike XML, the bitstream format is a binary encoding, and unlike XML it; provides a mechanism for the file to self-describe ""abbreviations"", which are; effectively size optimizations for the content. LLVM IR files may be optionally embedded into a `wrapper`_ structure, or in a; `native object file`_. Both of these mechanisms make it easy to embed extra; data along with LLVM IR files. This document first describes the LLVM bitstream format, describes the wrapper; format, then describes the record structure used by LLVM IR files. .. _bitstream container format:. Bitstream Format; ================. The bitstream format is literally a stream of bits, with a very simple; structure. This structure consists of the following concepts:. * A ""`magic number`_"" that identifies the contents of the stream. * Encoding `primitives`_ like variable bit-rate integers. * `Blocks`_, which define nested content. * `Data Records`_, which describe entities within the file. * Abbreviations, which specify compression optimizations for the file. Note that the :doc:`llvm-bcanalyzer <CommandGuide/llvm-bcanalyzer>` tool can be; used to dump and inspect arbitrary bitstreams, which is very useful for; understanding the encoding. .. _magic number:. Magic Numbers; -------------. The first four bytes of a bitstream are used as an application-specific magic; number. Generic bitcode tools may look at the first four bytes to determine; whether the stream is a known stream type. However, these tools should *not*; determine whether a bitstream is valid based on its magic number alone. New; application-specific bitstream formats are being developed all the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:18047,Usability,simpl,simple,18047,"ing the block ID we are describing, *not* the ``BLOCKINFO`` block; itself. The abbreviations defined in ``BLOCKINFO`` blocks receive abbreviation; IDs as described in `DEFINE_ABBREV`_. The ``BLOCKNAME`` record (code 2) can optionally occur in this block. The; elements of the record are the bytes of the string name of the block.; llvm-bcanalyzer can use this to dump out bitcode files symbolically. The ``SETRECORDNAME`` record (code 3) can also optionally occur in this block.; The first operand value is a record ID number, and the rest of the elements of; the record are the bytes for the string name of the record. llvm-bcanalyzer can; use this to dump out bitcode files symbolically. Note that although the data in ``BLOCKINFO`` blocks is described as ""metadata,""; the abbreviations they contain are essential for parsing records from the; corresponding blocks. It is not safe to skip them. .. _wrapper:. Bitcode Wrapper Format; ======================. Bitcode files for LLVM IR may optionally be wrapped in a simple wrapper; structure. This structure contains a simple header that indicates the offset; and size of the embedded BC file. This allows additional information to be; stored alongside the BC file. The structure of this file header is:. :raw-html:`<tt><blockquote>`; [Magic\ :sub:`32`, Version\ :sub:`32`, Offset\ :sub:`32`, Size\ :sub:`32`, CPUType\ :sub:`32`]; :raw-html:`</blockquote></tt>`. Each of the fields are 32-bit fields stored in little endian form (as with the; rest of the bitcode file fields). The Magic number is always ``0x0B17C0DE`` and; the version is currently always ``0``. The Offset field is the offset in bytes; to the start of the bitcode stream in the file, and the Size field is the size; in bytes of the stream. CPUType is a target-specific value that can be used to; encode the CPU of the target. .. _native object file:. Native Object File Wrapper Format; =================================. Bitcode files for LLVM IR may also be wrapped in a native obj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:18100,Usability,simpl,simple,18100," defined in ``BLOCKINFO`` blocks receive abbreviation; IDs as described in `DEFINE_ABBREV`_. The ``BLOCKNAME`` record (code 2) can optionally occur in this block. The; elements of the record are the bytes of the string name of the block.; llvm-bcanalyzer can use this to dump out bitcode files symbolically. The ``SETRECORDNAME`` record (code 3) can also optionally occur in this block.; The first operand value is a record ID number, and the rest of the elements of; the record are the bytes for the string name of the record. llvm-bcanalyzer can; use this to dump out bitcode files symbolically. Note that although the data in ``BLOCKINFO`` blocks is described as ""metadata,""; the abbreviations they contain are essential for parsing records from the; corresponding blocks. It is not safe to skip them. .. _wrapper:. Bitcode Wrapper Format; ======================. Bitcode files for LLVM IR may optionally be wrapped in a simple wrapper; structure. This structure contains a simple header that indicates the offset; and size of the embedded BC file. This allows additional information to be; stored alongside the BC file. The structure of this file header is:. :raw-html:`<tt><blockquote>`; [Magic\ :sub:`32`, Version\ :sub:`32`, Offset\ :sub:`32`, Size\ :sub:`32`, CPUType\ :sub:`32`]; :raw-html:`</blockquote></tt>`. Each of the fields are 32-bit fields stored in little endian form (as with the; rest of the bitcode file fields). The Magic number is always ``0x0B17C0DE`` and; the version is currently always ``0``. The Offset field is the offset in bytes; to the start of the bitcode stream in the file, and the Size field is the size; in bytes of the stream. CPUType is a target-specific value that can be used to; encode the CPU of the target. .. _native object file:. Native Object File Wrapper Format; =================================. Bitcode files for LLVM IR may also be wrapped in a native object file; (i.e. ELF, COFF, Mach-O). The bitcode must be stored in a section of the object; fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst:2830,Availability,down,downstream,2830,"============================. The implementation of the block frequency calculation analyses each loop,; bottom-up, ignoring backedges; i.e., as a DAG. After each loop is processed,; it's packaged up to act as a pseudo-node in its parent loop's (or the; function's) DAG analysis. Block Mass; ==========. For each DAG, the entry node is assigned a mass of ``UINT64_MAX`` and mass is; distributed to successors according to branch weights. Block Mass uses a; fixed-point representation where ``UINT64_MAX`` represents ``1.0`` and ``0``; represents a number just above ``0.0``. After mass is fully distributed, in any cut of the DAG that separates the exit; nodes from the entry node, the sum of the block masses of the nodes succeeded; by a cut edge should equal ``UINT64_MAX``. In other words, mass is conserved; as it ""falls"" through the DAG. If a function's basic block graph is a DAG, then block masses are valid block; frequencies. This works poorly in practice though, since downstream users rely; on adding block frequencies together without hitting the maximum. Loop Scale; ==========. Loop scale is a metric that indicates how many times a loop iterates per entry.; As mass is distributed through the loop's DAG, the (otherwise ignored) backedge; mass is collected. This backedge mass is used to compute the exit frequency,; and thus the loop scale. Implementation: Getting from mass and scale to frequency; ========================================================. After analysing the complete series of DAGs, each block has a mass (local to; its containing loop, if any), and each loop pseudo-node has a loop scale and; its own mass (from its parent's DAG). We can get an initial frequency assignment (with entry frequency of 1.0) by; multiplying these masses and loop scales together. A given block's frequency; is the product of its mass, the mass of containing loops' pseudo nodes, and the; containing loops' loop scales. Since downstream users need integers (not floating point), this ini",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst:3791,Availability,down,downstream,3791,"s it ""falls"" through the DAG. If a function's basic block graph is a DAG, then block masses are valid block; frequencies. This works poorly in practice though, since downstream users rely; on adding block frequencies together without hitting the maximum. Loop Scale; ==========. Loop scale is a metric that indicates how many times a loop iterates per entry.; As mass is distributed through the loop's DAG, the (otherwise ignored) backedge; mass is collected. This backedge mass is used to compute the exit frequency,; and thus the loop scale. Implementation: Getting from mass and scale to frequency; ========================================================. After analysing the complete series of DAGs, each block has a mass (local to; its containing loop, if any), and each loop pseudo-node has a loop scale and; its own mass (from its parent's DAG). We can get an initial frequency assignment (with entry frequency of 1.0) by; multiplying these masses and loop scales together. A given block's frequency; is the product of its mass, the mass of containing loops' pseudo nodes, and the; containing loops' loop scales. Since downstream users need integers (not floating point), this initial; frequency assignment is shifted as necessary into the range of ``uint64_t``. Block Bias; ==========. Block bias is a proposed *absolute* metric to indicate a bias toward or away; from a given block during a function's execution. The idea is that bias can be; used in isolation to indicate whether a block is relatively hot or cold, or to; compare two blocks to indicate whether one is hotter or colder than the other. The proposed calculation involves calculating a *reference* block frequency,; where:. * every branch weight is assumed to be 1 (i.e., every branch probability; distribution is even) and. * loop scales are ignored. This reference frequency represents what the block frequency would be in an; unbiased graph. The bias is the ratio of the block frequency to this reference block frequency.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst:1129,Usability,simpl,simple,1129," ============. Block Frequency is a metric for estimating the relative frequency of different; basic blocks. This document describes the terminology that the; ``BlockFrequencyInfo`` and ``MachineBlockFrequencyInfo`` analysis passes use. Branch Probability; ==================. Blocks with multiple successors have probabilities associated with each; outgoing edge. These are called branch probabilities. For a given block, the; sum of its outgoing branch probabilities should be 1.0. Branch Weight; =============. Rather than storing fractions on each edge, we store an integer weight.; Weights are relative to the other edges of a given predecessor block. The; branch probability associated with a given edge is its own weight divided by; the sum of the weights on the predecessor's outgoing edges. For example, consider this IR:. .. code-block:: llvm. define void @foo() {; ; ...; A:; br i1 %cond, label %B, label %C, !prof !0; ; ...; }; !0 = !{!""branch_weights"", i32 7, i32 8}. and this simple graph representation::. A -> B (edge-weight: 7); A -> C (edge-weight: 8). The probability of branching from block A to block B is 7/15, and the; probability of branching from block A to block C is 8/15. See :doc:`BranchWeightMetadata` for details about the branch weight IR; representation. Block Frequency; ===============. Block frequency is a relative metric that represents the number of times a; block executes. The ratio of a block frequency to the entry block frequency is; the expected number of times the block will execute per entry to the function. Block frequency is the main output of the ``BlockFrequencyInfo`` and; ``MachineBlockFrequencyInfo`` analysis passes. Implementation: a series of DAGs; ================================. The implementation of the block frequency calculation analyses each loop,; bottom-up, ignoring backedges; i.e., as a DAG. After each loop is processed,; it's packaged up to act as a pseudo-node in its parent loop's (or the; function's) DAG analysis. Block Ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BlockFrequencyTerminology.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:6941,Availability,down,down,6941,"his case with probability 10%; case 0: break; // Take this case with probability 10%; case 3: break; // Take this case with probability 10%; case 5: break; // This case is likely to be taken with probability 70%; }. CFG Modifications; =================. Branch Weight Metatada is not proof against CFG changes. If terminator operands'; are changed some action should be taken. In other case some misoptimizations may; occur due to incorrect branch prediction information. Function Entry Counts; =====================. To allow comparing different functions during inter-procedural analysis and; optimization, ``MD_prof`` nodes can also be assigned to a function definition.; The first operand is a string indicating the name of the associated counter. Currently, one counter is supported: ""function_entry_count"". The second operand; is a 64-bit counter that indicates the number of times that this function was; invoked (in the case of instrumentation-based profiles). In the case of; sampling-based profiles, this operand is an approximation of how many times; the function was invoked. For example, in the code below, the instrumentation for function foo(); indicates that it was called 2,590 times at runtime. .. code-block:: llvm. define i32 @foo() !prof !1 {; ret i32 0; }; !1 = !{!""function_entry_count"", i64 2590}. If ""function_entry_count"" has more than 2 operands, the later operands are; the GUID of the functions that needs to be imported by ThinLTO. This is only; set by sampling based profile. It is needed because the sampling based profile; was collected on a binary that had already imported and inlined these functions,; and we need to ensure the IR matches in the ThinLTO backends for profile; annotation. The reason why we cannot annotate this on the callsite is that it; can only goes down 1 level in the call chain. For the cases where; foo_in_a_cc()->bar_in_b_cc()->baz_in_c_cc(), we will need to go down 2 levels; in the call chain to import both bar_in_b_cc and baz_in_c_cc.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:7058,Availability,down,down,7058,"his case with probability 10%; case 0: break; // Take this case with probability 10%; case 3: break; // Take this case with probability 10%; case 5: break; // This case is likely to be taken with probability 70%; }. CFG Modifications; =================. Branch Weight Metatada is not proof against CFG changes. If terminator operands'; are changed some action should be taken. In other case some misoptimizations may; occur due to incorrect branch prediction information. Function Entry Counts; =====================. To allow comparing different functions during inter-procedural analysis and; optimization, ``MD_prof`` nodes can also be assigned to a function definition.; The first operand is a string indicating the name of the associated counter. Currently, one counter is supported: ""function_entry_count"". The second operand; is a 64-bit counter that indicates the number of times that this function was; invoked (in the case of instrumentation-based profiles). In the case of; sampling-based profiles, this operand is an approximation of how many times; the function was invoked. For example, in the code below, the instrumentation for function foo(); indicates that it was called 2,590 times at runtime. .. code-block:: llvm. define i32 @foo() !prof !1 {; ret i32 0; }; !1 = !{!""function_entry_count"", i64 2590}. If ""function_entry_count"" has more than 2 operands, the later operands are; the GUID of the functions that needs to be imported by ThinLTO. This is only; set by sampling based profile. It is needed because the sampling based profile; was collected on a binary that had already imported and inlined these functions,; and we need to ensure the IR matches in the ThinLTO backends for profile; annotation. The reason why we cannot annotate this on the callsite is that it; can only goes down 1 level in the call chain. For the cases where; foo_in_a_cc()->bar_in_b_cc()->baz_in_c_cc(), we will need to go down 2 levels; in the call chain to import both bar_in_b_cc and baz_in_c_cc.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:470,Integrability,depend,depends,470,"===========================; LLVM Branch Weight Metadata; ===========================. .. contents::; :local:. Introduction; ============. Branch Weight Metadata represents branch weights as its likeliness to be taken; (see :doc:`BlockFrequencyTerminology`). Metadata is assigned to an; ``Instruction`` that is a terminator as a ``MDNode`` of the ``MD_prof`` kind.; The first operator is always a ``MDString`` node with the string; ""branch_weights"". Number of operators depends on the terminator type. Branch weights might be fetch from the profiling file, or generated based on; `__builtin_expect`_ and `__builtin_expect_with_probability`_ instruction. All weights are represented as an unsigned 32-bit values, where higher value; indicates greater chance to be taken. Supported Instructions; ======================. ``BranchInst``; ^^^^^^^^^^^^^^. Metadata is only assigned to the conditional branches. There are two extra; operands for the true and the false branch. .. code-block:: none. !0 = !{; !""branch_weights"",; i32 <TRUE_BRANCH_WEIGHT>,; i32 <FALSE_BRANCH_WEIGHT>; }. ``SwitchInst``; ^^^^^^^^^^^^^^. Branch weights are assigned to every case (including the ``default`` case which; is always case #0). .. code-block:: none. !0 = !{; !""branch_weights"",; i32 <DEFAULT_BRANCH_WEIGHT>; [ , i32 <CASE_BRANCH_WEIGHT> ... ]; }. ``IndirectBrInst``; ^^^^^^^^^^^^^^^^^^. Branch weights are assigned to every destination. .. code-block:: none. !0 = !{; !""branch_weights"",; i32 <LABEL_BRANCH_WEIGHT>; [ , i32 <LABEL_BRANCH_WEIGHT> ... ]; }. ``CallInst``; ^^^^^^^^^^^^^^^^^^. Calls may have branch weight metadata, containing the execution count of; the call. It is currently used in SamplePGO mode only, to augment the; block and entry counts which may not be accurate with sampling. .. code-block:: none. !0 = !{; !""branch_weights"",; i32 <CALL_BRANCH_WEIGHT>; }. ``InvokeInst``; ^^^^^^^^^^^^^^^^^^. Invoke instruction may have branch weight metadata with one or two weights.; The second weight is option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:5731,Performance,optimiz,optimization,5731,". This is basically the same as ``switch`` statement in ``__builtin_expect``.; The probability that ``exp`` is equal to the expect value is given in; the third argument ``probability``, while the probability of other value is; the average of remaining probability(``1.0 - probability``). For example:. .. code-block:: c++. switch (__builtin_expect_with_probability(x, 5, 0.7)) {; default: break; // Take this case with probability 10%; case 0: break; // Take this case with probability 10%; case 3: break; // Take this case with probability 10%; case 5: break; // This case is likely to be taken with probability 70%; }. CFG Modifications; =================. Branch Weight Metatada is not proof against CFG changes. If terminator operands'; are changed some action should be taken. In other case some misoptimizations may; occur due to incorrect branch prediction information. Function Entry Counts; =====================. To allow comparing different functions during inter-procedural analysis and; optimization, ``MD_prof`` nodes can also be assigned to a function definition.; The first operand is a string indicating the name of the associated counter. Currently, one counter is supported: ""function_entry_count"". The second operand; is a 64-bit counter that indicates the number of times that this function was; invoked (in the case of instrumentation-based profiles). In the case of; sampling-based profiles, this operand is an approximation of how many times; the function was invoked. For example, in the code below, the instrumentation for function foo(); indicates that it was called 2,590 times at runtime. .. code-block:: llvm. define i32 @foo() !prof !1 {; ret i32 0; }; !1 = !{!""function_entry_count"", i64 2590}. If ""function_entry_count"" has more than 2 operands, the later operands are; the GUID of the functions that needs to be imported by ThinLTO. This is only; set by sampling based profile. It is needed because the sampling based profile; was collected on a binary that had alre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:2891,Safety,predict,prediction,2891,"Inst``; ^^^^^^^^^^^^^^^^^^. Invoke instruction may have branch weight metadata with one or two weights.; The second weight is optional and corresponds to the unwind branch.; If only one weight is set then it contains the execution count of the call; and used in SamplePGO mode only as described for the call instruction. If both; weights are specified then the second weight contains count of unwind branch; taken and the first weights contains the execution count of the call minus; the count of unwind branch taken. Both weights specified are used to calculate; BranchProbability as for BranchInst and for SamplePGO the sum of both weights; is used. .. code-block:: none. !0 = !{; !""branch_weights"",; i32 <INVOKE_NORMAL_WEIGHT>; [ , i32 <INVOKE_UNWIND_WEIGHT> ]; }. Other; ^^^^^. Other terminator instructions are not allowed to contain Branch Weight Metadata. .. _\__builtin_expect:. Built-in ``expect`` Instructions; ================================. ``__builtin_expect(long exp, long c)`` instruction provides branch prediction; information. The return value is the value of ``exp``. It is especially useful in conditional statements. Currently Clang supports two; conditional statements:. ``if`` statement; ^^^^^^^^^^^^^^^^. The ``exp`` parameter is the condition. The ``c`` parameter is the expected; comparison value. If it is equal to 1 (true), the condition is likely to be; true, in other case condition is likely to be false. For example:. .. code-block:: c++. if (__builtin_expect(x > 0, 1)) {; // This block is likely to be taken.; }. ``switch`` statement; ^^^^^^^^^^^^^^^^^^^^. The ``exp`` parameter is the value. The ``c`` parameter is the expected; value. If the expected value doesn't show on the cases list, the ``default``; case is assumed to be likely taken. .. code-block:: c++. switch (__builtin_expect(x, 5)) {; default: break;; case 0: // ...; case 3: // ...; case 5: // This case is likely to be taken.; }. .. _\__builtin_expect_with_probability:. Built-in ``expect.with.pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst:5584,Safety,predict,prediction,5584,"ock:: c++. if (__builtin_expect_with_probability(x > 0, 1, 0.8)) {; // This block is likely to be taken with probability 80%.; }. ``switch`` statement; ^^^^^^^^^^^^^^^^^^^^. This is basically the same as ``switch`` statement in ``__builtin_expect``.; The probability that ``exp`` is equal to the expect value is given in; the third argument ``probability``, while the probability of other value is; the average of remaining probability(``1.0 - probability``). For example:. .. code-block:: c++. switch (__builtin_expect_with_probability(x, 5, 0.7)) {; default: break; // Take this case with probability 10%; case 0: break; // Take this case with probability 10%; case 3: break; // Take this case with probability 10%; case 5: break; // This case is likely to be taken with probability 70%; }. CFG Modifications; =================. Branch Weight Metatada is not proof against CFG changes. If terminator operands'; are changed some action should be taken. In other case some misoptimizations may; occur due to incorrect branch prediction information. Function Entry Counts; =====================. To allow comparing different functions during inter-procedural analysis and; optimization, ``MD_prof`` nodes can also be assigned to a function definition.; The first operand is a string indicating the name of the associated counter. Currently, one counter is supported: ""function_entry_count"". The second operand; is a 64-bit counter that indicates the number of times that this function was; invoked (in the case of instrumentation-based profiles). In the case of; sampling-based profiles, this operand is an approximation of how many times; the function was invoked. For example, in the code below, the instrumentation for function foo(); indicates that it was called 2,590 times at runtime. .. code-block:: llvm. define i32 @foo() !prof !1 {; ret i32 0; }; !1 = !{!""function_entry_count"", i64 2590}. If ""function_entry_count"" has more than 2 operands, the later operands are; the GUID of the functions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BranchWeightMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:2049,Integrability,depend,depend,2049,"for details:. #. `Maintenance of metadata`_. .. _Reporting:. Reporting bugs; ==============. See :doc:`HowToSubmitABug` on further details on how to submit good bug reports. You can apply `labels <https://docs.github.com/en/issues/using-labels-and-milestones-to-track-work/managing-labels>`_; to the bug to provide extra information to make the bug easier to discover, such; as a label for the part of the project the bug pertains to. .. _Triaging:. Triaging bugs; =============. Open bugs that have not been marked with the ``confirmed`` label are bugs that; still need to be triaged. When triage is complete, the ``confirmed`` label; should be added along with any other labels that help to classify the report,; unless the issue is being :ref:`closed<Closing>`. The goal of triaging a bug is to make sure a newly reported bug ends up in a; good, actionable state. Try to answer the following questions while triaging:. * Is the reported behavior actually wrong?. * E.g. does a miscompile example depend on undefined behavior?. * Can you reproduce the bug from the details in the report?. * If not, is there a reasonable explanation why it cannot be reproduced?. * Is it related to an already reported bug?. * Are the following fields filled in correctly?. * Title; * Description; * Labels. * When able to do so, please add the appropriate labels to classify the bug,; such as the tool (``clang``, ``clang-format``, ``clang-tidy``, etc) or; component (``backend:<name>``, ``compiler-rt:<name>``, ``clang:<name>``, etc). * If the issue is with a particular revision of the C or C++ standard, please; add the appropriate language standard label (``c++20``, ``c99``, etc). * Please don't use both a general and a specific label. For example, bugs; labeled ``c++17`` shouldn't also have ``c++``, and bugs labeled; ``clang:codegen`` shouldn't also have ``clang``. * Add the ``good first issue`` label if you think this would be a good bug to; be fixed by someone new to LLVM. This label feeds into `the l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:3991,Integrability,message,message,3991," someone new to LLVM. This label feeds into `the landing page; for new contributors <https://github.com/llvm/llvm-project/contribute>`_. * If you are unsure of what a label is intended to be used for, please see the; `documentation for our labels <https://github.com/llvm/llvm-project/labels>`_. .. _Actively working on fixing:. Actively working on fixing bugs; ===============================. Please remember to assign the bug to yourself if you're actively working on; fixing it and to unassign it when you're no longer actively working on it. You; unassign a bug by removing the person from the ``Assignees`` field. .. _Closing:. Resolving/Closing bugs; ======================. Resolving bugs is good! Make sure to properly record the reason for resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:4101,Integrability,message,messages,4101,"ute>`_. * If you are unsure of what a label is intended to be used for, please see the; `documentation for our labels <https://github.com/llvm/llvm-project/labels>`_. .. _Actively working on fixing:. Actively working on fixing bugs; ===============================. Please remember to assign the bug to yourself if you're actively working on; fixing it and to unassign it when you're no longer actively working on it. You; unassign a bug by removing the person from the ``Assignees`` field. .. _Closing:. Resolving/Closing bugs; ======================. Resolving bugs is good! Make sure to properly record the reason for resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the; ``worksforme`` label and leaving a comment to encourage the reporter to; reopen the bug with more information if it's still repr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:295,Modifiability,evolve,evolve,295,"===================; LLVM Bug Life Cycle; ===================. .. contents::; :local:. Introduction - Achieving consistency in how we deal with bug reports; ====================================================================. We aim to achieve a basic level of consistency in how reported bugs evolve from; being reported, to being worked on, and finally getting closed out. The; consistency helps reporters, developers and others to gain a better; understanding of what a particular bug state actually means and what to expect; might happen next. At the same time, we aim to not over-specify the life cycle of bugs in; `the LLVM Bug Tracking System <https://github.com/llvm/llvm-project/issues>`_,; as the overall goal is to make it easier to work with and understand the bug; reports. The main parts of the life cycle documented here are:. #. `Reporting`_; #. `Triaging`_; #. `Actively working on fixing`_; #. `Closing`_. Furthermore, some of the metadata in the bug tracker, such as what labels we; use, needs to be maintained. See the following for details:. #. `Maintenance of metadata`_. .. _Reporting:. Reporting bugs; ==============. See :doc:`HowToSubmitABug` on further details on how to submit good bug reports. You can apply `labels <https://docs.github.com/en/issues/using-labels-and-milestones-to-track-work/managing-labels>`_; to the bug to provide extra information to make the bug easier to discover, such; as a label for the part of the project the bug pertains to. .. _Triaging:. Triaging bugs; =============. Open bugs that have not been marked with the ``confirmed`` label are bugs that; still need to be triaged. When triage is complete, the ``confirmed`` label; should be added along with any other labels that help to classify the report,; unless the issue is being :ref:`closed<Closing>`. The goal of triaging a bug is to make sure a newly reported bug ends up in a; good, actionable state. Try to answer the following questions while triaging:. * Is the reported behavior ac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:5401,Safety,avoid,avoid,5401," resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the; ``worksforme`` label and leaving a comment to encourage the reporter to; reopen the bug with more information if it's still reproducible for them. .. _Maintenance of metadata:. Maintenance of metadata; =======================. Project member with write access to the project can create new labels, but we; discourage adding ad hoc labels because we want to control the proliferation of; labels and avoid single-use labels. If you would like a new label added, please; open an issue asking to create an issue label and add the ``infrastructure``; label to the issue. The request should include a description of what the label; is for. Alternatively, you can ask for the label to be created on the; ``#infrastructure`` channel on the LLVM Discord.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:5256,Security,access,access,5256," resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the; ``worksforme`` label and leaving a comment to encourage the reporter to; reopen the bug with more information if it's still reproducible for them. .. _Maintenance of metadata:. Maintenance of metadata; =======================. Project member with write access to the project can create new labels, but we; discourage adding ad hoc labels because we want to control the proliferation of; labels and avoid single-use labels. If you would like a new label added, please; open an issue asking to create an issue label and add the ``infrastructure``; label to the issue. The request should include a description of what the label; is for. Alternatively, you can ask for the label to be created on the; ``#infrastructure`` channel on the LLVM Discord.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst:4882,Usability,clear,clearly,4882," resolving.; Examples of reasons for resolving are:. * If the issue has been resolved by a particular commit, close the issue with; a brief comment mentioning which commit(s) fixed it. If you are authoring; the fix yourself, your git commit message may include the phrase; ``Fixes #<issue number>`` on a line by itself. GitHub recognizes such commit; messages and will automatically close the specified issue with a reference; to your commit. * If the reported behavior is not a bug, it is appropriate to close the issue; with a comment explaining why you believe it is not a bug, and adding the; ``invalid`` tag. * If the bug duplicates another issue, close it as a duplicate by adding the; ``duplicate`` label with a comment pointing to the issue it duplicates. * If there is a sound reason for not fixing the issue (difficulty, ABI, open; research questions, etc), add the ``wontfix`` label and a comment explaining; why no changes are expected. * If there is a specific and plausible reason to think that a given bug is; otherwise inapplicable or obsolete. One example is an open bug that doesn't; contain enough information to clearly understand the problem being reported; (e.g. not reproducible). It is fine to close such a bug, adding with the; ``worksforme`` label and leaving a comment to encourage the reporter to; reopen the bug with more information if it's still reproducible for them. .. _Maintenance of metadata:. Maintenance of metadata; =======================. Project member with write access to the project can create new labels, but we; discourage adding ad hoc labels because we want to control the proliferation of; labels and avoid single-use labels. If you would like a new label added, please; open an issue asking to create an issue label and add the ``infrastructure``; label to the issue. The request should include a description of what the label; is for. Alternatively, you can ask for the label to be created on the; ``#infrastructure`` channel on the LLVM Discord.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BugLifeCycle.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BugLifeCycle.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:185,Availability,down,down,185,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:279,Availability,failure,failures,279,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:654,Availability,down,down,654,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2558,Availability,failure,failure,2558,"quires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2877,Availability,failure,failure,2877,"any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3903,Availability,failure,failure,3903,"rence resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4048,Availability,failure,failure,4048,"t`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4209,Availability,down,down,4209,"t program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one pi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5323,Availability,down,down,5323,"iles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6463,Availability,error,error,6463,"which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6808,Availability,down,down,6808,"scompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:10955,Availability,down,down,10955," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:436,Energy Efficiency,reduce,reduce,436,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:637,Energy Efficiency,reduce,reduce,637,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1341,Energy Efficiency,reduce,reduce,1341,"f failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries exe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3152,Energy Efficiency,reduce,reduce,3152,"enerate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3502,Energy Efficiency,reduce,reduce,3502,"m the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3542,Energy Efficiency,reduce,reduce,3542,"ts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3672,Energy Efficiency,reduce,reduced,3672," test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3748,Energy Efficiency,reduce,reduce,3748," test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4550,Energy Efficiency,reduce,reduce,4550," debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4620,Energy Efficiency,reduce,reduce,4620," debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5411,Energy Efficiency,reduce,reduce,5411,"iles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6669,Energy Efficiency,reduce,reduce,6669,"gpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is usefu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6470,Integrability,message,message,6470,"which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:7471,Integrability,message,message,7471,", see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produce IR which contains long names. Run ``opt; -passes=metarenamer`` over the IR to rename everything using easy-to-read,; metasyntactic names. Alternatively, run ``opt -passes=strip,instnamer`` to; rename everything with very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:289,Performance,optimiz,optimizer,289,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:328,Performance,optimiz,optimizers,328,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:522,Performance,optimiz,optimizing,522,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:563,Performance,optimiz,optimization,563,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:595,Performance,optimiz,optimizations,595,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3071,Performance,optimiz,optimizer,3071,"enerate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3183,Performance,optimiz,optimizer,3183,"enerate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3290,Performance,optimiz,optimizer,3290,"ting it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3618,Performance,optimiz,optimizations,3618,"ts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5192,Performance,optimiz,optimizations,5192,"wn the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6778,Performance,optimiz,optimization,6778,"scompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6901,Performance,optimiz,optimization,6901,"date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6953,Performance,load,load,6953,"date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6964,Performance,optimiz,optimization,6964,"date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6989,Performance,load,load,6989,"date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:7756,Performance,optimiz,optimizations,7756,"xtremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produce IR which contains long names. Run ``opt; -passes=metarenamer`` over the IR to rename everything using easy-to-read,; metasyntactic names. Alternatively, run ``opt -passes=strip,instnamer`` to; rename everything with very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:9149,Performance,perform,performed,9149,"th very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing by selecting out lines with ""``IC``"" in them. At this point, you have a decision to make. Is the number of transformations; small enough to step through them using a debugger? If so, then try that. If there are too many transformations, then a source modification approach may; be helpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:9183,Performance,perform,perform,9183,"th very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing by selecting out lines with ""``IC``"" in them. At this point, you have a decision to make. Is the number of transformations; small enough to step through them using a debugger? If so, then try that. If there are too many transformations, then a source modification approach may; be helpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:11190,Performance,perform,performed,11190," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1961,Safety,abort,abort,1961,"to; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2114,Safety,safe,safe,2114,"ar to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4405,Safety,safe,safe,4405,"se it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4775,Safety,safe,safe,4775,"ction as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4808,Safety,safe,safe,4808,"ction as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4932,Safety,safe,safe,4932,"`bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6837,Safety,avoid,avoid,6837,"date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3366,Security,expose,exposed,3366,"arts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:6450,Security,validat,validate,6450,"which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:449,Testability,test,test,449,"====================================; LLVM bugpoint tool: design and usage; ====================================. .. contents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1350,Testability,test,test,1350,"f failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries exe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1489,Testability,test,test,1489,"l ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1754,Testability,test,test,1754,"ailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1851,Testability,test,test,1851,"itABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2091,Testability,test,test,2091,"ar to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2252,Testability,test,test,2252,"gging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:2717,Testability,test,test,2717," and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe"" backend (which is assumed to generate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3223,Testability,test,test,3223,"enerate good code) to; generate a reference output. Once ``bugpoint`` has a reference output for the; test program, it tries executing it with the selected code generator. If the; selected code generator crashes, ``bugpoint`` starts the `crash debugger`_ on; the code generator. Otherwise, if the resulting output differs from the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3485,Testability,test,test,3485,"m the; reference output, it assumes the difference resulted from a code generator; failure, and starts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:3551,Testability,test,test,3551,"ts the `code generator debugger`_. Finally, if the output of the selected code generator matches the reference; output, ``bugpoint`` runs the test program after all of the LLVM passes have; been applied to it. If its output differs from the reference output, it assumes; the difference resulted from a failure in one of the LLVM passes, and enters the; `miscompilation debugger`_. Otherwise, there is no problem ``bugpoint`` can; debug. .. _crash debugger:. Crash debugger; --------------. If an optimizer or code generator crashes, ``bugpoint`` will try as hard as it; can to reduce the list of passes (for optimizer crashes) and the size of the; test program. First, ``bugpoint`` figures out which combination of optimizer; passes triggers the bug. This is useful when debugging a problem exposed by; ``opt``, for example, because it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4317,Testability,test,test,4317,"se it runs over 38 passes. Next, ``bugpoint`` tries removing functions from the test program, to reduce its; size. Usually it is able to reduce a test program to a single function, when; debugging intraprocedural optimizations. Once the number of functions has been; reduced, it attempts to delete various edges in the control flow graph, to; reduce the size of the function as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:4723,Testability,test,test,4723,"ction as much as possible. Finally, ``bugpoint``; deletes any individual LLVM instructions whose absence does not eliminate the; failure. At the end, ``bugpoint`` should tell you what passes crash, give you a; bitcode file, and give you instructions on how to reproduce the failure with; ``opt`` or ``llc``. .. _code generator debugger:. Code generator debugger; -----------------------. The code generator debugger attempts to narrow down the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5150,Testability,test,test,5150,"wn the amount of code that is; being miscompiled by the selected code generator. To do this, it takes the test; program and partitions it into two pieces: one piece which it compiles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:5437,Testability,test,test,5437,"iles with the; ""safe"" backend (into a shared object), and one piece which it runs with either; the JIT or the static LLC compiler. It uses several techniques to reduce the; amount of code pushed through the LLVM code generator, to reduce the potential; scope of the problem. After it is finished, it emits two bitcode files (called; ""test"" [to be compiled with the code generator] and ""safe"" [to be compiled with; the ""safe"" backend], respectively), and instructions for reproducing the; problem. The code generator debugger assumes that the ""safe"" backend produces; good code. .. _miscompilation debugger:. Miscompilation debugger; -----------------------. The miscompilation debugger works similarly to the code generator debugger. It; works by splitting the test program into two pieces, running the optimizations; specified on one piece, linking the two pieces back together, and then executing; the result. It attempts to narrow down the list of passes to the one (or few); which are causing the miscompilation, then reduce the portion of the test; program which is being miscompiled. The miscompilation debugger assumes that; the selected code generator is working properly. Advice for using bugpoint; =========================. ``bugpoint`` can be a remarkably useful tool, but it sometimes works in; non-obvious ways. Here are some hints and tips:. * In the code generator and miscompilation debuggers, ``bugpoint`` only works; with programs that have deterministic output. Thus, if the program outputs; ``argv[0]``, the date, time, or any other ""random"" data, ``bugpoint`` may; misinterpret differences in these data, when output, as the result of a; miscompilation. Programs should be temporarily modified to disable outputs; that are likely to vary from run to run. * In the `crash debugger`_, ``bugpoint`` does not distinguish different crashes; during reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:7249,Testability,log,log,7249,"ng reduction. Thus, if new crash or miscompilation happens, ``bugpoint``; will continue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produce IR which contains long names. Run ``opt; -passes=metarenamer`` over the IR to rename everything using easy-to-read,; metasyntactic names. Alternatively, run ``opt -passes=strip,instnamer`` to; rename everything with very short (often purely numeric) names. What to do when bugpoint isn't enough; ==================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:7316,Testability,log,log,7316,"inue with the new crash instead. If you would like to stick to; particular crash, you should write check scripts to validate the error; message, see ``-compile-command`` in :doc:`CommandGuide/bugpoint`. * In the code generator and miscompilation debuggers, debugging will go faster; if you manually modify the program or its inputs to reduce the runtime, but; still exhibit the problem. * ``bugpoint`` is extremely useful when working on a new optimization: it helps; track down regressions quickly. To avoid having to relink ``bugpoint`` every; time you change your optimization however, have ``bugpoint`` dynamically load; your optimization with the ``-load`` option. * ``bugpoint`` can generate a lot of output and run for a long period of time.; It is often useful to capture the output of the program to file. For example,; in the C shell, you can run:. .. code-block:: console. $ bugpoint ... |& tee bugpoint.log. to get a copy of ``bugpoint``'s output in the file ``bugpoint.log``, as well; as on your terminal. * ``bugpoint`` cannot debug problems with the LLVM linker. If ``bugpoint``; crashes before you see its ""All input ok"" message, you might try ``llvm-link; -v`` on the same set of input files. If that also crashes, you may be; experiencing a linker bug. * ``bugpoint`` is useful for proactively finding bugs in LLVM. Invoking; ``bugpoint`` with the ``-find-bugs`` option will cause the list of specified; optimizations to be randomized and applied to the program. This process will; repeat until a bug is found or the user kills ``bugpoint``. * ``bugpoint`` can produce IR which contains long names. Run ``opt; -passes=metarenamer`` over the IR to rename everything using easy-to-read,; metasyntactic names. Alternatively, run ``opt -passes=strip,instnamer`` to; rename everything with very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; Targ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:9167,Testability,test,test,9167,"th very short (often purely numeric) names. What to do when bugpoint isn't enough; =====================================; 	; Sometimes, ``bugpoint`` is not enough. In particular, InstCombine and; TargetLowering both have visitor structured code with lots of potential; transformations. If the process of using bugpoint has left you with still too; much code to figure out and the problem seems to be in instcombine, the; following steps may help. These same techniques are useful with TargetLowering; as well. Turn on ``-debug-only=instcombine`` and see which transformations within; instcombine are firing by selecting out lines with ""``IC``"" in them. At this point, you have a decision to make. Is the number of transformations; small enough to step through them using a debugger? If so, then try that. If there are too many transformations, then a source modification approach may; be helpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:10673,Testability,test,test,10673," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:1145,Usability,simpl,simplifications,1145,"ontents::; :local:. Description; ===========. ``bugpoint`` narrows down the source of problems in LLVM tools and passes. It; can be used to debug three types of failures: optimizer crashes, miscompilations; by optimizers, or bad native code generation (including problems in the static; and JIT compilers). It aims to reduce large test cases to small, useful ones.; For example, if ``opt`` crashes while optimizing a file, it will identify the; optimization (or combination of optimizations) that causes the crash, and reduce; the file down to a small example which triggers the crash. For detailed case scenarios, such as debugging ``opt``, or one of the LLVM code; generators, see :doc:`HowToSubmitABug`. Design Philosophy; =================. ``bugpoint`` is designed to be a useful tool without requiring any hooks into; the LLVM infrastructure at all. It works with any and all LLVM passes and code; generators, and does not need to ""know"" how they work. Because of this, it may; appear to do stupid things or miss obvious simplifications. ``bugpoint`` is; also designed to trade off programmer time for computer time in the; compiler-debugging process; consequently, it may take a long period of; (unattended) time to reduce a test case, but we feel it is still worth it. Note; that ``bugpoint`` is generally very quick unless debugging a miscompilation; where each test of the program (which requires executing it) takes a long time. Automatic Debugger Selection; ----------------------------. ``bugpoint`` reads each ``.bc`` or ``.ll`` file specified on the command line; and links them together into a single module, called the test program. If any; LLVM passes are specified on the command line, it runs these passes on the test; program. If any of the passes crash, or if they produce malformed output (which; causes the verifier to abort), ``bugpoint`` starts the `crash debugger`_. Otherwise, if the ``-output`` option was not specified, ``bugpoint`` runs the; test program with the ""safe""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:9684,Usability,guid,guide,9684,"rmations within; instcombine are firing by selecting out lines with ""``IC``"" in them. At this point, you have a decision to make. Is the number of transformations; small enough to step through them using a debugger? If so, then try that. If there are too many transformations, then a source modification approach may; be helpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an impor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:10014,Usability,simpl,simply,10014,"elpful. In this approach, you can modify the source code of instcombine to; disable just those transformations that are being performed on your test input; and perform a binary search over the set of transformations. One set of places; to modify are the ""``visit*``"" methods of ``InstCombiner`` (*e.g.*; ``visitICmpInst``) by adding a ""``return false``"" as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:10718,Usability,simpl,simple,10718," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Bugpoint.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7454,Availability,avail,available,7454,"xported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9670,Availability,avail,available,9670,"se options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:12749,Availability,avail,available,12749,"TRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``AllTargetsInfos`` - All the included target info libraries. **LLVM_INSTALL_TOOLCHAIN_ONLY**:BOOL; This option defaults to ``Off``: when set to ``On`` it removes many of the; LLVM development and testing tools as well as component libraries from the; default ``install`` target. Including the development tools is not recommended; for distributions as many of the LLVM tools are only intended for development; and testing use.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2721,Deployability,install,install,2721,"istribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2921,Deployability,install,install-distribution,2921,"binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2964,Deployability,install,install,2964,"bols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2980,Deployability,install,install-distribution,2980,"bols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3136,Deployability,install,install,3136,"e: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3153,Deployability,install,install-distribution,3153,"e: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3191,Deployability,install,install,3191,"orkflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; -----------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3224,Deployability,install,install,3224,"orkflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; -----------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3345,Deployability,install,install-distribution,3345,"is is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; whi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3431,Deployability,install,installs,3431,"is is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; whi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3480,Deployability,configurat,configuration,3480,"is is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; whi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3564,Deployability,install,install,3564," DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3586,Deployability,install,install,3586," DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4179,Deployability,configurat,configurations,4179,"targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4215,Deployability,configurat,configurations,4215,"l every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4272,Deployability,install,install-distribution,4272,"esting tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the projec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4912,Deployability,install,install,4912,"n`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPON",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:5035,Deployability,install,install,5035,"n`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPON",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:5138,Deployability,install,install,5138,"distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6051,Deployability,install,installed,6051,"e exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different port",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6313,Deployability,install,install,6313,"t is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11599,Deployability,install,install,11599,"etting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11894,Deployability,configurat,configurations,11894," construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:13333,Deployability,install,install,13333,"TRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``AllTargetsInfos`` - All the included target info libraries. **LLVM_INSTALL_TOOLCHAIN_ONLY**:BOOL; This option defaults to ``Off``: when set to ``On`` it removes many of the; LLVM development and testing tools as well as component libraries from the; default ``install`` target. Including the development tools is not recommended; for distributions as many of the LLVM tools are only intended for development; and testing use.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1800,Energy Efficiency,reduce,reduce,1800,"iler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1918,Energy Efficiency,reduce,reduces,1918,"""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Diff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6971,Energy Efficiency,power,powerful,6971,"get will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9933,Energy Efficiency,reduce,reduce,9933," The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10069,Energy Efficiency,reduce,reduce,10069,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10352,Energy Efficiency,reduce,reduce,10352,"support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10425,Energy Efficiency,reduce,reduces,10425,"ested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3270,Modifiability,config,configured,3270,"orkflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; -----------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3480,Modifiability,config,configuration,3480,"is is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; whi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4136,Modifiability,config,configured,4136," thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4179,Modifiability,config,configurations,4179,"targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4215,Modifiability,config,configurations,4215,"l every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4558,Modifiability,config,configured,4558,"c tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be includ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4606,Modifiability,variab,variable,4606,"c tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be includ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4800,Modifiability,variab,variable,4800,"d should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:5600,Modifiability,variab,variable,5600," the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particular distribution for a project is named; ``${project}-${distribution}-cmake-exports``, where ``${project}`` is the name; of the project in lowercase and ``${distribution}`` is the name of the; distribution in lowercase, unless the project is LLVM, in which case the target; is just named ``${distribution}-cmake-exports``. These targets need to be; explicitly included in the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS*; variable in order to be included as part of the distribution. Unlike with the single distribution setup, when building multiple distributions,; any components specified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6827,Modifiability,config,configuring,6827,"ly added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to pe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7363,Modifiability,config,configure,7363,"aries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebIn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:8955,Modifiability,portab,portable,8955,"of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10122,Modifiability,variab,variable,10122,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11512,Modifiability,variab,variable,11512,"etting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11791,Modifiability,variab,variable,11791,"vant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11894,Modifiability,config,configurations,11894," construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11961,Modifiability,variab,variables,11961," construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11974,Modifiability,config,configure,11974," construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:12062,Modifiability,variab,variable,12062,"ns; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``All",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:12441,Modifiability,variab,variable,12441,"iler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``AllTargetsInfos`` - All the included target info libraries. **LLVM_INSTALL_TOOLCHAIN_ONLY**:BOOL; This option defaults to ``Off``: when set to ``On`` it removes many of the; LLVM development and testing tools as well as component libraries from the; default ``install`` target. Including the development tools is not recommended; for distributions as many of the LLVM tools are only inten",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:787,Performance,perform,perform,787,"===============================; Building a Distribution of LLVM; ===============================. .. contents::; :local:. Introduction; ============. This document is geared toward people who want to build and package LLVM and any; combination of LLVM sub-project tools for distribution. This document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1050,Performance,perform,performance,1050,"ribution of LLVM; ===============================. .. contents::; :local:. Introduction; ============. This document is geared toward people who want to build and package LLVM and any; combination of LLVM sub-project tools for distribution. This document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be ver",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1062,Performance,optimiz,optimizations,1062,"ribution of LLVM; ===============================. .. contents::; :local:. Introduction; ============. This document is geared toward people who want to build and package LLVM and any; combination of LLVM sub-project tools for distribution. This document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be ver",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1297,Performance,perform,performance,1297," document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and impleme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1375,Performance,perform,performance,1375,"ctices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1438,Performance,perform,performance,1438,"oc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1677,Performance,optimiz,optimize,1677,"escribed in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1858,Performance,perform,performance,1858,"""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Diff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1927,Performance,optimiz,optimization,1927,"""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Diff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2231,Performance,optimiz,optimizing,2231,"e big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2554,Performance,perform,performance,2554," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2612,Performance,cache,cache,2612," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2647,Performance,cache,caches,2647," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2708,Performance,perform,perform,2708,"istribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2821,Performance,cache,caches,2821,"uplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:6769,Performance,cache,caches,6769,"ecified in *LLVM_RUNTIME_DISTRIBUTION_COMPONENTS* are not; automatically added to any distribution. Instead, you must include the targets; explicitly in some *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* list. By default, each target can appear in multiple distributions; a target will be; installed as part of all distributions it appears in, and it'll be exported by; the last distribution it appears in (the order of distributions is the order; they appear in *LLVM_DISTRIBUTIONS*). We also define some umbrella targets (e.g.; ``llvm-libraries`` to install all LLVM libraries); a target can appear in a; different distribution than its umbrella, in which case the target will be; exported by the distribution it appears in (and not the distribution its; umbrella appears in). Set *LLVM_STRICT_DISTRIBUTIONS* to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7560,Performance,optimiz,optimizations,7560,"to ``On`` if you want to; enforce a target appearing in only one distribution and umbrella distributions; being consistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7618,Performance,perform,performing,7618,"nsistent with target distributions. We strongly encourage looking at ``clang/cmake/caches/MultiDistributionExample.cmake``; as an example of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7799,Performance,optimiz,optimizations,7799,"ple of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option sh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7830,Performance,perform,perform,7830,"ple of configuring multiple distributions. Special Notes for Library-only Distributions; --------------------------------------------. One of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option sh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:7977,Performance,cache,cache,7977,"e of the most powerful features of LLVM is its library-first design mentality; and the way you can compose a wide variety of tools using different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:8082,Performance,optimiz,optimization,8082,"sing different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:8264,Performance,optimiz,optimization,8264,"recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant imp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9283,Performance,perform,performance,9283,"ault the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which opti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9988,Performance,perform,performance,9988," The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10179,Performance,optimiz,optimization,10179,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10215,Performance,optimiz,optimizes,10215,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10313,Performance,perform,performance,10313,"performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2440,Safety,safe,safe,2440,"the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific part",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3310,Testability,test,testing,3310,"orkflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; -----------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3603,Testability,test,testing,3603," DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:3766,Testability,test,testing,3766,"-G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9140,Testability,test,tests,9140,"ault the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which opti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:13268,Testability,test,testing,13268,"TRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``AllTargetsInfos`` - All the included target info libraries. **LLVM_INSTALL_TOOLCHAIN_ONLY**:BOOL; This option defaults to ``Off``: when set to ``On`` it removes many of the; LLVM development and testing tools as well as component libraries from the; default ``install`` target. Including the development tools is not recommended; for distributions as many of the LLVM tools are only intended for development; and testing use.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:13486,Testability,test,testing,13486,"TRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM target for the Native system; #. ``AllTargetsAsmParsers`` - All the included target ASM parsers libraries; #. ``AllTargetsDescs`` - All the included target descriptions libraries; #. ``AllTargetsDisassemblers`` - All the included target dissassemblers libraries; #. ``AllTargetsInfos`` - All the included target info libraries. **LLVM_INSTALL_TOOLCHAIN_ONLY**:BOOL; This option defaults to ``Off``: when set to ``On`` it removes many of the; LLVM development and testing tools as well as component libraries from the; default ``install`` target. Including the development tools is not recommended; for distributions as many of the LLVM tools are only intended for development; and testing use.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1414,Usability,guid,guidance,1414,"oc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1691,Usability,guid,guidance,1691,"iler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2494,Usability,simpl,simplest,2494," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:8050,Usability,simpl,simplest,8050,"sing different portions of; LLVM. Even in this situation using *BUILD_SHARED_LIBS* is not supported. If you; want to distribute LLVM as a shared library for use in a tool, the recommended; method is using *LLVM_BUILD_LLVM_DYLIB*, and you can use *LLVM_DYLIB_COMPONENTS*; to configure which LLVM components are part of libLLVM.; Note: *LLVM_BUILD_LLVM_DYLIB* is not available on Windows. Options for Optimizing LLVM; ===========================. There are four main build optimizations that our CMake build system supports.; When performing a bootstrap build it is not beneficial to do anything other than; setting *CMAKE_BUILD_TYPE* to ``Release`` for the stage-1 compiler. This is; because the more intensive optimizations are expensive to perform and the; stage-1 compiler is thrown away. All of the further options described should be; set on the stage-2 compiler either using a CMake cache file, or by prefixing the; option with *BOOTSTRAP_*. The first and simplest to use is the compiler optimization level by setting the; *CMAKE_BUILD_TYPE* option. The main values of interest are ``Release`` or; ``RelWithDebInfo``. By default the ``Release`` option uses the ``-O3``; optimization level, and ``RelWithDebInfo`` uses ``-O2``. If you want to generate; debug information and use ``-O3`` you can override the; *CMAKE_<LANG>_FLAGS_RELWITHDEBINFO* option for C and CXX.; DistributionExample.cmake does this. Another easy to use option is Link-Time-Optimization. You can set the; *LLVM_ENABLE_LTO* option on your stage-2 build to ``Thin`` or ``Full`` to enable; building LLVM with LTO. These options will significantly increase link time of; the binaries in the distribution, but it will create much faster binaries. This; option should not be used if your distribution includes static archives, as the; objects inside the archive will be LLVM bitcode, which is not portable. The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:10031,Usability,simpl,simplest,10031,"filing tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:590,Deployability,continuous,continuous,590,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:601,Deployability,integrat,integration,601,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1125,Deployability,integrat,integration,1125,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1174,Deployability,continuous,continuous,1174,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1185,Deployability,integrat,integration,1185,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1218,Deployability,update,updates,1218,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1361,Deployability,continuous,continuously,1361,"r; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool wil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1247,Energy Efficiency,reduce,reduce,1247,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:601,Integrability,integrat,integration,601,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1125,Integrability,integrat,integration,1125,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1185,Integrability,integrat,integration,1185,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1975,Modifiability,extend,extend,1975,"ctions, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool will also inspect indirect jumps, as inlined; functions and jump tables should also be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A control flow graph would be generated from a small buffer of; the instructions surrounding the 'target' control flow instruction. If the; target instruction is branched-to, the fallthro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:2079,Modifiability,polymorphi,polymorphic,2079,"resent in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool will also inspect indirect jumps, as inlined; functions and jump tables should also be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A control flow graph would be generated from a small buffer of; the instructions surrounding the 'target' control flow instruction. If the; target instruction is branched-to, the fallthrough of the branch should be the; CFI trap (on x86, this is a ``ud2`` instruction). ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:2174,Performance,perform,performance,2174,"art of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool will also inspect indirect jumps, as inlined; functions and jump tables should also be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A control flow graph would be generated from a small buffer of; the instructions surrounding the 'target' control flow instruction. If the; target instruction is branched-to, the fallthrough of the branch should be the; CFI trap (on x86, this is a ``ud2`` instruction). If the target instruction is; the fallthrough (i.e. immediately succeeds) of a co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:968,Security,validat,validate,968,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1374,Security,validat,validate,1374,"r; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool wil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:2134,Security,secur,security,2134,"art of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool will also inspect indirect jumps, as inlined; functions and jump tables should also be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A control flow graph would be generated from a small buffer of; the instructions surrounding the 'target' control flow instruction. If the; target instruction is branched-to, the fallthrough of the branch should be the; CFI trap (on x86, this is a ``ud2`` instruction). If the target instruction is; the fallthrough (i.e. immediately succeeds) of a co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:4170,Security,integrity,integrity,4170,"lso be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A control flow graph would be generated from a small buffer of; the instructions surrounding the 'target' control flow instruction. If the; target instruction is branched-to, the fallthrough of the branch should be the; CFI trap (on x86, this is a ``ud2`` instruction). If the target instruction is; the fallthrough (i.e. immediately succeeds) of a conditional jump, the; conditional jump target should be the CFI trap. If an indirect control flow; instruction does not conform to one of these formats, the target will be noted; as being CFI-unprotected. Note that in the second case outlined above (where the target instruction is the; fallthrough of a conditional jump), if the target represents a vcall that takes; arguments, these arguments may be pushed to the stack after the branch but; before the target instruction. In these cases, a secondary 'spill graph' in; constructed, to ensure the register argument used by the indirect jump/call is; not spilled from the stack at any point in the interim period. If there are no; spills that affect the target register, the target is marked as CFI-protected. Other Design Notes; ~~~~~~~~~~~~~~~~~~. Only machine code sections that are marked as executable will be subject to this; analysis. Non-executable sections do not require analysis as any execution; present in these sections has already violated the control flow integrity. Suitable extensions may be made at a later date to include analysis for indirect; control flow operations across DSO boundaries. Currently, these CFI features are; only experimental with an unstable ABI, making them unsuitable for analysis. The tool currently only supports the x86, x86_64, and AArch64 architectures.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:613,Testability,test,testing,613,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:928,Testability,test,tested,928,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:959,Testability,test,tests,959,"==============================================; Control Flow Verification Tool Design Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1060,Testability,test,tests,1060,"esign Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1097,Testability,test,test,1097,"esign Document; ==============================================. .. contents::; :local:. Objective; =========. This document provides an overview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1137,Testability,test,tests,1137,"rview of an external tool to verify the protection; mechanisms implemented by Clang's *Control Flow Integrity* (CFI) schemes; (``-fsanitize=cfi``). This tool, provided a binary or DSO, should infer whether; indirect control flow operations are protected by CFI, and should output these; results in a human-readable form. This tool should also be added as part of Clang's continuous integration testing; framework, where modifications to the compiler ensure that CFI protection; schemes are still present in the final binary. Location; ========. This tool will be present as a part of the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ==========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst:1782,Usability,simpl,simply,1782," the LLVM toolchain, and will reside in; the ""/llvm/tools/llvm-cfi-verify"" directory, relative to the LLVM trunk. It will; be tested in two methods:. - Unit tests to validate code sections, present in; ""/llvm/unittests/tools/llvm-cfi-verify"".; - Integration tests, present in ""/llvm/tools/clang/test/LLVMCFIVerify"". These; integration tests are part of clang as part of a continuous integration; framework, ensuring updates to the compiler that reduce CFI coverage on; indirect control flow instructions are identified. Background; ==========. This tool will continuously validate that CFI directives are properly; implemented around all indirect control flows by analysing the output machine; code. The analysis of machine code is important as it ensures that any bugs; present in linker or compiler do not subvert CFI protections in the final; shipped binary. Unprotected indirect control flow instructions will be flagged for manual; review. These unexpected control flows may simply have not been accounted for in; the compiler implementation of CFI (e.g. indirect jumps to facilitate switch; statements may not be fully protected). It may be possible in the future to extend this tool to flag unnecessary CFI; directives (e.g. CFI directives around a static call to a non-polymorphic base; type). This type of directive has no security implications, but may present; performance impacts. Design Ideas; ============. This tool will disassemble binaries and DSO's from their machine code format and; analyse the disassembled machine code. The tool will inspect virtual calls and; indirect function calls. This tool will also inspect indirect jumps, as inlined; functions and jump tables should also be subject to CFI protections. Non-virtual; calls (``-fsanitize=cfi-nvcall``) and cast checks (``-fsanitize=cfi-*cast*``); are not implemented due to a lack of information provided by the bytecode. The tool would operate by searching for indirect control flow instructions in; the disassembly. A con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CFIVerify.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CFIVerify.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:4597,Availability,avail,available,4597,"` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles or Visual Studio or Xcode project files). You can; explicitly specify the generator with the command line option ``-G ""Name of the; generator""``. To see a list of the available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; ===========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8018,Availability,down,down,8018,"e`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:ST",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:9899,Availability,avail,available,9899,"are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12686,Availability,error,error,12686,"ibrary (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is availa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:13545,Availability,avail,available,13545,"tional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:13597,Availability,avail,available,13597,"tional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:13860,Availability,avail,available,13860,"ral). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16634,Availability,avail,available,16634,"d list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17498,Availability,avail,available,17498,"the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which can; be used to override the default system tools. **LLVM_<target>_LINKER_FLAGS**:STRING; Defines the set of linker flags that should be applied to a <target>. **LLVM_DEFAULT_TARGET_TRIPLE**:STRING; LLVM target to use for code generation when no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:25383,Availability,avail,available,25383,"ly LLVM and another for clang+llvm using the same; source checkout.; The full list is:; ``clang;clang-tools-extra;cross-project-tests;libc;libclc;lld;lldb;openmp;polly;pstl``. **LLVM_ENABLE_RUNTIMES**:STRING; Build libc++, libc++abi, libunwind or compiler-rt using the just-built compiler.; This is the correct way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:25473,Availability,avail,available,25473,";lldb;openmp;polly;pstl``. **LLVM_ENABLE_RUNTIMES**:STRING; Build libc++, libc++abi, libunwind or compiler-rt using the just-built compiler.; This is the correct way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_O",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:25996,Availability,avail,available,25996,"The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:26222,Availability,error,error,26222,"aults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:26452,Availability,error,error,26452,"NABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:26707,Availability,avail,available,26707,"OOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip execut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:30725,Availability,avail,available,30725,"es ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32673,Availability,avail,available,32673,"; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containers would be iterated in; reverse order. This is useful for uncovering non-determinism caused by; iter",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32909,Availability,avail,available,32909,"nstall-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containers would be iterated in; reverse order. This is useful for uncovering non-determinism caused by; iteration of unordered containers. **LLVM_STATIC_LINK_CXX_STDLIB**:BOOL; Statically link to the C++ standard library if possible. This uses the flag; ""-static-libstdc++"", but a Clang host compiler will statically link to libc++; if used in con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:34992,Availability,error,error,34992,"LE_LIBCXX** flag. Defaults to OFF. **LLVM_TABLEGEN**:STRING; Full path to a native TableGen executable (usually named ``llvm-tblgen``). This is; intended for cross-compiling: if the user sets this variable, no native; TableGen will be created. **LLVM_TARGET_ARCH**:STRING; LLVM target to use for native code generation. This is required for JIT; generation. It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are cross-compiling, set it; to the target architecture name. **LLVM_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of targets to build, or *all* for building all; targets. Case-sensitive. Defaults to *all*. Example:; ``-DLLVM_TARGETS_TO_BUILD=""X86;PowerPC""``.; The full list, as of March 2023, is:; ``AArch64;AMDGPU;ARM;AVR;BPF;Hexagon;Lanai;LoongArch;Mips;MSP430;NVPTX;PowerPC;RISCV;Sparc;SystemZ;VE;WebAssembly;X86;XCore``. **LLVM_TEMPORARILY_ALLOW_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler version check will only warn when using a toolchain; which is about to be deprecated, instead of emitting an error. **LLVM_UBSAN_FLAGS**:STRING; Defines the set of compile flags used to enable UBSan. Only used if; ``LLVM_USE_SANITIZER`` contains ``Undefined``. This can be used to override; the default set of UBSan flags. **LLVM_USE_INTEL_JITEVENTS**:BOOL; Enable building support for Intel JIT Events API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:37766,Availability,error,errors,37766," recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:40991,Availability,reliab,reliably,40991," of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42569,Availability,avail,available,42569,"will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43067,Availability,avail,available,43067," ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:44620,Availability,avail,available,44620,"M_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries is determined by using the; ``llvm_map_components_to_libnames()`` CMake function. For a list of available; components look at the output of running ``llvm-config --components``. Note that for LLVM < 3.5 ``llvm_map_components_to_libraries()`` was; used instead of ``llvm_map_components_to_libnames()``. This is now deprecated; and will be removed in a future version of LLVM. .. _cmake-out-of-source-pass:. Developing LLVM passes out of source; ------------------------------------. It is possible to develop LLVM passes out of LLVM's source tree (i.e. against an; installed or built LLVM). An example of a project layout is provided below. .. code-block:: none. <project dir>/; |; CMakeLists.txt; <pass name>/; |; CMakeLists.txt; Pass.cpp; ... Contents of ``<project dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:47135,Availability,error,errors,47135,"ND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddLLVM). And then changing ``<project dir>/<pass name>/CMakeLists.txt`` to. .. code-block:: cmake. add_llvm_library(LLVMPassname MODULE; Pass.cpp; ). When you are done developing your pass, you may wish to integrate it; into the LLVM source tree. You can achieve it in two easy steps:. #. Copying ``<pass name>`` folder into ``<LLVM root>/lib/Transforms`` directory. #. Adding ``add_subdirectory(<pass name>)`` line into; ``<LLVM root>/lib/Transforms/CMakeLists.txt``. Compiler/Platform-specific topics; =================================. Notes for specific compilers and/or platforms. Windows; -------. **LLVM_COMPILER_JOBS**:STRING; Specifies the maximum number of parallel compiler jobs to use per project; when building with msbuild or Visual Studio. Only supported for the Visual; Studio 2010 CMake generator. 0 means use all processors. Default is 0. **CMAKE_MT**:STRING; When compiling with clang-cl, recent CMake versions will default to selecting; `llvm-mt` as the Manifest Tool instead of Microsoft's `mt.exe`. This will; often cause errors like:. .. code-block:: console. -- Check for working C compiler: [...]clang-cl.exe - broken; [...]; MT: command [...] failed (exit code 0x1) with the following output:; llvm-mt: error: no libxml2; ninja: build stopped: subcommand failed. To work around this error, set `CMAKE_MT=mt`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:47320,Availability,error,error,47320,"ND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddLLVM). And then changing ``<project dir>/<pass name>/CMakeLists.txt`` to. .. code-block:: cmake. add_llvm_library(LLVMPassname MODULE; Pass.cpp; ). When you are done developing your pass, you may wish to integrate it; into the LLVM source tree. You can achieve it in two easy steps:. #. Copying ``<pass name>`` folder into ``<LLVM root>/lib/Transforms`` directory. #. Adding ``add_subdirectory(<pass name>)`` line into; ``<LLVM root>/lib/Transforms/CMakeLists.txt``. Compiler/Platform-specific topics; =================================. Notes for specific compilers and/or platforms. Windows; -------. **LLVM_COMPILER_JOBS**:STRING; Specifies the maximum number of parallel compiler jobs to use per project; when building with msbuild or Visual Studio. Only supported for the Visual; Studio 2010 CMake generator. 0 means use all processors. Default is 0. **CMAKE_MT**:STRING; When compiling with clang-cl, recent CMake versions will default to selecting; `llvm-mt` as the Manifest Tool instead of Microsoft's `mt.exe`. This will; often cause errors like:. .. code-block:: console. -- Check for working C compiler: [...]clang-cl.exe - broken; [...]; MT: command [...] failed (exit code 0x1) with the following output:; llvm-mt: error: no libxml2; ninja: build stopped: subcommand failed. To work around this error, set `CMAKE_MT=mt`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:47400,Availability,error,error,47400,"ND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddLLVM). And then changing ``<project dir>/<pass name>/CMakeLists.txt`` to. .. code-block:: cmake. add_llvm_library(LLVMPassname MODULE; Pass.cpp; ). When you are done developing your pass, you may wish to integrate it; into the LLVM source tree. You can achieve it in two easy steps:. #. Copying ``<pass name>`` folder into ``<LLVM root>/lib/Transforms`` directory. #. Adding ``add_subdirectory(<pass name>)`` line into; ``<LLVM root>/lib/Transforms/CMakeLists.txt``. Compiler/Platform-specific topics; =================================. Notes for specific compilers and/or platforms. Windows; -------. **LLVM_COMPILER_JOBS**:STRING; Specifies the maximum number of parallel compiler jobs to use per project; when building with msbuild or Visual Studio. Only supported for the Visual; Studio 2010 CMake generator. 0 means use all processors. Default is 0. **CMAKE_MT**:STRING; When compiling with clang-cl, recent CMake versions will default to selecting; `llvm-mt` as the Manifest Tool instead of Microsoft's `mt.exe`. This will; often cause errors like:. .. code-block:: console. -- Check for working C compiler: [...]clang-cl.exe - broken; [...]; MT: command [...] failed (exit code 0x1) with the following output:; llvm-mt: error: no libxml2; ninja: build stopped: subcommand failed. To work around this error, set `CMAKE_MT=mt`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1339,Deployability,install,install,1339," If **you are a new contributor**, please start with the :doc:`GettingStarted`; page. This page is geared for existing contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3261,Deployability,install,install,3261,"ase, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3351,Deployability,install,install,3351,"he shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3391,Deployability,install,install,3391,"nvironment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3481,Deployability,install,install,3481,"nvironment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3533,Deployability,install,install,3533,"variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles or Visual Studio or Xcode project files). You can; explicitly specify the generator with the command line option ``-G ""N",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3551,Deployability,install,installation,3551,"variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles or Visual Studio or Xcode project files). You can; explicitly specify the generator with the command line option ``-G ""N",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8384,Deployability,install,installed,8384," Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8404,Deployability,install,install,8404," Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8640,Deployability,install,installed,8640," make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8841,Deployability,configurat,configuration,8841," usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:9476,Deployability,install,installed,9476,"*CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:9559,Deployability,install,install,9559,"_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10797,Deployability,install,install,10797,"ism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft too",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10925,Deployability,install,install,10925,"ecify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared libr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11054,Deployability,install,install,11054," may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11186,Deployability,install,install,11186,"NKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12703,Deployability,configurat,configuration,12703,"ibrary (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is availa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12821,Deployability,release,release,12821," toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit exe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:14268,Deployability,install,install,14268,"o avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code cover",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:14355,Deployability,install,installed,14355,"o avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code cover",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17943,Deployability,install,install-xcode-toolchain,17943,"DTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which can; be used to override the default system tools. **LLVM_<target>_LINKER_FLAGS**:STRING; Defines the set of linker flags that should be applied to a <target>. **LLVM_DEFAULT_TARGET_TRIPLE**:STRING; LLVM target to use for code generation when no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON`` are given. Defaults to; ``org.llvm.qch``.; This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:21622,Deployability,install,installed,21622,"aults to OFF. **LLVM_ENABLE_DOXYGEN_QT_HELP**:BOOL; Enables the generation of a Qt Compressed Help file. Defaults to OFF.; This affects the make target ``doxygen-llvm``. When enabled, apart from; the normal HTML output generated by doxygen, this will produce a QCH file; named ``org.llvm.qch``. You can then load this file into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and make use of C++ exceptions in your own code; that need to propagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of bo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:21897,Deployability,install,installed,21897,"le into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and make use of C++ exceptions in your own code; that need to propagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:22268,Deployability,install,install,22268,"ropagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:22771,Deployability,install,installed,22771,"to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the comp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:28974,Deployability,install,install,28974,"; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:29210,Deployability,install,install,29210,"LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:29482,Deployability,install,installed,29482,"d targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:30329,Deployability,install,install,30329,"PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/html``. **LLVM_INSTALL_UTILS**:BOOL; If enabled, utility binaries like ``FileCheck`` and ``not`` will be installed; to CMAKE_INSTALL_PREFIX. **LLVM_INTEGRATED_CRT_ALLOC**:PATH; On Windows, allows embedding a different C runtime allocator into the LLVM; tools and libraries. Using a lock-free allocator such as the ones listed below; greatly decreases ThinLTO link time by about an order of magnitude. It also; midly improves Clang build times, by about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31873,Deployability,install,install-time,31873,"al C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs ac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32379,Deployability,configurat,configurations,32379,"OL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36930,Deployability,install,installation,36930,"urces and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unsta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:37005,Deployability,install,installation,37005,"refix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38022,Deployability,install,install,38022,"_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated sc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38175,Deployability,install,install,38175,"y default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORC",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39085,Deployability,configurat,configuration,39085,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39790,Deployability,configurat,configurations,39790,"che scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embeddin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41063,Deployability,install,installed,41063," of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42741,Deployability,install,installed,42741,"NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42765,Deployability,install,installed,42765,"NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43122,Deployability,install,installed,43122,"de (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM head",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43166,Deployability,install,installation,43166,"de (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM head",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43295,Deployability,install,installed,43295,"ates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VER",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43331,Deployability,install,installed,43331,"s the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:45088,Deployability,install,installed,45088,"ist of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries is determined by using the; ``llvm_map_components_to_libnames()`` CMake function. For a list of available; components look at the output of running ``llvm-config --components``. Note that for LLVM < 3.5 ``llvm_map_components_to_libraries()`` was; used instead of ``llvm_map_components_to_libnames()``. This is now deprecated; and will be removed in a future version of LLVM. .. _cmake-out-of-source-pass:. Developing LLVM passes out of source; ------------------------------------. It is possible to develop LLVM passes out of LLVM's source tree (i.e. against an; installed or built LLVM). An example of a project layout is provided below. .. code-block:: none. <project dir>/; |; CMakeLists.txt; <pass name>/; |; CMakeLists.txt; Pass.cpp; ... Contents of ``<project dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:46297,Deployability,integrat,integrate,46297,"ct dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddLLVM). And then changing ``<project dir>/<pass name>/CMakeLists.txt`` to. .. code-block:: cmake. add_llvm_library(LLVMPassname MODULE; Pass.cpp; ). When you are done developing your pass, you may wish to integrate it; into the LLVM source tree. You can achieve it in two easy steps:. #. Copying ``<pass name>`` folder into ``<LLVM root>/lib/Transforms`` directory. #. Adding ``add_subdirectory(<pass name>)`` line into; ``<LLVM root>/lib/Transforms/CMakeLists.txt``. Compiler/Platform-specific topics; =================================. Notes for specific compilers and/or platforms. Windows; -------. **LLVM_COMPILER_JOBS**:STRING; Specifies the maximum number of parallel compiler jobs to use per project; when building with msbuild or Visual Studio. Only supported for the Visual; Studio 2010 CMake generator. 0 means use all processors. Default is 0. **CMAKE_MT**:STRING; When compiling with clang-cl, recent CMake versions will default to selecting; `llvm-mt` as the Manifest Tool instead of Microsoft's `mt.exe`. This will; often cause errors like:. .. code-block:: console. -- Check for working C compiler: [...]clang-cl.exe - broken; [...]; MT: command [...] failed (exit code 0x1) with t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:25600,Energy Efficiency,reduce,reduce,25600,"orrect way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaults to ON. **LLVM_ENABLE_WERROR**:BOOL; Stop and fail the build, if a compiler warning is triggered. Defaults to OFF. **LLVM_ENABLE_Z3_SOLVER**:BOOL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36603,Energy Efficiency,reduce,reduces,36603,"``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1256,Integrability,interface,interface,1256,"ject, it generates the files needed by your build tool; (GNU make, Visual Studio, etc.) for building LLVM. If **you are a new contributor**, please start with the :doc:`GettingStarted`; page. This page is geared for existing contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:14123,Integrability,depend,dependencies,14123,"he version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-da",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:21481,Integrability,depend,dependency,21481,"; only with MSVC. Defaults to ON. **LLVM_ENABLE_DOXYGEN**:BOOL; Enables the generation of browsable HTML documentation using doxygen.; Defaults to OFF. **LLVM_ENABLE_DOXYGEN_QT_HELP**:BOOL; Enables the generation of a Qt Compressed Help file. Defaults to OFF.; This affects the make target ``doxygen-llvm``. When enabled, apart from; the normal HTML output generated by doxygen, this will produce a QCH file; named ``org.llvm.qch``. You can then load this file into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and make use of C++ exceptions in your own code; that need to propagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:23208,Integrability,depend,dependency,23208,"of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the compiler command-line, if the compiler supports; this flag. Some systems, like Windows, do not need this flag. Defaults to ON. **LLVM_ENABLE_PROJECTS**:STRING; Semicolon-separated list of projects to build, or *all* for building all; (clang, lldb, lld, polly, etc) projects. This flag assumes that projects; are checked out side-by-side and not nested, i.e. clang needs to be in;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:24750,Integrability,depend,dependency,24750,"cific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the compiler command-line, if the compiler supports; this flag. Some systems, like Windows, do not need this flag. Defaults to ON. **LLVM_ENABLE_PROJECTS**:STRING; Semicolon-separated list of projects to build, or *all* for building all; (clang, lldb, lld, polly, etc) projects. This flag assumes that projects; are checked out side-by-side and not nested, i.e. clang needs to be in; parallel of llvm instead of nested in `llvm/tools`. This feature allows; to have one build for only LLVM and another for clang+llvm using the same; source checkout.; The full list is:; ``clang;clang-tools-extra;cross-project-tests;libc;libclc;lld;lldb;openmp;polly;pstl``. **LLVM_ENABLE_RUNTIMES**:STRING; Build libc++, libc++abi, libunwind or compiler-rt using the just-built compiler.; This is the correct way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_ENABLE_THREADS**:BOOL; Build with threads support, if available. Defaults to ON. **LLVM_ENABLE_UNWIND_TABLES**:BOOL; Enable unwind tables in the binary. Disabling unwind tables can reduce the; size of the libraries. Defaults to ON. **LLVM_ENABLE_WARNINGS**:BOOL; Enable all compiler warnings. Defaul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:35403,Integrability,depend,depend,35403,"D**:STRING; Semicolon-separated list of targets to build, or *all* for building all; targets. Case-sensitive. Defaults to *all*. Example:; ``-DLLVM_TARGETS_TO_BUILD=""X86;PowerPC""``.; The full list, as of March 2023, is:; ``AArch64;AMDGPU;ARM;AVR;BPF;Hexagon;Lanai;LoongArch;Mips;MSP430;NVPTX;PowerPC;RISCV;Sparc;SystemZ;VE;WebAssembly;X86;XCore``. **LLVM_TEMPORARILY_ALLOW_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler version check will only warn when using a toolchain; which is about to be deprecated, instead of emitting an error. **LLVM_UBSAN_FLAGS**:STRING; Defines the set of compile flags used to enable UBSan. Only used if; ``LLVM_USE_SANITIZER`` contains ``Undefined``. This can be used to override; the default set of UBSan flags. **LLVM_USE_INTEL_JITEVENTS**:BOOL; Enable building support for Intel JIT Events API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41389,Integrability,message,message,41389,"Make. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41443,Integrability,message,message,41443,"Make. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:46297,Integrability,integrat,integrate,46297,"ct dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. add_library(LLVMPassname MODULE Pass.cpp). Note if you intend for this pass to be merged into the LLVM source tree at some; point in the future it might make more sense to use LLVM's internal; ``add_llvm_library`` function with the MODULE argument instead by... Adding the following to ``<project dir>/CMakeLists.txt`` (after; ``find_package(LLVM ...)``). .. code-block:: cmake. list(APPEND CMAKE_MODULE_PATH ""${LLVM_CMAKE_DIR}""); include(AddLLVM). And then changing ``<project dir>/<pass name>/CMakeLists.txt`` to. .. code-block:: cmake. add_llvm_library(LLVMPassname MODULE; Pass.cpp; ). When you are done developing your pass, you may wish to integrate it; into the LLVM source tree. You can achieve it in two easy steps:. #. Copying ``<pass name>`` folder into ``<LLVM root>/lib/Transforms`` directory. #. Adding ``add_subdirectory(<pass name>)`` line into; ``<LLVM root>/lib/Transforms/CMakeLists.txt``. Compiler/Platform-specific topics; =================================. Notes for specific compilers and/or platforms. Windows; -------. **LLVM_COMPILER_JOBS**:STRING; Specifies the maximum number of parallel compiler jobs to use per project; when building with msbuild or Visual Studio. Only supported for the Visual; Studio 2010 CMake generator. 0 means use all processors. Default is 0. **CMAKE_MT**:STRING; When compiling with clang-cl, recent CMake versions will default to selecting; `llvm-mt` as the Manifest Tool instead of Microsoft's `mt.exe`. This will; often cause errors like:. .. code-block:: console. -- Check for working C compiler: [...]clang-cl.exe - broken; [...]; MT: command [...] failed (exit code 0x1) with t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:496,Modifiability,config,configure,496,"========================; Building LLVM with CMake; ========================. .. contents::; :local:. Introduction; ============. `CMake <http://www.cmake.org/>`_ is a cross-platform build-generator tool. CMake; does not build the project, it generates the files needed by your build tool; (GNU make, Visual Studio, etc.) for building LLVM. If **you are a new contributor**, please start with the :doc:`GettingStarted`; page. This page is geared for existing contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:778,Modifiability,variab,variables,778,"========================; Building LLVM with CMake; ========================. .. contents::; :local:. Introduction; ============. `CMake <http://www.cmake.org/>`_ is a cross-platform build-generator tool. CMake; does not build the project, it generates the files needed by your build tool; (GNU make, Visual Studio, etc.) for building LLVM. If **you are a new contributor**, please start with the :doc:`GettingStarted`; page. This page is geared for existing contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1499,Modifiability,variab,variable,1499,"contributors moving from the; legacy configure/make system. If you are really anxious about getting a functional LLVM build, go to the; `Quick start`_ section. If you are a CMake novice, start with `Basic CMake usage`_; and then go back to the `Quick start`_ section once you know what you are doing. The; `Options and variables`_ section is a reference for customizing your build. If; you already have experience with CMake, this is the recommended starting point. This page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:2072,Modifiability,variab,variables,2072,"kePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:2550,Modifiability,variab,variable,2550,"e. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:2807,Modifiability,variab,variables,2807,"root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Ba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3214,Modifiability,portab,portable,3214,"'t detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5481,Modifiability,variab,variables,5481,"citly specify the generator with the command line option ``-G ""Name of the; generator""``. To see a list of the available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5563,Modifiability,variab,variables,5563," generator""``. To see a list of the available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5587,Modifiability,variab,variables,5587,"available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5695,Modifiability,variab,variables,5695,"generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5747,Modifiability,variab,variables,5747,"case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable V",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5893,Modifiability,variab,variable,5893,"s. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5983,Modifiability,variab,variable,5983,"r; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6334,Modifiability,variab,variable,6334,"generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6405,Modifiability,variab,variable,6405,"must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Devel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6549,Modifiability,variab,variables,6549,"and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; ===========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6620,Modifiability,variab,variables,6620,"ize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6761,Modifiability,variab,variable,6761," Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debuggin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6877,Modifiability,variab,variables,6877,"to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6999,Modifiability,config,configures,6999,"le. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8737,Modifiability,variab,variables,8737,"debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8778,Modifiability,variab,variables,8778,"RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to rest",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8841,Modifiability,config,configuration,8841," usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8903,Modifiability,variab,variables,8903,"se_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8997,Modifiability,variab,variables,8997,"u find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10324,Modifiability,variab,variables,10324,"DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10391,Modifiability,variab,variables,10391,"x to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; ena",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10556,Modifiability,variab,variable,10556,"-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11292,Modifiability,variab,variables,11292,"E_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11317,Modifiability,variab,variables,11317,"iables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11359,Modifiability,variab,variables,11359,"ables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11460,Modifiability,variab,variable,11460,"ted notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12703,Modifiability,config,configuration,12703,"ibrary (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is availa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:15290,Modifiability,config,configuring,15290,"build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16023,Modifiability,config,config,16023,"ir to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17820,Modifiability,variab,variables,17820,"et. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which can; be used to override the default system tools. **LLVM_<target>_LINKER_FLAGS**:STRING; Defines the set of linker flags that should be applied to a <target>. **LLVM_DEFAULT_TARGET_TRIPLE**:STRING; LLVM target to use for code generation when no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:19290,Modifiability,variab,variable,19290,"n no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON`` are given. Defaults to; ``org.llvm.qch``.; This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effect. **LLVM_DOXYGEN_QHELPGENERATOR_PATH**:STRING; The path to the ``qhelpgenerator`` executable. Defaults to whatever CMake's; ``find_program()`` can find. This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise it has no; effect. **LLVM_DOXYGEN_QHP_CUST_FILTER_NAME**:STRING; See `Qt Help Project`_ for; more information. Defaults to the CMake variable ``${PACKAGE_STRING}`` which; is a combination of the package name and version string. This filter can then; be used in Qt Creator to select only documentation from LLVM when browsing; through all the help files that you might have loaded. This option is only; useful in combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effect. .. _Qt Help Project: http://qt-project.org/doc/qt-4.8/qthelpproject.html#custom-filters. **LLVM_DOXYGEN_QHP_NAMESPACE**:STRING; Namespace under which the intermediate Qt Help Project file lives. See `Qt; Help Project`_; for more information. Defaults to ""org.llvm"". This option is only useful in; combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise; it has no effect. **LLVM_DOXYGEN_SVG**:BOOL; Uses .svg files instead of .png files for graphs in the Doxygen output.; Defaults to OFF. .. _llvm_enable_assertions:. **LLVM_ENABLE_ASSERTIONS**:BOOL; Enables code assertions. Defaults to ON if and only if ``CMAKE_BUILD_TYPE``; is *Debug*. **LLVM_ENABLE_BINDINGS**",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:21951,Modifiability,variab,variables,21951,"le into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and make use of C++ exceptions in your own code; that need to propagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:22417,Modifiability,config,configured,22417,"_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:26811,Modifiability,variab,variables,26811,"OL; If enabled, the Z3 constraint solver is activated for the Clang static analyzer.; A recent version of the z3 library needs to be available on the system. **LLVM_ENABLE_ZLIB**:STRING; Used to decide if LLVM tools should support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:27095,Modifiability,variab,variable,27095,"ould support compression/decompression with; zlib. Allowed values are ``OFF``, ``ON`` (default, enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compile at all, or might fail at runtime due to known bugs in these; toolchains. **LLVM_INCLUDE_BENCHMARKS**:BOOL; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:27130,Modifiability,variab,variable,27130,"enable if zlib is found),; and ``FORCE_ON`` (error if zlib is not found). **LLVM_ENABLE_ZSTD**:STRING; Used to decide if LLVM tools should support compression/decompression with; zstd. Allowed values are ``OFF``, ``ON`` (default, enable if zstd is found),; and ``FORCE_ON`` (error if zstd is not found). **LLVM_EXPERIMENTAL_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of experimental targets to build and linked into; llvm. This will build the experimental target without needing it to add to the; list of all the targets available in the LLVM's main CMakeLists.txt. **LLVM_EXTERNAL_{CLANG,LLD,POLLY}_SOURCE_DIR**:PATH; These variables specify the path to the source directory for the external; LLVM projects Clang, lld, and Polly, respectively, relative to the top-level; source directory. If the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compile at all, or might fail at runtime due to known bugs in these; toolchains. **LLVM_INCLUDE_BENCHMARKS**:BOOL; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31221,Modifiability,variab,variable,31221,"SVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimize",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31550,Modifiability,variab,variable,31550,"libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31990,Modifiability,variab,variables,31990," path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32379,Modifiability,config,configurations,32379,"OL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:34101,Modifiability,variab,variable,34101,"fore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containers would be iterated in; reverse order. This is useful for uncovering non-determinism caused by; iteration of unordered containers. **LLVM_STATIC_LINK_CXX_STDLIB**:BOOL; Statically link to the C++ standard library if possible. This uses the flag; ""-static-libstdc++"", but a Clang host compiler will statically link to libc++; if used in conjunction with the **LLVM_ENABLE_LIBCXX** flag. Defaults to OFF. **LLVM_TABLEGEN**:STRING; Full path to a native TableGen executable (usually named ``llvm-tblgen``). This is; intended for cross-compiling: if the user sets this variable, no native; TableGen will be created. **LLVM_TARGET_ARCH**:STRING; LLVM target to use for native code generation. This is required for JIT; generation. It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are cross-compiling, set it; to the target architecture name. **LLVM_TARGETS_TO_BUILD**:STRING; Semicolon-separated list of targets to build, or *all* for building all; targets. Case-sensitive. Defaults to *all*. Example:; ``-DLLVM_TARGETS_TO_BUILD=""X86;PowerPC""``.; The full list, as of March 2023, is:; ``AArch64;AMDGPU;ARM;AVR;BPF;Hexagon;Lanai;LoongArch;Mips;MSP430;NVPTX;PowerPC;RISCV;Sparc;SystemZ;VE;WebAssembly;X86;XCore``. **LLVM_TEMPORARILY_ALLOW_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler version check will only warn when using a toolchain; which is about to be deprecated, instead of emitting an error. **LLVM_UBSAN_FLAGS**:STRING; Defines the set of compile flags used to enable UBSan. Only used ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36050,Modifiability,variab,variable,36050,"ING; Defines the set of compile flags used to enable UBSan. Only used if; ``LLVM_USE_SANITIZER`` contains ``Undefined``. This can be used to override; the default set of UBSan flags. **LLVM_USE_INTEL_JITEVENTS**:BOOL; Enable building support for Intel JIT Events API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36232,Modifiability,variab,variable,36232," **LLVM_USE_INTEL_JITEVENTS**:BOOL; Enable building support for Intel JIT Events API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:37799,Modifiability,variab,variables,37799,"ory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38718,Modifiability,variab,variables,38718," If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D opti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39049,Modifiability,variab,variables,39049,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39085,Modifiability,config,configuration,39085,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39118,Modifiability,variab,variables,39118,"RING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39142,Modifiability,variab,variables,39142,"RING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39790,Modifiability,config,configurations,39790,"che scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embeddin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:40727,Modifiability,variab,variables,40727,"e information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:40751,Modifiability,variab,variables,40751,"e information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43501,Modifiability,variab,variables,43501,"command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43520,Modifiability,variab,variables,43520," ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:44679,Modifiability,config,config,44679,"M_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries is determined by using the; ``llvm_map_components_to_libnames()`` CMake function. For a list of available; components look at the output of running ``llvm-config --components``. Note that for LLVM < 3.5 ``llvm_map_components_to_libraries()`` was; used instead of ``llvm_map_components_to_libnames()``. This is now deprecated; and will be removed in a future version of LLVM. .. _cmake-out-of-source-pass:. Developing LLVM passes out of source; ------------------------------------. It is possible to develop LLVM passes out of LLVM's source tree (i.e. against an; installed or built LLVM). An example of a project layout is provided below. .. code-block:: none. <project dir>/; |; CMakeLists.txt; <pass name>/; |; CMakeLists.txt; Pass.cpp; ... Contents of ``<project dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}); include_directories(${LLVM_INCLUDE_DIRS}). add_subdirectory(<pass name>). Contents of ``<project dir>/<pass name>/CMakeLists.txt``:. .. code-block:: cmake. ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1915,Performance,perform,perform,1915," page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:5495,Performance,cache,cache,5495,"citly specify the generator with the command line option ``-G ""Name of the; generator""``. To see a list of the available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for; Visual Studio 12, you can execute:. .. code-block:: console. $ cmake -G ""Visual Studio 12"" path/to/llvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6093,Performance,cache,cache,6093,"lvm/source/root. For a given development platform there can be more than one adequate; generator. If you use Visual Studio, ""NMake Makefiles"" is a generator you can use; for building with NMake. By default, CMake chooses the most specific generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6291,Performance,cache,cache,6291,"generator; supported by your development environment. If you want an alternative generator,; you must tell this to CMake with the ``-G`` option. .. todo::. Explain variables and cache. Move explanation here from #options section. .. _Options and variables:. Options and variables; =====================. Variables customize how the build will be generated. Options are boolean; variables, with possible values ON/OFF. Options and variables are defined on the; CMake command line like this:. .. code-block:: console. $ cmake -DVARIABLE=value path/to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:7014,Performance,optimiz,optimization,7014,"le. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage by using ``lld``, see; the :ref:`LLVM_USE_LINKER <llvm_use_linker>` option.; * Assertions are internal checks to help you find bugs. They typically slo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12963,Performance,optimiz,optimized,12963,"brary, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17647,Performance,cache,cache,17647,"et. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which can; be used to override the default system tools. **LLVM_<target>_LINKER_FLAGS**:STRING; Defines the set of linker flags that should be applied to a <target>. **LLVM_DEFAULT_TARGET_TRIPLE**:STRING; LLVM target to use for code generation when no target is explicitly specified.; It defaults to ""host"", meaning that it shall pick the architecture; of the machine where LLVM is being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:19530,Performance,load,loaded,19530,"being built. If you are building a cross-compiler,; set it to the target triple of your desired architecture. **LLVM_DOXYGEN_QCH_FILENAME**:STRING; The filename of the Qt Compressed Help file that will be generated when; ``-DLLVM_ENABLE_DOXYGEN=ON`` and; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON`` are given. Defaults to; ``org.llvm.qch``.; This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effect. **LLVM_DOXYGEN_QHELPGENERATOR_PATH**:STRING; The path to the ``qhelpgenerator`` executable. Defaults to whatever CMake's; ``find_program()`` can find. This option is only useful in combination with; ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise it has no; effect. **LLVM_DOXYGEN_QHP_CUST_FILTER_NAME**:STRING; See `Qt Help Project`_ for; more information. Defaults to the CMake variable ``${PACKAGE_STRING}`` which; is a combination of the package name and version string. This filter can then; be used in Qt Creator to select only documentation from LLVM when browsing; through all the help files that you might have loaded. This option is only; useful in combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effect. .. _Qt Help Project: http://qt-project.org/doc/qt-4.8/qthelpproject.html#custom-filters. **LLVM_DOXYGEN_QHP_NAMESPACE**:STRING; Namespace under which the intermediate Qt Help Project file lives. See `Qt; Help Project`_; for more information. Defaults to ""org.llvm"". This option is only useful in; combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise; it has no effect. **LLVM_DOXYGEN_SVG**:BOOL; Uses .svg files instead of .png files for graphs in the Doxygen output.; Defaults to OFF. .. _llvm_enable_assertions:. **LLVM_ENABLE_ASSERTIONS**:BOOL; Enables code assertions. Defaults to ON if and only if ``CMAKE_BUILD_TYPE``; is *Debug*. **LLVM_ENABLE_BINDINGS**:BOOL; If disabled, do not try to build the OCaml bindings. **LLVM_ENABLE_DIA_SDK**:BOOL; Enable building with MSVC DIA SDK for PDB deb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:20932,Performance,load,load,20932,"seful in; combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise; it has no effect. **LLVM_DOXYGEN_SVG**:BOOL; Uses .svg files instead of .png files for graphs in the Doxygen output.; Defaults to OFF. .. _llvm_enable_assertions:. **LLVM_ENABLE_ASSERTIONS**:BOOL; Enables code assertions. Defaults to ON if and only if ``CMAKE_BUILD_TYPE``; is *Debug*. **LLVM_ENABLE_BINDINGS**:BOOL; If disabled, do not try to build the OCaml bindings. **LLVM_ENABLE_DIA_SDK**:BOOL; Enable building with MSVC DIA SDK for PDB debugging support. Available; only with MSVC. Defaults to ON. **LLVM_ENABLE_DOXYGEN**:BOOL; Enables the generation of browsable HTML documentation using doxygen.; Defaults to OFF. **LLVM_ENABLE_DOXYGEN_QT_HELP**:BOOL; Enables the generation of a Qt Compressed Help file. Defaults to OFF.; This affects the make target ``doxygen-llvm``. When enabled, apart from; the normal HTML output generated by doxygen, this will produce a QCH file; named ``org.llvm.qch``. You can then load this file into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and make use of C++ exceptions in your own code; that need to propagate through LLVM code. Defaults to OFF. **LLVM_ENABLE_EXPENSIVE_CHECKS**:BOOL; Enable additional time/memory expensive checking. Defaults to OFF. **LLVM_ENABLE_HTTPLIB**:BOOL; Enables the optional cpp-httplib dependency which is used by llvm-debuginfod; to serve debug info over HTTP. `cpp-httplib <https://github.com/yhirose/cpp-httplib>`_; must be installed, or `httplib_ROOT` must be set. Defaults to OFF. **LLVM_ENABLE_FFI**:BOOL; Indicates whether the LLVM Interpreter will be linked with the Foreign Function; Interface library (libffi) in order to enable calling external functions.; If the library or its headers are installed in a custom; location, you can als",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:23434,Performance,optimiz,optimization,23434," usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the compiler command-line, if the compiler supports; this flag. Some systems, like Windows, do not need this flag. Defaults to ON. **LLVM_ENABLE_PROJECTS**:STRING; Semicolon-separated list of projects to build, or *all* for building all; (clang, lldb, lld, polly, etc) projects. This flag assumes that projects; are checked out side-by-side and not nested, i.e. clang needs to be in; parallel of llvm instead of nested in `llvm/tools`. This feature allows; to have one build for only LLVM and another for clang+llvm using the same; source checkout.; The full list",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32233,Performance,optimiz,optimized,32233,"is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not termi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32463,Performance,concurren,concurrent,32463,"such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32557,Performance,concurren,concurrent,32557," user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38794,Performance,cache,cache,38794,"iables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configuratio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38856,Performance,cache,cache,38856,"defaults is more likely to cause; things to go wrong. They are also unstable across LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Test",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38950,Performance,cache,cache,38950,"cross LLVM versions. **LLVM_TOOLS_INSTALL_DIR**:STRING; The path to install the main LLVM tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:38987,Performance,cache,cache,38987,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39042,Performance,cache,cached,39042,"M tools, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to *CMAKE_INSTALL_BINDIR*. **LLVM_UTILS_INSTALL_DIR**:STRING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39111,Performance,cache,cached,39111,"RING; The path to install auxiliary LLVM utilities, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_INSTALL_UTILS* is enabled.; Defaults to *LLVM_TOOLS_INSTALL_DIR*. **LLVM_EXAMPLES_INSTALL_DIR**:STRING; The path for examples of using LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39346,Performance,cache,cache,39346,"sing LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39393,Performance,cache,cache,39393,"sing LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39457,Performance,cache,cache,39457,"sing LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39502,Performance,cache,cache,39502,"sing LLVM, relative to the *CMAKE_INSTALL_PREFIX*.; Only matters if *LLVM_BUILD_EXAMPLES* is enabled.; Defaults to ""examples"". CMake Caches; ============. Recently LLVM and Clang have been adding some more complicated build system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39547,Performance,cache,cache,39547,"d system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39619,Performance,cache,cache,39619,"d system; features. Utilizing these new features often involves a complicated chain of; CMake variables passed on the command line. Clang provides a collection of CMake; cache scripts to make these features more approachable. CMake cache files are utilized using CMake's -C flag:. .. code-block:: console. $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39912,Performance,perform,performed,39912," $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; impor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42303,Performance,cache,cache,42303,"ION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1878,Safety,detect,detect,1878," page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:2174,Safety,detect,detect,2174,"====. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the build directory:. .. code-block:: console. $ cmake --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:9826,Safety,avoid,avoid,9826,"are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:13313,Safety,avoid,avoid,13313,"espective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36906,Safety,detect,detected,36906,"_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source tree that uses sphinx (e.g. ``docs-llvm-html``, ``docs-clang-html``; and ``docs-lld-html``). Defaults to ON. **SPHINX_OUTPUT_MAN**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) the targets for building; the man pages are added (but not built by default unless ``LLVM_BUILD_DOCS``; is enabled). Currently the only target added is ``docs-llvm-man``. Defaults; to ON. **SPHINX_WARNINGS_AS_ERRORS**:BOOL; If enabled then sphinx documentation warnings will be treated as; errors. Defaults to ON. Advanced variables; ~~~~~~~~~~~~~~~~~~. These are niche, and changing them from their de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:3997,Security,access,accessible,3997,"e --build . The ``--build`` option tells ``cmake`` to invoke the underlying build; tool (``make``, ``ninja``, ``xcodebuild``, ``msbuild``, etc.). The underlying build tool can be invoked directly, of course, but; the ``--build`` option is portable. #. After LLVM has finished building, install it from the build directory:. .. code-block:: console. $ cmake --build . --target install. The ``--target`` option with ``install`` parameter in addition to; the ``--build`` option tells ``cmake`` to build the ``install`` target. It is possible to set a different install prefix at installation time; by invoking the ``cmake_install.cmake`` script generated in the; build directory:. .. code-block:: console. $ cmake -DCMAKE_INSTALL_PREFIX=/tmp/llvm -P cmake_install.cmake. .. _Basic CMake usage:; .. _Usage:. Basic CMake usage; =================. This section explains basic aspects of CMake; which you may need in your day-to-day usage. CMake comes with extensive documentation, in the form of html files, and as; online help accessible via the ``cmake`` executable itself. Execute ``cmake; --help`` for further help options. CMake allows you to specify a build tool (e.g., GNU make, Visual Studio,; or Xcode). If not specified on the command line, CMake tries to guess which; build tool to use, based on your environment. Once it has identified your; build tool, CMake uses the corresponding *Generator* to create files for your; build tool (e.g., Makefiles or Visual Studio or Xcode project files). You can; explicitly specify the generator with the command line option ``-G ""Name of the; generator""``. To see a list of the available generators on your system, execute. .. code-block:: console. $ cmake --help. This will list the generator names at the end of the help text. Generators' names are case-sensitive, and may contain spaces. For this reason,; you should enter them exactly as they are listed in the ``cmake --help``; output, in quotes. For example, to generate project files specifically for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:22822,Security,access,access,22822,"to enable calling external functions.; If the library or its headers are installed in a custom; location, you can also set the variables FFI_INCLUDE_DIR and; FFI_LIBRARY_DIR to the directories where ffi.h and libffi.so can be found,; respectively. Defaults to OFF. **LLVM_ENABLE_IDE**:BOOL; Tell the build system that an IDE is being used. This in turn disables the; creation of certain convenience build system targets, such as the various; ``install-*`` and ``check-*`` targets, since IDEs don't always deal well with; a large number of targets. This is usually autodetected, but it can be; configured manually to explicitly control the generation of those targets. **LLVM_ENABLE_LIBCXX**:BOOL; If the host compiler and linker supports the stdlib flag, -stdlib=libc++ is; passed to invocations of both so that the project is built using libc++; instead of stdlibc++. Defaults to OFF. **LLVM_ENABLE_LLVM_LIBC**: BOOL; If the LLVM libc overlay is installed in a location where the host linker; can access it, all built executables will be linked against the LLVM libc; overlay before linking against the system libc. Defaults to OFF. **LLVM_ENABLE_LIBPFM**:BOOL; Enable building with libpfm to support hardware counter measurements in LLVM; tools.; Defaults to ON. **LLVM_ENABLE_LLD**:BOOL; This option is equivalent to `-DLLVM_USE_LINKER=lld`, except during a 2-stage; build where a dependency is added from the first stage to the second ensuring; that lld is built before stage2 begins. **LLVM_ENABLE_LTO**:STRING; Add ``-flto`` or ``-flto=`` flags to the compile and link command; lines, enabling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the comp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36284,Security,sanitiz,sanitizer,36284,"API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:1935,Testability,test,tests,1935," page is geared towards users of the LLVM CMake build. If you're looking for; information about modifying the LLVM CMake build system you may want to see the; :doc:`CMakePrimer` page. It has a basic overview of the CMake language. .. _Quick start:. Quick start; ===========. We use here the command-line, non-interactive CMake interface. #. `Download <http://www.cmake.org/cmake/resources/software.html>`_ and install; CMake. Version 3.20.0 is the minimum required. #. Open a shell. Your development tools must be reachable from this shell; through the PATH environment variable. #. Create a build directory. Building LLVM in the source; directory is not supported. cd to this directory:. .. code-block:: console. $ mkdir mybuilddir; $ cd mybuilddir. #. Execute this command in the shell replacing `path/to/llvm/source/root` with; the path to the root of your LLVM source tree:. .. code-block:: console. $ cmake path/to/llvm/source/root. CMake will detect your development environment, perform a series of tests, and; generate the files required for building LLVM. CMake will use default values; for all build parameters. See the `Options and variables`_ section for; a list of build parameters that you can modify. This can fail if CMake can't detect your toolset, or if it thinks that the; environment is not sane enough. In this case, make sure that the toolset that; you intend to use is the only one reachable from the shell, and that the shell; itself is the correct one for your development environment. CMake will refuse; to build MinGW makefiles if you have a POSIX shell reachable through the PATH; environment variable, for instance. You can force CMake to use a given build; tool; for instructions, see the `Usage`_ section, below. You may; also wish to control which targets LLVM enables, or which LLVM; components are built; see the `Frequently Used LLVM-related; variables`_ below. #. After CMake has finished running, proceed to use IDE project files, or start; the build from the buil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12226,Testability,assert,assertion,12226,"ative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Su",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12345,Testability,assert,assertions,12345,"ted variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:12842,Testability,assert,assertions,12842," toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version built without it. **LLVM_ADDITIONAL_BUILD_TYPES**:LIST; Adding a semicolon separated list of additional build types to this flag; allows for them to be specified as values in CMAKE_BUILD_TYPE without; encountering a fatal error during the configuration process. **LLVM_UNREACHABLE_OPTIMIZE**:BOOL; This flag controls the behavior of `llvm_unreachable()` in release build; (when assertions are disabled in general). When ON (default) then; `llvm_unreachable()` is considered ""undefined behavior"" and optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit exe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:13958,Testability,benchmark,benchmarks,13958,"nd optimized as; such. When OFF it is instead replaced with a guaranteed ""trap"". **LLVM_APPEND_VC_REV**:BOOL; Embed version control revision info (Git revision id).; The version info is provided by the ``LLVM_REVISION`` macro in; ``llvm/include/llvm/Support/VCSRevision.h``. Developers using git who don't; need revision info can disable this option to avoid re-linking most binaries; after a branch switch. Defaults to ON. **LLVM_FORCE_VC_REVISION**:STRING; Force a specific Git revision id rather than calling to git to determine it.; This is useful in environments where git is not available or non-functional; but the VC revision is available through other means. **LLVM_FORCE_VC_REPOSITORY**:STRING; Set the git repository to include in version info rather than calling git to; determine it. **LLVM_BUILD_32_BITS**:BOOL; Build 32-bit executables and libraries on 64-bit systems. This option is; available only on some 64-bit Unix systems. Defaults to OFF. **LLVM_BUILD_BENCHMARKS**:BOOL; Adds benchmarks to the list of default targets. Defaults to OFF. **LLVM_BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:15884,Testability,test,test,15884," llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the tar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:15949,Testability,test,test,15949,"ir to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16114,Testability,test,test,16114,"eport for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16701,Testability,test,tests,16701," coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16783,Testability,test,test,16783,"lude all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACH",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:16846,Testability,test,test,16846,"idual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17043,Testability,test,tests,17043,"parate directory under the; config.test_exec_root path. This feature allows code coverage analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:17085,Testability,test,tests,17085," analysis of each; individual test case. Defaults to OFF. **LLVM_BUILD_LLVM_DYLIB**:BOOL; If enabled, the target for building the libLLVM shared library is added.; This library contains all of LLVM's components in a single shared library.; Defaults to OFF. This cannot be used in conjunction with BUILD_SHARED_LIBS.; Tools will only be linked to the libLLVM shared library if LLVM_LINK_LLVM_DYLIB; is also ON.; The components in the library can be customised by setting LLVM_DYLIB_COMPONENTS; to a list of the desired components.; This option is not available on Windows. **LLVM_BUILD_TESTS**:BOOL; Include LLVM unit tests in the 'all' build target. Defaults to OFF. Targets; for building each unit test are generated in any case. You can build a; specific unit test using the targets defined under *unittests*, such as; ADTTests, IRTests, SupportTests, etc. (Search for ``add_llvm_unittest`` in; the subdirectories of *unittests* for a complete list of unit tests.) It is; possible to build all unit tests with the target *UnitTests*. **LLVM_BUILD_TOOLS**:BOOL; Build LLVM tools. Defaults to ON. Targets for building each tool are generated; in any case. You can build a tool separately by invoking its target. For; example, you can build *llvm-as* with a Makefile-based system by executing *make; llvm-as* at the root of your build directory. **LLVM_CCACHE_BUILD**:BOOL; If enabled and the ``ccache`` program is available, then LLVM will be; built using ``ccache`` to speed up rebuilds of LLVM and its components.; Defaults to OFF. The size and location of the cache maintained; by ``ccache`` can be adjusted via the LLVM_CCACHE_MAXSIZE and LLVM_CCACHE_DIR; options, which are passed to the CCACHE_MAXSIZE and CCACHE_DIR environment; variables, respectively. **LLVM_CREATE_XCODE_TOOLCHAIN**:BOOL; macOS Only: If enabled CMake will generate a target named; 'install-xcode-toolchain'. This target will create a directory at; $CMAKE_INSTALL_PREFIX/Toolchains containing an xctoolchain directory which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:20226,Testability,assert,assertions,20226,"AME**:STRING; See `Qt Help Project`_ for; more information. Defaults to the CMake variable ``${PACKAGE_STRING}`` which; is a combination of the package name and version string. This filter can then; be used in Qt Creator to select only documentation from LLVM when browsing; through all the help files that you might have loaded. This option is only; useful in combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``;; otherwise it has no effect. .. _Qt Help Project: http://qt-project.org/doc/qt-4.8/qthelpproject.html#custom-filters. **LLVM_DOXYGEN_QHP_NAMESPACE**:STRING; Namespace under which the intermediate Qt Help Project file lives. See `Qt; Help Project`_; for more information. Defaults to ""org.llvm"". This option is only useful in; combination with ``-DLLVM_ENABLE_DOXYGEN_QT_HELP=ON``; otherwise; it has no effect. **LLVM_DOXYGEN_SVG**:BOOL; Uses .svg files instead of .png files for graphs in the Doxygen output.; Defaults to OFF. .. _llvm_enable_assertions:. **LLVM_ENABLE_ASSERTIONS**:BOOL; Enables code assertions. Defaults to ON if and only if ``CMAKE_BUILD_TYPE``; is *Debug*. **LLVM_ENABLE_BINDINGS**:BOOL; If disabled, do not try to build the OCaml bindings. **LLVM_ENABLE_DIA_SDK**:BOOL; Enable building with MSVC DIA SDK for PDB debugging support. Available; only with MSVC. Defaults to ON. **LLVM_ENABLE_DOXYGEN**:BOOL; Enables the generation of browsable HTML documentation using doxygen.; Defaults to OFF. **LLVM_ENABLE_DOXYGEN_QT_HELP**:BOOL; Enables the generation of a Qt Compressed Help file. Defaults to OFF.; This affects the make target ``doxygen-llvm``. When enabled, apart from; the normal HTML output generated by doxygen, this will produce a QCH file; named ``org.llvm.qch``. You can then load this file into Qt Creator.; This option is only useful in combination with ``-DLLVM_ENABLE_DOXYGEN=ON``;; otherwise this has no effect. **LLVM_ENABLE_EH**:BOOL; Build LLVM with exception-handling support. This is necessary if you wish to; link against LLVM libraries and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:24426,Testability,test,tests,24426,"ling link-time optimization. Possible values are ``Off``,; ``On``, ``Thin`` and ``Full``. Defaults to OFF. **LLVM_ENABLE_MODULES**:BOOL; Compile with `Clang Header Modules; <https://clang.llvm.org/docs/Modules.html>`_. **LLVM_ENABLE_PEDANTIC**:BOOL; Enable pedantic mode. This disables compiler-specific extensions, if; possible. Defaults to ON. **LLVM_ENABLE_PIC**:BOOL; Add the ``-fPIC`` flag to the compiler command-line, if the compiler supports; this flag. Some systems, like Windows, do not need this flag. Defaults to ON. **LLVM_ENABLE_PROJECTS**:STRING; Semicolon-separated list of projects to build, or *all* for building all; (clang, lldb, lld, polly, etc) projects. This flag assumes that projects; are checked out side-by-side and not nested, i.e. clang needs to be in; parallel of llvm instead of nested in `llvm/tools`. This feature allows; to have one build for only LLVM and another for clang+llvm using the same; source checkout.; The full list is:; ``clang;clang-tools-extra;cross-project-tests;libc;libclc;lld;lldb;openmp;polly;pstl``. **LLVM_ENABLE_RUNTIMES**:STRING; Build libc++, libc++abi, libunwind or compiler-rt using the just-built compiler.; This is the correct way to build runtimes when putting together a toolchain.; It will build the builtins separately from the other runtimes to preserve; correct dependency ordering. If you want to build the runtimes using a system; compiler, see the `libc++ documentation <https://libcxx.llvm.org/BuildingLibcxx.html>`_.; Note: the list should not have duplicates with `LLVM_ENABLE_PROJECTS`.; The full list is:; ``compiler-rt;libc;libcxx;libcxxabi;libunwind;openmp``; To enable all of them, use:; ``LLVM_ENABLE_RUNTIMES=all``. **LLVM_ENABLE_RTTI**:BOOL; Build LLVM with run-time type information. Defaults to OFF. **LLVM_ENABLE_SPHINX**:BOOL; If specified, CMake will search for the ``sphinx-build`` executable and will make; the ``SPHINX_OUTPUT_HTML`` and ``SPHINX_OUTPUT_MAN`` CMake options available.; Defaults to OFF. **LLVM_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:28008,Testability,benchmark,benchmarks,28008," the in-tree subdirectory for an external project; exists (e.g., llvm/tools/clang for Clang), then the corresponding variable; will not be used. If the variable for an external project does not point; to a valid path, then that project will not be built. **LLVM_EXTERNAL_PROJECTS**:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compile at all, or might fail at runtime due to known bugs in these; toolchains. **LLVM_INCLUDE_BENCHMARKS**:BOOL; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to inst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:28291,Testability,test,tests,28291,"*:STRING; Semicolon-separated list of additional external projects to build as part of; llvm. For each project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compile at all, or might fail at runtime due to known bugs in these; toolchains. **LLVM_INCLUDE_BENCHMARKS**:BOOL; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:28401,Testability,test,tests,28401," project LLVM_EXTERNAL_<NAME>_SOURCE_DIR have to be specified; with the path for the source code of the project. Example:; ``-DLLVM_EXTERNAL_PROJECTS=""Foo;Bar""; -DLLVM_EXTERNAL_FOO_SOURCE_DIR=/src/foo; -DLLVM_EXTERNAL_BAR_SOURCE_DIR=/src/bar``. **LLVM_EXTERNALIZE_DEBUGINFO**:BOOL; Generate dSYM files and strip executables and libraries (Darwin Only).; Defaults to OFF. **LLVM_FORCE_USE_OLD_TOOLCHAIN**:BOOL; If enabled, the compiler and standard library versions won't be checked. LLVM; may not compile at all, or might fail at runtime due to known bugs in these; toolchains. **LLVM_INCLUDE_BENCHMARKS**:BOOL; Generate build targets for the LLVM benchmarks. Defaults to ON. **LLVM_INCLUDE_EXAMPLES**:BOOL; Generate build targets for the LLVM examples. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM examples. **LLVM_INCLUDE_TESTS**:BOOL; Generate build targets for the LLVM unit tests. Defaults to ON. You can use; this option to disable the generation of build targets for the LLVM unit; tests. **LLVM_INCLUDE_TOOLS**:BOOL; Generate build targets for the LLVM tools. Defaults to ON. You can use this; option to disable the generation of build targets for the LLVM tools. **LLVM_INSTALL_BINUTILS_SYMLINKS**:BOOL; Install symlinks from the binutils tool names to the corresponding LLVM tools.; For example, ar will be symlinked to llvm-ar. **LLVM_INSTALL_CCTOOLS_SYMLINKS**:BOOL; Install symliks from the cctools tool names to the corresponding LLVM tools.; For example, lipo will be symlinked to llvm-lipo. **LLVM_INSTALL_OCAMLDOC_HTML_DIR**:STRING; The path to install OCamldoc-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/ocaml-html``. **LLVM_INSTALL_SPHINX_HTML_DIR**:STRING; The path to install Sphinx-generated HTML documentation to. This path can; either be absolute or relative to the CMAKE_INSTALL_PREFIX. Defaults to; ``${CMAKE_INST",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:30829,Testability,test,test,30829,"y about 5-10%. At the moment, rpmalloc,; snmalloc and mimalloc are supported. Use the path to `git clone` to select; the respective allocator, for example:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Dar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:30998,Testability,test,tests,30998,"xample:. .. code-block:: console. $ D:\git> git clone https://github.com/mjansson/rpmalloc; $ D:\llvm-project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31108,Testability,test,tests,31108,"project> cmake ... -DLLVM_INTEGRATED_CRT_ALLOC=D:\git\rpmalloc. This flag needs to be used along with the static CRT, ie. if building the; Release target, add -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31295,Testability,test,tests,31295,"SVC_RUNTIME_LIBRARY=MultiThreaded. **LLVM_INSTALL_DOXYGEN_HTML_DIR**:STRING; The path to install Doxygen-generated HTML documentation to. This path can; either be absolute or relative to the *CMAKE_INSTALL_PREFIX*. Defaults to; ``${CMAKE_INSTALL_DOCDIR}/llvm/doxygen-html``. **LLVM_LINK_LLVM_DYLIB**:BOOL; If enabled, tools will be linked with the libLLVM shared library. Defaults; to OFF. Setting LLVM_LINK_LLVM_DYLIB to ON also sets LLVM_BUILD_LLVM_DYLIB; to ON.; This option is not available on Windows. **LLVM_LIT_ARGS**:STRING; Arguments given to lit. ``make check`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimize",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:31794,Testability,log,logic,31794,"k`` and ``make clang-test`` are affected.; By default, ``'-sv --no-progress-bar'`` on Visual C++ and Xcode, ``'-sv'`` on; others. **LLVM_LIT_TOOLS_DIR**:PATH; The path to GnuWin32 tools for tests. Valid on Windows host. Defaults to; the empty string, in which case lit will look for tools needed for tests; (e.g. ``grep``, ``sort``, etc.) in your %PATH%. If GnuWin32 is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of log",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32143,Testability,assert,asserts,32143,"is not in your; %PATH%, then you can set this variable to the GnuWin32 directory so that; lit can find tools needed for tests in that directory. **LLVM_NATIVE_TOOL_DIR**:STRING; Full path to a directory containing executables for the build host; (containing binaries such as ``llvm-tblgen`` and ``clang-tblgen``). This is; intended for cross-compiling: if the user sets this variable and the; directory contains executables with the expected names, no separate; native versions of those executables will be built. **LLVM_NO_INSTALL_NAME_DIR_FOR_BUILD_TREE**:BOOL; Defaults to ``OFF``. If set to ``ON``, CMake's default logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not termi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:32806,Testability,log,logical,32806,"fault logic for library IDs; on Darwin in the build tree will be used. Otherwise the install-time library; IDs will be used in the build tree as well. Mainly useful when other CMake; library ID control variables (e.g., ``CMAKE_INSTALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containers would be iterated in; reverse order. This is useful for uncovering non-determinism caused by; iteration of unordered containers. **LLVM_STATIC_LINK_CXX_STDLIB**:BOOL; Statically link to the C++ standard library if possible. This uses the flag; ""-stat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:33036,Testability,log,logical,33036,"ALL_NAME_DIR``) are being; set to non-standard values. **LLVM_OPTIMIZED_TABLEGEN**:BOOL; If enabled and building a debug or asserts build the CMake build system will; generate a Release build tree to build a fully optimized tablegen for use; during the build. Enabling this option can significantly speed up build times; especially when building LLVM in Debug configurations. **LLVM_PARALLEL_COMPILE_JOBS**:STRING; Define the maximum number of concurrent compilation jobs. **LLVM_PARALLEL_LINK_JOBS**:STRING; Define the maximum number of concurrent link jobs. **LLVM_RAM_PER_COMPILE_JOB**:STRING; Calculates the amount of Ninja compile jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_COMPILE_JOBS. Compile jobs ; will be between one and amount of logical cores. **LLVM_RAM_PER_LINK_JOB**:STRING; Calculates the amount of Ninja link jobs according to available resources.; Value has to be in MB, overwrites LLVM_PARALLEL_LINK_JOBS. Link jobs will ; be between one and amount of logical cores. Link jobs will not run ; exclusively therefore you should add an offset of one or two compile jobs ; to be sure its not terminated in your memory restricted environment. On ELF; platforms also consider ``LLVM_USE_SPLIT_DWARF`` in Debug build. **LLVM_PROFDATA_FILE**:PATH; Path to a profdata file to pass into clang's -fprofile-instr-use flag. This; can only be specified if you're building with clang. **LLVM_REVERSE_ITERATION**:BOOL; If enabled, all supported unordered llvm containers would be iterated in; reverse order. This is useful for uncovering non-determinism caused by; iteration of unordered containers. **LLVM_STATIC_LINK_CXX_STDLIB**:BOOL; Statically link to the C++ standard library if possible. This uses the flag; ""-static-libstdc++"", but a Clang host compiler will statically link to libc++; if used in conjunction with the **LLVM_ENABLE_LIBCXX** flag. Defaults to OFF. **LLVM_TABLEGEN**:STRING; Full path to a native TableGen executable (usually name",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:36326,Testability,test,tests,36326,"API. Defaults to OFF. **LLVM_USE_LINKER**:STRING; Add ``-fuse-ld={name}`` to the link invocation. The possible value depend on; your compiler, for clang the value can be an absolute path to your custom; linker, otherwise clang will prefix the name with ``ld.`` and apply its usual; search. For example to link LLVM with the Gold linker, cmake can be invoked; with ``-DLLVM_USE_LINKER=gold``. **LLVM_USE_OPROFILE**:BOOL; Enable building OProfile JIT support. Defaults to OFF. **LLVM_USE_PERF**:BOOL; Enable building support for Perf (linux profiling tool) JIT support. Defaults to OFF. **LLVM_USE_RELATIVE_PATHS_IN_FILES**:BOOL; Rewrite absolute source paths in sources and debug info to relative ones. The; source prefix can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_RELATIVE_PATHS_IN_DEBUG_INFO**:BOOL; Rewrite absolute source paths in debug info to relative ones. The source prefix; can be adjusted via the LLVM_SOURCE_PREFIX variable. **LLVM_USE_SANITIZER**:STRING; Define the sanitizer used to build LLVM binaries and tests. Possible values; are ``Address``, ``Memory``, ``MemoryWithOrigins``, ``Undefined``, ``Thread``,; ``DataFlow``, and ``Address;Undefined``. Defaults to empty string. **LLVM_USE_SPLIT_DWARF**:BOOL; If enabled CMake will pass ``-gsplit-dwarf`` to the compiler. This option; reduces link-time memory usage by reducing the amount of debug information that; the linker needs to resolve. It is recommended for platforms using the ELF object; format, like Linux systems when linker memory usage is too high. **SPHINX_EXECUTABLE**:STRING; The path to the ``sphinx-build`` executable detected by CMake.; For installation instructions, see; https://www.sphinx-doc.org/en/master/usage/installation.html. **SPHINX_OUTPUT_HTML**:BOOL; If enabled (and ``LLVM_ENABLE_SPHINX`` is enabled) then the targets for; building the documentation as html are added (but not built by default unless; ``LLVM_BUILD_DOCS`` is enabled). There is a target for each project in the; source",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:40135,Testability,test,tests,40135,"; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:40206,Testability,test,testing,40206," A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:43818,Testability,assert,assertions,43818," is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Note: this is only; available when building LLVM with CMake.**. If LLVM is installed in your operating system's normal installation prefix (e.g.; on Linux this is usually ``/usr/``) ``find_package(LLVM ...)`` will; automatically find LLVM if it is installed correctly. If LLVM is not installed; or you wish to build directly against the LLVM build tree you can use; ``LLVM_DIR`` as previously mentioned. The ``LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries is determined by using the; ``llvm_map_components_to_libnames()`` CMake function. For a list of available; components look at the output of running ``llvm-config --components``. Note that for LLVM < 3.5 ``llvm_map_components_to_libraries()`` was; used instead of ``llvm_ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:15112,Usability,clear,clear-profile-data,15112,"BUILD_DOCS**:BOOL; Adds all *enabled* documentation targets (i.e. Doxgyen and Sphinx targets) as; dependencies of the default build targets. This results in all of the (enabled); documentation targets being as part of a normal build. If the ``install``; target is run then this also enables all built documentation targets to be; installed. Defaults to OFF. To enable a particular documentation target, see; see LLVM_ENABLE_SPHINX and LLVM_ENABLE_DOXYGEN. **LLVM_BUILD_EXAMPLES**:BOOL; Build LLVM examples. Defaults to OFF. Targets for building each example are; generated in any case. See documentation for *LLVM_BUILD_TOOLS* above for more; details. **LLVM_BUILD_INSTRUMENTED_COVERAGE**:BOOL; If enabled, `source-based code coverage; <https://clang.llvm.org/docs/SourceBasedCodeCoverage.html>`_ instrumentation; is enabled while building llvm. If CMake can locate the code coverage; scripts and the llvm-cov and llvm-profdata tools that pair to your compiler,; the build will also generate the `generate-coverage-report` target to generate; the code coverage report for LLVM, and the `clear-profile-data` utility target; to delete captured profile data. See documentation for; *LLVM_CODE_COVERAGE_TARGETS* and *LLVM_COVERAGE_SOURCE_DIRS* for more; information on configuring code coverage reports. **LLVM_CODE_COVERAGE_TARGETS**:STRING; If set to a semicolon separated list of targets, those targets will be used; to drive the code coverage reports. If unset, the target list will be; constructed using the LLVM build's CMake export list. **LLVM_COVERAGE_SOURCE_DIRS**:STRING; If set to a semicolon separated list of directories, the coverage reports; will limit code coverage summaries to just the listed directories. If unset,; coverage reports will include all sources identified by the tooling. **LLVM_INDIVIDUAL_TEST_COVERAGE**:BOOL; Enable individual test case coverage. When set to ON, code coverage data for; each test case will be generated and stored in a separate directory under the; co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41132,Usability,simpl,simple,41132,"y building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41230,Usability,simpl,simple,41230," see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmak",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41251,Usability,simpl,simple-tool,41251," see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmak",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:41838,Usability,simpl,simple-tool,41838,"========================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; importable CMake targets. This means that clients of LLVM can now reliably use; CMake to develop their own LLVM-based projects against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:42064,Usability,simpl,simple-tool,42064,"s against an installed version of; LLVM regardless of how it was built. Here is a simple example of a CMakeLists.txt file that imports the LLVM libraries; and uses them to build a simple application ``simple-tool``. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(SimpleProject). find_package(LLVM REQUIRED CONFIG). message(STATUS ""Found LLVM ${LLVM_PACKAGE_VERSION}""); message(STATUS ""Using LLVMConfig.cmake in: ${LLVM_DIR}""). # Set your project compile flags.; # E.g. if using the C++ header files; # you will need to enable C++11 support; # for your compiler. include_directories(${LLVM_INCLUDE_DIRS}); separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_definitions(${LLVM_DEFINITIONS_LIST}). # Now build our tools; add_executable(simple-tool tool.cpp). # Find the libraries that correspond to the LLVM components; # that we wish to use; llvm_map_components_to_libnames(llvm_libs support core irreader). # Link against LLVM libraries; target_link_libraries(simple-tool ${llvm_libs}). The ``find_package(...)`` directive when used in CONFIG mode (as in the above; example) will look for the ``LLVMConfig.cmake`` file in various locations (see; cmake manual for details). It creates a ``LLVM_DIR`` cache entry to save the; directory where ``LLVMConfig.cmake`` is found or allows the user to specify the; directory (e.g. by passing ``-DLLVM_DIR=/usr/lib/cmake/llvm`` to; the ``cmake`` command or by setting it directly in ``ccmake`` or ``cmake-gui``). This file is available in two different locations. * ``<LLVM_INSTALL_PACKAGE_DIR>/LLVMConfig.cmake`` where; ``<LLVM_INSTALL_PACKAGE_DIR>`` is the location where LLVM CMake modules are; installed as part of an installed version of LLVM. This is typically; ``cmake/llvm/`` within the lib directory. On Linux, this is typically; ``/usr/lib/cmake/llvm/LLVMConfig.cmake``. * ``<LLVM_BUILD_ROOT>/lib/cmake/llvm/LLVMConfig.cmake`` where; ``<LLVM_BUILD_ROOT>`` is the root of the LLVM build tree. **Not",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:44455,Usability,simpl,simple-tool,44455,"`LLVMConfig.cmake`` file sets various useful variables. Notable variables; include. ``LLVM_CMAKE_DIR``; The path to the LLVM CMake directory (i.e. the directory containing; LLVMConfig.cmake). ``LLVM_DEFINITIONS``; A list of preprocessor defines that should be used when building against LLVM. ``LLVM_ENABLE_ASSERTIONS``; This is set to ON if LLVM was built with assertions, otherwise OFF. ``LLVM_ENABLE_EH``; This is set to ON if LLVM was built with exception handling (EH) enabled,; otherwise OFF. ``LLVM_ENABLE_RTTI``; This is set to ON if LLVM was built with run time type information (RTTI),; otherwise OFF. ``LLVM_INCLUDE_DIRS``; A list of include paths to directories containing LLVM header files. ``LLVM_PACKAGE_VERSION``; The LLVM version. This string can be used with CMake conditionals, e.g., ``if; (${LLVM_PACKAGE_VERSION} VERSION_LESS ""3.5"")``. ``LLVM_TOOLS_BINARY_DIR``; The path to the directory containing the LLVM tools (e.g. ``llvm-as``). Notice that in the above example we link ``simple-tool`` against several LLVM; libraries. The list of libraries is determined by using the; ``llvm_map_components_to_libnames()`` CMake function. For a list of available; components look at the output of running ``llvm-config --components``. Note that for LLVM < 3.5 ``llvm_map_components_to_libraries()`` was; used instead of ``llvm_map_components_to_libnames()``. This is now deprecated; and will be removed in a future version of LLVM. .. _cmake-out-of-source-pass:. Developing LLVM passes out of source; ------------------------------------. It is possible to develop LLVM passes out of LLVM's source tree (i.e. against an; installed or built LLVM). An example of a project layout is provided below. .. code-block:: none. <project dir>/; |; CMakeLists.txt; <pass name>/; |; CMakeLists.txt; Pass.cpp; ... Contents of ``<project dir>/CMakeLists.txt``:. .. code-block:: cmake. find_package(LLVM REQUIRED CONFIG). separate_arguments(LLVM_DEFINITIONS_LIST NATIVE_COMMAND ${LLVM_DEFINITIONS}); add_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMake.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:619,Availability,avail,available,619,"============; CMake Primer; ============. .. contents::; :local:. .. warning::; Disclaimer: This documentation is written by LLVM project contributors `not`; anyone affiliated with the CMake project. This document may contain; inaccurate terminology, phrasing, or technical details. It is provided with; the best intentions. Introduction; ============. The LLVM project and many of the core projects built on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1067,Availability,error,errors,1067,"rning::; Disclaimer: This documentation is written by LLVM project contributors `not`; anyone affiliated with the CMake project. This document may contain; inaccurate terminology, phrasing, or technical details. It is provided with; the best intentions. Introduction; ============. The LLVM project and many of the core projects built on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:11645,Availability,avail,available,11645,"In C parlance, all commands are varargs functions). When a command is; invoked with extra arguments (beyond the named ones) CMake will store the full; list of arguments (both named and unnamed) in a list named ``ARGV``, and the; sublist of unnamed arguments in ``ARGN``. Below is a trivial example of; providing a wrapper function for CMake's built in function ``add_dependencies``. .. code-block:: cmake. function(add_deps target); add_dependencies(${target} ${ARGN}); endfunction(). This example defines a new macro named ``add_deps`` which takes a required first; argument, and just calls another function passing through the first argument and; all trailing arguments. CMake provides a module ``CMakeParseArguments`` which provides an implementation; of advanced argument parsing. We use this all over LLVM, and it is recommended; for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:14850,Availability,avail,available,14850,"eferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; documentation. To highlight a few useful functions see:. * `add_custom_command <https://cmake.org/cmake/help/v3.4/command/add_custom_command.html>`_; * `add_custom_target <https://cmake.org/cmake/help/v3.4/command/add_custom_target.html>`_; * `file <https://cmake.org/cmake/help/v3.4/command/file.html>`_; * `list <https://cmake.org/cmake/help/v3.4/command/list.html>`_; * `math <https://cmake.org/cmake/help/v3.4/command/math.html>`_; * `string <https://cmake.org/cmake/help/v3.4/command/string.html>`_. The full documentation for CMake commands is in the ``cmake-commands`` manpage; and available on `CMake's website <https://cmake.org/cmake/help/v3.4/manual/cmake-commands.7.html>`_; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13769,Deployability,install,installed,13769,"_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; documentation. To highlight a few useful functions see:. * `add_custom_command <https://cmake.org/cmake/help/v3.4/command/add_custom_command.html>`_; * `add_custom_target <https://cmake.org/cmake/help/v3.4/command/add_custom_target.html>`_; * `file <https://cmake.org/cmake/help/v3.4/command/file.html>`_; * `list <https://cmake.org/cmake/help/v3.4/command/list.html>`_; * `math <https://cmake.org/cmake/help/v3.4/command/math.html>`_; * `string <https://cmake.org/cmake/help/v3.4/command/string.html>`_. The full document",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13297,Energy Efficiency,reduce,reduce,13297,"efining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; docum",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5153,Integrability,message,message,5153,"extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:7871,Integrability,message,message,7871,"e CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:7913,Integrability,message,message,7913,"e CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:7948,Integrability,message,message,7948,"e CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8308,Integrability,message,message,8308,"ve; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you woul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8518,Integrability,message,message,8518,"e, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Mod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8626,Integrability,message,message,8626,"full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8722,Integrability,message,message,8722," That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8954,Integrability,message,message,8954,"ther stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functions are universally referred to as commands, and they; are the primary method of defining code that can be called multiple times. In LLVM we have several CMake modules that are included as part of our; distribution for developers",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:9068,Integrability,message,message,9068," background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functions are universally referred to as commands, and they; are the primary method of defining code that can be called multiple times. In LLVM we have several CMake modules that are included as part of our; distribution for developers who don't build our project from source. Those; modules are the fundamental pieces needed to build LLV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:9176,Integrability,message,message,9176,"ndif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functions are universally referred to as commands, and they; are the primary method of defining code that can be called multiple times. In LLVM we have several CMake modules that are included as part of our; distribution for developers who don't build our project from source. Those; modules are the fundamental pieces needed to build LLVM-based projects with; CMake. We also rely on modules as a way of organizing the build system's; functionality for ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:10945,Integrability,wrap,wrapper,10945,"developers who don't build our project from source. Those; modules are the fundamental pieces needed to build LLVM-based projects with; CMake. We also rely on modules as a way of organizing the build system's; functionality for maintainability and re-use within LLVM projects. Argument Handling; -----------------. When defining a CMake command handling arguments is very useful. The examples; in this section will all use the CMake ``function`` block, but this all applies; to the ``macro`` block as well. CMake commands can have named arguments that are required at every call site. In; addition, all commands will implicitly accept a variable number of extra; arguments (In C parlance, all commands are varargs functions). When a command is; invoked with extra arguments (beyond the named ones) CMake will store the full; list of arguments (both named and unnamed) in a list named ``ARGV``, and the; sublist of unnamed arguments in ``ARGN``. Below is a trivial example of; providing a wrapper function for CMake's built in function ``add_dependencies``. .. code-block:: cmake. function(add_deps target); add_dependencies(${target} ${ARGN}); endfunction(). This example defines a new macro named ``add_deps`` which takes a required first; argument, and just calls another function passing through the first argument and; all trailing arguments. CMake provides a module ``CMakeParseArguments`` which provides an implementation; of advanced argument parsing. We use this all over LLVM, and it is recommended; for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions V",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12709,Integrability,message,message,12709,"https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13161,Integrability,wrap,wrappers,13161,"ariables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13225,Integrability,wrap,wrappers,13225,"efining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; docum",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13652,Integrability,wrap,wrapper,13652,"macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; documentation. To highlight a few useful functions see:. * `add_custom_command <https://cmake.org/cmake/help/v3.4/command/add_custom_command.html>`_; * `add_custom_target <https://cmake.org/cmake/help/v3.4/command/add_custom_target.html>`_; * `file <https://cmake.org/cmake/help/v3.4/command/file.html>`_; * `list <https://cmake.org/cmake/help/v3.4/command/list.html>`_; * `math <https://cma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:13704,Integrability,wrap,wrapper,13704,"${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; documentation. To highlight a few useful functions see:. * `add_custom_command <https://cmake.org/cmake/help/v3.4/command/add_custom_command.html>`_; * `add_custom_target <https://cmake.org/cmake/help/v3.4/command/add_custom_target.html>`_; * `file <https://cmake.org/cmake/help/v3.4/command/file.html>`_; * `list <https://cmake.org/cmake/help/v3.4/command/list.html>`_; * `math <https://cmake.org/cmake/help/v3.4/command/math.html>`_; * `string <https://cm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:2855,Modifiability,variab,variables,2855,"uage-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:2891,Modifiability,variab,variables,2891,"defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sour",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:2963,Modifiability,variab,variable,2963,"CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3091,Modifiability,variab,variable,3091,"ll CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple pla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3582,Modifiability,variab,variable,3582,"nimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3676,Modifiability,variab,variables,3676,"PPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Bec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3739,Modifiability,variab,variable,3739,"PPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Bec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3841,Modifiability,variab,variable,3841," CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For exampl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:4042,Modifiability,variab,variable,4042,"the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:4796,Modifiability,variab,variable,4796,"ere are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the comm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5591,Modifiability,variab,variable,5591,"y_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the valu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5813,Modifiability,variab,variable,5813,":. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all sco",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5893,Modifiability,variab,variable,5893,"yout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5997,Modifiability,variab,variables,5997,"yout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6242,Modifiability,variab,variable,6242,"because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6287,Modifiability,variab,variable,6287,"because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6487,Modifiability,variab,variable,6487,", which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6695,Modifiability,variab,variable,6695,"ariables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6781,Modifiability,variab,variable,6781,"them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6887,Modifiability,variab,variable,6887,"enerally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:7061,Modifiability,variab,variables,7061,"mentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:8347,Modifiability,variab,variable,8347,"ntrol flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks work the way you'd expect:. .. code-block:: cmake. if(<condition>); message(""do stuff""); elseif(<condition>); message(""do other stuff""); else(); message(""do other other stuff""); endif(). The single most important thing to know about CMake's if blocks coming from a C; background is that they do not have their own scope. Variables set inside; conditional blocks persist after the ``endif()``. Loops; -----. The most common form of the CMake ``foreach`` block is:. .. code-block:: cmake. foreach(var ...); message(""do stuff""); endforeach(). The variable argument portion of the ``foreach`` block can contain dereferenced; lists, values to iterate, or a mix of both:. .. code-block:: cmake. foreach(var foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var ${my_list}); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var ${my_list} out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. There is also a more modern CMake foreach syntax. The code below is equivalent; to the code above:. .. code-block:: cmake. foreach(var IN ITEMS foo bar baz); message(${var}); endforeach(); # prints:; # foo; # bar; # baz. set(my_list 1 2 3); foreach(var IN LISTS my_list); message(${var}); endforeach(); # prints:; # 1; # 2; # 3. foreach(var IN LISTS my_list ITEMS out_of_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:10185,Modifiability,maintainab,maintainability,10185,"_bounds); message(${var}); endforeach(); # prints:; # 1; # 2; # 3; # out_of_bounds. Similar to the conditional statements, these generally behave how you would; expect, and they do not have their own scope. CMake also supports ``while`` loops, although they are not widely used in LLVM. Modules, Functions and Macros; =============================. Modules; -------. Modules are CMake's vehicle for enabling code reuse. CMake modules are just; CMake script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functions are universally referred to as commands, and they; are the primary method of defining code that can be called multiple times. In LLVM we have several CMake modules that are included as part of our; distribution for developers who don't build our project from source. Those; modules are the fundamental pieces needed to build LLVM-based projects with; CMake. We also rely on modules as a way of organizing the build system's; functionality for maintainability and re-use within LLVM projects. Argument Handling; -----------------. When defining a CMake command handling arguments is very useful. The examples; in this section will all use the CMake ``function`` block, but this all applies; to the ``macro`` block as well. CMake commands can have named arguments that are required at every call site. In; addition, all commands will implicitly accept a variable number of extra; arguments (In C parlance, all commands are varargs functions). When a command is; invoked with extra arguments (beyond the named ones) CMake will store the full; list of arguments (both named and unnamed) in a list named ``ARGV``, and the; sublist of unnamed arguments in ``ARGN``. Below is a trivial example of; providing a wrapper function for CMake's built in function ``add_dependencies``. .. code-block:: cmake. function(add_deps target); add_dependencies(${target} ${ARGN}); endfunction(). This example defines a new macro named ``add_deps`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:10594,Modifiability,variab,variable,10594,"Make script files. They can contain code to execute on include as well as; definitions for commands. In CMake macros and functions are universally referred to as commands, and they; are the primary method of defining code that can be called multiple times. In LLVM we have several CMake modules that are included as part of our; distribution for developers who don't build our project from source. Those; modules are the fundamental pieces needed to build LLVM-based projects with; CMake. We also rely on modules as a way of organizing the build system's; functionality for maintainability and re-use within LLVM projects. Argument Handling; -----------------. When defining a CMake command handling arguments is very useful. The examples; in this section will all use the CMake ``function`` block, but this all applies; to the ``macro`` block as well. CMake commands can have named arguments that are required at every call site. In; addition, all commands will implicitly accept a variable number of extra; arguments (In C parlance, all commands are varargs functions). When a command is; invoked with extra arguments (beyond the named ones) CMake will store the full; list of arguments (both named and unnamed) in a list named ``ARGV``, and the; sublist of unnamed arguments in ``ARGN``. Below is a trivial example of; providing a wrapper function for CMake's built in function ``add_dependencies``. .. code-block:: cmake. function(add_deps target); add_dependencies(${target} ${ARGN}); endfunction(). This example defines a new macro named ``add_deps`` which takes a required first; argument, and just calls another function passing through the first argument and; all trailing arguments. CMake provides a module ``CMakeParseArguments`` which provides an implementation; of advanced argument parsing. We use this all over LLVM, and it is recommended; for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmak",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12169,Modifiability,variab,variables,12169,"st; argument, and just calls another function passing through the first argument and; all trailing arguments. CMake provides a module ``CMakeParseArguments`` which provides an implementation; of advanced argument parsing. We use this all over LLVM, and it is recommended; for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake bui",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12434,Modifiability,variab,variables,12434,"for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12603,Modifiability,variab,variables,12603,"ation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12958,Modifiability,variab,variables,12958,"---------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1275,Performance,perform,performs,1275,"with; the best intentions. Introduction; ============. The LLVM project and many of the core projects built on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1427,Performance,cache,caches,1427," on LLVM build using CMake.; This document aims to provide a brief overview of CMake for developers modifying; LLVM projects or building their own projects on top of LLVM. The official CMake language references is available in the cmake-language; manpage and `cmake-language online documentation; <https://cmake.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3153,Performance,perform,performed,3153," CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5731,Performance,cache,cached,5731," a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6154,Performance,cache,cache-entry,6154,"age(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:4325,Safety,avoid,avoid,4325,"the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereferenc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:14024,Security,sanitiz,sanitizer,14024,"eferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake built-in commands.; We use these wrappers to provide consistent behaviors across LLVM components; and to reduce code duplication. We generally (but not always) follow the convention that commands prefaced with; ``llvm_`` are intended to be used only as building blocks for other commands.; Wrapper commands that are intended for direct use are generally named following; with the project in the middle of the command name (i.e. ``add_llvm_executable``; is the wrapper for ``add_executable``). The LLVM ``add_*`` wrapper functions are; all defined in ``AddLLVM.cmake`` which is installed as part of the LLVM; distribution. It can be included and used by any LLVM sub-project that requires; LLVM. .. note::. Not all LLVM projects require LLVM for all use cases. For example compiler-rt; can be built without LLVM, and the compiler-rt sanitizer libraries are used; with GCC. Useful Built-in Commands; ========================. CMake has a bunch of useful built-in commands. This document isn't going to; go into details about them because The CMake project has excellent; documentation. To highlight a few useful functions see:. * `add_custom_command <https://cmake.org/cmake/help/v3.4/command/add_custom_command.html>`_; * `add_custom_target <https://cmake.org/cmake/help/v3.4/command/add_custom_target.html>`_; * `file <https://cmake.org/cmake/help/v3.4/command/file.html>`_; * `list <https://cmake.org/cmake/help/v3.4/command/list.html>`_; * `math <https://cmake.org/cmake/help/v3.4/command/math.html>`_; * `string <https://cmake.org/cmake/help/v3.4/command/string.html>`_. The full documentation for CMake commands is in the ``cmake-commands`` manpage; and available on `CMake's website <https://cmake.org/cmake/help/v3.4/manual/cmake-commands.7.html>`_; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:1726,Usability,simpl,simple,1726,"ke.org/cmake/help/v3.4/manual/cmake-language.7.html>`_. 10,000 ft View; ==============. CMake is a tool that reads script files in its own language that describe how a; software project builds. As CMake evaluates the scripts it constructs an; internal representation of the software project. Once the scripts have been; fully processed, if there are no errors, CMake will generate build files to; actually build the project. CMake supports generating build files for a variety; of command line build tools as well as for popular IDEs. When a user runs CMake it performs a variety of checks similar to how autoconf; worked historically. During the checks and the evaluation of the build; description scripts CMake caches values into the CMakeCache. This is useful; because it allows the build system to skip long-running checks during; incremental development. CMake caching also has some drawbacks, but that will be; discussed later. Scripting Overview; ==================. CMake's scripting language has a very simple grammar. Every language construct; is a command that matches the pattern _name_(_args_). Commands come in three; primary types: language-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:21479,Availability,mask,mask,21479,"ntity moves producing the following; code:. .. code-block:: text. ;; X is in EAX, Y is in ECX; mov %EAX, %EDX; sar %EDX, 31; idiv %ECX; ret. This approach is extremely general (if it can handle the X86 architecture, it; can handle anything!) and allows all of the target specific knowledge about the; instruction stream to be isolated in the instruction selector. Note that; physical registers should have a short lifetime for good code generation, and; all physical registers are assumed dead on entry to and exit from basic blocks; (before register allocation). Thus, if you need a value to be live across basic; block boundaries, it *must* live in a virtual register. Call-clobbered registers; ^^^^^^^^^^^^^^^^^^^^^^^^. Some machine instructions, like calls, clobber a large number of physical; registers. Rather than adding ``<def,dead>`` operands for all of them, it is; possible to use an ``MO_RegisterMask`` operand instead. The register mask; operand holds a bit mask of preserved registers, and everything else is; considered to be clobbered by the instruction. Machine code in SSA form; ^^^^^^^^^^^^^^^^^^^^^^^^. ``MachineInstr``'s are initially selected in SSA-form, and are maintained in; SSA-form until register allocation happens. For the most part, this is; trivially simple since LLVM is already in SSA form; LLVM PHI nodes become; machine code PHI nodes, and virtual registers are only allowed to have a single; definition. After register allocation, machine code is no longer in SSA-form because there; are no virtual registers left in the code. .. _MachineBasicBlock:. The ``MachineBasicBlock`` class; -------------------------------. The ``MachineBasicBlock`` class contains a list of machine instructions; (:raw-html:`<tt>` `MachineInstr`_ :raw-html:`</tt>` instances). It roughly; corresponds to the LLVM code input to the instruction selector, but there can be; a one-to-many mapping (i.e. one LLVM basic block can map to multiple machine; basic blocks). The ``MachineBasicBlock",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:21505,Availability,mask,mask,21505,"ntity moves producing the following; code:. .. code-block:: text. ;; X is in EAX, Y is in ECX; mov %EAX, %EDX; sar %EDX, 31; idiv %ECX; ret. This approach is extremely general (if it can handle the X86 architecture, it; can handle anything!) and allows all of the target specific knowledge about the; instruction stream to be isolated in the instruction selector. Note that; physical registers should have a short lifetime for good code generation, and; all physical registers are assumed dead on entry to and exit from basic blocks; (before register allocation). Thus, if you need a value to be live across basic; block boundaries, it *must* live in a virtual register. Call-clobbered registers; ^^^^^^^^^^^^^^^^^^^^^^^^. Some machine instructions, like calls, clobber a large number of physical; registers. Rather than adding ``<def,dead>`` operands for all of them, it is; possible to use an ``MO_RegisterMask`` operand instead. The register mask; operand holds a bit mask of preserved registers, and everything else is; considered to be clobbered by the instruction. Machine code in SSA form; ^^^^^^^^^^^^^^^^^^^^^^^^. ``MachineInstr``'s are initially selected in SSA-form, and are maintained in; SSA-form until register allocation happens. For the most part, this is; trivially simple since LLVM is already in SSA form; LLVM PHI nodes become; machine code PHI nodes, and virtual registers are only allowed to have a single; definition. After register allocation, machine code is no longer in SSA-form because there; are no virtual registers left in the code. .. _MachineBasicBlock:. The ``MachineBasicBlock`` class; -------------------------------. The ``MachineBasicBlock`` class contains a list of machine instructions; (:raw-html:`<tt>` `MachineInstr`_ :raw-html:`</tt>` instances). It roughly; corresponds to the LLVM code input to the instruction selector, but there can be; a one-to-many mapping (i.e. one LLVM basic block can map to multiple machine; basic blocks). The ``MachineBasicBlock",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:27630,Availability,down,down,27630,"tion describes some of the important classes. There are also a number; of important subsystems that interact at this layer, they are described later in; this manual. .. _MCStreamer:. The ``MCStreamer`` API; ----------------------. MCStreamer is best thought of as an assembler API. It is an abstract API which; is *implemented* in different ways (e.g. to output a .s file, output an ELF .o; file, etc) but whose API correspond directly to what you see in a .s file.; MCStreamer has one method per directive, such as EmitLabel, EmitSymbolAttribute,; switchSection, emitValue (for .byte, .word), etc, which directly correspond to; assembly level directives. It also has an EmitInstruction method, which is used; to output an MCInst to the streamer. This API is most important for two clients: the llvm-mc stand-alone assembler is; effectively a parser that parses a line, then invokes a method on MCStreamer. In; the code generator, the `Code Emission`_ phase of the code generator lowers; higher level LLVM IR and Machine* constructs down to the MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39098,Availability,error,errors,39098,"-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:41969,Availability,down,down,41969," types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legali",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:56985,Availability,alive,alive,56985,"ments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These are in; physical registers, so the physical register is assumed to be killed by the end; of the basic block. Live intervals for virtual registers are computed for some; ordering of the machine instructions ``[1, N]``. A live interval is an interval; ``[i, j)``, where ``1 >= i >= j > N``, for which a variable is live. .. note::; More to come... .. _Register Allocation:; .. _register allocator:. Register Allocation; -------------------. The *Register Allocation problem* consists in mapping a program; :raw-html:`<b><tt>` P\ :sub:`v`\ :raw-html:`</tt></b>`, tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:57212,Availability,avail,available,57212,"d as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These are in; physical registers, so the physical register is assumed to be killed by the end; of the basic block. Live intervals for virtual registers are computed for some; ordering of the machine instructions ``[1, N]``. A live interval is an interval; ``[i, j)``, where ``1 >= i >= j > N``, for which a variable is live. .. note::; More to come... .. _Register Allocation:; .. _register allocator:. Register Allocation; -------------------. The *Register Allocation problem* consists in mapping a program; :raw-html:`<b><tt>` P\ :sub:`v`\ :raw-html:`</tt></b>`, that can use an unbounded; number of virtual registers, to a program :raw-html:`<b><tt>` P\ :sub:`p`\; :raw-html:`</tt></b>` that contains a finite (possibly small) number of physical; registers. Each target architecture has a different number of physical; registers.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:60357,Availability,avail,available,60357,"e. Moreover, the class ``MCRegAliasIterator`` enumerates all the physical; registers aliased to a register. Physical registers, in LLVM, are grouped in *Register Classes*. Elements in the; same register class are functionally equivalent, and can be interchangeably; used. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; definition of the ``GR8`` register class in; ``lib/Target/X86/X86RegisterInfo.td`` for an example of this. Virtual registers are also denoted by integer numbers. Contrary to physical; registers, different virtual registers never share the same number. Whereas; physical registers are statically defined in a ``TargetRegisterInfo.td`` file; and cannot be created by the application developer, that is not the case with; virtual registers. In order to create new virtual registers, use the method; ``MachineRegisterInfo::createVirtualRegister()``. This method will return a new; virtual register. Use a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:63786,Availability,alive,alive,63786,"pre-colored; registers: the ones *implicitly* defined, and those *explicitly*; defined. Explicitly defined registers are normal operands, and can be accessed; with ``MachineInstr::getOperand(int)::getReg()``. In order to check which; registers are implicitly defined by an instruction, use the; ``TargetInstrInfo::get(opcode)::ImplicitDefs``, where ``opcode`` is the opcode; of the target instruction. One important difference between explicit and; implicit physical registers is that the latter are defined statically for each; instruction, whereas the former may vary depending on the program being; compiled. For example, an instruction that represents a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64411,Availability,error,error,64411,"ts a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtua",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:72926,Availability,mask,mask,72926,"ction. If we emit compact unwind info for the function, that compact unwind; info will be encoded in the ``__TEXT,__unwind_info`` section. If we emit DWARF; unwind info, the ``__TEXT,__unwind_info`` section will contain the offset of the; FDE in the ``__TEXT,__eh_frame`` section in the final linked image. For X86, there are three modes for the compact unwind encoding:. *Function with a Frame Pointer (``EBP`` or ``RBP``)*; ``EBP/RBP``-based frame, where ``EBP/RBP`` is pushed onto the stack; immediately after the return address, then ``ESP/RSP`` is moved to; ``EBP/RBP``. Thus to unwind, ``ESP/RSP`` is restored with the current; ``EBP/RBP`` value, then ``EBP/RBP`` is restored by popping the stack, and the; return is done by popping the stack once more into the PC. All non-volatile; registers that need to be restored must have been saved in a small range on; the stack that starts ``EBP-4`` to ``EBP-1020`` (``RBP-8`` to; ``RBP-1020``). The offset (divided by 4 in 32-bit mode and 8 in 64-bit mode); is encoded in bits 16-23 (mask: ``0x00FF0000``). The registers saved are; encoded in bits 0-14 (mask: ``0x00007FFF``) as five 3-bit entries from the; following table:. ============== ============= ===============; Compact Number i386 Register x86-64 Register; ============== ============= ===============; 1 ``EBX`` ``RBX``; 2 ``ECX`` ``R12``; 3 ``EDX`` ``R13``; 4 ``EDI`` ``R14``; 5 ``ESI`` ``R15``; 6 ``EBP`` ``RBP``; ============== ============= ===============. *Frameless with a Small Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; To return, a constant (encoded in the compact unwind encoding) is added to the; ``ESP/RSP``. Then the return is done by popping the stack into the PC. All; non-volatile registers that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:72996,Availability,mask,mask,72996,"_unwind_info`` section. If we emit DWARF; unwind info, the ``__TEXT,__unwind_info`` section will contain the offset of the; FDE in the ``__TEXT,__eh_frame`` section in the final linked image. For X86, there are three modes for the compact unwind encoding:. *Function with a Frame Pointer (``EBP`` or ``RBP``)*; ``EBP/RBP``-based frame, where ``EBP/RBP`` is pushed onto the stack; immediately after the return address, then ``ESP/RSP`` is moved to; ``EBP/RBP``. Thus to unwind, ``ESP/RSP`` is restored with the current; ``EBP/RBP`` value, then ``EBP/RBP`` is restored by popping the stack, and the; return is done by popping the stack once more into the PC. All non-volatile; registers that need to be restored must have been saved in a small range on; the stack that starts ``EBP-4`` to ``EBP-1020`` (``RBP-8`` to; ``RBP-1020``). The offset (divided by 4 in 32-bit mode and 8 in 64-bit mode); is encoded in bits 16-23 (mask: ``0x00FF0000``). The registers saved are; encoded in bits 0-14 (mask: ``0x00007FFF``) as five 3-bit entries from the; following table:. ============== ============= ===============; Compact Number i386 Register x86-64 Register; ============== ============= ===============; 1 ``EBX`` ``RBX``; 2 ``ECX`` ``R12``; 3 ``EDX`` ``R13``; 4 ``EDI`` ``R14``; 5 ``ESI`` ``R15``; 6 ``EBP`` ``RBP``; ============== ============= ===============. *Frameless with a Small Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; To return, a constant (encoded in the compact unwind encoding) is added to the; ``ESP/RSP``. Then the return is done by popping the stack into the PC. All; non-volatile registers that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1024 bytes in 32-bit mode; and 2048 in 64-bit mode. The number of registers saved is encoded in bits 9-12; (mask: ``0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:73834,Availability,mask,mask,73834,"P-1020`` (``RBP-8`` to; ``RBP-1020``). The offset (divided by 4 in 32-bit mode and 8 in 64-bit mode); is encoded in bits 16-23 (mask: ``0x00FF0000``). The registers saved are; encoded in bits 0-14 (mask: ``0x00007FFF``) as five 3-bit entries from the; following table:. ============== ============= ===============; Compact Number i386 Register x86-64 Register; ============== ============= ===============; 1 ``EBX`` ``RBX``; 2 ``ECX`` ``R12``; 3 ``EDX`` ``R13``; 4 ``EDI`` ``R14``; 5 ``ESI`` ``R15``; 6 ``EBP`` ``RBP``; ============== ============= ===============. *Frameless with a Small Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; To return, a constant (encoded in the compact unwind encoding) is added to the; ``ESP/RSP``. Then the return is done by popping the stack into the PC. All; non-volatile registers that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1024 bytes in 32-bit mode; and 2048 in 64-bit mode. The number of registers saved is encoded in bits 9-12; (mask: ``0x00001C00``). Bits 0-9 (mask: ``0x000003FF``) contain which; registers were saved and their order. (See the; ``encodeCompactUnwindRegistersWithoutFrame()`` function in; ``lib/Target/X86FrameLowering.cpp`` for the encoding algorithm.). *Frameless with a Large Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; This case is like the ""Frameless with a Small Constant Stack Size"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; ------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:73999,Availability,mask,mask,73999," in bits 0-14 (mask: ``0x00007FFF``) as five 3-bit entries from the; following table:. ============== ============= ===============; Compact Number i386 Register x86-64 Register; ============== ============= ===============; 1 ``EBX`` ``RBX``; 2 ``ECX`` ``R12``; 3 ``EDX`` ``R13``; 4 ``EDI`` ``R14``; 5 ``ESI`` ``R15``; 6 ``EBP`` ``RBP``; ============== ============= ===============. *Frameless with a Small Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; To return, a constant (encoded in the compact unwind encoding) is added to the; ``ESP/RSP``. Then the return is done by popping the stack into the PC. All; non-volatile registers that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1024 bytes in 32-bit mode; and 2048 in 64-bit mode. The number of registers saved is encoded in bits 9-12; (mask: ``0x00001C00``). Bits 0-9 (mask: ``0x000003FF``) contain which; registers were saved and their order. (See the; ``encodeCompactUnwindRegistersWithoutFrame()`` function in; ``lib/Target/X86FrameLowering.cpp`` for the encoding algorithm.). *Frameless with a Large Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; This case is like the ""Frameless with a Small Constant Stack Size"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstracti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:74032,Availability,mask,mask,74032,"le:. ============== ============= ===============; Compact Number i386 Register x86-64 Register; ============== ============= ===============; 1 ``EBX`` ``RBX``; 2 ``ECX`` ``R12``; 3 ``EDX`` ``R13``; 4 ``EDI`` ``R14``; 5 ``ESI`` ``R15``; 6 ``EBP`` ``RBP``; ============== ============= ===============. *Frameless with a Small Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; To return, a constant (encoded in the compact unwind encoding) is added to the; ``ESP/RSP``. Then the return is done by popping the stack into the PC. All; non-volatile registers that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1024 bytes in 32-bit mode; and 2048 in 64-bit mode. The number of registers saved is encoded in bits 9-12; (mask: ``0x00001C00``). Bits 0-9 (mask: ``0x000003FF``) contain which; registers were saved and their order. (See the; ``encodeCompactUnwindRegistersWithoutFrame()`` function in; ``lib/Target/X86FrameLowering.cpp`` for the encoding algorithm.). *Frameless with a Large Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; This case is like the ""Frameless with a Small Constant Stack Size"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:74675,Availability,mask,mask,74675,"sters that need to be restored must have been saved on the; stack immediately after the return address. The stack size (divided by 4 in; 32-bit mode and 8 in 64-bit mode) is encoded in bits 16-23 (mask:; ``0x00FF0000``). There is a maximum stack size of 1024 bytes in 32-bit mode; and 2048 in 64-bit mode. The number of registers saved is encoded in bits 9-12; (mask: ``0x00001C00``). Bits 0-9 (mask: ``0x000003FF``) contain which; registers were saved and their order. (See the; ``encodeCompactUnwindRegistersWithoutFrame()`` function in; ``lib/Target/X86FrameLowering.cpp`` for the encoding algorithm.). *Frameless with a Large Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; This case is like the ""Frameless with a Small Constant Stack Size"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used by the MC layer (`MCInst`_, `MCStreamer`_, etc). This; is done with a combination of several different classes: the (misnamed); target-independent AsmPrinter class, target-specific subclasses of AsmPrinter; (such as SparcAsmPrinter), and the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:75034,Availability,down,down,75034,"2; (mask: ``0x00001C00``). Bits 0-9 (mask: ``0x000003FF``) contain which; registers were saved and their order. (See the; ``encodeCompactUnwindRegistersWithoutFrame()`` function in; ``lib/Target/X86FrameLowering.cpp`` for the encoding algorithm.). *Frameless with a Large Constant Stack Size (``EBP`` or ``RBP`` is not used as a frame pointer)*; This case is like the ""Frameless with a Small Constant Stack Size"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used by the MC layer (`MCInst`_, `MCStreamer`_, etc). This; is done with a combination of several different classes: the (misnamed); target-independent AsmPrinter class, target-specific subclasses of AsmPrinter; (such as SparcAsmPrinter), and the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:78472,Availability,avail,available,78472,"by this are fed into the; instruction printer or the encoder. Finally, at your choosing, you can also implement a subclass of MCCodeEmitter; which lowers MCInst's into machine code bytes and relocations. This is; important if you want to support direct .o file emission, or would like to; implement an assembler for your target. Emitting function stack size information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A section containing metadata on function stack sizes will be emitted when; ``TargetLoweringObjectFile::StackSizesSection`` is not null, and; ``TargetOptions::EmitStackSizeSection`` is set (-stack-size-section). The; section will contain an array of pairs of function symbol values (pointer size); and stack sizes (unsigned LEB128). The stack size values only include the space; allocated in the function prologue. Functions with dynamic stack allocations are; not included. VLIW Packetizer; ---------------. In a Very Long Instruction Word (VLIW) architecture, the compiler is responsible; for mapping instructions to functional-units available on the architecture. To; that end, the compiler creates groups of instructions called *packets* or; *bundles*. The VLIW packetizer in LLVM is a target-independent mechanism to; enable the packetization of machine instructions. Mapping from instructions to functional units; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Instructions in a VLIW target can typically be mapped to multiple functional; units. During the process of packetizing, the compiler must be able to reason; about whether an instruction can be added to a packet. This decision can be; complex since the compiler has to examine all possible mappings of instructions; to functional units. Therefore to alleviate compilation-time complexity, the; VLIW packetizer parses the instruction classes of a target and generates tables; at compiler build time. These tables can then be queried by the provided; machine-independent API to determine if an instruction can be accommodat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81732,Availability,down,down,81732,"zer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : Mnemo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88995,Availability,avail,available,88995,"sed. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, and; includes support for ISA extensions such as MMX and SSE. X86 Target Triples supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following are the known target triples that are supported by the X86; backend. This is not an exhaustive list, and it would be useful to add those; that people test. * **i686-pc-linux-gnu** --- Linux. * **i386-unknown-freebsd5.3** --- FreeBSD 5.3. * **i686-pc-cygwin** --- Cygwin on Win32. * **i686-pc-mingw32** --- MingW on Win32. * **i386-pc-mingw32msvc** --- MingW crosscompiler on Linux. * **i686-apple-darwin*** --- Apple Darwin on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:99894,Availability,avail,available,99894," vararg function,; these register arguments can be spilled into the parameter area. Thus, the; parameter area must be large enough to store all the parameters for the largest; call sequence made by the caller. The size must also be minimally large enough; to spill registers r3-r10. This allows callees blind to the call signature,; such as thunks and vararg functions, enough space to cache the argument; registers. Therefore, the parameter area is minimally 32 bytes (64 bytes in 64; bit mode.) Also note that since the parameter area is a fixed offset from the; top of the frame, that a callee can access its split arguments using fixed; offsets from the stack pointer (or base pointer.). Combining the information about the linkage, parameter areas and alignment. A; stack frame is minimally 64 bytes in 32 bit mode and 128 bytes in 64 bit mode. The *dynamic area* starts out as size zero. If a function uses dynamic alloca; then space is added to the stack, the linkage and parameter areas are shifted to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic space need to observe 16 byte alignment. The *locals area* is where the llvm compiler reserves space for local variables. The *saved registers area* is where the llvm compiler spills callee saved; registers on entry to the callee. Prolog/Epilog; ^^^^^^^^^^^^^. The llvm prolog and epilog are the same as described in the PowerPC ABI, with; the following exceptions. Callee saved registers are spilled after the frame is; created. This allows the llvm epilog/prolog support to be common with other; targets. The base pointer callee saved register r31 is saved in the TOC slot of; linkage area. This simplifies allocation of space for the base pointer an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:4283,Deployability,release,release,4283,"ode generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:9325,Deployability,update,update,9325,"t; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; implementation, and have virtual methods implemented. To get to these; implementations, the :raw-html:`<tt>` `TargetMachine`_ :raw-html:`</tt>` class; provides accessors that should be implemented by the target. .. _TargetMachine:. The ``TargetMachine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92985,Deployability,configurat,configurations,92985,"struction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106811,Deployability,update,update,106811," BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. since x86_64 ABI mandates rdi, rsi, rdx, rcx, r8, r9 for argument passing; and rbx, r12 - r15 are callee saved. Program start; ^^^^^^^^^^^^^. An eBPF program receives a single argument and co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:1965,Energy Efficiency,schedul,scheduling,1965,"r a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:5014,Energy Efficiency,efficient,efficient,5014,"s not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SS",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:5225,Energy Efficiency,efficient,efficient,5225,"kend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-schedul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6229,Energy Efficiency,schedul,scheduling,6229,"to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7085,Energy Efficiency,schedul,scheduling,7085," Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7607,Energy Efficiency,efficient,efficient,7607,"ca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:8712,Energy Efficiency,reduce,reduce,8712," permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract descr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:8984,Energy Efficiency,reduce,reduces,8984,"chitecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:15833,Energy Efficiency,allocate,allocated,15833," ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------------. Target machine instructions are represented as instances of the ``MachineInstr``; class. This class is an extremely abstract way of representing machine; instructions. In particular, it only keeps track of an opcode number and a set; of operands. The opcode number is a simple unsigned integer that only has meaning to a; specific backend. All of the instructions for a target should be defined in the; ``*InstrInfo.td`` file for the target. The opcode enum values are auto-generated; from this description. The ``MachineInstr`` class does not have any information; about how to interpret the instruction (i.e., what the semantics of the; instruction are); for that you must refer to the :raw-html:`<tt>`; `TargetInstrInfo`_ :raw-html:`</tt>` class. The operands of a machine instruction can be of several different types: a; register reference, a constant",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:28666,Energy Efficiency,allocate,allocate,28666,"MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer and TargetRegistry::RegisterMCObjectStreamer; passing callbacks that allocate the corresponding target streamer and pass it; to createAsmStreamer or to the appropriate object streamer constructor. The ``MCContext`` class; -----------------------. The MCContext class is the owner of a variety of uniqued data structures at the; MC layer, including symbols, sections, etc. As such, this is the class that you; interact with to create symbols and sections. This class can not be subclassed. The ``MCSymbol`` class; ----------------------. The MCSymbol class represents a symbol (aka label) in the assembly file. There; are two interesting kinds of symbols: assembler temporary symbols, and normal; symbols. Assembler temporary symbols are used and processed by the assembler; but are discarded when the object file is produced. The distinction is usually; represented by adding a prefix to the label, for example ""L"" labels are; assembler temporary labels in MachO. MCSymbols are created by MCContext and uniqued there. This means that MCSymbols; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:33844,Energy Efficiency,schedul,scheduling,33844,"truction Selection is the process of translating LLVM code presented to the; code generator into target-specific machine instructions. There are several; well-known ways to do this in the literature. LLVM uses a SelectionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:33889,Energy Efficiency,schedul,scheduling,33889,"truction Selection is the process of translating LLVM code presented to the; code generator into target-specific machine instructions. There are several; well-known ways to do this in the literature. LLVM uses a SelectionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34152,Energy Efficiency,efficient,efficiently,34152,"ctionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37326,Energy Efficiency,efficient,efficient,37326," notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:38397,Energy Efficiency,schedul,scheduling,38397,") simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-vie",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39794,Energy Efficiency,schedul,scheduled,39794," names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize Selectio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39836,Energy Efficiency,schedul,scheduling-unit,39836," names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize Selectio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39928,Energy Efficiency,schedul,scheduling,39928," names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize Selectio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:40972,Energy Efficiency,charge,charge,40972,"e of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:42419,Energy Efficiency,charge,charge,42419,"at; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionD",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:43307,Energy Efficiency,efficient,efficient,43307,"_Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionDAG vector operations that; are created from the shufflevector IR. The shufflevector forms that should be; handled include:. * Vector select --- Each element of the vector is chosen from either of the; corresponding elements of the 2 input vectors. This operation may also be; known as a ""blend"" or ""bitwise select"" in target assembly. This type of shuffle; maps directly to the ``shuffle_vector`` SelectionDAG node. * Insert subvector --- A vector is placed into a longer vector type starting; at index 0. This type of shuffle maps directly to the ``insert_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Extract subvector --- A vector is pulled from a longer vector type starting; at index 0. This type of shuffle maps directly to the ``extract_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Splat --- All elements of the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53555,Energy Efficiency,schedul,scheduling,53555,"the future, we will extend pattern fragments to allow them to define multiple; values (e.g. the four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to dete",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53661,Energy Efficiency,schedul,scheduler,53661,"four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:55363,Energy Efficiency,efficient,efficient,55363,"Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the value, but it is never used) and the set of registers; that are used by the instruction, but are never used after the instruction; (i.e., they are killed). Live variable information is computed for; each *virtual* register and *register allocatable* physical register; in the function. This is done in a very efficient manner because it uses SSA to; sparsely compute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a function. Live in values are; typically arguments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:59750,Energy Efficiency,allocate,allocated,59750,"; architecture. For instance, by inspecting; ``lib/Target/X86/X86GenRegisterInfo.inc`` we see that the 32-bit register; ``EAX`` is denoted by 43, and the MMX register ``MM0`` is mapped to 65. Some architectures contain registers that share the same physical location. A; notable example is the X86 platform. For instance, in the X86 architecture, the; registers ``EAX``, ``AX`` and ``AL`` share the first eight bits. These physical; registers are marked as *aliased* in LLVM. Given a particular architecture, you; can check which registers are aliased by inspecting its ``RegisterInfo.td``; file. Moreover, the class ``MCRegAliasIterator`` enumerates all the physical; registers aliased to a register. Physical registers, in LLVM, are grouped in *Register Classes*. Elements in the; same register class are functionally equivalent, and can be interchangeably; used. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; defin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:69490,Energy Efficiency,allocate,allocates,69490,"he register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register allocation. Live; ranges are assigned to registers one at a time in an order that is driven by; heuristics. Since code can be rewritten on-the-fly during allocation, this; framework allows interesting allocators to be developed as extensions. It is; not itself a production register allocator but is a potentially useful; stand-alone mode for triaging bugs and as a performance baseline. * *Greedy* --- *The default allocator*. This is a highly tuned implementation of; the *Basic* allocator that incorporates global live range splitting. This; allocator works hard to minimize the cost of spill code. * *PBQP* --- A Partitioned Boolean Quadratic Programming (PBQP) based register; allocator. This allocator works by constructing a PBQP problem representing; the register allocation problem under consideration, solving this using a PBQP; solver, and mapping the solution back t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:78215,Energy Efficiency,allocate,allocated,78215,"to MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ops used by the code generator into the actual machine instructions they; correspond to. The MCInsts that are generated by this are fed into the; instruction printer or the encoder. Finally, at your choosing, you can also implement a subclass of MCCodeEmitter; which lowers MCInst's into machine code bytes and relocations. This is; important if you want to support direct .o file emission, or would like to; implement an assembler for your target. Emitting function stack size information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A section containing metadata on function stack sizes will be emitted when; ``TargetLoweringObjectFile::StackSizesSection`` is not null, and; ``TargetOptions::EmitStackSizeSection`` is set (-stack-size-section). The; section will contain an array of pairs of function symbol values (pointer size); and stack sizes (unsigned LEB128). The stack size values only include the space; allocated in the function prologue. Functions with dynamic stack allocations are; not included. VLIW Packetizer; ---------------. In a Very Long Instruction Word (VLIW) architecture, the compiler is responsible; for mapping instructions to functional-units available on the architecture. To; that end, the compiler creates groups of instructions called *packets* or; *bundles*. The VLIW packetizer in LLVM is a target-independent mechanism to; enable the packetization of machine instructions. Mapping from instructions to functional units; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Instructions in a VLIW target can typically be mapped to multiple functional; units. During the process of packetizing, the compiler must be able to reason; about whether an instruction can be added to a packet. This decision can be; complex since the compiler has to examine all possible mappings of instructions; to functional units. Therefore to alleviate compilation-time complexity, the; VLIW packetiz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:79905,Energy Efficiency,consumption,consumption,79905,"ing, the compiler must be able to reason; about whether an instruction can be added to a packet. This decision can be; complex since the compiler has to examine all possible mappings of instructions; to functional units. Therefore to alleviate compilation-time complexity, the; VLIW packetizer parses the instruction classes of a target and generates tables; at compiler build time. These tables can then be queried by the provided; machine-independent API to determine if an instruction can be accommodated in a; packet. How the packetization tables are generated and used; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The packetizer reads instruction classes from a target's itineraries and creates; a deterministic finite automaton (DFA) to represent the state of a packet. A DFA; consists of three major elements: inputs, states, and transitions. The set of; inputs for the generated DFA represents the instruction being added to a; packet. The states represent the possible consumption of functional units by; instructions in a packet. In the DFA, transitions from one state to another; occur on the addition of an instruction to an existing packet. If there is a; legal mapping of functional units to instructions, then the DFA contains a; corresponding transition. The absence of a transition indicates that a legal; mapping does not exist and that the instruction cannot be added to the packet. To generate tables for a VLIW target, add *Target*\ GenDFAPacketizer.inc as a; target to the Makefile in the target directory. The exported API provides three; functions: ``DFAPacketizer::clearResources()``,; ``DFAPacketizer::reserveResources(MachineInstr *MI)``, and; ``DFAPacketizer::canReserveResources(MachineInstr *MI)``. These functions allow; a target packetizer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81957,Energy Efficiency,power,powerful,81957,"n. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:84202,Energy Efficiency,power,powerful,84202,"mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 GR32:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr16 GR32:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr8 GR64:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr16 GR64:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr32 GR64:$dst, GR32 :$src)>;. This shows a powerful example of the instruction aliases, matching the same; mnemonic in multiple different ways depending on what operands are present in; the assembly. The result of instruction aliases can include operands in a; different order than the destination instruction, and can use an input multiple; times, for example:. ::. def : InstAlias<""clrb $reg"", (XOR8rr GR8 :$reg, GR8 :$reg)>;; def : InstAlias<""clrw $reg"", (XOR16rr GR16:$reg, GR16:$reg)>;; def : InstAlias<""clrl $reg"", (XOR32rr GR32:$reg, GR32:$reg)>;; def : InstAlias<""clrq $reg"", (XOR64rr GR64:$reg, GR64:$reg)>;. This example also shows that tied operands are only listed once. In the X86; backend, XOR8rr has two input GR8's and one output GR8 (where an input is tied; to the output). InstAliases take a flattened operand list without duplicates; for tied operands. The result of an instruction alias can also use immediates; and fixed physical registers which are added as simple immediate operands in the; result, for example:. ::. // Fixed Immediate operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92377,Energy Efficiency,allocate,allocated,92377,"instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the beh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92673,Energy Efficiency,allocate,allocated,92673,"r their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93320,Energy Efficiency,allocate,allocate,93320,"pace; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX32rm16 -> movsx, 32-bit register, 16-bit memory. The PowerPC backend; -------------------. The PowerPC code generator lives in the lib/Target/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:95749,Energy Efficiency,allocate,allocated,95749,"o provide space to save the frame; pointer in the PowerPC linkage area of the caller frame. Other details of; PowerPC ABI can be found at `PowerPC ABI; <http://developer.apple.com/documentation/DeveloperTools/Conceptual/LowLevelABI/Articles/32bitPowerPC.html>`_\; . Note: This link describes the 32 bit ABI. The 64 bit ABI is similar except; space for GPRs are 8 bytes wide (not 4) and r13 is reserved for system use. Frame Layout; ^^^^^^^^^^^^. The size of a PowerPC frame is usually fixed for the duration of a function's; invocation. Since the frame is fixed size, all references into the frame can be; accessed via fixed offsets from the stack pointer. The exception to this is; when dynamic alloca or variable sized arrays are present, then a base pointer; (r31) is used as a proxy for the stack pointer and stack pointer is free to grow; or shrink. A base pointer is also used if llvm-gcc is not passed the; -fomit-frame-pointer flag. The stack pointer is always aligned to 16 bytes, so; that space allocated for altivec vectors will be properly aligned. An invocation frame is laid out as follows (low memory at top):. :raw-html:`<table border=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<td>Linkage<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Parameter area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Dynamic area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Locals area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Saved registers area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr style=""border-style: none hidden none hidden;"">`; :raw-html:`<td><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Previous Frame<br><br></td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The *linkage* area is used by a callee to save special registers prior to; allocating its own frame. Only three entries are relevant to LLVM. The first; entry is the previous stack pointer (sp), aka link. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:1062,Integrability,interface,interfaces,1062,"======================. .. role:: raw-html(raw); :format: html. .. raw:: html. <style>; .unknown { background-color: #C0C0C0; text-align: center; }; .unknown:before { content: ""?"" }; .no { background-color: #C11B17 }; .no:before { content: ""N"" }; .partial { background-color: #F88017 }; .yes { background-color: #0F0; }; .yes:before { content: ""Y"" }; .na { background-color: #6666FF; }; .na:before { content: ""N/A"" }; </style>. .. contents::; :local:. .. warning::; This is a work in progress. Introduction; ============. The LLVM target-independent code generator is a framework that provides a suite; of reusable components for translating the LLVM internal representation to the; machine code for a specified target---either in assembly form (suitable for a; static compiler) or in binary machine code format (usable for a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description inte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:1194,Integrability,interface,interfaces,1194,"nd-color: #C0C0C0; text-align: center; }; .unknown:before { content: ""?"" }; .no { background-color: #C11B17 }; .no:before { content: ""N"" }; .partial { background-color: #F88017 }; .yes { background-color: #0F0; }; .yes:before { content: ""Y"" }; .na { background-color: #6666FF; }; .na:before { content: ""N/A"" }; </style>. .. contents::; :local:. .. warning::; This is a work in progress. Introduction; ============. The LLVM target-independent code generator is a framework that provides a suite; of reusable components for translating the LLVM internal representation to the; machine code for a specified target---either in assembly form (suitable for a; static compiler) or in binary machine code format (usable for a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:2104,Integrability,interface,interfaces,2104," properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implemen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:2510,Integrability,interface,interface,2510," this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implementing a new `code generation algorithm`_, it should only depend on the; target-description and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:3152,Integrability,depend,depend,3152,"criptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implementing a new `code generation algorithm`_, it should only depend on the; target-description and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:3405,Integrability,interface,interface,3405," completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implementing a new `code generation algorithm`_, it should only depend on the; target-description and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:3549,Integrability,interface,interfaces,3549,"d in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implementing a new `code generation algorithm`_, it should only depend on the; target-description and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:4184,Integrability,interface,interfaces,4184,"tion and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it only implements these; two interfaces, and does its own thing. Note that C backend was removed from the; trunk since LLVM 3.1 release. Another example of a code generator like this is a; (purely hypothetical) backend that converts LLVM to the GCC RTL form and uses; GCC to emit machine code for a target. This design also implies that it is possible to design and implement radically; different code generators in the LLVM system that do not make use of any of the; built-in components. Doing so is not recommended at all, but could be required; for radically different targets that do not fit into the LLVM machine; description model: FPGAs for example. .. _high-level design of the code generator:. The high-level design of the code generator; -------------------------------------------. The LLVM target-independent code generator is designed to support efficient and; quality code generation for standard register-based microprocessors. Code; generation in this model is divided into the following stages:. 1. `Instructio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:9360,Integrability,interface,interface,9360,"t; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractions to reduce the amount of repetition. As LLVM continues to be developed and refined, we plan to move more and more of; the target description to the ``.td`` form. Doing so gives us a number of; advantages. The most important is that it makes it easier to port LLVM because; it reduces the amount of C++ code that has to be written, and the surface area; of the code generator that needs to be understood before someone can get; something working. Second, it makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; implementation, and have virtual methods implemented. To get to these; implementations, the :raw-html:`<tt>` `TargetMachine`_ :raw-html:`</tt>` class; provides accessors that should be implemented by the target. .. _TargetMachine:. The ``TargetMachine",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:10900,Integrability,interface,interfaces,10900,"ieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; implementation, and have virtual methods implemented. To get to these; implementations, the :raw-html:`<tt>` `TargetMachine`_ :raw-html:`</tt>` class; provides accessors that should be implemented by the target. .. _TargetMachine:. The ``TargetMachine`` class; ---------------------------. The ``TargetMachine`` class provides virtual methods that are used to access the; target-specific implementations of the various target description classes via; the ``get*Info`` methods (``getInstrInfo``, ``getRegisterInfo``,; ``getFrameInfo``, etc.). This class is designed to be specialized by a concrete; target implementation (e.g., ``X86TargetMachine``) which implements the various; virtual methods. The only required target description class is the; :raw-html:`<tt>` `DataLayout`_ :raw-html:`</tt>` class, but if the code; generator components are to be used, the other interfaces should be implemented; as well. .. _DataLayout:. The ``DataLayout`` class; ------------------------. The ``DataLayout`` class is the only required target description class, and it; is the only class that is not extensible (you cannot derive a new class from; it). ``DataLayout`` specifies information about how the target lays out memory; for structures, the alignment requirements for various data types, the size of; pointers in the target, and whether the target is little-endian or; big-endian. .. _TargetLowering:. The ``TargetLowering`` class; ----------------------------. The ``TargetLowering`` class is used by SelectionDAG based instruction selectors; primarily to describe how LLVM code should be lowered to SelectionDAG; operations. Among other things, this class indicates:. * an initial register class to use for various ``ValueType``\s,. * which operations are natively supported by the target machine,. * the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14892,Integrability,interface,interface,14892,"he ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:23522,Integrability,depend,dependencies,23522,"blocks). The ``MachineBasicBlock`` class has a ""``getBasicBlock``"" method,; which returns the LLVM basic block that it comes from. .. _MachineFunction:. The ``MachineFunction`` class; -----------------------------. The ``MachineFunction`` class contains a list of machine basic blocks; (:raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>` instances). It; corresponds one-to-one with the LLVM function input to the instruction selector.; In addition to a list of basic blocks, the ``MachineFunction`` contains a; ``MachineConstantPool``, a ``MachineFrameInfo``, a ``MachineFunctionInfo``, and; a ``MachineRegisterInfo``. See ``include/llvm/CodeGen/MachineFunction.h`` for; more information. ``MachineInstr Bundles``; ------------------------. LLVM code generator can model sequences of instructions as MachineInstr; bundles. A MI bundle can model a VLIW group / pack which contains an arbitrary; number of parallel instructions. It can also be used to model a sequential list; of instructions (potentially with data dependencies) that cannot be legally; separated (e.g. ARM Thumb2 IT blocks). Conceptually a MI bundle is a MI with a number of other MIs nested within:. ::. --------------; | Bundle | ---------; -------------- \; | ----------------; | | MI |; | ----------------; | |; | ----------------; | | MI |; | ----------------; | |; | ----------------; | | MI |; | ----------------; |; --------------; | Bundle | --------; -------------- \; | ----------------; | | MI |; | ----------------; | |; | ----------------; | | MI |; | ----------------; | |; | ...; |; --------------; | Bundle | --------; -------------- \; |; ... MI bundle support does not change the physical representations of; MachineBasicBlock and MachineInstr. All the MIs (including top level and nested; ones) are stored as sequential list of MIs. The ""bundled"" MIs are marked with; the 'InsideBundle' flag. A top level MI with the special BUNDLE opcode is used; to represent the start of a bundle. It's legal to mix BUNDLE M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:35355,Integrability,depend,dependencies,35355,"ayload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the node and result value being used,; respectively. Each value produced by an ``SDNode`` has an associated ``MVT``; (Machine Value Type) indicating what the type of the value is. SelectionDAGs contain two different kinds of values: those that represent data; flow and those that represent control flow dependencies. Data values are simple; edges with an integer or floating point value type. Control edges are; represented as ""chain"" edges which are of type ``MVT::Other``. These edges; provide an ordering between nodes that have side effects (such as loads, stores,; calls, returns, etc). All nodes that have side effects should take a token; chain as input and produce a new one as output. By convention, token chain; inputs are always operand #0, and chain results are always the last value; produced by an operation. However, after instruction selection, the; machine nodes have their chain after the instruction's operands, and; may be followed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39704,Integrability,depend,dependency,39704,"g info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; vararg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:40773,Integrability,interface,interface,40773," on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45482,Integrability,depend,depend,45482,"ctor length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53689,Integrability,depend,depending,53689,"four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:63298,Integrability,depend,depending,63298,"operand, the method; ``MachineOperand::isUse()`` informs if that register is being used by the; instruction. The method ``MachineOperand::isDef()`` informs if that registers is; being defined. We will call physical registers present in the LLVM bitcode before register; allocation *pre-colored registers*. Pre-colored registers are used in many; different situations, for instance, to pass parameters of functions calls, and; to store results of particular instructions. There are two types of pre-colored; registers: the ones *implicitly* defined, and those *explicitly*; defined. Explicitly defined registers are normal operands, and can be accessed; with ``MachineInstr::getOperand(int)::getReg()``. In order to check which; registers are implicitly defined by an instruction, use the; ``TargetInstrInfo::get(opcode)::ImplicitDefs``, where ``opcode`` is the opcode; of the target instruction. One important difference between explicit and; implicit physical registers is that the latter are defined statically for each; instruction, whereas the former may vary depending on the program being; compiled. For example, an instruction that represents a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to inser",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:76293,Integrability,rout,routines,76293," the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of the lowering for free if you are; implementing an ELF, COFF, or MachO target, because the; TargetLoweringObjectFile class implements much of the common logic. #. Second, you need to implement an instruction printer for your target. The; instruction printer takes an `MCInst`_ and renders it to a raw_ostream as; text. Most of this is automatically generated from the .td file (when you; specify something like ""``add $dst, $src1, $src2``"" in the instructions), but; you need to implement routines to print operands. #. Third, you need to implement code that lowers a `MachineInstr`_ to an MCInst,; usually implemented in ""<target>MCInstLower.cpp"". This lowering process is; often target specific, and is responsible for turning jump table entries,; constant pool indices, global variable addresses, etc into MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:76892,Integrability,rout,routines,76892,", etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of the lowering for free if you are; implementing an ELF, COFF, or MachO target, because the; TargetLoweringObjectFile class implements much of the common logic. #. Second, you need to implement an instruction printer for your target. The; instruction printer takes an `MCInst`_ and renders it to a raw_ostream as; text. Most of this is automatically generated from the .td file (when you; specify something like ""``add $dst, $src1, $src2``"" in the instructions), but; you need to implement routines to print operands. #. Third, you need to implement code that lowers a `MachineInstr`_ to an MCInst,; usually implemented in ""<target>MCInstLower.cpp"". This lowering process is; often target specific, and is responsible for turning jump table entries,; constant pool indices, global variable addresses, etc into MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ops used by the code generator into the actual machine instructions they; correspond to. The MCInsts that are generated by this are fed into the; instruction printer or the encoder. Finally, at your choosing, you can also implement a subclass of MCCodeEmitter; which lowers MCInst's into machine code bytes and relocations. This is; important if you want to support direct .o file emission, or would like to; implement an assembler for your target. Emitting function stack size information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A section ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:83008,Integrability,depend,depend,83008,"alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32BitMode]>;. In this example, the mnemonic gets mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 GR32:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr16 GR32:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:83301,Integrability,depend,depending,83301,"nt mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32BitMode]>;. In this example, the mnemonic gets mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 GR32:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr16 GR32:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr8 GR64:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr16 GR64:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr32 GR64:$dst, GR32 :$src)>;. This shows a powerful example of the instruction aliases, matching the same; mnemonic in multiple dif",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:84302,Integrability,depend,depending,84302,"mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 GR32:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr16 GR32:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr8 GR64:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr16 GR64:$dst, GR16 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr32 GR64:$dst, GR32 :$src)>;. This shows a powerful example of the instruction aliases, matching the same; mnemonic in multiple different ways depending on what operands are present in; the assembly. The result of instruction aliases can include operands in a; different order than the destination instruction, and can use an input multiple; times, for example:. ::. def : InstAlias<""clrb $reg"", (XOR8rr GR8 :$reg, GR8 :$reg)>;; def : InstAlias<""clrw $reg"", (XOR16rr GR16:$reg, GR16:$reg)>;; def : InstAlias<""clrl $reg"", (XOR32rr GR32:$reg, GR32:$reg)>;; def : InstAlias<""clrq $reg"", (XOR64rr GR64:$reg, GR64:$reg)>;. This example also shows that tied operands are only listed once. In the X86; backend, XOR8rr has two input GR8's and one output GR8 (where an input is tied; to the output). InstAliases take a flattened operand list without duplicates; for tied operands. The result of an instruction alias can also use immediates; and fixed physical registers which are added as simple immediate operands in the; result, for example:. ::. // Fixed Immediate operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:85908,Integrability,interface,interfaces,85908,"s and one output GR8 (where an input is tied; to the output). InstAliases take a flattened operand list without duplicates; for tied operands. The result of an instruction alias can also use immediates; and fixed physical registers which are added as simple immediate operands in the; result, for example:. ::. // Fixed Immediate operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixed register operand.; def : InstAlias<""fcomi"", (COM_FIr ST1)>;. // Simple alias.; def : InstAlias<""fcomi $reg"", (COM_FIr RST:$reg)>;. Instruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument li",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93414,Integrability,depend,depends,93414,"o TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX32rm16 -> movsx, 32-bit register, 16-bit memory. The PowerPC backend; -------------------. The PowerPC code generator lives in the lib/Target/PowerPC directory. The code; generation is retargetable to several variations or *subtargets* of the PowerPC; ISA; including ppc32, ppc64 and altivec. LLVM PowerPC ABI; ^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:107843,Integrability,rout,routine,107843,". eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. since x86_64 ABI mandates rdi, rsi, rdx, rcx, r8, r9 for argument passing; and rbx, r12 - r15 are callee saved. Program start; ^^^^^^^^^^^^^. An eBPF program receives a single argument and contains; a single eBPF main routine; the program does not contain eBPF functions.; Function calls are limited to a predefined set of kernel functions. The size; of a program is limited to 4K instructions: this ensures fast termination and; a limited number of kernel function calls. Prior to running an eBPF program,; a verifier performs static analysis to prevent loops in the code and; to ensure valid register usage and operand types. The AMDGPU backend; ------------------. The AMDGPU code generator lives in the ``lib/Target/AMDGPU``; directory. This code generator is capable of targeting a variety of; AMD GPU processors. Refer to :doc:`AMDGPUUsage` for more information.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:3248,Modifiability,portab,portable,3248,"criptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; target-specific issues. The code for the target-independent JIT lives in; ``lib/ExecutionEngine/JIT``. Depending on which part of the code generator you are interested in working on,; different pieces of this will be useful to you. In any case, you should be; familiar with the `target description`_ and `machine code representation`_; classes. If you want to add a backend for a new target, you will need to; `implement the target description`_ classes for your new target and understand; the :doc:`LLVM code representation <LangRef>`. If you are interested in; implementing a new `code generation algorithm`_, it should only depend on the; target-description and machine code representation classes, ensuring that it is; portable. Required components in the code generator; -----------------------------------------. The two pieces of the LLVM code generator are the high-level interface to the; code generator and the set of reusable components that can be used to build; target-specific backends. The two most important interfaces (:raw-html:`<tt>`; `TargetMachine`_ :raw-html:`</tt>` and :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>`) are the only ones that are required to be defined for a; backend to fit into the LLVM system, but the others must be defined if the; reusable code generator components are going to be used. This design has two important implications. The first is that LLVM can support; completely non-traditional code generation targets. For example, the C backend; does not require register allocation, instruction selection, or any of the other; standard components provided by the system. As such, it on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14366,Modifiability,variab,variables,14366,"the set. The target-specific implementations of these classes is auto-generated from a; :doc:`TableGen/index` description of the register file. .. _TargetInstrInfo:. The ``TargetInstrInfo`` class; -----------------------------. The ``TargetInstrInfo`` class is used to describe the machine instructions; supported by the target. Descriptions define things like the mnemonic for; the opcode, the number of operands, the list of implicit register uses and defs,; whether the instruction has certain target-independent properties (accesses; memory, is commutable, etc), and holds any target-specific flags. The ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:20227,Modifiability,extend,extend,20227,"; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One important issue that the code generator needs to be aware of is the presence; of fixed registers. In particular, there are often places in the instruction; stream where the register allocator *must* arrange for a particular value to be; in a particular register. This can occur due to limitations of the instruction; set (e.g., the X86 can only do a 32-bit divide with the ``EAX``/``EDX``; registers), or external factors like calling conventions. In any case, the; instruction selector should emit code that copies a virtual register into or out; of a physical register when needed. For example, consider this simple LLVM example:. .. code-block:: llvm. define i32 @test(i32 %X, i32 %Y) {; %Z = sdiv i32 %X, %Y; ret i32 %Z; }. The X86 instruction selector might produce this machine code for the ``div`` and; ``ret``:. .. code-block:: text. ;; Start of div; %EAX = mov %reg1024 ;; Copy X (in reg1024) into EAX; %reg1027 = sar %reg1024, 31; %EDX = mov %reg1027 ;; Sign extend X into EDX; idiv %reg1025 ;; Divide by Y (in reg1025); %reg1026 = mov %EAX ;; Read the result (Z) out of EAX. ;; Start of ret; %EAX = mov %reg1026 ;; 32-bit return value goes in EAX; ret. By the end of code generation, the register allocator would coalesce the; registers and delete the resultant identity moves producing the following; code:. .. code-block:: text. ;; X is in EAX, Y is in ECX; mov %EAX, %EDX; sar %EDX, 31; idiv %ECX; ret. This approach is extremely general (if it can handle the X86 architecture, it; can handle anything!) and allows all of the target specific knowledge about the; instruction stream to be isolated in the instruction selector. Note that; physical registers should have a short lifetime for good code generation, and; all physical registers are assumed dead on entry to and exit from basic blocks; (before register allocation). Thus, if you need a value to be live across basic; block boundaries, it *must* live in a virtual register. Call-clobbered r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:26200,Modifiability,variab,variables,26200,"Operand's that represent the cumulative inputs and outputs of; the bundled MIs. Packing / bundling of MachineInstrs for VLIW architectures should; generally be done as part of the register allocation super-pass. More; specifically, the pass which determines what MIs should be bundled; together should be done after code generator exits SSA form; (i.e. after two-address pass, PHI elimination, and copy coalescing).; Such bundles should be finalized (i.e. adding BUNDLE MIs and input and; output register MachineOperands) after virtual registers have been; rewritten into physical registers. This eliminates the need to add; virtual register operands to BUNDLE instructions which would; effectively double the virtual register def and use lists. Bundles may; use virtual registers and be formed in SSA form, but may not be; appropriate for all use cases. .. _MC Layer:. The ""MC"" Layer; ==============. The MC Layer is used to represent and process code at the raw machine code; level, devoid of ""high level"" information like ""constant pools"", ""jump tables"",; ""global variables"" or anything like that. At this level, LLVM handles things; like label names, machine instructions, and sections in the object file. The; code in this layer is used for a number of important purposes: the tail end of; the code generator uses it to write a .s or .o file, and it is also used by the; llvm-mc tool to implement standalone machine code assemblers and disassemblers. This section describes some of the important classes. There are also a number; of important subsystems that interact at this layer, they are described later in; this manual. .. _MCStreamer:. The ``MCStreamer`` API; ----------------------. MCStreamer is best thought of as an assembler API. It is an abstract API which; is *implemented* in different ways (e.g. to output a .s file, output an ELF .o; file, etc) but whose API correspond directly to what you see in a .s file.; MCStreamer has one method per directive, such as EmitLabel, EmitSymbol",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:28180,Modifiability,inherit,inherits,28180,"ectives. It also has an EmitInstruction method, which is used; to output an MCInst to the streamer. This API is most important for two clients: the llvm-mc stand-alone assembler is; effectively a parser that parses a line, then invokes a method on MCStreamer. In; the code generator, the `Code Emission`_ phase of the code generator lowers; higher level LLVM IR and Machine* constructs down to the MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer and TargetRegistry::RegisterMCObjectStreamer; passing callbacks that allocate the corresponding target streamer and pass it; to createAsmStreamer or to the appropriate object streamer constructor. The ``MCContext`` class; -----------------------. The MCContext class is the owner of a variety of uniqued data structures at the; MC layer, including symbols, sections, etc. As such, this is the class that you; interact with to create symbols and sections. This class can not be subclassed. The ``MCSymbol`` class; ----------------------. The MCSymbol class represents a symbol (aka label) in the assembly file. There; are two interesting kinds of s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:28289,Modifiability,inherit,inherit,28289,"ectives. It also has an EmitInstruction method, which is used; to output an MCInst to the streamer. This API is most important for two clients: the llvm-mc stand-alone assembler is; effectively a parser that parses a line, then invokes a method on MCStreamer. In; the code generator, the `Code Emission`_ phase of the code generator lowers; higher level LLVM IR and Machine* constructs down to the MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer and TargetRegistry::RegisterMCObjectStreamer; passing callbacks that allocate the corresponding target streamer and pass it; to createAsmStreamer or to the appropriate object streamer constructor. The ``MCContext`` class; -----------------------. The MCContext class is the owner of a variety of uniqued data structures at the; MC layer, including symbols, sections, etc. As such, this is the class that you; interact with to create symbols and sections. This class can not be subclassed. The ``MCSymbol`` class; ----------------------. The MCSymbol class represents a symbol (aka label) in the assembly file. There; are two interesting kinds of s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39169,Modifiability,config,configure,39169,"-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:41832,Modifiability,extend,extending,41832,"used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:42708,Modifiability,extend,extending,42708,"nsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionDAG vector operations that; are created from the shufflevector IR. The shufflevector forms that should be; handled include:. * Vector select --- Each element of the vector is chosen from either of the; corresponding elements of the 2 inpu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:48918,Modifiability,extend,extended,48918," ""fmadds $FRT, $FRA, $FRC, $FRB"",; [(set F4RC:$FRT, (fadd (fmul F4RC:$FRA, F4RC:$FRC),; F4RC:$FRB))]>;; def FADDS : AForm_2<59, 21,; (ops F4RC:$FRT, F4RC:$FRA, F4RC:$FRB),; ""fadds $FRT, $FRA, $FRB"",; [(set F4RC:$FRT, (fadd F4RC:$FRA, F4RC:$FRB))]>;. The highlighted portion of the instruction definitions indicates the pattern; used to match the instructions. The DAG operators (like ``fmul``/``fadd``); are defined in the ``include/llvm/Target/TargetSelectionDAG.td`` file.; ""``F4RC``"" is the register class of the input and result values. The TableGen DAG instruction selector generator reads the instruction patterns; in the ``.td`` file and automatically builds parts of the pattern matching code; for your target. It has the following strengths:. * At compiler-compile time, it analyzes your instruction patterns and tells you; if your patterns make sense or not. * It can handle arbitrary constraints on operands for the pattern match. In; particular, it is straight-forward to say things like ""match any immediate; that is a 13-bit sign-extended value"". For examples, see the ``immSExt16``; and related ``tblgen`` classes in the PowerPC backend. * It knows several important identities for the patterns defined. For example,; it knows that addition is commutative, so it allows the ``FMADDS`` pattern; above to match ""``(fadd X, (fmul Y, Z))``"" as well as ""``(fadd (fmul X, Y),; Z)``"", without the target author having to specially handle this case. * It has a full-featured type-inferencing system. In particular, you should; rarely have to explicitly tell the system what type parts of your patterns; are. In the ``FMADDS`` case above, we didn't have to tell ``tblgen`` that all; of the nodes in the pattern are of type 'f32'. It was able to infer and; propagate this knowledge from the fact that ``F4RC`` has type 'f32'. * Targets can define their own (and rely on built-in) ""pattern fragments"".; Pattern fragments are chunks of reusable patterns that get inlined into your; patterns during ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:52623,Modifiability,extend,extend,52623,"gConstraint<""$dst.reg = $ea_res"">, NoEncode<""$ea_res"">;. def : Pat<(pre_store GPRC:$rS, ptr_rc:$ptrreg, iaddroff:$ptroff),; (STWU GPRC:$rS, iaddroff:$ptroff, ptr_rc:$ptrreg)>;. Here, the pair of ``ptroff`` and ``ptrreg`` operands is matched onto the; complex operand ``dst`` of class ``memri`` in the ``STWU`` instruction. * While the system does automate a lot, it still allows you to write custom C++; code to match special cases if there is something that is hard to; express. While it has many strengths, the system currently has some limitations,; primarily because it is a work in progress and is not yet finished:. * Overall, there is no way to define or match SelectionDAG nodes that define; multiple values (e.g. ``SMUL_LOHI``, ``LOAD``, ``CALL``, etc). This is the; biggest reason that you currently still *have to* write custom C++ code; for your instruction selector. * There is no great way to support matching complex addressing modes yet. In; the future, we will extend pattern fragments to allow them to define multiple; values (e.g. the four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assign",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:52815,Modifiability,extend,extend,52815,"ptroff`` and ``ptrreg`` operands is matched onto the; complex operand ``dst`` of class ``memri`` in the ``STWU`` instruction. * While the system does automate a lot, it still allows you to write custom C++; code to match special cases if there is something that is hard to; express. While it has many strengths, the system currently has some limitations,; primarily because it is a work in progress and is not yet finished:. * Overall, there is no way to define or match SelectionDAG nodes that define; multiple values (e.g. ``SMUL_LOHI``, ``LOAD``, ``CALL``, etc). This is the; biggest reason that you currently still *have to* write custom C++ code; for your instruction selector. * There is no great way to support matching complex addressing modes yet. In; the future, we will extend pattern fragments to allow them to define multiple; values (e.g. the four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is esta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:54524,Modifiability,variab,variable,54524,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the value, but it is never used) and the set of registers; that are used by the instruction, but are never used after the instruction; (i.e., they are killed). Live variable information is computed for; each *virtual* register and *register allocatable* physical register; in the function. This is done in a very efficient manner because it uses SSA to; sparsely compute lifetime information for virtual registers (which are in SSA; form) and only has to tra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:54919,Modifiability,variab,variables,54919,"d; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the value, but it is never used) and the set of registers; that are used by the instruction, but are never used after the instruction; (i.e., they are killed). Live variable information is computed for; each *virtual* register and *register allocatable* physical register; in the function. This is done in a very efficient manner because it uses SSA to; sparsely compute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a functio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:55215,Modifiability,variab,variable,55215,"ntire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the value, but it is never used) and the set of registers; that are used by the instruction, but are never used after the instruction; (i.e., they are killed). Live variable information is computed for; each *virtual* register and *register allocatable* physical register; in the function. This is done in a very efficient manner because it uses SSA to; sparsely compute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a function. Live in values are; typically arguments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:56372,Modifiability,variab,variable,56372,"ute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a function. Live in values are; typically arguments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:56962,Modifiability,variab,variable,56962,"ments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These are in; physical registers, so the physical register is assumed to be killed by the end; of the basic block. Live intervals for virtual registers are computed for some; ordering of the machine instructions ``[1, N]``. A live interval is an interval; ``[i, j)``, where ``1 >= i >= j > N``, for which a variable is live. .. note::; More to come... .. _Register Allocation:; .. _register allocator:. Register Allocation; -------------------. The *Register Allocation problem* consists in mapping a program; :raw-html:`<b><tt>` P\ :sub:`v`\ :raw-html:`</tt></b>`, tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:57717,Modifiability,variab,variable,57717,"I`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These are in; physical registers, so the physical register is assumed to be killed by the end; of the basic block. Live intervals for virtual registers are computed for some; ordering of the machine instructions ``[1, N]``. A live interval is an interval; ``[i, j)``, where ``1 >= i >= j > N``, for which a variable is live. .. note::; More to come... .. _Register Allocation:; .. _register allocator:. Register Allocation; -------------------. The *Register Allocation problem* consists in mapping a program; :raw-html:`<b><tt>` P\ :sub:`v`\ :raw-html:`</tt></b>`, that can use an unbounded; number of virtual registers, to a program :raw-html:`<b><tt>` P\ :sub:`p`\; :raw-html:`</tt></b>` that contains a finite (possibly small) number of physical; registers. Each target architecture has a different number of physical; registers. If the number of physical registers is not enough to accommodate all; the virtual registers, some of them will have to be mapped into memory. These; virtuals are called *spilled virtuals*. How registers are represented in LLVM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, physical registers are denoted by integer numbers that normally range; from 1 to 1023. To see how this numbering is defined for a particular; architecture, you can ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:75456,Modifiability,variab,variables,75456,"ze"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used by the MC layer (`MCInst`_, `MCStreamer`_, etc). This; is done with a combination of several different classes: the (misnamed); target-independent AsmPrinter class, target-specific subclasses of AsmPrinter; (such as SparcAsmPrinter), and the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:77183,Modifiability,variab,variable,77183," general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of the lowering for free if you are; implementing an ELF, COFF, or MachO target, because the; TargetLoweringObjectFile class implements much of the common logic. #. Second, you need to implement an instruction printer for your target. The; instruction printer takes an `MCInst`_ and renders it to a raw_ostream as; text. Most of this is automatically generated from the .td file (when you; specify something like ""``add $dst, $src1, $src2``"" in the instructions), but; you need to implement routines to print operands. #. Third, you need to implement code that lowers a `MachineInstr`_ to an MCInst,; usually implemented in ""<target>MCInstLower.cpp"". This lowering process is; often target specific, and is responsible for turning jump table entries,; constant pool indices, global variable addresses, etc into MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ops used by the code generator into the actual machine instructions they; correspond to. The MCInsts that are generated by this are fed into the; instruction printer or the encoder. Finally, at your choosing, you can also implement a subclass of MCCodeEmitter; which lowers MCInst's into machine code bytes and relocations. This is; important if you want to support direct .o file emission, or would like to; implement an assembler for your target. Emitting function stack size information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A section containing metadata on function stack sizes will be emitted when; ``TargetLoweringObjectFile::StackSizesSection`` is not null, and; ``TargetOptions::EmitStackSizeSection`` is set (-stack-size-section). The; section will contain an array of pairs of function symbol values (pointer size); and stack ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86869,Modifiability,variab,variable,86869,"stract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87046,Modifiability,variab,variable,87046,"ument explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87240,Modifiability,variab,variable,87240,"timization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimizat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87453,Modifiability,variab,variable,87453,"calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:90762,Modifiability,flexible,flexible,90762,"* **i386-unknown-freebsd5.3** --- FreeBSD 5.3. * **i686-pc-cygwin** --- Cygwin on Win32. * **i686-pc-mingw32** --- MingW on Win32. * **i386-pc-mingw32msvc** --- MingW crosscompiler on Linux. * **i686-apple-darwin*** --- Apple Darwin on X86. * **x86_64-unknown-linux-gnu** --- Linux. X86 Calling Conventions supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following target-specific calling conventions are known to backend:. * **x86_StdCall** --- stdcall calling convention seen on Microsoft Windows; platform (CC ID = 64). * **x86_FastCall** --- fastcall calling convention seen on Microsoft Windows; platform (CC ID = 65). * **x86_ThisCall** --- Similar to X86_StdCall. Passes first argument in ECX,; others via stack. Callee is responsible for stack cleaning. This convention is; used by MSVC by default for methods in its ABI (CC ID = 70). .. _X86 addressing mode:. Representing X86 addressing modes in MachineInstrs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The x86 has a very flexible way of accessing memory. It is capable of forming; memory addresses of the following expression directly in integer instructions; (which use ModR/M addressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the abi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92628,Modifiability,variab,variables,92628,"r their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92757,Modifiability,variab,variables,92757,"perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92985,Modifiability,config,configurations,92985,"struction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93269,Modifiability,variab,variables,93269,"pace; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX32rm16 -> movsx, 32-bit register, 16-bit memory. The PowerPC backend; -------------------. The PowerPC code generator lives in the lib/Target/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:95450,Modifiability,variab,variable,95450,"h two deviations. LLVM uses a PC relative; (PIC) or static addressing for accessing global values, so no TOC (r2) is; used. Second, r31 is used as a frame pointer to allow dynamic growth of a stack; frame. LLVM takes advantage of having no TOC to provide space to save the frame; pointer in the PowerPC linkage area of the caller frame. Other details of; PowerPC ABI can be found at `PowerPC ABI; <http://developer.apple.com/documentation/DeveloperTools/Conceptual/LowLevelABI/Articles/32bitPowerPC.html>`_\; . Note: This link describes the 32 bit ABI. The 64 bit ABI is similar except; space for GPRs are 8 bytes wide (not 4) and r13 is reserved for system use. Frame Layout; ^^^^^^^^^^^^. The size of a PowerPC frame is usually fixed for the duration of a function's; invocation. Since the frame is fixed size, all references into the frame can be; accessed via fixed offsets from the stack pointer. The exception to this is; when dynamic alloca or variable sized arrays are present, then a base pointer; (r31) is used as a proxy for the stack pointer and stack pointer is free to grow; or shrink. A base pointer is also used if llvm-gcc is not passed the; -fomit-frame-pointer flag. The stack pointer is always aligned to 16 bytes, so; that space allocated for altivec vectors will be properly aligned. An invocation frame is laid out as follows (low memory at top):. :raw-html:`<table border=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<td>Linkage<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Parameter area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Dynamic area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Locals area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Saved registers area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr style=""border-style: none hidden none hidden;"">`; :raw-html:`<td><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Previous Frame<br><br></td>`; :ra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:100307,Modifiability,variab,variables,100307,"the parameter area is minimally 32 bytes (64 bytes in 64; bit mode.) Also note that since the parameter area is a fixed offset from the; top of the frame, that a callee can access its split arguments using fixed; offsets from the stack pointer (or base pointer.). Combining the information about the linkage, parameter areas and alignment. A; stack frame is minimally 64 bytes in 32 bit mode and 128 bytes in 64 bit mode. The *dynamic area* starts out as size zero. If a function uses dynamic alloca; then space is added to the stack, the linkage and parameter areas are shifted to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic space need to observe 16 byte alignment. The *locals area* is where the llvm compiler reserves space for local variables. The *saved registers area* is where the llvm compiler spills callee saved; registers on entry to the callee. Prolog/Epilog; ^^^^^^^^^^^^^. The llvm prolog and epilog are the same as described in the PowerPC ABI, with; the following exceptions. Callee saved registers are spilled after the frame is; created. This allows the llvm epilog/prolog support to be common with other; targets. The base pointer callee saved register r31 is saved in the TOC slot of; linkage area. This simplifies allocation of space for the base pointer and; makes it convenient to locate programmatically and during debugging. Dynamic Allocation; ^^^^^^^^^^^^^^^^^^. .. note::. TODO - More to come. The NVPTX backend; -----------------. The NVPTX code generator under lib/Target/NVPTX is an open-source version of; the NVIDIA NVPTX code generator for LLVM. It is contributed by NVIDIA and is; a port of the code generator used in the CUDA compiler (nvcc). It targets the; PTX 3.0/3.1 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102469,Modifiability,extend,extended,102469,"r=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<th>Option</th>`; :raw-html:`<th>Description</th>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_20</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 2.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_21</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:104494,Modifiability,extend,extended,104494,"eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:104661,Modifiability,extend,extended,104661,"eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6121,Performance,optimiz,optimizations,6121,"tion in this model is divided into the following stages:. 1. `Instruction Selection`_ --- This phase determines an efficient way to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6253,Performance,optimiz,optimization,6253,"to; express the input LLVM code in the target instruction set. This stage; produces the initial code for the program in the target instruction set, then; makes use of virtual registers in SSA form and physical registers that; represent any required register assignments due to target constraints or; calling conventions. This step turns the LLVM code into a DAG of target; instructions. 2. `Scheduling and Formation`_ --- This phase takes the DAG of target; instructions produced by the instruction selection phase, determines an; ordering of the instructions, then emits the instructions as :raw-html:`<tt>`; `MachineInstr`_\s :raw-html:`</tt>` with that ordering. Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:6894,Performance,optimiz,optimizations,6894,". Note that we; describe this in the `instruction selection section`_ because it operates on; a `SelectionDAG`_. 3. `SSA-based Machine Code Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7110,Performance,optimiz,optimizations,7110," Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7556,Performance,optimiz,optimization,7556," from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7678,Performance,optimiz,optimization,7678,"ca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored out, the LLVM code generator uses the; :doc:`TableGen/index` tool to describe big chunks of the; target machine, which allows the use of domain-specific and target-specific; abstractio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14946,Performance,perform,perform,14946,"he ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34052,Performance,optimiz,optimizations,34052,"ctionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34076,Performance,perform,performed,34076,"ctionDAG based; instruction selector. Portions of the DAG instruction selector are generated from the target; description (``*.td``) files. Our goal is for the entire instruction selector; to be generated from these ``.td`` files, though currently there are still; things that require custom C++ code. `GlobalISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:34395,Performance,perform,performs,34395,"lISel <https://llvm.org/docs/GlobalISel/index.html>`_ is another; instruction selection framework. .. _SelectionDAG:. Introduction to SelectionDAGs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG provides an abstraction for code representation in a way that; is amenable to instruction selection using automatic techniques; (e.g. dynamic-programming based optimal pattern matching selectors). It is also; well-suited to other phases of code generation; in particular, instruction; scheduling (SelectionDAG's are very close to scheduling DAGs post-selection).; Additionally, the SelectionDAG provides a host representation where a large; variety of very-low-level (but target-independent) `optimizations`_ may be; performed; ones which require extensive information about the instructions; efficiently supported by the target. The SelectionDAG is a Directed-Acyclic-Graph whose nodes are instances of the; ``SDNode`` class. The primary payload of the ``SDNode`` is its operation code; (Opcode) that indicates what operation the node performs and the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the node and result value being used,; respectively. Each value produced by an ``SDNode`` has an associated ``MVT``; (Machine Value Type) indicating what the type of the value is. SelectionDAGs contain two different kinds of values: those that represent data; flow and those that represent control flow depende",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:35606,Performance,load,loads,35606,"single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the node and result value being used,; respectively. Each value produced by an ``SDNode`` has an associated ``MVT``; (Machine Value Type) indicating what the type of the value is. SelectionDAGs contain two different kinds of values: those that represent data; flow and those that represent control flow dependencies. Data values are simple; edges with an integer or floating point value type. Control edges are; represented as ""chain"" edges which are of type ``MVT::Other``. These edges; provide an ordering between nodes that have side effects (such as loads, stores,; calls, returns, etc). All nodes that have side effects should take a token; chain as input and produce a new one as output. By convention, token chain; inputs are always operand #0, and chain results are always the last value; produced by an operation. However, after instruction selection, the; machine nodes have their chain after the instruction's operands, and; may be followed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:36974,Performance,perform,performs,36974,"llowed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37101,Performance,perform,performs,37101,"e final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `Sele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37117,Performance,optimiz,optimizations,37117,"e final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `Sele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37588,Performance,optimiz,optimizer,37588,"a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37852,Performance,optimiz,optimizer,37852,"AG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39363,Performance,optimiz,optimization,39363,"MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:39511,Performance,optimiz,optimization,39511,"d and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using ``-debug-only=isel``,; which prints out the DAG, along with other information like debug info,; after each of these steps. Alternatively, ``-debug-only=isel-dump`` shows only; the DAG dumps, but the results can be filtered by function names using; ``-filter-print-funcs=<function names>``. One great way to visualize what is going on here is to take advantage of a few; LLC command line options. The following options pop up a window displaying the; SelectionDAG at specific times (if you only get errors printed to the console; while using this, you probably `need to configure your; system <ProgrammersManual.html#viewing-graphs-while-debugging-code>`_ to add support for it). * ``-view-dag-combine1-dags`` displays the DAG after being built, before the; first optimization pass. * ``-view-legalize-dags`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:42718,Performance,load,loads,42718,"nsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by open-coding another sequence of operations to; emulate the operation (""expansion""), by promoting one type to a larger type that; supports the operation (""promotion""), or by using a target-specific hook to; implement the legalization (""custom""). A target implementation tells the legalizer which operations are not supported; (and which of the above three actions to take) by calling the; ``setOperationAction`` method in its ``TargetLowering`` constructor. If a target has legal vector types, it is expected to produce efficient machine; code for common forms of the shufflevector IR instruction using those types.; This may require custom legalization for SelectionDAG vector operations that; are created from the shufflevector IR. The shufflevector forms that should be; handled include:. * Vector select --- Each element of the vector is chosen from either of the; corresponding elements of the 2 inpu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:44989,Performance,optimiz,optimize,44989,"dex 0. This type of shuffle maps directly to the ``insert_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Extract subvector --- A vector is pulled from a longer vector type starting; at index 0. This type of shuffle maps directly to the ``extract_subvector``; SelectionDAG node with the ``index`` operand set to 0. * Splat --- All elements of the vector have identical scalar elements. This; operation may also be known as a ""broadcast"" or ""duplicate"" in target assembly.; The shufflevector IR instruction may change the vector length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techni",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45245,Performance,optimiz,optimization,45245,"- All elements of the vector have identical scalar elements. This; operation may also be known as a ""broadcast"" or ""duplicate"" in target assembly.; The shufflevector IR instruction may change the vector length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45451,Performance,perform,performing,45451,"ctor length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45463,Performance,optimiz,optimizations,45463,"ctor length, so this operation; may map to multiple SelectionDAG nodes including ``shuffle_vector``,; ``concat_vectors``, ``insert_subvector``, and ``extract_subvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45794,Performance,optimiz,optimizations,45794,"ot; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design; and Implementation. .. _Select instructions from DAG:. SelectionDAG Select Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^. The Select phase is the bulk of the target-specific code for instruction; selection. This phase takes a legal SelectionDAG as input, pattern matches the; instructions supported by the target to this DAG, and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45808,Performance,perform,performed,45808,"ot; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design; and Implementation. .. _Select instructions from DAG:. SelectionDAG Select Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^. The Select phase is the bulk of the target-specific code for instruction; selection. This phase takes a legal SelectionDAG as input, pattern matches the; instructions supported by the target to this DAG, and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45821,Performance,optimiz,optimizing,45821,"ot; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design; and Implementation. .. _Select instructions from DAG:. SelectionDAG Select Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^. The Select phase is the bulk of the target-specific code for instruction; selection. This phase takes a legal SelectionDAG as input, pattern matches the; instructions supported by the target to this DAG, and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:47649,Performance,perform,perform,47649,"ection. This phase takes a legal SelectionDAG as input, pattern matches the; instructions supported by the target to this DAG, and produces a new DAG of; target code. For example, consider the following LLVM fragment:. .. code-block:: llvm. %t1 = fadd float %W, %X; %t2 = fmul float %t1, %Y; %t3 = fadd float %t2, %Z. This LLVM code corresponds to a SelectionDAG that looks basically like this:. .. code-block:: text. (fadd:f32 (fmul:f32 (fadd:f32 W, X), Y), Z). If a target supports floating point multiply-and-add (FMA) operations, one of; the adds can be merged with the multiply. On the PowerPC, for example, the; output of the instruction selector might look like this DAG:. ::. (FMADDS (FADDS W, X), Y, Z). The ``FMADDS`` instruction is a ternary instruction that multiplies its first; two operands and adds the third (as single-precision floating-point numbers).; The ``FADDS`` instruction is a simple binary single-precision add instruction.; To perform this pattern match, the PowerPC backend includes the following; instruction definitions:. .. code-block:: text; :emphasize-lines: 4-5,9. def FMADDS : AForm_1<59, 29,; (ops F4RC:$FRT, F4RC:$FRA, F4RC:$FRC, F4RC:$FRB),; ""fmadds $FRT, $FRA, $FRC, $FRB"",; [(set F4RC:$FRT, (fadd (fmul F4RC:$FRA, F4RC:$FRC),; F4RC:$FRB))]>;; def FADDS : AForm_2<59, 21,; (ops F4RC:$FRT, F4RC:$FRA, F4RC:$FRB),; ""fadds $FRT, $FRA, $FRB"",; [(set F4RC:$FRT, (fadd F4RC:$FRA, F4RC:$FRB))]>;. The highlighted portion of the instruction definitions indicates the pattern; used to match the instructions. The DAG operators (like ``fmul``/``fadd``); are defined in the ``include/llvm/Target/TargetSelectionDAG.td`` file.; ""``F4RC``"" is the register class of the input and result values. The TableGen DAG instruction selector generator reads the instruction patterns; in the ``.td`` file and automatically builds parts of the pattern matching code; for your target. It has the following strengths:. * At compiler-compile time, it analyzes your instruction patterns and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:50394,Performance,load,load,50394,"arely have to explicitly tell the system what type parts of your patterns; are. In the ``FMADDS`` case above, we didn't have to tell ``tblgen`` that all; of the nodes in the pattern are of type 'f32'. It was able to infer and; propagate this knowledge from the fact that ``F4RC`` has type 'f32'. * Targets can define their own (and rely on built-in) ""pattern fragments"".; Pattern fragments are chunks of reusable patterns that get inlined into your; patterns during compiler-compile time. For example, the integer ""``(not; x)``"" operation is actually defined as a pattern fragment that expands as; ""``(xor x, -1)``"", since the SelectionDAG does not have a native '``not``'; operation. Targets can define their own short-hand fragments as they see fit.; See the definition of '``not``' and '``ineg``' for examples. * In addition to instructions, targets can specify arbitrary patterns that map; to one or more instructions using the 'Pat' class. For example, the PowerPC; has no way to load an arbitrary integer immediate into a register in one; instruction. To tell tblgen how to do this, it defines:. ::. // Arbitrary immediate support. Implement in terms of LIS/ORI.; def : Pat<(i32 imm:$imm),; (ORI (LIS (HI16 imm:$imm)), (LO16 imm:$imm))>;. If none of the single-instruction patterns for loading an immediate into a; register match, this will be used. This rule says ""match an arbitrary i32; immediate, turning it into an ``ORI`` ('or a 16-bit immediate') and an ``LIS``; ('load 16-bit immediate, where the immediate is shifted to the left 16 bits'); instruction"". To make this work, the ``LO16``/``HI16`` node transformations; are used to manipulate the input immediate (in this case, take the high or low; 16-bits of the immediate). * When using the 'Pat' class to map a pattern to an instruction that has one; or more complex operands (like e.g. `X86 addressing mode`_), the pattern may; either specify the operand as a whole using a ``ComplexPattern``, or else it; may specify the components o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:50701,Performance,load,loading,50701,"argets can define their own (and rely on built-in) ""pattern fragments"".; Pattern fragments are chunks of reusable patterns that get inlined into your; patterns during compiler-compile time. For example, the integer ""``(not; x)``"" operation is actually defined as a pattern fragment that expands as; ""``(xor x, -1)``"", since the SelectionDAG does not have a native '``not``'; operation. Targets can define their own short-hand fragments as they see fit.; See the definition of '``not``' and '``ineg``' for examples. * In addition to instructions, targets can specify arbitrary patterns that map; to one or more instructions using the 'Pat' class. For example, the PowerPC; has no way to load an arbitrary integer immediate into a register in one; instruction. To tell tblgen how to do this, it defines:. ::. // Arbitrary immediate support. Implement in terms of LIS/ORI.; def : Pat<(i32 imm:$imm),; (ORI (LIS (HI16 imm:$imm)), (LO16 imm:$imm))>;. If none of the single-instruction patterns for loading an immediate into a; register match, this will be used. This rule says ""match an arbitrary i32; immediate, turning it into an ``ORI`` ('or a 16-bit immediate') and an ``LIS``; ('load 16-bit immediate, where the immediate is shifted to the left 16 bits'); instruction"". To make this work, the ``LO16``/``HI16`` node transformations; are used to manipulate the input immediate (in this case, take the high or low; 16-bits of the immediate). * When using the 'Pat' class to map a pattern to an instruction that has one; or more complex operands (like e.g. `X86 addressing mode`_), the pattern may; either specify the operand as a whole using a ``ComplexPattern``, or else it; may specify the components of the complex operand separately. The latter is; done e.g. for pre-increment instructions by the PowerPC back end:. ::. def STWU : DForm_1<37, (outs ptr_rc:$ea_res), (ins GPRC:$rS, memri:$dst),; ""stwu $rS, $dst"", LdStStoreUpd, []>,; RegConstraint<""$dst.reg = $ea_res"">, NoEncode<""$ea_res"">;. def : P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:50887,Performance,load,load,50887,"ring compiler-compile time. For example, the integer ""``(not; x)``"" operation is actually defined as a pattern fragment that expands as; ""``(xor x, -1)``"", since the SelectionDAG does not have a native '``not``'; operation. Targets can define their own short-hand fragments as they see fit.; See the definition of '``not``' and '``ineg``' for examples. * In addition to instructions, targets can specify arbitrary patterns that map; to one or more instructions using the 'Pat' class. For example, the PowerPC; has no way to load an arbitrary integer immediate into a register in one; instruction. To tell tblgen how to do this, it defines:. ::. // Arbitrary immediate support. Implement in terms of LIS/ORI.; def : Pat<(i32 imm:$imm),; (ORI (LIS (HI16 imm:$imm)), (LO16 imm:$imm))>;. If none of the single-instruction patterns for loading an immediate into a; register match, this will be used. This rule says ""match an arbitrary i32; immediate, turning it into an ``ORI`` ('or a 16-bit immediate') and an ``LIS``; ('load 16-bit immediate, where the immediate is shifted to the left 16 bits'); instruction"". To make this work, the ``LO16``/``HI16`` node transformations; are used to manipulate the input immediate (in this case, take the high or low; 16-bits of the immediate). * When using the 'Pat' class to map a pattern to an instruction that has one; or more complex operands (like e.g. `X86 addressing mode`_), the pattern may; either specify the operand as a whole using a ``ComplexPattern``, or else it; may specify the components of the complex operand separately. The latter is; done e.g. for pre-increment instructions by the PowerPC back end:. ::. def STWU : DForm_1<37, (outs ptr_rc:$ea_res), (ins GPRC:$rS, memri:$dst),; ""stwu $rS, $dst"", LdStStoreUpd, []>,; RegConstraint<""$dst.reg = $ea_res"">, NoEncode<""$ea_res"">;. def : Pat<(pre_store GPRC:$rS, ptr_rc:$ptrreg, iaddroff:$ptroff),; (STWU GPRC:$rS, iaddroff:$ptroff, ptr_rc:$ptrreg)>;. Here, the pair of ``ptroff`` and ``ptrreg`` opera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:57225,Performance,perform,perform,57225,"d as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These are in; physical registers, so the physical register is assumed to be killed by the end; of the basic block. Live intervals for virtual registers are computed for some; ordering of the machine instructions ``[1, N]``. A live interval is an interval; ``[i, j)``, where ``1 >= i >= j > N``, for which a variable is live. .. note::; More to come... .. _Register Allocation:; .. _register allocator:. Register Allocation; -------------------. The *Register Allocation problem* consists in mapping a program; :raw-html:`<b><tt>` P\ :sub:`v`\ :raw-html:`</tt></b>`, that can use an unbounded; number of virtual registers, to a program :raw-html:`<b><tt>` P\ :sub:`p`\; :raw-html:`</tt></b>` that contains a finite (possibly small) number of physical; registers. Each target architecture has a different number of physical; registers.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64236,Performance,load,loads,64236," the latter are defined statically for each; instruction, whereas the former may vary depending on the program being; compiled. For example, an instruction that represents a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64516,Performance,load,load,64516,"::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64867,Performance,load,load,64867,"^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:64908,Performance,load,loadRegFromStackSlot,64908,"^. There are two ways to map virtual registers to physical registers (or to memory; slots). The first way, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:65023,Performance,load,load,65023,"ay, that we will call *direct mapping*, is based on the use; of methods of the classes ``TargetRegisterInfo``, and ``MachineOperand``. The; second way, that we will call *indirect mapping*, relies on the ``VirtRegMap``; class in order to insert loads and stores sending and getting values to and from; memory. The direct mapping provides more flexibility to the developer of the register; allocator; however, it is more error prone, and demands more implementation; work. Basically, the programmer will have to specify where load and store; instructions should be inserted in the target function being compiled in order; to get and store values in memory. To assign a physical register to a virtual; register present in a given operand, use ``MachineOperand::setReg(p_reg)``. To; insert a store instruction, use ``TargetInstrInfo::storeRegToStackSlot(...)``,; and to insert a load instruction, use ``TargetInstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instruction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:65965,Performance,load,load,65965,"nstrInfo::loadRegFromStackSlot``. The indirect mapping shields the application developer from the complexities of; inserting load and store instructions. In order to map a virtual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equiva",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:66116,Performance,load,loaded,66116,"tual register to a; physical one, use ``VirtRegMap::assignVirt2Phys(vreg, preg)``. In order to map; a certain virtual register to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:66194,Performance,load,load,66194,"er to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address instructions. LLVM; provides the pass ``TwoAddressInstructionPass`` for this specific purpose. It; must be run before regis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:67855,Performance,perform,performed,67855,"``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address instructions. LLVM; provides the pass ``TwoAddressInstructionPass`` for this specific purpose. It; must be run before register allocation takes place. After its execution, the; resulting code may no longer be in SSA form. This happens, for instance, in; situations where an instruction such as ``%a = ADD %b %c`` is converted to two; instructions such as:. ::. %a = MOVE %b; %a = ADD %a %c. Notice that, internally, the second instruction is represented as ``ADD; %a[def/use] %c``. I.e., the register operand ``%a`` is both used and defined by; the instruction. The SSA deconstruction phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. An important transformation that happens during register allocation is called; the *SSA Deconstruction Phase*. The SSA form simplifies many analyses that are; performed on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely subs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:68642,Performance,optimiz,optimization,68642,"^^^^^^^^^^^^^^^^^^^^. An important transformation that happens during register allocation is called; the *SSA Deconstruction Phase*. The SSA form simplifies many analyses that are; performed on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register alloc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:68655,Performance,perform,performed,68655,"^^^^^^^^^^^^^^^^^^^^. An important transformation that happens during register allocation is called; the *SSA Deconstruction Phase*. The SSA form simplifies many analyses that are; performed on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register alloc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:70036,Performance,perform,performance,70036,"MemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register allocation. Live; ranges are assigned to registers one at a time in an order that is driven by; heuristics. Since code can be rewritten on-the-fly during allocation, this; framework allows interesting allocators to be developed as extensions. It is; not itself a production register allocator but is a potentially useful; stand-alone mode for triaging bugs and as a performance baseline. * *Greedy* --- *The default allocator*. This is a highly tuned implementation of; the *Basic* allocator that incorporates global live range splitting. This; allocator works hard to minimize the cost of spill code. * *PBQP* --- A Partitioned Boolean Quadratic Programming (PBQP) based register; allocator. This allocator works by constructing a PBQP problem representing; the register allocation problem under consideration, solving this using a PBQP; solver, and mapping the solution back to a register assignment. The type of register allocator used in ``llc`` can be chosen with the command; line option ``-regalloc=...``:. .. code-block:: bash. $ llc -regalloc=linearscan file.bc -o ln.s; $ llc -regalloc=fast file.bc -o fa.s; $ llc -regalloc=pbqp file.bc -o pbqp.s. .. _Prolog/Epilog Code Insertion:. Prolog/Epilog Code Insertion; ----------------------------. .. note::. To Be Written. Compact Unwind; --------------. Thro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:70115,Performance,tune,tuned,70115,"als::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register allocation. Live; ranges are assigned to registers one at a time in an order that is driven by; heuristics. Since code can be rewritten on-the-fly during allocation, this; framework allows interesting allocators to be developed as extensions. It is; not itself a production register allocator but is a potentially useful; stand-alone mode for triaging bugs and as a performance baseline. * *Greedy* --- *The default allocator*. This is a highly tuned implementation of; the *Basic* allocator that incorporates global live range splitting. This; allocator works hard to minimize the cost of spill code. * *PBQP* --- A Partitioned Boolean Quadratic Programming (PBQP) based register; allocator. This allocator works by constructing a PBQP problem representing; the register allocation problem under consideration, solving this using a PBQP; solver, and mapping the solution back to a register assignment. The type of register allocator used in ``llc`` can be chosen with the command; line option ``-regalloc=...``:. .. code-block:: bash. $ llc -regalloc=linearscan file.bc -o ln.s; $ llc -regalloc=fast file.bc -o fa.s; $ llc -regalloc=pbqp file.bc -o pbqp.s. .. _Prolog/Epilog Code Insertion:. Prolog/Epilog Code Insertion; ----------------------------. .. note::. To Be Written. Compact Unwind; --------------. Throwing an exception requires *unwinding* out of a function. The information on; how to unwind a given function is traditionally expressed in DWARF unwind; (a.k.a. frame) ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81575,Performance,perform,performs,81575,"*MI)``, and; ``DFAPacketizer::canReserveResources(MachineInstr *MI)``. These functions allow; a target packetizer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86203,Performance,optimiz,optimization,86203,"e operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixed register operand.; def : InstAlias<""fcomi"", (COM_FIr ST1)>;. // Simple alias.; def : InstAlias<""fcomi $reg"", (COM_FIr RST:$reg)>;. Instruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAsse",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86251,Performance,optimiz,optimization,86251,"<""fcomi"", (COM_FIr ST1)>;. // Simple alias.; def : InstAlias<""fcomi $reg"", (COM_FIr RST:$reg)>;. Instruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86385,Performance,perform,performed,86385,"nstruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87881,Performance,optimiz,optimization,87881,"OT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88073,Performance,optimiz,optimized,88073,"eters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88190,Performance,perform,performance,88190," WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88245,Performance,optimiz,optimization,88245,"lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88299,Performance,optimiz,optimization,88299," The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88346,Performance,optimiz,optimization,88346," The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88378,Performance,optimiz,optimization,88378,"nts:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88437,Performance,perform,performed,88437,"nts:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88540,Performance,optimiz,optimization,88540,"ailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, and; includes support for ISA extensions such as MMX and SSE. X86 Target Triples supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88566,Performance,perform,performed,88566,"ailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, and; includes support for ISA extensions such as MMX and SSE. X86 Target Triples supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:91111,Performance,load,load,91111,"et-specific calling conventions are known to backend:. * **x86_StdCall** --- stdcall calling convention seen on Microsoft Windows; platform (CC ID = 64). * **x86_FastCall** --- fastcall calling convention seen on Microsoft Windows; platform (CC ID = 65). * **x86_ThisCall** --- Similar to X86_StdCall. Passes first argument in ECX,; others via stack. Callee is responsible for stack cleaning. This convention is; used by MSVC by default for methods in its ABI (CC ID = 70). .. _X86 addressing mode:. Representing X86 addressing modes in MachineInstrs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The x86 has a very flexible way of accessing memory. It is capable of forming; memory addresses of the following expression directly in integer instructions; (which use ModR/M addressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are cu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:91777,Performance,perform,perform,91777,". It is capable of forming; memory addresses of the following expression directly in integer instructions; (which use ModR/M addressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with norma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:91785,Performance,load,loads,91785,". It is capable of forming; memory addresses of the following expression directly in integer instructions; (which use ModR/M addressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with norma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92832,Performance,load,loads,92832,"perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93068,Performance,load,load,93068," are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:99234,Performance,cache,cache,99234,"</td>`; :raw-html:`<td>Saved LR</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>24</td>`; :raw-html:`<td>Reserved</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>32</td>`; :raw-html:`<td>Reserved</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>40</td>`; :raw-html:`<td>Saved FP (r31)</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The *parameter area* is used to store arguments being passed to a callee; function. Following the PowerPC ABI, the first few arguments are actually; passed in registers, with the space in the parameter area unused. However, if; there are not enough registers or the callee is a thunk or vararg function,; these register arguments can be spilled into the parameter area. Thus, the; parameter area must be large enough to store all the parameters for the largest; call sequence made by the caller. The size must also be minimally large enough; to spill registers r3-r10. This allows callees blind to the call signature,; such as thunks and vararg functions, enough space to cache the argument; registers. Therefore, the parameter area is minimally 32 bytes (64 bytes in 64; bit mode.) Also note that since the parameter area is a fixed offset from the; top of the frame, that a callee can access its split arguments using fixed; offsets from the stack pointer (or base pointer.). Combining the information about the linkage, parameter areas and alignment. A; stack frame is minimally 64 bytes in 32 bit mode and 128 bytes in 64 bit mode. The *dynamic area* starts out as size zero. If a function uses dynamic alloca; then space is added to the stack, the linkage and parameter areas are shifted to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102752,Performance,perform,performs,102752,"tml:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_21</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102891,Performance,load,loading,102891," capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105051,Performance,load,load,105051,"64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data ac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105105,Performance,load,load,105105,"64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data ac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:108144,Performance,perform,performs,108144,". eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. since x86_64 ABI mandates rdi, rsi, rdx, rcx, r8, r9 for argument passing; and rbx, r12 - r15 are callee saved. Program start; ^^^^^^^^^^^^^. An eBPF program receives a single argument and contains; a single eBPF main routine; the program does not contain eBPF functions.; Function calls are limited to a predefined set of kernel functions. The size; of a program is limited to 4K instructions: this ensures fast termination and; a limited number of kernel function calls. Prior to running an eBPF program,; a verifier performs static analysis to prevent loops in the code and; to ensure valid register usage and operand types. The AMDGPU backend; ------------------. The AMDGPU code generator lives in the ``lib/Target/AMDGPU``; directory. This code generator is capable of targeting a variety of; AMD GPU processors. Refer to :doc:`AMDGPUUsage` for more information.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37618,Safety,redund,redundancies,37618,"a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:60606,Safety,avoid,avoid,60606,"ed. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; definition of the ``GR8`` register class in; ``lib/Target/X86/X86RegisterInfo.td`` for an example of this. Virtual registers are also denoted by integer numbers. Contrary to physical; registers, different virtual registers never share the same number. Whereas; physical registers are statically defined in a ``TargetRegisterInfo.td`` file; and cannot be created by the application developer, that is not the case with; virtual registers. In order to create new virtual registers, use the method; ``MachineRegisterInfo::createVirtualRegister()``. This method will return a new; virtual register. Use an ``IndexedMap<Foo, VirtReg2IndexFunctor>`` to hold; information per virtual register. If you need to enumerate all virtual; registers, use the function ``TargetRegisterInfo::index2VirtReg()`` to find the; virtual register numbers:. .. code-block:: c++. for (unsigned",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:66219,Safety,avoid,avoiding,66219,"er to memory, use; ``VirtRegMap::assignVirt2StackSlot(vreg)``. This method will return the stack; slot where ``vreg``'s value will be located. If it is necessary to map another; virtual register to the same stack slot, use; ``VirtRegMap::assignVirt2StackSlot(vreg, stack_location)``. One important point; to consider when using the indirect mapping, is that even if a virtual register; is mapped to memory, it still needs to be mapped to a physical register. This; physical register is the location where the virtual register is supposed to be; found before being stored or after being reloaded. If the indirect strategy is used, after all the virtual registers have been; mapped to physical registers or stack slots, it is necessary to use a spiller; object to place load and store instructions in the code. Every virtual that has; been mapped to a stack slot will be stored to memory after being defined and will; be loaded before being used. The implementation of the spiller tries to recycle; load/store instructions, avoiding unnecessary instructions. For an example of; how to invoke the spiller, see ``RegAllocLinearScan::runOnMachineFunction`` in; ``lib/CodeGen/RegAllocLinearScan.cpp``. Handling two address instructions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With very rare exceptions (e.g., function calls), the LLVM machine code; instructions are three address instructions. That is, each instruction is; expected to define at most one register, and to use at most two registers.; However, some architectures use two address instructions. In this case, the; defined register is also one of the used registers. For instance, an instruction; such as ``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address instructions. LLVM; provides the pass ``TwoAddressInstructionPass`` for this specific purpose. It; must be run before regis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:68169,Safety,safe,safely,68169,"pose. It; must be run before register allocation takes place. After its execution, the; resulting code may no longer be in SSA form. This happens, for instance, in; situations where an instruction such as ``%a = ADD %b %c`` is converted to two; instructions such as:. ::. %a = MOVE %b; %a = ADD %a %c. Notice that, internally, the second instruction is represented as ``ADD; %a[def/use] %c``. I.e., the register operand ``%a`` is both used and defined by; the instruction. The SSA deconstruction phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. An important transformation that happens during register allocation is called; the *SSA Deconstruction Phase*. The SSA form simplifies many analyses that are; performed on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addInte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:68844,Safety,safe,safely,68844,"d on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely substituted by the single instruction:. ::. %EAX = LOAD %mem_address. Instructions can be folded with the; ``TargetRegisterInfo::foldMemoryOperand(...)`` method. Care must be taken when; folding instructions; a folded instruction can be quite different from the; original instruction. See ``LiveIntervals::addIntervalsForSpills`` in; ``lib/CodeGen/LiveIntervalAnalysis.cpp`` for an example of its use. Built in register allocators; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The LLVM infrastructure provides the application developer with three different; register allocators:. * *Fast* --- This register allocator is the default for debug builds. It; allocates registers on a basic block level, attempting to keep values in; registers and reusing registers as appropriate. * *Basic* --- This is an incremental approach to register allocation. Live; ranges are assigned to registers one at a time in an order that is driven by; heuristics. Since code can be rewritten on-the-fly during allocation, this; framework allows inte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106320,Safety,abort,abort,106320,"-----+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed acro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:1568,Security,expose,exposed,1568,"style>. .. contents::; :local:. .. warning::; This is a work in progress. Introduction; ============. The LLVM target-independent code generator is a framework that provides a suite; of reusable components for translating the LLVM internal representation to the; machine code for a specified target---either in assembly form (suitable for a; static compiler) or in binary machine code format (usable for a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representation,; etc). This code lives in ``lib/CodeGen/``. 5. `Implementations of the abstract target description interfaces`_ for; particular targets. These machine descriptions make use of the components; provided by LLVM, and can optionally provide custom target-specific passes,; to build complete code generators for a specific target. Target descriptions; live in ``lib/Target/``. 6. The target-independent JIT components. The LLVM JIT is completely target; independent (it uses the ``TargetJITInfo`` structure to interface for; tar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:10193,Security,access,accessors,10193,"makes it easier to change things. In particular,; if tables and other things are all emitted by ``tblgen``, we only need a change; in one place (``tblgen``) to update all of the targets to a new interface. .. _Abstract target description:; .. _target description:. Target description classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; implementation, and have virtual methods implemented. To get to these; implementations, the :raw-html:`<tt>` `TargetMachine`_ :raw-html:`</tt>` class; provides accessors that should be implemented by the target. .. _TargetMachine:. The ``TargetMachine`` class; ---------------------------. The ``TargetMachine`` class provides virtual methods that are used to access the; target-specific implementations of the various target description classes via; the ``get*Info`` methods (``getInstrInfo``, ``getRegisterInfo``,; ``getFrameInfo``, etc.). This class is designed to be specialized by a concrete; target implementation (e.g., ``X86TargetMachine``) which implements the various; virtual methods. The only required target description class is the; :raw-html:`<tt>` `DataLayout`_ :raw-html:`</tt>` class, but if the code; generator components are to be used, the other interfaces should be implemented; as well. .. _DataLayout:. The ``DataLayout`` class; ------------------------. The ``DataLayout`` class is the only required target description class, and it; is the only class that is not extensible (you cannot derive a new class f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:10393,Security,access,access,10393,"n classes; ==========================. The LLVM target description classes (located in the ``include/llvm/Target``; directory) provide an abstract description of the target machine independent of; any particular client. These classes are designed to capture the *abstract*; properties of the target (such as the instructions and registers it has), and do; not incorporate any particular pieces of code generation algorithms. All of the target description classes (except the :raw-html:`<tt>` `DataLayout`_; :raw-html:`</tt>` class) are designed to be subclassed by the concrete target; implementation, and have virtual methods implemented. To get to these; implementations, the :raw-html:`<tt>` `TargetMachine`_ :raw-html:`</tt>` class; provides accessors that should be implemented by the target. .. _TargetMachine:. The ``TargetMachine`` class; ---------------------------. The ``TargetMachine`` class provides virtual methods that are used to access the; target-specific implementations of the various target description classes via; the ``get*Info`` methods (``getInstrInfo``, ``getRegisterInfo``,; ``getFrameInfo``, etc.). This class is designed to be specialized by a concrete; target implementation (e.g., ``X86TargetMachine``) which implements the various; virtual methods. The only required target description class is the; :raw-html:`<tt>` `DataLayout`_ :raw-html:`</tt>` class, but if the code; generator components are to be used, the other interfaces should be implemented; as well. .. _DataLayout:. The ``DataLayout`` class; ------------------------. The ``DataLayout`` class is the only required target description class, and it; is the only class that is not extensible (you cannot derive a new class from; it). ``DataLayout`` specifies information about how the target lays out memory; for structures, the alignment requirements for various data types, the size of; pointers in the target, and whether the target is little-endian or; big-endian. .. _TargetLowering:. The ``TargetLowe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:12892,Security,expose,exposes,12892,"mounts, and. * various high-level characteristics, like whether it is profitable to turn; division by a constant into a multiplication sequence. .. _TargetRegisterInfo:. The ``TargetRegisterInfo`` class; --------------------------------. The ``TargetRegisterInfo`` class is used to describe the register file of the; target and any interactions between the registers. Registers are represented in the code generator by unsigned integers. Physical; registers (those that actually exist in the target description) are unique; small numbers, and virtual registers are generally large. Note that; register ``#0`` is reserved as a flag value. Each register in the processor description has an associated; ``TargetRegisterDesc`` entry, which provides a textual name for the register; (used for assembly output and debugging dumps) and a set of aliases (used to; indicate whether one register overlaps with another). In addition to the per-register description, the ``TargetRegisterInfo`` class; exposes a set of processor specific register classes (instances of the; ``TargetRegisterClass`` class). Each register class contains sets of registers; that have the same properties (for example, they are all 32-bit integer; registers). Each SSA virtual register created by the instruction selector has; an associated register class. When the register allocator runs, it replaces; virtual registers with a physical register in the set. The target-specific implementations of these classes is auto-generated from a; :doc:`TableGen/index` description of the register file. .. _TargetInstrInfo:. The ``TargetInstrInfo`` class; -----------------------------. The ``TargetInstrInfo`` class is used to describe the machine instructions; supported by the target. Descriptions define things like the mnemonic for; the opcode, the number of operands, the list of implicit register uses and defs,; whether the instruction has certain target-independent properties (accesses; memory, is commutable, etc), and holds any targ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:13847,Security,access,accesses,13847,"ster overlaps with another). In addition to the per-register description, the ``TargetRegisterInfo`` class; exposes a set of processor specific register classes (instances of the; ``TargetRegisterClass`` class). Each register class contains sets of registers; that have the same properties (for example, they are all 32-bit integer; registers). Each SSA virtual register created by the instruction selector has; an associated register class. When the register allocator runs, it replaces; virtual registers with a physical register in the set. The target-specific implementations of these classes is auto-generated from a; :doc:`TableGen/index` description of the register file. .. _TargetInstrInfo:. The ``TargetInstrInfo`` class; -----------------------------. The ``TargetInstrInfo`` class is used to describe the machine instructions; supported by the target. Descriptions define things like the mnemonic for; the opcode, the number of operands, the list of implicit register uses and defs,; whether the instruction has certain target-independent properties (accesses; memory, is commutable, etc), and holds any target-specific flags. The ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14872,Security,expose,exposes,14872,"he ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37631,Security,expose,exposed,37631,"a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction being compiled. This step uses traditional prepass; scheduling techniques. After all of these steps are complete, the SelectionDAG is destroyed and the; rest of the code generation passes are run. One of the most common ways to debug these steps is using `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:40378,Security,expose,expose,40378,"gs`` displays the DAG before Legalization. * ``-view-dag-combine2-dags`` displays the DAG before the second optimization; pass. * ``-view-isel-dags`` displays the DAG before the Select phase. * ``-view-sched-dags`` displays the DAG before Scheduling. The ``-view-sunit-dags`` displays the Scheduler's dependency graph. This graph; is based on the final SelectionDAG, with nodes that must be scheduled together; bundled into a single scheduling-unit node, and with immediate operands and; other nodes that aren't relevant for scheduling omitted. The option ``-filter-view-dags`` allows to select the name of the basic block; that you are interested to visualize and filters all the previous; ``view-*-dags`` options. .. _Build initial DAG:. Initial SelectionDAG Construction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The initial SelectionDAG is na\ :raw-html:`&iuml;`\ vely peephole expanded from; the LLVM input by the ``SelectionDAGBuilder`` class. The intent of this pass; is to expose as much low-level, target-specific details to the SelectionDAG as; possible. This pass is mostly hard-coded (e.g. an LLVM ``add`` turns into an; ``SDNode add`` while a ``getelementptr`` is expanded into the obvious; arithmetic). This pass requires target-specific hooks to lower calls, returns,; varargs, etc. For these features, the :raw-html:`<tt>` `TargetLowering`_; :raw-html:`</tt>` interface is used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:62877,Security,access,accessed,62877," if a; given machine operand is a register, use the boolean function; ``MachineOperand::isRegister()``. To obtain the integer code of a register, use; ``MachineOperand::getReg()``. An instruction may define or use a register. For; instance, ``ADD reg:1026 := reg:1025 reg:1024`` defines the registers 1024, and; uses registers 1025 and 1026. Given a register operand, the method; ``MachineOperand::isUse()`` informs if that register is being used by the; instruction. The method ``MachineOperand::isDef()`` informs if that registers is; being defined. We will call physical registers present in the LLVM bitcode before register; allocation *pre-colored registers*. Pre-colored registers are used in many; different situations, for instance, to pass parameters of functions calls, and; to store results of particular instructions. There are two types of pre-colored; registers: the ones *implicitly* defined, and those *explicitly*; defined. Explicitly defined registers are normal operands, and can be accessed; with ``MachineInstr::getOperand(int)::getReg()``. In order to check which; registers are implicitly defined by an instruction, use the; ``TargetInstrInfo::get(opcode)::ImplicitDefs``, where ``opcode`` is the opcode; of the target instruction. One important difference between explicit and; implicit physical registers is that the latter are defined statically for each; instruction, whereas the former may vary depending on the program being; compiled. For example, an instruction that represents a function call will; always implicitly define or use the same set of physical registers. To read the; registers implicitly used by an instruction, use; ``TargetInstrInfo::get(opcode)::ImplicitUses``. Pre-colored registers impose; constraints on any register allocation algorithm. The register allocator must; make sure that none of them are overwritten by the values of virtual registers; while still alive. Mapping virtual registers to physical registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:71855,Security,access,access,71855,"ode Insertion:. Prolog/Epilog Code Insertion; ----------------------------. .. note::. To Be Written. Compact Unwind; --------------. Throwing an exception requires *unwinding* out of a function. The information on; how to unwind a given function is traditionally expressed in DWARF unwind; (a.k.a. frame) info. But that format was originally developed for debuggers to; backtrace, and each Frame Description Entry (FDE) requires ~20-30 bytes per; function. There is also the cost of mapping from an address in a function to the; corresponding FDE at runtime. An alternative unwind encoding is called *compact; unwind* and requires just 4-bytes per function. The compact unwind encoding is a 32-bit value, which is encoded in an; architecture-specific way. It specifies which registers to restore and from; where, and how to unwind out of the function. When the linker creates a final; linked image, it will create a ``__TEXT,__unwind_info`` section. This section is; a small and fast way for the runtime to access unwind info for any given; function. If we emit compact unwind info for the function, that compact unwind; info will be encoded in the ``__TEXT,__unwind_info`` section. If we emit DWARF; unwind info, the ``__TEXT,__unwind_info`` section will contain the offset of the; FDE in the ``__TEXT,__eh_frame`` section in the final linked image. For X86, there are three modes for the compact unwind encoding:. *Function with a Frame Pointer (``EBP`` or ``RBP``)*; ``EBP/RBP``-based frame, where ``EBP/RBP`` is pushed onto the stack; immediately after the return address, then ``ESP/RSP`` is moved to; ``EBP/RBP``. Thus to unwind, ``ESP/RSP`` is restored with the current; ``EBP/RBP`` value, then ``EBP/RBP`` is restored by popping the stack, and the; return is done by popping the stack once more into the PC. All non-volatile; registers that need to be restored must have been saved in a small range on; the stack that starts ``EBP-4`` to ``EBP-1020`` (``RBP-8`` to; ``RBP-1020``). The offset ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:90778,Security,access,accessing,90778,"* **i386-unknown-freebsd5.3** --- FreeBSD 5.3. * **i686-pc-cygwin** --- Cygwin on Win32. * **i686-pc-mingw32** --- MingW on Win32. * **i386-pc-mingw32msvc** --- MingW crosscompiler on Linux. * **i686-apple-darwin*** --- Apple Darwin on X86. * **x86_64-unknown-linux-gnu** --- Linux. X86 Calling Conventions supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following target-specific calling conventions are known to backend:. * **x86_StdCall** --- stdcall calling convention seen on Microsoft Windows; platform (CC ID = 64). * **x86_FastCall** --- fastcall calling convention seen on Microsoft Windows; platform (CC ID = 65). * **x86_ThisCall** --- Similar to X86_StdCall. Passes first argument in ECX,; others via stack. Callee is responsible for stack cleaning. This convention is; used by MSVC by default for methods in its ABI (CC ID = 70). .. _X86 addressing mode:. Representing X86 addressing modes in MachineInstrs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The x86 has a very flexible way of accessing memory. It is capable of forming; memory addresses of the following expression directly in integer instructions; (which use ModR/M addressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the abi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:91944,Security,access,access,91944,"ressing):. ::. SegmentReg: Base + [1,2,4,8] * IndexReg + Disp32. In order to represent this, LLVM tracks no less than 5 operands for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92089,Security,access,accesses,92089,"nds for each memory; operand of this form. This means that the ""load"" form of '``mov``' has the; following ``MachineOperand``\s in this order:. ::. Index: 0 | 1 2 3 4 5; Meaning: DestReg, | BaseReg, Scale, IndexReg, Displacement Segment; OperandTy: VirtReg, | VirtReg, UnsImm, VirtReg, SignExtImm PhysReg. Stores, and all other instructions, treat the four memory operands in the same; way and in the same order. If the segment register is unspecified (regno = 0),; then no segment override is generated. ""Lea"" operations do not have a segment; register specified, so they only have 4 operands for their memory reference. X86 address spaces supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. x86 has a feature which provides the ability to perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92811,Security,access,accessed,92811,"perform loads and stores to; different address spaces via the x86 segment registers. A segment override; prefix byte on an instruction causes the instruction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93196,Security,access,accessed,93196," are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:94573,Security,access,accessing,94573,"e operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX32rm16 -> movsx, 32-bit register, 16-bit memory. The PowerPC backend; -------------------. The PowerPC code generator lives in the lib/Target/PowerPC directory. The code; generation is retargetable to several variations or *subtargets* of the PowerPC; ISA; including ppc32, ppc64 and altivec. LLVM PowerPC ABI; ^^^^^^^^^^^^^^^^. LLVM follows the AIX PowerPC ABI, with two deviations. LLVM uses a PC relative; (PIC) or static addressing for accessing global values, so no TOC (r2) is; used. Second, r31 is used as a frame pointer to allow dynamic growth of a stack; frame. LLVM takes advantage of having no TOC to provide space to save the frame; pointer in the PowerPC linkage area of the caller frame. Other details of; PowerPC ABI can be found at `PowerPC ABI; <http://developer.apple.com/documentation/DeveloperTools/Conceptual/LowLevelABI/Articles/32bitPowerPC.html>`_\; . Note: This link describes the 32 bit ABI. The 64 bit ABI is similar except; space for GPRs are 8 bytes wide (not 4) and r13 is reserved for system use. Frame Layout; ^^^^^^^^^^^^. The size of a PowerPC frame is usually fixed for the duration of a function's; invocation. Since the frame is fixed size, all references into the frame can be; accessed via fixed offsets from the stack pointer. The exception to this is; when dynamic alloca or variable sized arrays are present, then a base pointer; (r31) is used as a proxy for the stack pointer and stack pointe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:95350,Security,access,accessed,95350,"l variations or *subtargets* of the PowerPC; ISA; including ppc32, ppc64 and altivec. LLVM PowerPC ABI; ^^^^^^^^^^^^^^^^. LLVM follows the AIX PowerPC ABI, with two deviations. LLVM uses a PC relative; (PIC) or static addressing for accessing global values, so no TOC (r2) is; used. Second, r31 is used as a frame pointer to allow dynamic growth of a stack; frame. LLVM takes advantage of having no TOC to provide space to save the frame; pointer in the PowerPC linkage area of the caller frame. Other details of; PowerPC ABI can be found at `PowerPC ABI; <http://developer.apple.com/documentation/DeveloperTools/Conceptual/LowLevelABI/Articles/32bitPowerPC.html>`_\; . Note: This link describes the 32 bit ABI. The 64 bit ABI is similar except; space for GPRs are 8 bytes wide (not 4) and r13 is reserved for system use. Frame Layout; ^^^^^^^^^^^^. The size of a PowerPC frame is usually fixed for the duration of a function's; invocation. Since the frame is fixed size, all references into the frame can be; accessed via fixed offsets from the stack pointer. The exception to this is; when dynamic alloca or variable sized arrays are present, then a base pointer; (r31) is used as a proxy for the stack pointer and stack pointer is free to grow; or shrink. A base pointer is also used if llvm-gcc is not passed the; -fomit-frame-pointer flag. The stack pointer is always aligned to 16 bytes, so; that space allocated for altivec vectors will be properly aligned. An invocation frame is laid out as follows (low memory at top):. :raw-html:`<table border=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<td>Linkage<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Parameter area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Dynamic area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Locals area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>Saved registers area<br><br></td>`; :raw-html:`</tr>`; :raw-html:`<tr sty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:99449,Security,access,access,99449," :raw-html:`<tr>`; :raw-html:`<td>40</td>`; :raw-html:`<td>Saved FP (r31)</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The *parameter area* is used to store arguments being passed to a callee; function. Following the PowerPC ABI, the first few arguments are actually; passed in registers, with the space in the parameter area unused. However, if; there are not enough registers or the callee is a thunk or vararg function,; these register arguments can be spilled into the parameter area. Thus, the; parameter area must be large enough to store all the parameters for the largest; call sequence made by the caller. The size must also be minimally large enough; to spill registers r3-r10. This allows callees blind to the call signature,; such as thunks and vararg functions, enough space to cache the argument; registers. Therefore, the parameter area is minimally 32 bytes (64 bytes in 64; bit mode.) Also note that since the parameter area is a fixed offset from the; top of the frame, that a callee can access its split arguments using fixed; offsets from the stack pointer (or base pointer.). Combining the information about the linkage, parameter areas and alignment. A; stack frame is minimally 64 bytes in 32 bit mode and 128 bytes in 64 bit mode. The *dynamic area* starts out as size zero. If a function uses dynamic alloca; then space is added to the stack, the linkage and parameter areas are shifted to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic space need to observe 16 byte alignment. The *locals area* is where the llvm compiler reserves space for local variables. The *saved registers area* is where the llvm compiler spills callee saved; registers on entry to the callee. Prolog/Epilog",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105516,Security,access,access,105516,"OR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-spa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105556,Security,access,access,105556,"OR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-spa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105668,Security,access,access,105668," conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:105843,Security,access,access,105843,"BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106254,Security,access,access,106254,"-----+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_ABS 0x1 used to access packet data; BPF_IND 0x2 used to access packet data; BPF_MEM 0x3 memory; (reserved) 0x4; (reserved) 0x5; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed acro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:106601,Security,hash,hash,106601,"; BPF_XADD 0x6 exclusive add. Packet data access (BPF_ABS, BPF_IND); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Two non-generic instructions: (BPF_ABS | <size> | BPF_LD) and; (BPF_IND | <size> | BPF_LD) which are used to access packet data.; Register R6 is an implicit input that must contain pointer to sk_buff.; Register R0 is an implicit output which contains the data fetched; from the packet. Registers R1-R5 are scratch registers and must not; be used to store the data across BPF_ABS | BPF_LD or BPF_IND | BPF_LD; instructions. These instructions have implicit program exit condition; as well. When eBPF program is trying to access the data beyond; the packet boundary, the interpreter will abort the execution of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. si",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:107325,Security,access,accessed,107325,"of the program. BPF_IND | BPF_W | BPF_LD is equivalent to:; R0 = ntohl(\*(u32 \*) (((struct sk_buff \*) R6)->data + src_reg + imm32)). eBPF maps; ^^^^^^^^^. eBPF maps are provided for sharing data between kernel and user-space.; Currently implemented types are hash and array, with potential extension to; support bloom filters, radix trees, etc. A map is defined by its type,; maximum number of elements, key size and value size in bytes. eBPF syscall; supports create, update, find and delete functions on maps. Function calls; ^^^^^^^^^^^^^^. Function call arguments are passed using up to five registers (R1 - R5).; The return value is passed in a dedicated register (R0). Four additional; registers (R6 - R9) are callee-saved, and the values in these registers; are preserved within kernel functions. R0 - R5 are scratch registers within; kernel functions, and eBPF programs must therefor store/restore values in; these registers if needed across function calls. The stack can be accessed; using the read-only frame pointer R10. eBPF registers map 1:1 to hardware; registers on x86_64 and other 64-bit architectures. For example, x86_64; in-kernel JIT maps them as. ::. R0 - rax; R1 - rdi; R2 - rsi; R3 - rdx; R4 - rcx; R5 - r8; R6 - rbx; R7 - r13; R8 - r14; R9 - r15; R10 - rbp. since x86_64 ABI mandates rdi, rsi, rdx, rcx, r8, r9 for argument passing; and rbx, r12 - r15 are callee saved. Program start; ^^^^^^^^^^^^^. An eBPF program receives a single argument and contains; a single eBPF main routine; the program does not contain eBPF functions.; Function calls are limited to a predefined set of kernel functions. The size; of a program is limited to 4K instructions: this ensures fast termination and; a limited number of kernel function calls. Prior to running an eBPF program,; a verifier performs static analysis to prevent loops in the code and; to ensure valid register usage and operand types. The AMDGPU backend; ------------------. The AMDGPU code generator lives in the ``lib/Ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:15000,Testability,stub,stubs,15000,"he ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:19925,Testability,test,test,19925,"ruction.; BuildMI(MBB, DL, TII.get(X86::JNE)).addMBB(&MBB);. If you need to add a definition operand (other than the optional destination; register), you must explicitly mark it as such:. .. code-block:: c++. MI.addReg(Reg, RegState::Define);. Fixed (preassigned) registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One important issue that the code generator needs to be aware of is the presence; of fixed registers. In particular, there are often places in the instruction; stream where the register allocator *must* arrange for a particular value to be; in a particular register. This can occur due to limitations of the instruction; set (e.g., the X86 can only do a 32-bit divide with the ``EAX``/``EDX``; registers), or external factors like calling conventions. In any case, the; instruction selector should emit code that copies a virtual register into or out; of a physical register when needed. For example, consider this simple LLVM example:. .. code-block:: llvm. define i32 @test(i32 %X, i32 %Y) {; %Z = sdiv i32 %X, %Y; ret i32 %Z; }. The X86 instruction selector might produce this machine code for the ``div`` and; ``ret``:. .. code-block:: text. ;; Start of div; %EAX = mov %reg1024 ;; Copy X (in reg1024) into EAX; %reg1027 = sar %reg1024, 31; %EDX = mov %reg1027 ;; Sign extend X into EDX; idiv %reg1025 ;; Divide by Y (in reg1025); %reg1026 = mov %EAX ;; Read the result (Z) out of EAX. ;; Start of ret; %EAX = mov %reg1026 ;; 32-bit return value goes in EAX; ret. By the end of code generation, the register allocator would coalesce the; registers and delete the resultant identity moves producing the following; code:. .. code-block:: text. ;; X is in EAX, Y is in ECX; mov %EAX, %EDX; sar %EDX, 31; idiv %ECX; ret. This approach is extremely general (if it can handle the X86 architecture, it; can handle anything!) and allows all of the target specific knowledge about the; instruction stream to be isolated in the instruction selector. Note that; physical registers should have a short l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:28478,Testability,log,logic,28478,"rses a line, then invokes a method on MCStreamer. In; the code generator, the `Code Emission`_ phase of the code generator lowers; higher level LLVM IR and Machine* constructs down to the MC layer, emitting; directives through MCStreamer. On the implementation side of MCStreamer, there are two major implementations:; one for writing out a .s file (MCAsmStreamer), and one for writing out a .o; file (MCObjectStreamer). MCAsmStreamer is a straightforward implementation; that prints out a directive for each method (e.g. ``EmitValue -> .byte``), but; MCObjectStreamer implements a full assembler. For target specific directives, the MCStreamer has a MCTargetStreamer instance.; Each target that needs it defines a class that inherits from it and is a lot; like MCStreamer itself: It has one method per directive and two classes that; inherit from it, a target object streamer and a target asm streamer. The target; asm streamer just prints it (``emitFnStart -> .fnstart``), and the object; streamer implement the assembler logic for it. To make llvm use these classes, the target initialization must call; TargetRegistry::RegisterAsmStreamer and TargetRegistry::RegisterMCObjectStreamer; passing callbacks that allocate the corresponding target streamer and pass it; to createAsmStreamer or to the appropriate object streamer constructor. The ``MCContext`` class; -----------------------. The MCContext class is the owner of a variety of uniqued data structures at the; MC layer, including symbols, sections, etc. As such, this is the class that you; interact with to create symbols and sections. This class can not be subclassed. The ``MCSymbol`` class; ----------------------. The MCSymbol class represents a symbol (aka label) in the assembly file. There; are two interesting kinds of symbols: assembler temporary symbols, and normal; symbols. Assembler temporary symbols are used and processed by the assembler; but are discarded when the object file is produced. The distinction is usually; rep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:53242,Testability,log,logical,53242,"ecause it is a work in progress and is not yet finished:. * Overall, there is no way to define or match SelectionDAG nodes that define; multiple values (e.g. ``SMUL_LOHI``, ``LOAD``, ``CALL``, etc). This is the; biggest reason that you currently still *have to* write custom C++ code; for your instruction selector. * There is no great way to support matching complex addressing modes yet. In; the future, we will extend pattern fragments to allow them to define multiple; values (e.g. the four operands of the `X86 addressing mode`_, which are; currently matched with custom C++ code). In addition, we'll extend fragments; so that a fragment can match multiple different patterns. * We don't automatically infer flags like ``isStore``/``isLoad`` yet. * We don't automatically generate the set of supported registers and operations; for the `Legalizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:54000,Testability,log,logically,54000,"alizer`_ yet. * We don't have a way of tying in custom legalized nodes yet. Despite these limitations, the instruction selector generator is still quite; useful for most of the binary and logical operations in typical instruction; sets. If you run into any problems or can't figure out how to do something,; please let Chris know!. .. _Scheduling and Formation:; .. _SelectionDAG Scheduling and Formation:. SelectionDAG Scheduling and Formation Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The scheduling phase takes the DAG of target instructions from the selection; phase and assigns an order. The scheduler can pick an order depending on; various constraints of the machines (i.e. order for minimal register pressure or; try to cover instruction latencies). Once an order is established, the DAG is; converted to a list of :raw-html:`<tt>` `MachineInstr`_\s :raw-html:`</tt>` and; the SelectionDAG is destroyed. Note that this phase is logically separate from the instruction selection phase,; but is tied to it closely in the code because it operates on SelectionDAGs. Future directions for the SelectionDAG; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Optional function-at-a-time selection. #. Auto-generate entire selector from ``.td`` file. .. _SSA-based Machine Code Optimizations:. SSA-based Machine Code Optimizations; ------------------------------------. To Be Written. Live Intervals; --------------. Live Intervals are the ranges (intervals) where a variable is *live*. They are; used by some `register allocator`_ passes to determine if two or more virtual; registers which require the same physical register are live at the same point in; the program (i.e., they conflict). When this situation occurs, one virtual; register must be *spilled*. Live Variable Analysis; ^^^^^^^^^^^^^^^^^^^^^^. The first step in determining the live intervals of variables is to calculate; the set of registers that are immediately dead after the instruction (i.e., the; instruction calculates the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:60060,Testability,assert,assert,60060," the; registers ``EAX``, ``AX`` and ``AL`` share the first eight bits. These physical; registers are marked as *aliased* in LLVM. Given a particular architecture, you; can check which registers are aliased by inspecting its ``RegisterInfo.td``; file. Moreover, the class ``MCRegAliasIterator`` enumerates all the physical; registers aliased to a register. Physical registers, in LLVM, are grouped in *Register Classes*. Elements in the; same register class are functionally equivalent, and can be interchangeably; used. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; definition of the ``GR8`` register class in; ``lib/Target/X86/X86RegisterInfo.td`` for an example of this. Virtual registers are also denoted by integer numbers. Contrary to physical; registers, different virtual registers never share the same number. Whereas; physical registers are statically defined in a ``TargetRegisterInfo.td`` file; and cannot ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:76556,Testability,log,logic,76556,"Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of the lowering for free if you are; implementing an ELF, COFF, or MachO target, because the; TargetLoweringObjectFile class implements much of the common logic. #. Second, you need to implement an instruction printer for your target. The; instruction printer takes an `MCInst`_ and renders it to a raw_ostream as; text. Most of this is automatically generated from the .td file (when you; specify something like ""``add $dst, $src1, $src2``"" in the instructions), but; you need to implement routines to print operands. #. Third, you need to implement code that lowers a `MachineInstr`_ to an MCInst,; usually implemented in ""<target>MCInstLower.cpp"". This lowering process is; often target specific, and is responsible for turning jump table entries,; constant pool indices, global variable addresses, etc into MCLabels as; appropriate. This translation layer is also responsible for expanding pseudo; ops used by the code generator into the actual machine instructions they; correspond to. The MCInsts that are generated by this are fed into the; instruction printer or",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87524,Testability,test,test,87524," calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:89727,Testability,test,test,89727," can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the ``lib/Target/X86`` directory. This code; generator is capable of targeting a variety of x86-32 and x86-64 processors, and; includes support for ISA extensions such as MMX and SSE. X86 Target Triples supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following are the known target triples that are supported by the X86; backend. This is not an exhaustive list, and it would be useful to add those; that people test. * **i686-pc-linux-gnu** --- Linux. * **i386-unknown-freebsd5.3** --- FreeBSD 5.3. * **i686-pc-cygwin** --- Cygwin on Win32. * **i686-pc-mingw32** --- MingW on Win32. * **i386-pc-mingw32msvc** --- MingW crosscompiler on Linux. * **i686-apple-darwin*** --- Apple Darwin on X86. * **x86_64-unknown-linux-gnu** --- Linux. X86 Calling Conventions supported; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following target-specific calling conventions are known to backend:. * **x86_StdCall** --- stdcall calling convention seen on Microsoft Windows; platform (CC ID = 64). * **x86_FastCall** --- fastcall calling convention seen on Microsoft Windows; platform (CC ID = 65). * **x86_ThisCall** --- Similar to X86_StdCall. Passes first argument in ECX,; others via stack. Callee is responsible for stack cleaning. This convention is; used by MSVC by default for methods in its ABI (CC ID = 70). .. _X86 addressing mode:. Representing X86 addressing modes in MachineInstrs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:104395,Testability,log,logical,104395,"eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:104427,Testability,log,logical,104427,"eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:104578,Testability,log,logical,104578,"eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF_NEG 0x8 arithmetic negation; BPF_MOD 0x9 modulo; BPF_XOR 0xa bitwise logical XOR; BPF_MOV 0xb move register to register; BPF_ARSH 0xc right shift (sign extended); BPF_END 0xd endianness conversion. If BPF_CLASS(code) == BPF_JMP, BPF_OP(code) is one of. ::. BPF_JA 0x0 unconditional jump; BPF_JEQ 0x1 jump ==; BPF_JGT 0x2 jump >; BPF_JGE 0x3 jump >=; BPF_JSET 0x4 jump if (DST & SRC); BPF_JNE 0x5 jump !=; BPF_JSGT 0x6 jump signed >; BPF_JSGE 0x7 jump signed >=; BPF_CALL 0x8 function call; BPF_EXIT 0x9 function return. Instruction encoding (load, store); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; For load and store instructions the 8-bit 'code' field is divided as:. ::. +--------+--------+-------------------+; | 3 bits | 2 bits | 3 bits |; | mode | size | instruction class |; +--------+--------+-------------------+; (MSB) (LSB). Size modifier is one of. ::. BPF_W 0x0 word; BPF_H 0x1 half word; BPF_B 0x2 byte; BPF_DW 0x3 double word. Mode modifier is one of. ::. BPF_IMM 0x0 immediate; BPF_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:921,Usability,usab,usable,921,"==========================================; The LLVM Target-Independent Code Generator; ==========================================. .. role:: raw-html(raw); :format: html. .. raw:: html. <style>; .unknown { background-color: #C0C0C0; text-align: center; }; .unknown:before { content: ""?"" }; .no { background-color: #C11B17 }; .no:before { content: ""N"" }; .partial { background-color: #F88017 }; .yes { background-color: #0F0; }; .yes:before { content: ""Y"" }; .na { background-color: #6666FF; }; .na:before { content: ""N/A"" }; </style>. .. contents::; :local:. .. warning::; This is a work in progress. Introduction; ============. The LLVM target-independent code generator is a framework that provides a suite; of reusable components for translating the LLVM internal representation to the; machine code for a specified target---either in assembly form (suitable for a; static compiler) or in binary machine code format (usable for a JIT; compiler). The LLVM target-independent code generator consists of six main; components:. 1. `Abstract target description`_ interfaces which capture important properties; about various aspects of the machine, independently of how they will be used.; These interfaces are defined in ``include/llvm/Target/``. 2. Classes used to represent the `code being generated`_ for a target. These; classes are intended to be abstract enough to represent the machine code for; *any* target machine. These classes are defined in; ``include/llvm/CodeGen/``. At this level, concepts like ""constant pool; entries"" and ""jump tables"" are explicitly exposed. 3. Classes and algorithms used to represent code at the object file level, the; `MC Layer`_. These classes represent assembly level constructs like labels,; sections, and instructions. At this level, concepts like ""constant pool; entries"" and ""jump tables"" don't exist. 4. `Target-independent algorithms`_ used to implement various phases of native; code generation (register allocation, scheduling, stack frame representati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:16203,Usability,simpl,simple,16203,"ses; ================================. At the high-level, LLVM code is translated to a machine specific representation; formed out of :raw-html:`<tt>` `MachineFunction`_ :raw-html:`</tt>`,; :raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>`, and :raw-html:`<tt>`; `MachineInstr`_ :raw-html:`</tt>` instances (defined in; ``include/llvm/CodeGen``). This representation is completely target agnostic,; representing instructions in their most abstract form: an opcode and a series of; operands. This representation is designed to support both an SSA representation; for machine code, as well as a register allocated, non-SSA form. .. _MachineInstr:. The ``MachineInstr`` class; --------------------------. Target machine instructions are represented as instances of the ``MachineInstr``; class. This class is an extremely abstract way of representing machine; instructions. In particular, it only keeps track of an opcode number and a set; of operands. The opcode number is a simple unsigned integer that only has meaning to a; specific backend. All of the instructions for a target should be defined in the; ``*InstrInfo.td`` file for the target. The opcode enum values are auto-generated; from this description. The ``MachineInstr`` class does not have any information; about how to interpret the instruction (i.e., what the semantics of the; instruction are); for that you must refer to the :raw-html:`<tt>`; `TargetInstrInfo`_ :raw-html:`</tt>` class. The operands of a machine instruction can be of several different types: a; register reference, a constant integer, a basic block reference, etc. In; addition, a machine operand should be marked as a def or a use of the value; (though only registers are allowed to be defs). By convention, the LLVM code generator orders instruction operands so that all; register definitions come before the register uses, even on architectures that; are normally printed in other orders. For example, the SPARC add instruction:; ""``add %i1, %i2, %i3``"" adds ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:19869,Usability,simpl,simple,19869,".; MI = BuildMI(MBB, DL, TII.get(X86::SAHF));. // Create a self looping branch instruction.; BuildMI(MBB, DL, TII.get(X86::JNE)).addMBB(&MBB);. If you need to add a definition operand (other than the optional destination; register), you must explicitly mark it as such:. .. code-block:: c++. MI.addReg(Reg, RegState::Define);. Fixed (preassigned) registers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One important issue that the code generator needs to be aware of is the presence; of fixed registers. In particular, there are often places in the instruction; stream where the register allocator *must* arrange for a particular value to be; in a particular register. This can occur due to limitations of the instruction; set (e.g., the X86 can only do a 32-bit divide with the ``EAX``/``EDX``; registers), or external factors like calling conventions. In any case, the; instruction selector should emit code that copies a virtual register into or out; of a physical register when needed. For example, consider this simple LLVM example:. .. code-block:: llvm. define i32 @test(i32 %X, i32 %Y) {; %Z = sdiv i32 %X, %Y; ret i32 %Z; }. The X86 instruction selector might produce this machine code for the ``div`` and; ``ret``:. .. code-block:: text. ;; Start of div; %EAX = mov %reg1024 ;; Copy X (in reg1024) into EAX; %reg1027 = sar %reg1024, 31; %EDX = mov %reg1027 ;; Sign extend X into EDX; idiv %reg1025 ;; Divide by Y (in reg1025); %reg1026 = mov %EAX ;; Read the result (Z) out of EAX. ;; Start of ret; %EAX = mov %reg1026 ;; 32-bit return value goes in EAX; ret. By the end of code generation, the register allocator would coalesce the; registers and delete the resultant identity moves producing the following; code:. .. code-block:: text. ;; X is in EAX, Y is in ECX; mov %EAX, %EDX; sar %EDX, 31; idiv %ECX; ret. This approach is extremely general (if it can handle the X86 architecture, it; can handle anything!) and allows all of the target specific knowledge about the; instruction stream to be isolat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:21817,Usability,simpl,simple,21817,"instruction selector. Note that; physical registers should have a short lifetime for good code generation, and; all physical registers are assumed dead on entry to and exit from basic blocks; (before register allocation). Thus, if you need a value to be live across basic; block boundaries, it *must* live in a virtual register. Call-clobbered registers; ^^^^^^^^^^^^^^^^^^^^^^^^. Some machine instructions, like calls, clobber a large number of physical; registers. Rather than adding ``<def,dead>`` operands for all of them, it is; possible to use an ``MO_RegisterMask`` operand instead. The register mask; operand holds a bit mask of preserved registers, and everything else is; considered to be clobbered by the instruction. Machine code in SSA form; ^^^^^^^^^^^^^^^^^^^^^^^^. ``MachineInstr``'s are initially selected in SSA-form, and are maintained in; SSA-form until register allocation happens. For the most part, this is; trivially simple since LLVM is already in SSA form; LLVM PHI nodes become; machine code PHI nodes, and virtual registers are only allowed to have a single; definition. After register allocation, machine code is no longer in SSA-form because there; are no virtual registers left in the code. .. _MachineBasicBlock:. The ``MachineBasicBlock`` class; -------------------------------. The ``MachineBasicBlock`` class contains a list of machine instructions; (:raw-html:`<tt>` `MachineInstr`_ :raw-html:`</tt>` instances). It roughly; corresponds to the LLVM code input to the instruction selector, but there can be; a one-to-many mapping (i.e. one LLVM basic block can map to multiple machine; basic blocks). The ``MachineBasicBlock`` class has a ""``getBasicBlock``"" method,; which returns the LLVM basic block that it comes from. .. _MachineFunction:. The ``MachineFunction`` class; -----------------------------. The ``MachineFunction`` class contains a list of machine basic blocks; (:raw-html:`<tt>` `MachineBasicBlock`_ :raw-html:`</tt>` instances). It; corresponds on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:30593,Usability,simpl,simple,30593,"n be compared for pointer equivalence to find out if they are the same symbol.; Note that pointer inequality does not guarantee the labels will end up at; different addresses though. It's perfectly legal to output something like this; to the .s file:. ::. foo:; bar:; .byte 4. In this case, both the foo and bar symbols will have the same address. The ``MCSection`` class; -----------------------. The ``MCSection`` class represents an object-file specific section. It is; subclassed by object file specific implementations (e.g. ``MCSectionMachO``,; ``MCSectionCOFF``, ``MCSectionELF``) and these are created and uniqued by; MCContext. The MCStreamer has a notion of the current section, which can be; changed with the SwitchToSection method (which corresponds to a "".section""; directive in a .s file). .. _MCInst:. The ``MCInst`` class; --------------------. The ``MCInst`` class is a target-independent representation of an instruction.; It is a simple class (much more so than `MachineInstr`_) that holds a; target-specific opcode and a vector of MCOperands. MCOperand, in turn, is a; simple discriminated union of three cases: 1) a simple immediate, 2) a target; register ID, 3) a symbolic expression (e.g. ""``Lfoo-Lbar+42``"") as an MCExpr. MCInst is the common currency used to represent machine instructions at the MC; layer. It is the type used by the instruction encoder, the instruction printer,; and the type generated by the assembly parser and disassembler. .. _ObjectFormats:. Object File Format; ------------------. The MC layer's object writers support a variety of object formats. Because of; target-specific aspects of object formats each target only supports a subset of; the formats supported by the MC layer. Most targets support emitting ELF; objects. Other vendor-specific objects are generally supported only on targets; that are supported by that vendor (i.e. MachO is only supported on targets; supported by Darwin, and XCOFF is only supported on targets that support AIX).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:30733,Usability,simpl,simple,30733,"els will end up at; different addresses though. It's perfectly legal to output something like this; to the .s file:. ::. foo:; bar:; .byte 4. In this case, both the foo and bar symbols will have the same address. The ``MCSection`` class; -----------------------. The ``MCSection`` class represents an object-file specific section. It is; subclassed by object file specific implementations (e.g. ``MCSectionMachO``,; ``MCSectionCOFF``, ``MCSectionELF``) and these are created and uniqued by; MCContext. The MCStreamer has a notion of the current section, which can be; changed with the SwitchToSection method (which corresponds to a "".section""; directive in a .s file). .. _MCInst:. The ``MCInst`` class; --------------------. The ``MCInst`` class is a target-independent representation of an instruction.; It is a simple class (much more so than `MachineInstr`_) that holds a; target-specific opcode and a vector of MCOperands. MCOperand, in turn, is a; simple discriminated union of three cases: 1) a simple immediate, 2) a target; register ID, 3) a symbolic expression (e.g. ""``Lfoo-Lbar+42``"") as an MCExpr. MCInst is the common currency used to represent machine instructions at the MC; layer. It is the type used by the instruction encoder, the instruction printer,; and the type generated by the assembly parser and disassembler. .. _ObjectFormats:. Object File Format; ------------------. The MC layer's object writers support a variety of object formats. Because of; target-specific aspects of object formats each target only supports a subset of; the formats supported by the MC layer. Most targets support emitting ELF; objects. Other vendor-specific objects are generally supported only on targets; that are supported by that vendor (i.e. MachO is only supported on targets; supported by Darwin, and XCOFF is only supported on targets that support AIX).; Additionally some targets have their own object formats (i.e. DirectX, SPIR-V; and WebAssembly). The table below captures a snapshot of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:30781,Usability,simpl,simple,30781,"els will end up at; different addresses though. It's perfectly legal to output something like this; to the .s file:. ::. foo:; bar:; .byte 4. In this case, both the foo and bar symbols will have the same address. The ``MCSection`` class; -----------------------. The ``MCSection`` class represents an object-file specific section. It is; subclassed by object file specific implementations (e.g. ``MCSectionMachO``,; ``MCSectionCOFF``, ``MCSectionELF``) and these are created and uniqued by; MCContext. The MCStreamer has a notion of the current section, which can be; changed with the SwitchToSection method (which corresponds to a "".section""; directive in a .s file). .. _MCInst:. The ``MCInst`` class; --------------------. The ``MCInst`` class is a target-independent representation of an instruction.; It is a simple class (much more so than `MachineInstr`_) that holds a; target-specific opcode and a vector of MCOperands. MCOperand, in turn, is a; simple discriminated union of three cases: 1) a simple immediate, 2) a target; register ID, 3) a symbolic expression (e.g. ""``Lfoo-Lbar+42``"") as an MCExpr. MCInst is the common currency used to represent machine instructions at the MC; layer. It is the type used by the instruction encoder, the instruction printer,; and the type generated by the assembly parser and disassembler. .. _ObjectFormats:. Object File Format; ------------------. The MC layer's object writers support a variety of object formats. Because of; target-specific aspects of object formats each target only supports a subset of; the formats supported by the MC layer. Most targets support emitting ELF; objects. Other vendor-specific objects are generally supported only on targets; that are supported by that vendor (i.e. MachO is only supported on targets; supported by Darwin, and XCOFF is only supported on targets that support AIX).; Additionally some targets have their own object formats (i.e. DirectX, SPIR-V; and WebAssembly). The table below captures a snapshot of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:35385,Usability,simpl,simple,35385,"d the operands to the; operation. The various operation node types are described at the top of the; ``include/llvm/CodeGen/ISDOpcodes.h`` file. Although most operations define a single value, each node in the graph may; define multiple values. For example, a combined div/rem operation will define; both the dividend and the remainder. Many other situations require multiple; values as well. Each node also has some number of operands, which are edges to; the node defining the used value. Because nodes may define multiple values,; edges are represented by instances of the ``SDValue`` class, which is a; ``<SDNode, unsigned>`` pair, indicating the node and result value being used,; respectively. Each value produced by an ``SDNode`` has an associated ``MVT``; (Machine Value Type) indicating what the type of the value is. SelectionDAGs contain two different kinds of values: those that represent data; flow and those that represent control flow dependencies. Data values are simple; edges with an integer or floating point value type. Control edges are; represented as ""chain"" edges which are of type ``MVT::Other``. These edges; provide an ordering between nodes that have side effects (such as loads, stores,; calls, returns, etc). All nodes that have side effects should take a token; chain as input and produce a new one as output. By convention, token chain; inputs are always operand #0, and chain results are always the last value; produced by an operation. However, after instruction selection, the; machine nodes have their chain after the instruction's operands, and; may be followed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a tar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:36985,Usability,simpl,simple,36985,"llowed by glue nodes. A SelectionDAG has designated ""Entry"" and ""Root"" nodes. The Entry node is; always a marker node with an Opcode of ``ISD::EntryToken``. The Root node is; the final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37110,Usability,simpl,simple,37110,"e final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `Sele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37155,Usability,simpl,simplify,37155,"e final side-effecting node in the token chain. For example, in a single basic; block function it would be the return node. One important concept for SelectionDAGs is the notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `Sele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:37391,Usability,simpl,simpler,37391," notion of a ""legal"" vs.; ""illegal"" DAG. A legal DAG for a target is one that only uses supported; operations and supported types. On a 32-bit PowerPC, for example, a DAG with a; value of type i1, i8, i16, or i64 would be illegal, as would a DAG that uses a; SREM or UREM operation. The `legalize types`_ and `legalize operations`_ phases; are responsible for turning an illegal DAG into a legal DAG. .. _SelectionDAG-Process:. SelectionDAG Instruction Selection Process; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SelectionDAG-based instruction selection consists of the following steps:. #. `Build initial DAG`_ --- This stage performs a simple translation from the; input LLVM code to an illegal SelectionDAG. #. `Optimize SelectionDAG`_ --- This stage performs simple optimizations on the; SelectionDAG to simplify it, and recognize meta instructions (like rotates; and ``div``/``rem`` pairs) for targets that support these meta operations.; This makes the resultant code more efficient and the `select instructions; from DAG`_ phase (below) simpler. #. `Legalize SelectionDAG Types`_ --- This stage transforms SelectionDAG nodes; to eliminate any types that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to clean up; redundancies exposed by type legalization. #. `Legalize SelectionDAG Ops`_ --- This stage transforms SelectionDAG nodes to; eliminate any operations that are unsupported on the target. #. `Optimize SelectionDAG`_ --- The SelectionDAG optimizer is run to eliminate; inefficiencies introduced by operation legalization. #. `Select instructions from DAG`_ --- Finally, the target instruction selector; matches the DAG operations to target instructions. This process translates; the target-independent input DAG into another DAG of target instructions. #. `SelectionDAG Scheduling and Formation`_ --- The last phase assigns a linear; order to the instructions in the target-instruction DAG and emits them into; the MachineFunction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:45670,Usability,simpl,simple,45670,"bvector``. Prior to the existence of the Legalize passes, we required that every target; `selector`_ supported and handled every operator and type even if they are not; natively supported. The introduction of the Legalize phases allows all of the; canonicalization patterns to be shared across targets, and makes it very easy to; optimize the canonicalized code because it is still in the form of a DAG. .. _optimizations:; .. _Optimize SelectionDAG:; .. _selector:. SelectionDAG Optimization Phase: the DAG Combiner; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SelectionDAG optimization phase is run multiple times for code generation,; immediately after the DAG is built and once after each legalization. The first; run of the pass allows the initial code to be cleaned up (e.g. performing; optimizations that depend on knowing that the operators have restricted type; inputs). Subsequent runs of the pass clean up the messy code generated by the; Legalize passes, which allows Legalize to be very simple (it can focus on making; code legal instead of focusing on generating *good* and legal code). One important class of optimizations performed is optimizing inserted sign and; zero extension instructions. We currently use ad-hoc techniques, but could move; to more rigorous techniques in the future. Here are some good papers on the; subject:. ""`Widening integer arithmetic <http://www.eecs.harvard.edu/~nr/pubs/widen-abstract.html>`_"" :raw-html:`<br>`; Kevin Redwine and Norman Ramsey :raw-html:`<br>`; International Conference on Compiler Construction (CC) 2004. ""`Effective sign extension elimination <http://portal.acm.org/citation.cfm?doid=512529.512552>`_"" :raw-html:`<br>`; Motohiro Kawahito, Hideaki Komatsu, and Toshio Nakatani :raw-html:`<br>`; Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design; and Implementation. .. _Select instructions from DAG:. SelectionDAG Select Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^. The Select phase is the bulk of the target",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:47597,Usability,simpl,simple,47597,"^^^^^^^^^^^^. The Select phase is the bulk of the target-specific code for instruction; selection. This phase takes a legal SelectionDAG as input, pattern matches the; instructions supported by the target to this DAG, and produces a new DAG of; target code. For example, consider the following LLVM fragment:. .. code-block:: llvm. %t1 = fadd float %W, %X; %t2 = fmul float %t1, %Y; %t3 = fadd float %t2, %Z. This LLVM code corresponds to a SelectionDAG that looks basically like this:. .. code-block:: text. (fadd:f32 (fmul:f32 (fadd:f32 W, X), Y), Z). If a target supports floating point multiply-and-add (FMA) operations, one of; the adds can be merged with the multiply. On the PowerPC, for example, the; output of the instruction selector might look like this DAG:. ::. (FMADDS (FADDS W, X), Y, Z). The ``FMADDS`` instruction is a ternary instruction that multiplies its first; two operands and adds the third (as single-precision floating-point numbers).; The ``FADDS`` instruction is a simple binary single-precision add instruction.; To perform this pattern match, the PowerPC backend includes the following; instruction definitions:. .. code-block:: text; :emphasize-lines: 4-5,9. def FMADDS : AForm_1<59, 29,; (ops F4RC:$FRT, F4RC:$FRA, F4RC:$FRC, F4RC:$FRB),; ""fmadds $FRT, $FRA, $FRC, $FRB"",; [(set F4RC:$FRT, (fadd (fmul F4RC:$FRA, F4RC:$FRC),; F4RC:$FRB))]>;; def FADDS : AForm_2<59, 21,; (ops F4RC:$FRT, F4RC:$FRA, F4RC:$FRB),; ""fadds $FRT, $FRA, $FRB"",; [(set F4RC:$FRT, (fadd F4RC:$FRA, F4RC:$FRB))]>;. The highlighted portion of the instruction definitions indicates the pattern; used to match the instructions. The DAG operators (like ``fmul``/``fadd``); are defined in the ``include/llvm/Target/TargetSelectionDAG.td`` file.; ""``F4RC``"" is the register class of the input and result values. The TableGen DAG instruction selector generator reads the instruction patterns; in the ``.td`` file and automatically builds parts of the pattern matching code; for your target. It has the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:60592,Usability,simpl,simple,60592,"ed. Each virtual register can only be mapped to physical registers of a; particular class. For instance, in the X86 architecture, some virtuals can only; be allocated to 8 bit registers. A register class is described by; ``TargetRegisterClass`` objects. To discover if a virtual register is; compatible with a given physical, this code can be used:. .. code-block:: c++. bool RegMapping_Fer::compatible_class(MachineFunction &mf,; unsigned v_reg,; unsigned p_reg) {; assert(TargetRegisterInfo::isPhysicalRegister(p_reg) &&; ""Target register must be physical"");; const TargetRegisterClass *trc = mf.getRegInfo().getRegClass(v_reg);; return trc->contains(p_reg);; }. Sometimes, mostly for debugging purposes, it is useful to change the number of; physical registers available in the target architecture. This must be done; statically, inside the ``TargetRegisterInfo.td`` file. Just ``grep`` for; ``RegisterClass``, the last parameter of which is a list of registers. Just; commenting some out is one simple way to avoid them being used. A more polite; way is to explicitly exclude some registers from the *allocation order*. See the; definition of the ``GR8`` register class in; ``lib/Target/X86/X86RegisterInfo.td`` for an example of this. Virtual registers are also denoted by integer numbers. Contrary to physical; registers, different virtual registers never share the same number. Whereas; physical registers are statically defined in a ``TargetRegisterInfo.td`` file; and cannot be created by the application developer, that is not the case with; virtual registers. In order to create new virtual registers, use the method; ``MachineRegisterInfo::createVirtualRegister()``. This method will return a new; virtual register. Use an ``IndexedMap<Foo, VirtReg2IndexFunctor>`` to hold; information per virtual register. If you need to enumerate all virtual; registers, use the function ``TargetRegisterInfo::index2VirtReg()`` to find the; virtual register numbers:. .. code-block:: c++. for (unsigned",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:67820,Usability,simpl,simplifies,67820,"``ADD %EAX, %EBX``, in X86 is actually equivalent to ``%EAX = %EAX +; %EBX``. In order to produce correct code, LLVM must convert three address instructions; that represent two address instructions into true two address instructions. LLVM; provides the pass ``TwoAddressInstructionPass`` for this specific purpose. It; must be run before register allocation takes place. After its execution, the; resulting code may no longer be in SSA form. This happens, for instance, in; situations where an instruction such as ``%a = ADD %b %c`` is converted to two; instructions such as:. ::. %a = MOVE %b; %a = ADD %a %c. Notice that, internally, the second instruction is represented as ``ADD; %a[def/use] %c``. I.e., the register operand ``%a`` is both used and defined by; the instruction. The SSA deconstruction phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. An important transformation that happens during register allocation is called; the *SSA Deconstruction Phase*. The SSA form simplifies many analyses that are; performed on the control flow graph of programs. However, traditional; instruction sets do not implement PHI instructions. Thus, in order to generate; executable code, compilers must replace PHI instructions with other instructions; that preserve their semantics. There are many ways in which PHI instructions can safely be removed from the; target code. The most traditional PHI deconstruction algorithm replaces PHI; instructions with copy instructions. That is the strategy adopted by LLVM. The; SSA deconstruction algorithm is implemented in; ``lib/CodeGen/PHIElimination.cpp``. In order to invoke this pass, the identifier; ``PHIEliminationID`` must be marked as required in the code of the register; allocator. Instruction folding; ^^^^^^^^^^^^^^^^^^^. *Instruction folding* is an optimization performed during register allocation; that removes unnecessary copy instructions. For instance, a sequence of; instructions such as:. ::. %EBX = LOAD %mem_address; %EAX = COPY %EBX. can be safely subs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:80517,Usability,clear,clearResources,80517,"tizer reads instruction classes from a target's itineraries and creates; a deterministic finite automaton (DFA) to represent the state of a packet. A DFA; consists of three major elements: inputs, states, and transitions. The set of; inputs for the generated DFA represents the instruction being added to a; packet. The states represent the possible consumption of functional units by; instructions in a packet. In the DFA, transitions from one state to another; occur on the addition of an instruction to an existing packet. If there is a; legal mapping of functional units to instructions, then the DFA contains a; corresponding transition. The absence of a transition indicates that a legal; mapping does not exist and that the instruction cannot be added to the packet. To generate tables for a VLIW target, add *Target*\ GenDFAPacketizer.inc as a; target to the Makefile in the target directory. The exported API provides three; functions: ``DFAPacketizer::clearResources()``,; ``DFAPacketizer::reserveResources(MachineInstr *MI)``, and; ``DFAPacketizer::canReserveResources(MachineInstr *MI)``. These functions allow; a target packetizer to add an instruction to an existing packet and to check; whether an instruction can be added to a packet. See; ``llvm/CodeGen/DFAPacketizer.h`` for more information. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:81923,Usability,simpl,simplest,81923,"n. Implementing a Native Assembler; ===============================. Though you're probably reading this because you want to write or maintain a; compiler backend, LLVM also fully supports building a native assembler.; We've tried hard to automate the generation of the assembler from the .td files; (in particular the instruction syntax and encodings), which means that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:82189,Usability,simpl,simple,82189,"ns that a large; part of the manual and repetitive data entry can be factored and shared with the; compiler. Instruction Parsing; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:82321,Usability,simpl,simple,82321,"; -------------------. .. note::. To Be Written. Instruction Alias Processing; ----------------------------. Once the instruction is parsed, it enters the MatchInstructionImpl function.; The MatchInstructionImpl function performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32BitMode]>;. In this example, the mnemonic gets mapped into a different one depending on; the current instruction set. Instruction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:82574,Usability,simpl,simply,82574,"n performs alias processing and then does actual; matching. Alias processing is the phase that canonicalizes different lexical forms of the; same instructions down to one representation. There are several different kinds; of alias that are possible to implement and they are listed below in the order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32BitMode]>;. In this example, the mnemonic gets mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instructi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:82887,Usability,simpl,simply,82887," order; that they are processed (which is in order from simplest/weakest to most; complex/powerful). Generally you want to use the first alias mechanism that; meets the needs of your instruction, because it will allow a more concise; description. Mnemonic Aliases; ^^^^^^^^^^^^^^^^. The first phase of alias processing is simple instruction mnemonic remapping for; classes of instructions which are allowed with two different mnemonics. This; phase is a simple and unconditionally remapping from one input mnemonic to one; output mnemonic. It isn't possible for this form of alias to look at the; operands at all, so the remapping must apply for all forms of a given mnemonic.; Mnemonic aliases are defined simply, for example X86 has:. ::. def : MnemonicAlias<""cbw"", ""cbtw"">;; def : MnemonicAlias<""smovq"", ""movsq"">;; def : MnemonicAlias<""fldcww"", ""fldcw"">;; def : MnemonicAlias<""fucompi"", ""fucomip"">;; def : MnemonicAlias<""ud2a"", ""ud2"">;. ... and many others. With a MnemonicAlias definition, the mnemonic is remapped; simply and directly. Though MnemonicAlias's can't look at any aspect of the; instruction (such as the operands) they can depend on global modes (the same; ones supported by the matcher), through a Requires clause:. ::. def : MnemonicAlias<""pushf"", ""pushfq"">, Requires<[In64BitMode]>;; def : MnemonicAlias<""pushf"", ""pushfl"">, Requires<[In32BitMode]>;. In this example, the mnemonic gets mapped into a different one depending on; the current instruction set. Instruction Aliases; ^^^^^^^^^^^^^^^^^^^. The most general phase of alias processing occurs while matching is happening:; it provides new forms for the matcher to match along with a specific instruction; to generate. An instruction alias has two parts: the string to match and the; instruction to generate. For example:. ::. def : InstAlias<""movsx $src, $dst"", (MOVSX16rr8W GR16:$dst, GR8 :$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX16rm8W GR16:$dst, i8mem:$src)>;; def : InstAlias<""movsx $src, $dst"", (MOVSX32rr8 G",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:85139,Usability,simpl,simple,85139,"; def : InstAlias<""movsx $src, $dst"", (MOVSX64rr32 GR64:$dst, GR32 :$src)>;. This shows a powerful example of the instruction aliases, matching the same; mnemonic in multiple different ways depending on what operands are present in; the assembly. The result of instruction aliases can include operands in a; different order than the destination instruction, and can use an input multiple; times, for example:. ::. def : InstAlias<""clrb $reg"", (XOR8rr GR8 :$reg, GR8 :$reg)>;; def : InstAlias<""clrw $reg"", (XOR16rr GR16:$reg, GR16:$reg)>;; def : InstAlias<""clrl $reg"", (XOR32rr GR32:$reg, GR32:$reg)>;; def : InstAlias<""clrq $reg"", (XOR64rr GR64:$reg, GR64:$reg)>;. This example also shows that tied operands are only listed once. In the X86; backend, XOR8rr has two input GR8's and one output GR8 (where an input is tied; to the output). InstAliases take a flattened operand list without duplicates; for tied operands. The result of an instruction alias can also use immediates; and fixed physical registers which are added as simple immediate operands in the; result, for example:. ::. // Fixed Immediate operand.; def : InstAlias<""aad"", (AAD8i8 10)>;. // Fixed register operand.; def : InstAlias<""fcomi"", (COM_FIr ST1)>;. // Simple alias.; def : InstAlias<""fcomi $reg"", (COM_FIr RST:$reg)>;. Instruction aliases can also have a Requires clause to make them subtarget; specific. If the back-end supports it, the instruction printer can automatically emit the; alias rather than what's being aliased. It typically leads to better, more; readable code. If it's better to print out what's being aliased, then pass a '0'; as the third parameter to the InstAlias definition. Instruction Matching; --------------------. .. note::. To Be Written. .. _Implementations of the abstract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:100794,Usability,simpl,simplifies,100794,"d to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic space need to observe 16 byte alignment. The *locals area* is where the llvm compiler reserves space for local variables. The *saved registers area* is where the llvm compiler spills callee saved; registers on entry to the callee. Prolog/Epilog; ^^^^^^^^^^^^^. The llvm prolog and epilog are the same as described in the PowerPC ABI, with; the following exceptions. Callee saved registers are spilled after the frame is; created. This allows the llvm epilog/prolog support to be common with other; targets. The base pointer callee saved register r31 is saved in the TOC slot of; linkage area. This simplifies allocation of space for the base pointer and; makes it convenient to locate programmatically and during debugging. Dynamic Allocation; ^^^^^^^^^^^^^^^^^^. .. note::. TODO - More to come. The NVPTX backend; -----------------. The NVPTX code generator under lib/Target/NVPTX is an open-source version of; the NVIDIA NVPTX code generator for LLVM. It is contributed by NVIDIA and is; a port of the code generator used in the CUDA compiler (nvcc). It targets the; PTX 3.0/3.1 ISA and can target any compute capability greater than or equal to; 2.0 (Fermi). This target is of production quality and should be completely compatible with; the official NVIDIA toolchain. Code Generator Options:. :raw-html:`<table border=""1"" cellspacing=""0"">`; :raw-html:`<tr>`; :raw-html:`<th>Option</th>`; :raw-html:`<th>Description</th>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_20</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 2.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_21</td>`; :raw-html:`<td align=""le",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:103560,Usability,simpl,simplify,103560," backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB) (LSB). Three LSB bits store instruction class which is one of:. ::. BPF_LD 0x0; BPF_LDX 0x1; BPF_ST 0x2; BPF_STX 0x3; BPF_ALU 0x4; BPF_JMP 0x5; (unused) 0x6; BPF_ALU64 0x7. When BPF_CLASS(code) == BPF_ALU or BPF_ALU64 or BPF_JMP,; 4th bit encodes source operand. ::. BPF_X 0x1 use src_reg register as source operand; BPF_K 0x0 use 32 bit immediate as source operand. and four MSB bits store operation code. ::. BPF_ADD 0x0 add; BPF_SUB 0x1 subtract; BPF_MUL 0x2 multiply; BPF_DIV 0x3 divide; BPF_OR 0x4 bitwise logical OR; BPF_AND 0x5 bitwise logical AND; BPF_LSH 0x6 left shift; BPF_RSH 0x7 right shift (zero extended); BPF",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:4055,Availability,down,down,4055,"our work will be used by other people, and you in turn; will depend on the work of others. Any decision you take will affect users; and colleagues, and you should take those consequences into account. Remember; that we're a world-wide community, so you might not be communicating in; someone else's primary language. .. _be respectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and other exclusionary; behavior aren't acceptable. This includes, but is not limited to:. * Violent threats or language directed against another person.; * Discriminatory jokes and language.; * Posting sexually explicit or violent material.; * Posting (or threatening to post) other people's personally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the above behavior. In general, if someone asks you to stop, then stop. Persisting in such; behavior after being asked to stop is considered harassment. .. _when we disagree, try to understand why:. * **When we disagree, try to understand why.** Disagreements, both social and; technical, happen all the time and LLVM is no exception. It is important that; we resolve disagreements and differing views constructively. Remember that; we're different. The strength of LLVM comes from ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:3115,Integrability,depend,depend,3115,"tion, violations of this code outside these spaces may, in rare; cases, affect a person's ability to participate within them, when the conduct; amounts to an egregious violation of this code. If you believe someone is violating the code of conduct, we ask that you report; it by emailing conduct@llvm.org. For more details please see the ; :doc:`Reporting Guide <ReportingGuide>`. .. _be friendly and patient:. * **Be friendly and patient.**. .. _be welcoming:. * **Be welcoming.** We strive to be a community that welcomes and supports; people of all backgrounds and identities. This includes, but is not limited; to members of any race, ethnicity, culture, national origin, colour,; immigration status, social and economic class, educational level, sex, sexual; orientation, gender identity and expression, age, size, family status,; political belief, religion or lack thereof, and mental and physical ability. .. _be considerate:. * **Be considerate.** Your work will be used by other people, and you in turn; will depend on the work of others. Any decision you take will affect users; and colleagues, and you should take those consequences into account. Remember; that we're a world-wide community, so you might not be communicating in; someone else's primary language. .. _be respectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:357,Modifiability,evolve,evolve,357,"..; This work is licensed under a Creative Commons Attribution 3.0 Unported License.; SPDX-License-Identifier: CC-BY-3.0. ==============================; LLVM Community Code of Conduct; ==============================. The LLVM community has always worked to be a welcoming and respectful; community, and we want to ensure that doesn't change as we grow and evolve. To; that end, we have a few ground rules that we ask people to adhere to:. * `be friendly and patient`_,; * `be welcoming`_,; * `be considerate`_,; * `be respectful`_,; * `be careful in the words that you choose and be kind to others`_, and; * `when we disagree, try to understand why`_. This isn't an exhaustive list of things that you can't do. Rather, take it in; the spirit in which it's intended - a guide to make it easier to communicate; and participate in the community. This code of conduct applies to all spaces managed by the LLVM project or The; LLVM Foundation. This includes IRC channels, mailing lists, bug trackers, LLVM; events such as the developer meetings and socials, and any other forums created; by the project that the community uses for communication. It applies to all of; your communication and conduct in these spaces, including emails, chats, things; you say, slides, videos, posters, signs, or even t-shirts you display in these; spaces. . In rare cases, violations of this code outside of these spaces may affect a ; persons ability to participate within these spaces. Important examples ; include `sexual and gender-based violence`_, `hate crimes`_, and `hate speech`_. ; We do not conduct proactive research, but we have an obligation to respond ; to any reported concerns. We are not interested in evaluating severity, ; responding punitively, or holding people accountable. Both the relevance ; and our response is instead focused on how a persons continued participation ; impacts the communitys safety, wellbeing, and inclusivity. We specifically ; prioritize remaining a welcoming community to v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:1900,Safety,safe,safety,1900,"of conduct applies to all spaces managed by the LLVM project or The; LLVM Foundation. This includes IRC channels, mailing lists, bug trackers, LLVM; events such as the developer meetings and socials, and any other forums created; by the project that the community uses for communication. It applies to all of; your communication and conduct in these spaces, including emails, chats, things; you say, slides, videos, posters, signs, or even t-shirts you display in these; spaces. . In rare cases, violations of this code outside of these spaces may affect a ; persons ability to participate within these spaces. Important examples ; include `sexual and gender-based violence`_, `hate crimes`_, and `hate speech`_. ; We do not conduct proactive research, but we have an obligation to respond ; to any reported concerns. We are not interested in evaluating severity, ; responding punitively, or holding people accountable. Both the relevance ; and our response is instead focused on how a persons continued participation ; impacts the communitys safety, wellbeing, and inclusivity. We specifically ; prioritize remaining a welcoming community to victims as well as groups ; subjected to systemic marginalization or underrepresentation. In addition, violations of this code outside these spaces may, in rare; cases, affect a person's ability to participate within them, when the conduct; amounts to an egregious violation of this code. If you believe someone is violating the code of conduct, we ask that you report; it by emailing conduct@llvm.org. For more details please see the ; :doc:`Reporting Guide <ReportingGuide>`. .. _be friendly and patient:. * **Be friendly and patient.**. .. _be welcoming:. * **Be welcoming.** We strive to be a community that welcomes and supports; people of all backgrounds and identities. This includes, but is not limited; to members of any race, ethnicity, culture, national origin, colour,; immigration status, social and economic class, educational level, sex, se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:3636,Security,attack,attack,3636,"e strive to be a community that welcomes and supports; people of all backgrounds and identities. This includes, but is not limited; to members of any race, ethnicity, culture, national origin, colour,; immigration status, social and economic class, educational level, sex, sexual; orientation, gender identity and expression, age, size, family status,; political belief, religion or lack thereof, and mental and physical ability. .. _be considerate:. * **Be considerate.** Your work will be used by other people, and you in turn; will depend on the work of others. Any decision you take will affect users; and colleagues, and you should take those consequences into account. Remember; that we're a world-wide community, so you might not be communicating in; someone else's primary language. .. _be respectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and other exclusionary; behavior aren't acceptable. This includes, but is not limited to:. * Violent threats or language directed against another person.; * Discriminatory jokes and language.; * Posting sexually explicit or violent material.; * Posting (or threatening to post) other people's personally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the abo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:3724,Security,threat,threatened,3724,"t limited; to members of any race, ethnicity, culture, national origin, colour,; immigration status, social and economic class, educational level, sex, sexual; orientation, gender identity and expression, age, size, family status,; political belief, religion or lack thereof, and mental and physical ability. .. _be considerate:. * **Be considerate.** Your work will be used by other people, and you in turn; will depend on the work of others. Any decision you take will affect users; and colleagues, and you should take those consequences into account. Remember; that we're a world-wide community, so you might not be communicating in; someone else's primary language. .. _be respectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and other exclusionary; behavior aren't acceptable. This includes, but is not limited to:. * Violent threats or language directed against another person.; * Discriminatory jokes and language.; * Posting sexually explicit or violent material.; * Posting (or threatening to post) other people's personally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the above behavior. In general, if someone asks you to stop, then stop. Persisting in such; behavior after being asked to stop i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:4192,Security,threat,threats,4192,"ould take those consequences into account. Remember; that we're a world-wide community, so you might not be communicating in; someone else's primary language. .. _be respectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and other exclusionary; behavior aren't acceptable. This includes, but is not limited to:. * Violent threats or language directed against another person.; * Discriminatory jokes and language.; * Posting sexually explicit or violent material.; * Posting (or threatening to post) other people's personally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the above behavior. In general, if someone asks you to stop, then stop. Persisting in such; behavior after being asked to stop is considered harassment. .. _when we disagree, try to understand why:. * **When we disagree, try to understand why.** Disagreements, both social and; technical, happen all the time and LLVM is no exception. It is important that; we resolve disagreements and differing views constructively. Remember that; we're different. The strength of LLVM comes from its varied community, people; from a wide range of backgrounds. Different people have different; perspectives on issues. Being unable to understand why someon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:4348,Security,threat,threatening,4348,"pectful:. * **Be respectful.** Not all of us will agree all the time, but disagreement is; no excuse for poor behavior and poor manners. We might all experience some; frustration now and then, but we cannot allow that frustration to turn into; a personal attack. It's important to remember that a community where people; feel uncomfortable or threatened is not a productive one. Members of the LLVM; community should be respectful when dealing with other members as well as; with people outside the LLVM community. .. _be careful in the words that you choose and be kind to others:. * **Be careful in the words that you choose and be kind to others.** Do not; insult or put down other participants. Harassment and other exclusionary; behavior aren't acceptable. This includes, but is not limited to:. * Violent threats or language directed against another person.; * Discriminatory jokes and language.; * Posting sexually explicit or violent material.; * Posting (or threatening to post) other people's personally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the above behavior. In general, if someone asks you to stop, then stop. Persisting in such; behavior after being asked to stop is considered harassment. .. _when we disagree, try to understand why:. * **When we disagree, try to understand why.** Disagreements, both social and; technical, happen all the time and LLVM is no exception. It is important that; we resolve disagreements and differing views constructively. Remember that; we're different. The strength of LLVM comes from its varied community, people; from a wide range of backgrounds. Different people have different; perspectives on issues. Being unable to understand why someone holds; a viewpoint doesn't mean that they're wrong. Don't forget that it is human to; err and blaming each other doesn't get us anywhere. Instead, focus on helping; to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:5635,Security,confidential,confidential,5635,"stop, then stop. Persisting in such; behavior after being asked to stop is considered harassment. .. _when we disagree, try to understand why:. * **When we disagree, try to understand why.** Disagreements, both social and; technical, happen all the time and LLVM is no exception. It is important that; we resolve disagreements and differing views constructively. Remember that; we're different. The strength of LLVM comes from its varied community, people; from a wide range of backgrounds. Different people have different; perspectives on issues. Being unable to understand why someone holds; a viewpoint doesn't mean that they're wrong. Don't forget that it is human to; err and blaming each other doesn't get us anywhere. Instead, focus on helping; to resolve issues and learning from mistakes. Reporting; =========. If you believe someone is violating the code of conduct you can always report; it to the LLVM Foundation Code of Conduct Committee by emailing; conduct@llvm.org. All reports will be kept confidential. This isn't a public; list and only members of the advisory committee will receive the report. For; details on what to include in the report, please see the :doc:`Reporting Guide; <ReportingGuide>`. If you believe anyone is in physical danger, please notify appropriate law; enforcement first. If you are unsure what law enforcement agency is; appropriate, please include this in your report and we will attempt to notify; them. If the violation occurs at an event such as a Developer Meeting and requires; immediate attention, you can also reach out to any of the event organizers or; staff. Event organizers and staff will be prepared to handle the incident and; able to help. If you cannot find one of the organizers, the venue staff can; locate one for you. We will also post detailed contact information for specific; events as part of each events' information. In person reports will still be; kept confidential exactly as above, but also feel free to (anonymously if; needed",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:6553,Security,confidential,confidential,6553,"emailing; conduct@llvm.org. All reports will be kept confidential. This isn't a public; list and only members of the advisory committee will receive the report. For; details on what to include in the report, please see the :doc:`Reporting Guide; <ReportingGuide>`. If you believe anyone is in physical danger, please notify appropriate law; enforcement first. If you are unsure what law enforcement agency is; appropriate, please include this in your report and we will attempt to notify; them. If the violation occurs at an event such as a Developer Meeting and requires; immediate attention, you can also reach out to any of the event organizers or; staff. Event organizers and staff will be prepared to handle the incident and; able to help. If you cannot find one of the organizers, the venue staff can; locate one for you. We will also post detailed contact information for specific; events as part of each events' information. In person reports will still be; kept confidential exactly as above, but also feel free to (anonymously if; needed) email conduct@llvm.org. Code of Conduct Committee; =========================. The committee will consist of a minimum of 5 members and members are asked to; serve at least a 1 year term. New committee members will be selected by the; current committee and the LLVM Foundation Board of Directors. When responding to a Code of Conduct report, the committee follows the; following ; :doc:`Response Guide<ResponseGuide>`. The current committee members are:. * Kit Barton (kbarton\@llvm.org); * Kristof Beyls (kristof.beyls\@llvm.org); * Stella Stamenova (sstamenova\@llvm.org); * David Blaikie (dblaikie\@llvm.org); * Mike Edwards (medwards\@llvm.org); * Cyndy Ishida (cishida\@llvm.org); * Tanya Lattner (tanyalattner\@llvm.org). Transparency Reports; ====================. * `July 15, 2023 <https://llvm.org/coc-reports/2023-07-15-report.html>`_; * `July 15, 2022 <https://llvm.org/coc-reports/2022-07-15-report.html>`_; * `April 28, 2022 <https://llvm.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:770,Usability,guid,guide,770,"..; This work is licensed under a Creative Commons Attribution 3.0 Unported License.; SPDX-License-Identifier: CC-BY-3.0. ==============================; LLVM Community Code of Conduct; ==============================. The LLVM community has always worked to be a welcoming and respectful; community, and we want to ensure that doesn't change as we grow and evolve. To; that end, we have a few ground rules that we ask people to adhere to:. * `be friendly and patient`_,; * `be welcoming`_,; * `be considerate`_,; * `be respectful`_,; * `be careful in the words that you choose and be kind to others`_, and; * `when we disagree, try to understand why`_. This isn't an exhaustive list of things that you can't do. Rather, take it in; the spirit in which it's intended - a guide to make it easier to communicate; and participate in the community. This code of conduct applies to all spaces managed by the LLVM project or The; LLVM Foundation. This includes IRC channels, mailing lists, bug trackers, LLVM; events such as the developer meetings and socials, and any other forums created; by the project that the community uses for communication. It applies to all of; your communication and conduct in these spaces, including emails, chats, things; you say, slides, videos, posters, signs, or even t-shirts you display in these; spaces. . In rare cases, violations of this code outside of these spaces may affect a ; persons ability to participate within these spaces. Important examples ; include `sexual and gender-based violence`_, `hate crimes`_, and `hate speech`_. ; We do not conduct proactive research, but we have an obligation to respond ; to any reported concerns. We are not interested in evaluating severity, ; responding punitively, or holding people accountable. Both the relevance ; and our response is instead focused on how a persons continued participation ; impacts the communitys safety, wellbeing, and inclusivity. We specifically ; prioritize remaining a welcoming community to v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst:5402,Usability,learn,learning,5402,"onally identifying; information (""doxing"").; * Personal insults, especially those using racist or sexist terms.; * Unwelcome sexual attention.; * Advocating for, or encouraging, any of the above behavior. In general, if someone asks you to stop, then stop. Persisting in such; behavior after being asked to stop is considered harassment. .. _when we disagree, try to understand why:. * **When we disagree, try to understand why.** Disagreements, both social and; technical, happen all the time and LLVM is no exception. It is important that; we resolve disagreements and differing views constructively. Remember that; we're different. The strength of LLVM comes from its varied community, people; from a wide range of backgrounds. Different people have different; perspectives on issues. Being unable to understand why someone holds; a viewpoint doesn't mean that they're wrong. Don't forget that it is human to; err and blaming each other doesn't get us anywhere. Instead, focus on helping; to resolve issues and learning from mistakes. Reporting; =========. If you believe someone is violating the code of conduct you can always report; it to the LLVM Foundation Code of Conduct Committee by emailing; conduct@llvm.org. All reports will be kept confidential. This isn't a public; list and only members of the advisory committee will receive the report. For; details on what to include in the report, please see the :doc:`Reporting Guide; <ReportingGuide>`. If you believe anyone is in physical danger, please notify appropriate law; enforcement first. If you are unsure what law enforcement agency is; appropriate, please include this in your report and we will attempt to notify; them. If the violation occurs at an event such as a Developer Meeting and requires; immediate attention, you can also reach out to any of the event organizers or; staff. Event organizers and staff will be prepared to handle the incident and; able to help. If you cannot find one of the organizers, the venue staff can;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeOfConduct.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeOfConduct.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:312,Availability,robust,robustness,312,"=====================================; LLVM Code-Review Policy and Practices; =====================================. LLVM's code-review policy and practices help maintain high code quality across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2471,Availability,fault,fault,2471,"elated changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:4363,Availability,down,downstream,4363,"er), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7430,Availability,ping,ping,7430,". LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11790,Availability,ping,ping,11790,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11862,Availability,ping,ping,11862,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1041,Deployability,patch,patches,1041,"iew Policy and Practices; =====================================. LLVM's code-review policy and practices help maintain high code quality across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern wou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1096,Deployability,patch,patches,1096,"y across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1109,Deployability,patch,patches,1109,"y across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1225,Deployability,patch,patch,1225,"y across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1338,Deployability,patch,patch,1338," introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1438,Deployability,patch,patch,1438,"butors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault fro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1921,Deployability,patch,patch,1921,"------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2277,Deployability,patch,patch,2277,"eveloper owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2486,Deployability,patch,patch,2486,"elated changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2568,Deployability,patch,patch,2568,"-------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The ori",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2681,Deployability,patch,patch,2681,"-------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The ori",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:2798,Deployability,patch,patch,2798,"pectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ----------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3588,Deployability,patch,patch,3588,"ices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3667,Deployability,patch,patch,3667,"ng reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:4512,Deployability,patch,patches,4512,"ince the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; fr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:4669,Deployability,patch,patch,4669,"t. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:4723,Deployability,patch,patch,4723,"at Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Ef",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:4867,Deployability,patch,patch,4867,"ews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5016,Deployability,patch,patch,5016,"---. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5131,Deployability,patch,patch,5131,"dent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5270,Deployability,patch,patch,5270," significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5380,Deployability,update,updated,5380," significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5388,Deployability,patch,patch,5388," significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6125,Deployability,patch,patch,6125,"thor and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6328,Deployability,patch,patch,6328,"that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6468,Deployability,patch,patch,6468,"evision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6986,Deployability,patch,patch,6986,"ber of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7440,Deployability,patch,patch,7440,". LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7497,Deployability,patch,patch,7497,". LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7665,Deployability,patch,patch,7665,"hen providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:7924,Deployability,patch,patch,7924," be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8036,Deployability,patch,patches,8036," be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8390,Deployability,patch,patch,8390,"ar community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8658,Deployability,patch,patch,8658,"ons, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8906,Deployability,patch,patch,8906,"ly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8944,Deployability,patch,patches,8944,"ly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9004,Deployability,patch,patch,9004,"re of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9059,Deployability,patch,patch,9059,"re of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9133,Deployability,patch,patch,9133,"re of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9218,Deployability,patch,patch,9218,"significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9278,Deployability,update,updates,9278,"significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9458,Deployability,patch,patch,9458,"o know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9615,Deployability,patch,patch,9615,"uld be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9696,Deployability,patch,patch,9696,"uld be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:9968,Deployability,patch,patches,9968,"eview. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Exp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11094,Deployability,patch,patch,11094,", you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11225,Deployability,patch,patch,11225,"nly understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that some",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11290,Deployability,patch,patch,11290,"nly understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that some",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11535,Deployability,patch,patches,11535,"Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11573,Deployability,patch,patches,11573,"be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11693,Deployability,patch,patch,11693," LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but appr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:11773,Deployability,patch,patch,11773,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12109,Deployability,patch,patch,12109,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12137,Deployability,patch,patches,12137,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12189,Deployability,patch,patch,12189,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12357,Deployability,patch,patch,12357,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12675,Deployability,patch,patch,12675,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12698,Deployability,patch,patches,12698,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6372,Energy Efficiency,efficient,efficient,6372,"that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5597,Integrability,message,message,5597,"ing initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6575,Integrability,message,message,6575,"evision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:284,Modifiability,maintainab,maintainability,284,"=====================================; LLVM Code-Review Policy and Practices; =====================================. LLVM's code-review policy and practices help maintain high code quality across; the project. Specifically, our code review process aims to:. * Improve readability and maintainability.; * Improve robustness and prevent the introduction of defects.; * Best leverage the experience of other contributors for each proposed change.; * Help grow and develop new contributors, through mentorship by community leaders. It is important for all contributors to understand our code-review; practices and participate in the code-review process. General Policies; ================. What Code Should Be Reviewed?; -----------------------------. All developers are required to have significant changes reviewed before they; are committed to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6196,Modifiability,refactor,refactoring,6196," must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6237,Performance,perform,performance,6237," must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3022,Security,access,access,3022,"mmit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too signi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:8624,Security,access,access,8624,"ikely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in case others wish to review""). If approval is received very; quickly, a patch author may also elect to wait before committing (and this is; certainly considered polite for non-trivial patches). Especially given the; global nature of our community, this waiting time should be at least 24 hours.; Please also be mindful of weekends and major holidays. Our goal is to ensure community consensus around design decisions and; significant implementation choices, and one responsibility of a reviewer, when; providing an overall approval for a patch, is to be reasonably sure that such; consensus exists. If you're not familiar enough with the community to know,; then you shouldn't be providing final approval to commit. A reviewer providing; final approval should have commit access to the LLVM project. Every patch should be reviewed by at least one technical expert in the areas of; the project affected by the change. Splitting Requests and Conditional Acceptance; ---------------------------------------------. Reviewers may request certain aspects of a patch to be broken out into separate; patches for independent review. Reviewers may also accept a patch; conditioned on the author providing a follow-up patch addressing some; particular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6249,Testability,test,tests,6249," must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:10307,Testability,test,test,10307,"ite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:10365,Testability,test,test,10365,"ite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:1861,Usability,feedback,feedback,1861,"itted to the repository. Must Code Be Reviewed Prior to Being Committed?; -----------------------------------------------. Code can be reviewed either before it is committed or after. We expect; significant patches to be reviewed before being committed. Smaller patches; (or patches where the developer owns the component) that meet; likely-community-consensus requirements (as apply to all patch approvals) can; be committed prior to an explicit review. In situations where there is any; uncertainty, a patch should be reviewed prior to being committed. Please note that the developer responsible for a patch is also; responsible for making all necessary review-related changes, including; those requested during any post-commit review. .. _post_commit_review:. Can Code Be Reviewed After It Is Committed?; -------------------------------------------. Post-commit review is encouraged, and can be accomplished using any of the; tools detailed below. There is a strong expectation that authors respond; promptly to post-commit feedback and address it. Failure to do so is cause for; the patch to be :ref:`reverted <revert_policy>`. If a community member expresses a concern about a recent commit, and this; concern would have been significant enough to warrant a conversation during; pre-commit review (including around the need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo furthe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3148,Usability,feedback,feedback,3148,"he need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3192,Usability,feedback,feedback,3192,"he need for more design discussions),; they may ask for a revert to the original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3241,Usability,feedback,feedback,3241,"e original author who is responsible to revert; the patch promptly. Developers often disagree, and erring on the side of the; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:3425,Usability,feedback,feedback,3425,"e; developer asking for more review prevents any lingering disagreement over; code in the tree. This does not indicate any fault from the patch author,; this is inherent to our post-commit review practices.; Reverting a patch ensures that design discussions can happen without blocking; other development; it's entirely possible the patch will end up being reapplied; essentially as-is once concerns have been resolved. Before being recommitted, the patch generally should undergo further review.; The community member who identified the problem is expected to engage; actively in the review. In cases where the problem is identified by a buildbot,; a community member with access to hardware similar to that on the buildbot is; expected to engage in the review. Please note: The bar for post-commit feedback is not higher than for pre-commit; feedback. Don't delay unnecessarily in providing feedback. However, if you see; something after code has been committed about which you would have commented; pre-commit (had you noticed it earlier), please feel free to provide that; feedback at any time. That having been said, if a substantial period of time has passed since the; original change was committed, it may be better to create a new patch to; address the issues than comment on the original commit. The original patch; author, for example, might no longer be an active contributor to the project. What Tools Are Used for Code Review?; ------------------------------------. Pre-commit code reviews are conducted on GitHub with Pull Requests. See; :ref:`GitHub <github-reviews>` documentation. When Is an RFC Required?; ------------------------. Some changes are too significant for just a code review. Changes that should; change the LLVM Language Reference (e.g., adding new target-independent; intrinsics), adding language extensions in Clang, and so on, require an RFC; (Request for Comment) email on the project's ``*-dev`` mailing list first. For; changes that promise significant impact o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:5310,Usability,feedback,feedback,5310," significant impact on users and/or downstream code bases,; reviewers can request an RFC achieving consensus before proceeding with code; review. That having been said, posting initial patches can help with; discussions on an RFC. Code-Review Workflow; ====================. Code review can be an iterative process, which continues until the patch is; ready to be committed. Specifically, once a patch is sent out for review, it; needs an explicit approval before it is committed. Do not assume silent; approval, or solicit objections to a patch with a deadline. Acknowledge All Reviewer Feedback; ---------------------------------. All comments by reviewers should be acknowledged by the patch author. It is; generally expected that suggested changes will be incorporated into a future; revision of the patch unless the author and/or other reviewers can articulate a; good reason to do otherwise (and then the reviewers must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6841,Usability,feedback,feedback,6841,"ber of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6887,Usability,feedback,feedback,6887,"ber of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if that person hasn't done so yet. Note that, if a reviewer has requested a particular community member to review,; and after a week that community member has yet to respond, feel free to ping; the patch (which literally means submitting a comment on the patch with the; word, ""Ping.""), or alternatively, ask the original reviewer for further; suggestions. If it is likely that others will want to review a recently-posted patch,; especially if there might be objections, but no one else has done so yet, it is; also polite to provide a qualified approval (e.g., ""LGTM, but please wait for a; couple of days in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:10058,Usability,clear,clear,10058,"rticular issue or concern (although no committed patch should leave the; project in a broken state). Moreover, reviewers can accept a patch conditioned on; the author applying some set of minor updates prior to committing, and when; applicable, it is polite for reviewers to do so. Don't Unintentionally Block a Review; ------------------------------------. If you review a patch, but don't intend for the review process to block on your; approval, please state that explicitly. Out of courtesy, we generally wait on; committing a patch until all reviewers are satisfied, and if you don't intend; to look at the patch again in a timely fashion, please communicate that fact in; the review. Who Can/Should Review Code?; ===========================. Non-Experts Should Review Code; ------------------------------. You do not need to be an expert in some area of the code base to review patches;; it's fine to ask questions about what some piece of code is doing. If it's not; clear to you what is going on, you're unlikely to be the only one. Please; remember that it is not in the long-term best interest of the community to have; components that are only understood well by a small number of people. Extra; comments and/or test cases can often help (and asking for comments in the test; cases is fine as well). Moreover, authors are encouraged to interpret questions as a reason to reexamine; the readability of the code in question. Structural changes, or further; comments, may be appropriate. If you're new to the LLVM community, you might also find this presentation helpful:; .. _How to Contribute to LLVM, A 2019 LLVM Developers' Meeting Presentation: https://youtu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12387,Usability,clear,clear,12387,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:12660,Usability,feedback,feedback,12660,"outu.be/C5Y977rLqpw. A good way for new contributors to increase their knowledge of the code base is; to review code. It is perfectly acceptable to review code and explicitly; defer to others for approval decisions. Experts Should Review Code; --------------------------. If you are an expert in an area of the compiler affected by a proposed patch,; then you are highly encouraged to review the code. If you are a relevant code; owner, and no other experts are reviewing a patch, you must either help arrange; for an expert to review the patch or review it yourself. Code Reviews, Speed, and Reciprocity; ------------------------------------. Sometimes code reviews will take longer than you might hope, especially for; larger features. Common ways to speed up review times for your patches are:. * Review other people's patches. If you help out, everybody will be more; willing to do the same for you; goodwill is our currency.; * Ping the patch. If it is urgent, provide reasons why it is important to you to; get this patch landed and ping it every couple of days. If it is; not urgent, the common courtesy ping rate is one week. Remember that you're; asking for valuable time from other professional developers.; * Ask for help on IRC. Developers on IRC will be able to either help you; directly, or tell you who might be a good reviewer.; * Split your patch into multiple smaller patches that build on each other. The; smaller your patch is, the higher the probability that somebody will take a quick; look at it. When doing this, it is helpful to add ""[N/M]"" (for 1 <= N <= M) to; the title of each patch in the series, so it is clear that there is an order; and what that order is. Developers should participate in code reviews as both reviewers and; authors. If someone is kind enough to review your code, you should return the; favor for someone else. Note that anyone is welcome to review and give feedback; on a patch, but approval of patches should be consistent with the policy above.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodeReview.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:2534,Availability,avail,available,2534," to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`). Each toolchain provides a good reference for what it accepts:. * Clang: https://clang.llvm.org/cxx_status.html. * libc++: https://libcxx.llvm.org/Status/Cxx17.html. * GCC: https://gcc.gnu.org/projects/cxx-status.html#cxx17. * libstdc++: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017. * MSVC: https://msdn.microsoft.com/en-us/library/hh567368.aspx. C++ Standard Library; --------------------. Instead of implementing custom data structures, we encourage the use of C++; standard library facilities or LLVM support libraries whenever they are; available for a particular task. LLVM and related projects emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libraries (for example, `ADT; <https://github.com/llvm/llvm-project/tree/main/llvm/include/llvm/ADT>`_); implement specialized data structures or functionality",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:3224,Availability,avail,available,3224," choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`). Each toolchain provides a good reference for what it accepts:. * Clang: https://clang.llvm.org/cxx_status.html. * libc++: https://libcxx.llvm.org/Status/Cxx17.html. * GCC: https://gcc.gnu.org/projects/cxx-status.html#cxx17. * libstdc++: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017. * MSVC: https://msdn.microsoft.com/en-us/library/hh567368.aspx. C++ Standard Library; --------------------. Instead of implementing custom data structures, we encourage the use of C++; standard library facilities or LLVM support libraries whenever they are; available for a particular task. LLVM and related projects emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libraries (for example, `ADT; <https://github.com/llvm/llvm-project/tree/main/llvm/include/llvm/ADT>`_); implement specialized data structures or functionality missing in the standard; library. Such libraries are usually implemented in the ``llvm`` namespace and; follow the expected standard interface, when there is one. When both C++ and the LLVM support libraries provide similar functionality, and; there isn't a specific reason to favor the C++ implementation, it is generally; preferable to use the LLVM library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:4287,Availability,avail,available,4287,"emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libraries (for example, `ADT; <https://github.com/llvm/llvm-project/tree/main/llvm/include/llvm/ADT>`_); implement specialized data structures or functionality missing in the standard; library. Such libraries are usually implemented in the ``llvm`` namespace and; follow the expected standard interface, when there is one. When both C++ and the LLVM support libraries provide similar functionality, and; there isn't a specific reason to favor the C++ implementation, it is generally; preferable to use the LLVM library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like the I/O streams, and instead; use LLVM's streams library (raw_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:4817,Availability,avail,available,4817,"ty, and; there isn't a specific reason to favor the C++ implementation, it is generally; preferable to use the LLVM library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like the I/O streams, and instead; use LLVM's streams library (raw_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14244,Availability,error,error,14244,"s needed. Don't duplicate function or class name at the beginning of the comment.; For humans it is obvious which function or class is being documented;; automatic documentation processing tools are smart enough to bind the comment; to the correct declaration. Avoid:. .. code-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14561,Availability,error,error,14561,"comment; to the correct declaration. Avoid:. .. code-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14599,Availability,error,error,14599,"de-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily ne",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14794,Availability,error,error,14794,": c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15253,Availability,error,errors,15253,"essage; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15269,Availability,error,error,15269,"essage; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15517,Availability,error,error,15517,"n, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:34731,Availability,error,error,34731,"eclared Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When providing an out of line implementation of a function in a source file, do; not open namespace blocks in the source file. Instead, use namespace qualifiers; to help ensure that your definition matches an existing declaration. Do this:. .. code-block:: c++. // Foo.h; namespace llvm {; int foo(const char *s);; }. // Foo.cpp; #include ""Foo.h""; using namespace llvm;; int llvm::foo(const char *s) {; // ...; }. Doing this helps to avoid bugs where the definition does not match the; declaration from the header. For example, the following C++ code defines a new; overload of ``llvm::foo`` instead of providing a definition for the existing; function declared in the header:. .. code-block:: c++. // Foo.cpp; #include ""Foo.h""; namespace llvm {; int foo(char *s) { // Mismatch between ""const char *"" and ""char *""; }; } // namespace llvm. This error will not be caught until the build is nearly complete, when the; linker fails to find a definition for any uses of the original function. If the; function were instead defined with a namespace qualifier, the error would have; been caught immediately when the definition was compiled. Class method implementations must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and how many previous decisions; have to be remembered by the reader to understand a block of code. Aim to; reduce indentation where possible when it doesn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:34945,Availability,error,error,34945,"n a source file, do; not open namespace blocks in the source file. Instead, use namespace qualifiers; to help ensure that your definition matches an existing declaration. Do this:. .. code-block:: c++. // Foo.h; namespace llvm {; int foo(const char *s);; }. // Foo.cpp; #include ""Foo.h""; using namespace llvm;; int llvm::foo(const char *s) {; // ...; }. Doing this helps to avoid bugs where the definition does not match the; declaration from the header. For example, the following C++ code defines a new; overload of ``llvm::foo`` instead of providing a definition for the existing; function declared in the header:. .. code-block:: c++. // Foo.cpp; #include ""Foo.h""; namespace llvm {; int foo(char *s) { // Mismatch between ""const char *"" and ""char *""; }; } // namespace llvm. This error will not be caught until the build is nearly complete, when the; linker fails to find a definition for any uses of the original function. If the; function were instead defined with a namespace qualifier, the error would have; been caught immediately when the definition was compiled. Class method implementations must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and how many previous decisions; have to be remembered by the reader to understand a block of code. Aim to; reduce indentation where possible when it doesn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasOneUse() && doOtherThing(I)) {; ... some long code ....; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45408,Availability,error,error,45408,"ere are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47494,Availability,error,error,47494,"sertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47551,Availability,recover,recoverable,47551,"sertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47563,Availability,error,error,47563,"sertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:49139,Availability,mainten,maintenance,49139,"et"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60114,Availability,avail,available,60114,"e() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:1348,Deployability,patch,patches,1348,"re; particularly important for large-scale code bases that follow a library-based; design (like LLVM). While this document may provide guidance for some mechanical formatting issues,; whitespace, or other ""microscopic details"", these are not fixed standards.; Always follow the golden rule:. .. _Golden Rule:. **If you are extending, enhancing, or bug fixing already implemented code,; use the style that is already being used so that the source is uniform and; easy to follow.**. Note that some code bases (e.g. ``libc++``) have special reasons to deviate; from the coding standards. For example, in the case of ``libc++``, this is; because the naming and other conventions are dictated by the C++ standard. There are some conventions that are not uniformly followed in the code base; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5461,Deployability,patch,patch,5461,"ersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5541,Deployability,patch,patch,5541,"ersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5733,Deployability,patch,patch,5733,"e LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5845,Deployability,patch,patch,5845,"tory should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6078,Deployability,install,install,6078,"`black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6109,Deployability,install,install,6109,"psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to document:. .. _header file c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:8391,Deployability,release,released,8391,"tion -------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// This file contains the declaration of the Instruction class, which is the; /// base class for all of the VM instructions.; ///; //===----------------------------------------------------------------------===//. A few things to note about this particular format: The ""``-*- C++ -*-``"" string; on the first line is there to tell Emacs that the source file is a C++ file, not; a C file (Emacs assumes ``.h`` files are C files by default). .. note::. This tag is not necessary in ``.cpp`` files. The name of the file is also; on the first line, along with a very short description of the purpose of the; file. The next section in the file is a concise note that defines the license that the; file is released under. This makes it perfectly clear what terms the source; code can be distributed under and should not be modified in any way. The main body is a `Doxygen <http://www.doxygen.nl/>`_ comment (identified by; the ``///`` comment marker instead of the usual ``//``) describing the purpose; of the file. The first sentence (or a passage beginning with ``\brief``) is; used as an abstract. Any additional information should be separated by a blank; line. If an algorithm is based on a paper or is described in another source,; provide a reference. Header Guard; """""""""""""""""""""""". The header file's guard should be the all-caps path that a user of this header; would #include, using '_' instead of path separator and extension marker.; For example, the header file; ``llvm/include/llvm/Analysis/Utils/Local.h`` would be ``#include``-ed as; ``#include ""llvm/Analysis/Utils/Local.h""``, so its guard is; ``LLVM_ANALYSIS_UTILS_LOCAL_H``. Class overviews; """"""""""""""""""""""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46872,Deployability,release,release,46872,"Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:17168,Energy Efficiency,reduce,reduce,17168,". and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Also many other projects have; standardized on 80 columns, so some people have already configured their editors; for it (vs something else, like 90 columns). Whitespace; ^^^^^^^^^^. In all cases, prefer s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22269,Energy Efficiency,reduce,reduce,22269,"ing with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:35453,Energy Efficiency,reduce,reduce,35453,"ng a definition for the existing; function declared in the header:. .. code-block:: c++. // Foo.cpp; #include ""Foo.h""; namespace llvm {; int foo(char *s) { // Mismatch between ""const char *"" and ""char *""; }; } // namespace llvm. This error will not be caught until the build is nearly complete, when the; linker fails to find a definition for any uses of the original function. If the; function were instead defined with a namespace qualifier, the error would have; been caught immediately when the definition was compiled. Class method implementations must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and how many previous decisions; have to be remembered by the reader to understand a block of code. Aim to; reduce indentation where possible when it doesn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasOneUse() && doOtherThing(I)) {; ... some long code ....; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:38177,Energy Efficiency,reduce,reduces,38177,"or>(&I)) {; Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS != RHS) {; ...; }; }; }. When you have very, very small loops, this sort of structure is fine. But if it; exceeds more than 10-15 lines, it becomes difficult for people to read and; understand at a glance. The problem with this sort of code is that it gets very; nested very quickly. Meaning that the reader of the code has to keep a lot of; context in their brain to remember what is going immediately on in the loop,; because they don't know if/when the ``if`` conditions will have ``else``\s etc.; It is strongly preferred to structure the loop like this:. .. code-block:: c++. for (Instruction &I : BB) {; auto *BO = dyn_cast<BinaryOperator>(&I);; if (!BO) continue;. Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS == RHS) continue;. ...; }. This has all the benefits of using early exits for functions: it reduces nesting; of the loop, it makes it easier to describe why the conditions are true, and it; makes it obvious to the reader that there is no ``else`` coming up that they; have to push context into their brain for. If a loop is large, this can be a; big understandability win. Don't use ``else`` after a ``return``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. For similar reasons as above (reduction of indentation and easier reading), please; do not use ``'else'`` or ``'else if'`` after something that interrupts control; flow --- like ``return``, ``break``, ``continue``, ``goto``, etc. For example:. .. code-block:: c++. case 'J': {; if (Signed) {; Type = Context.getsigjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; }; }. It is better to write it like this:. .. code-block:: c++. case 'J':; if (Signed) {; Type = Con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:39821,Energy Efficiency,reduce,reduce,39821,"ype();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; } else {; break; // Unnecessary.; }; }; }. It is better to write it like this:. .. code-block:: c++. case 'J':; if (Signed) {; Type = Context.getsigjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_sigjmp_buf;; return QualType();; }; } else {; Type = Context.getjmp_bufType();; if (Type.isNull()) {; Error = ASTContext::GE_Missing_jmp_buf;; return QualType();; }; }; break;. Or better yet (in this case) as:. .. code-block:: c++. case 'J':; if (Signed); Type = Context.getsigjmp_bufType();; else; Type = Context.getjmp_bufType();. if (Type.isNull()) {; Error = Signed ? ASTContext::GE_Missing_sigjmp_buf :; ASTContext::GE_Missing_jmp_buf;; return QualType();; }; break;. The idea is to reduce indentation and the amount of code you have to keep track; of when reading the code. Note: this advice does not apply to a ``constexpr if`` statement. The; substatement of the ``else`` clause may be a discarded statement, so removing; the ``else`` can cause unexpected template instantiations. Thus, the following; example is correct:. .. code-block:: c++. template<typename T>; static constexpr bool VarTempl = true;. template<typename T>; int func() {; if constexpr (VarTempl<T>); return 1;; else; static_assert(!VarTempl<T>);; }. Turn Predicate Loops into Predicate Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. It is very common to write small loops that just compute a boolean value. There; are a number of ways that people commonly write these, but an example of this; sort of thing is:. .. code-block:: c++. bool FoundFoo = false;; for (unsigned I = 0, E = BarList.size(); I != E; ++I); if (BarList[I]->isFoo()) {; FoundFoo = true;; break;; }. if (FoundFoo) {; ...; }. Instead of this sort of loop, we prefer to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:41277,Energy Efficiency,reduce,reduces,41277,"urn 1;; else; static_assert(!VarTempl<T>);; }. Turn Predicate Loops into Predicate Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. It is very common to write small loops that just compute a boolean value. There; are a number of ways that people commonly write these, but an example of this; sort of thing is:. .. code-block:: c++. bool FoundFoo = false;; for (unsigned I = 0, E = BarList.size(); I != E; ++I); if (BarList[I]->isFoo()) {; FoundFoo = true;; break;; }. if (FoundFoo) {; ...; }. Instead of this sort of loop, we prefer to use a predicate function (which may; be `static`_) that uses `early exits`_:. .. code-block:: c++. /// \returns true if the specified list has an element that is a foo.; static bool containsFoo(const std::vector<Bar*> &List) {; for (unsigned I = 0, E = List.size(); I != E; ++I); if (List[I]->isFoo()); return true;; return false;; }; ... if (containsFoo(BarList)) {; ...; }. There are many reasons for doing this: it reduces indentation and factors out; code which can often be shared by other code that checks for the same predicate.; More importantly, it *forces you to pick a name* for the function, and forces; you to write a comment for it. In this silly example, this doesn't add much; value. However, if the condition is complex, this can make it a lot easier for; the reader to understand the code that queries for this predicate. Instead of; being faced with the in-line details of how we check to see if the BarList; contains a foo, we can trust the function name and continue reading with better; locality. The Low-Level Issues; --------------------. Name Types, Functions, Variables, and Enumerators Properly; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Poorly-chosen names can mislead the reader and cause bugs. We cannot stress; enough how important it is to use *descriptive* names. Pick names that match; the semantics and role of the underlying entities, within reason. Avoid; abbreviations unless they are well known. Af",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45170,Energy Efficiency,reduce,reduces,45170,"at mimic STL classes can have member names in STL's; style of lower-case words separated by underscores (e.g. ``begin()``,; ``push_back()``, and ``empty()``). Classes that provide multiple; iterators should add a singular prefix to ``begin()`` and ``end()``; (e.g. ``global_begin()`` and ``use_begin()``). Here are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45883,Energy Efficiency,allocate,allocate,45883,"light = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:50218,Energy Efficiency,reduce,reduces,50218,"ing explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'), but should not use any others. Provide a Virtual Method Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a header file and has a vtable (either it has virtual; methods or it derives from classes with virtual methods), it must always have at; least one out-of-line virtual method in the class. Without this, the compiler; will copy the vtable and RTTI into every ``.o`` file that ``#include``\s the; header, bloating ``.o`` file sizes and increasing link times. Don't use default labels in fully covered switches over enumerations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``-Wswitch`` warns if a switch, without a default label, over an enumeration; does not cover every enumeration value. If you ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:53978,Energy Efficiency,efficient,efficient,53978,"o I = BB->begin(); I != BB->end(); ++I); ... use I ... The problem with this construct is that it evaluates ""``BB->end()``"" every time; through the loop. Instead of writing the loop like this, we strongly prefer; loops to be written so that they evaluate it once before the loop starts. A; convenient way to do this is like so:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(), E = BB->end(); I != E; ++I); ... use I ... The observant may quickly point out that these two loops may have different; semantics: if the container (a basic block in this case) is being mutated, then; ""``BB->end()``"" may change its value every time through the loop and the second; loop may not in fact be correct. If you actually do depend on this behavior,; please write the loop in the first form and add a comment indicating that you; did it intentionally. Why do we prefer the second form (when correct)? Writing the loop in the first; form has two problems. First it may be less efficient than evaluating it at the; start of the loop. In this case, the cost is probably minor --- a few extra; loads every time through the loop. However, if the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55722,Energy Efficiency,efficient,efficient,55722,"ing at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations and constant references; to ``raw_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these are equivalent:. .. code-block:: c++. std::cout << std::endl;; std::cout << '\n' << std::flush;. Most of the time, you probably have no reason to flush the output stream, so; it's better to use a literal ``'\n'``. Don't use ``inline`` when defining a function in a class definition; ^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:58507,Energy Efficiency,reduce,reduce,58507,"cks) ... somefunc(42);; assert(3 != 4 && ""laws of math are failing me"");. A = foo(42, 92) + bar(X);. The reason for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is useful; because we want code to `fit into 80 columns`_ without excessive wrapping, but; also because it makes it easier to understand the code. To facilitate this and; avoid some insanely deep nesting on occasion, don't indent namespaces. If it; helps readability, feel free to add a comment indicating what namespace is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60336,Energy Efficiency,reduce,reduce,60336," a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-referenc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:3697,Integrability,interface,interface,3697,"chain provides a good reference for what it accepts:. * Clang: https://clang.llvm.org/cxx_status.html. * libc++: https://libcxx.llvm.org/Status/Cxx17.html. * GCC: https://gcc.gnu.org/projects/cxx-status.html#cxx17. * libstdc++: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017. * MSVC: https://msdn.microsoft.com/en-us/library/hh567368.aspx. C++ Standard Library; --------------------. Instead of implementing custom data structures, we encourage the use of C++; standard library facilities or LLVM support libraries whenever they are; available for a particular task. LLVM and related projects emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libraries (for example, `ADT; <https://github.com/llvm/llvm-project/tree/main/llvm/include/llvm/ADT>`_); implement specialized data structures or functionality missing in the standard; library. Such libraries are usually implemented in the ``llvm`` namespace and; follow the expected standard interface, when there is one. When both C++ and the LLVM support libraries provide similar functionality, and; there isn't a specific reason to favor the C++ implementation, it is generally; preferable to use the LLVM library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like the I/O streams, and instead; use LLVM's streams library (raw_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current min",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:9859,Integrability,interface,interfaces,9859,"an algorithm is based on a paper or is described in another source,; provide a reference. Header Guard; """""""""""""""""""""""". The header file's guard should be the all-caps path that a user of this header; would #include, using '_' instead of path separator and extension marker.; For example, the header file; ``llvm/include/llvm/Analysis/Utils/Local.h`` would be ``#include``-ed as; ``#include ""llvm/Analysis/Utils/Local.h""``, so its guard is; ``LLVM_ANALYSIS_UTILS_LOCAL_H``. Class overviews; """""""""""""""""""""""""""""". Classes are a fundamental part of an object-oriented design. As such, a; class definition should have a comment block that explains what the class is; used for and how it works. Every non-trivial class is expected to have a; ``doxygen`` comment block. Method information; """""""""""""""""""""""""""""""""""". Methods and global functions should also be documented. A quick note about; what it does and a description of the edge cases is all that is necessary here.; The reader should be able to understand how to use interfaces without reading; the code itself. Good things to talk about here are what happens when something unexpected; happens, for instance, does the method return null?. Comment Formatting; ^^^^^^^^^^^^^^^^^^. In general, prefer C++-style comments (``//`` for normal comments, ``///`` for; ``doxygen`` documentation comments). There are a few cases when it is; useful to use C-style (``/* */``) comments however:. #. When writing C code to be compatible with C89. #. When writing a header file that may be ``#include``\d by a C source file. #. When writing a source file that is used by a tool that only accepts C-style; comments. #. When documenting the significance of constants used as actual parameters in; a call. This is most helpful for ``bool`` parameters, or passing ``0`` or; ``nullptr``. The comment should contain the parameter name, which ought to be; meaningful. For example, it's not clear what the parameter means in this call:. .. code-block:: c++. Object.emitName(nullptr);. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:11443,Integrability,interface,interfaces,11443," tool that only accepts C-style; comments. #. When documenting the significance of constants used as actual parameters in; a call. This is most helpful for ``bool`` parameters, or passing ``0`` or; ``nullptr``. The comment should contain the parameter name, which ought to be; meaningful. For example, it's not clear what the parameter means in this call:. .. code-block:: c++. Object.emitName(nullptr);. An in-line C-style comment makes the intent obvious:. .. code-block:: c++. Object.emitName(/*Prefix=*/nullptr);. Commenting out large blocks of code is discouraged, but if you really have to do; this (for documentation purposes or as a suggestion for debug printing), use; ``#if 0`` and ``#endif``. These nest properly and are better behaved in general; than C style comments. Doxygen Use in Documentation Comments; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use the ``\file`` command to turn the standard file header into a file-level; comment. Include descriptive paragraphs for all public interfaces (public classes,; member and non-member functions). Avoid restating the information that can; be inferred from the API name. The first sentence (or a paragraph beginning; with ``\brief``) is used as an abstract. Try to use a single sentence as the; ``\brief`` adds visual clutter. Put detailed discussion into separate; paragraphs. To refer to parameter names inside a paragraph, use the ``\p name`` command.; Don't use the ``\arg name`` command since it starts a new paragraph that; contains documentation for the parameter. Wrap non-inline code examples in ``\code ... \endcode``. To document a function parameter, start a new paragraph with the; ``\param name`` command. If the parameter is used as an out or an in/out; parameter, use the ``\param [out] name`` or ``\param [in,out] name`` command,; respectively. To describe function return value, start a new paragraph with the ``\returns``; command. A minimal documentation comment:. .. code-block:: c++. /// Sets the xyzzy property to \p Baz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14040,Integrability,message,messages,14040,"ments for public APIs into the; header file. Documentation comments for private APIs can go to the; implementation file. In any case, implementation files can include additional; comments (not necessarily in Doxygen markup) to explain implementation details; as needed. Don't duplicate function or class name at the beginning of the comment.; For humans it is obvious which function or class is being documented;; automatic documentation processing tools are smart enough to bind the comment; to the correct declaration. Avoid:. .. code-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14250,Integrability,message,message,14250,"s needed. Don't duplicate function or class name at the beginning of the comment.; For humans it is obvious which function or class is being documented;; automatic documentation processing tools are smart enough to bind the comment; to the correct declaration. Avoid:. .. code-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14567,Integrability,message,message,14567,"comment; to the correct declaration. Avoid:. .. code-block:: c++. // Example.h:. // example - Does something important.; void example();. // Example.cpp:. // example - Does something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:14690,Integrability,message,message,14690,"oes something important.; void example() { ... }. Preferred:. .. code-block:: c++. // Example.h:. /// Does something important.; void example();. // Example.cpp:. /// Builds a B-tree in order to do foo. See paper by...; void example() { ... }. Error and Warning Messages; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Clear diagnostic messages are important to help users identify and fix issues in; their inputs. Use succinct but correct English prose that gives the user the; context needed to understand what went wrong. Also, to match error message; styles commonly produced by other tools, start the first sentence with a; lower-case letter, and finish the last sentence without a period, if it would; end in one otherwise. Sentences which end with different punctuation, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15497,Integrability,message,message,15497,"n, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15523,Integrability,message,messages,15523,"n, such as; ""did you forget ';'?"", should still do so. For example this is a good error message:. .. code-block:: none. error: file.o: section header 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15543,Integrability,message,messages,15543,"er 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hid",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:16351,Integrability,interface,interface,16351,"are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:16566,Integrability,interface,interfaces,16566,"same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:16630,Integrability,depend,dependencies,16630,"same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:16793,Integrability,interface,interfaces,16793," comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somew",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:16980,Integrability,depend,depends,16980,"odule Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:17023,Integrability,depend,depends,17023,"odule Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hidden dependencies which are not explicitly; ``#include``\d in the header, but should be. It is also a form of documentation; in the ``.cpp`` file to indicate where the interfaces it implements are defined. LLVM project and subproject headers should be grouped from most specific to least; specific, for the same reasons described above. For example, LLDB depends on; both clang and LLVM, and clang depends on LLVM. So an LLDB source file should; include ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22180,Integrability,interface,interface,22180,"lvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:29004,Integrability,wrap,wrapper,29004,"^^. In general, there is no relative ordering among pointers. As a result,; when unordered containers like sets and maps are used with pointer keys; the iteration order is undefined. Hence, iterating such containers may; result in non-deterministic code generation. While the generated code; might work correctly, non-determinism can make it harder to reproduce bugs and; debug the compiler. In case an ordered result is expected, remember to; sort an unordered container before iteration. Or use ordered containers; like ``vector``/``MapVector``/``SetVector`` if you want to iterate pointer; keys. Beware of non-deterministic sorting order of equal elements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``std::sort`` uses a non-stable sorting algorithm in which the order of equal; elements is not guaranteed to be preserved. Thus using ``std::sort`` for a; container having equal elements may result in non-deterministic behavior.; To uncover such instances of non-determinism, LLVM has introduced a new; llvm::sort wrapper function. For an EXPENSIVE_CHECKS build this will randomly; shuffle the container before sorting. Default to using ``llvm::sort`` instead; of ``std::sort``. Style Issues; ============. The High-Level Issues; ---------------------. Self-contained Headers; ^^^^^^^^^^^^^^^^^^^^^^. Header files should be self-contained (compile on their own) and end in ``.h``.; Non-header files that are meant for inclusion should end in ``.inc`` and be; used sparingly. All header files should be self-contained. Users and refactoring tools should; not have to adhere to special conditions to include the header. Specifically, a; header should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:30216,Integrability,interface,interface,30216," The High-Level Issues; ---------------------. Self-contained Headers; ^^^^^^^^^^^^^^^^^^^^^^. Header files should be self-contained (compile on their own) and end in ``.h``.; Non-header files that are meant for inclusion should end in ``.inc`` and be; used sparingly. All header files should be self-contained. Users and refactoring tools should; not have to adhere to special conditions to include the header. Specifically, a; header should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such files with the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:30263,Integrability,depend,dependences,30263,"er files should be self-contained (compile on their own) and end in ``.h``.; Non-header files that are meant for inclusion should end in ``.inc`` and be; used sparingly. All header files should be self-contained. Users and refactoring tools should; not have to adhere to special conditions to include the header. Specifically, a; header should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such files with the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:30674,Integrability,depend,dependencies,30674,"eader should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such files with the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before thei",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:30972,Integrability,depend,dependencies,30972,"h the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31060,Integrability,depend,dependencies,31060,"uld be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31128,Integrability,depend,dependencies,31128,"uld be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31386,Integrability,depend,dependencies,31386," files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31472,Integrability,depend,dependencies,31472," files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31506,Integrability,depend,depends,31506," files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31597,Integrability,depend,dependencies,31597," files (for example ``include/llvm/Foo``) defines a; library (``Foo``). One library (both; its headers and implementation) should only use things from the libraries; listed in its dependencies. Some of this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31707,Integrability,depend,depended,31707," this constraint can be enforced by classic Unix linkers (Mac & Windows; linkers, as well as lld, do not enforce this constraint). A Unix linker; searches left to right through the libraries specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can incl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:32998,Integrability,depend,dependencies,32998,"ve the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; you'll find out about later. Keep ""Internal"" Headers Private; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Many modules have a complex implementation that causes them to use more than one; implementation (``.cpp``) file. It is often tempting to put the internal; communication interface (helper classes, extra functions, etc) in the public; module header file. Don't do this!. If you really need to do something like this, put a private header file in the; same directory as the source files, and include it locally. This ensures that; your private interface remains private and undisturbed by outsiders. .. note::. It's okay to put extra implementation methods in a public class itself. Just; make them private (or protected) and all is well. Use Namespace Qualifiers to Implement Previously Declared Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When providing an out of line implementation of a function in a source file, do; not open namespace blocks in the sou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:33282,Integrability,interface,interface,33282,"need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; you'll find out about later. Keep ""Internal"" Headers Private; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Many modules have a complex implementation that causes them to use more than one; implementation (``.cpp``) file. It is often tempting to put the internal; communication interface (helper classes, extra functions, etc) in the public; module header file. Don't do this!. If you really need to do something like this, put a private header file in the; same directory as the source files, and include it locally. This ensures that; your private interface remains private and undisturbed by outsiders. .. note::. It's okay to put extra implementation methods in a public class itself. Just; make them private (or protected) and all is well. Use Namespace Qualifiers to Implement Previously Declared Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When providing an out of line implementation of a function in a source file, do; not open namespace blocks in the source file. Instead, use namespace qualifiers; to help ensure that your definition matches an existing declaration. Do this:. .. code-block:: c++. // Foo.h; namespace llvm {; int foo(const char *s);; }. // Foo.cpp; #include ""Foo.h""; using namespace llvm;; int llvm::foo(const char *s) {; // ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:33554,Integrability,interface,interface,33554,"go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; you'll find out about later. Keep ""Internal"" Headers Private; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Many modules have a complex implementation that causes them to use more than one; implementation (``.cpp``) file. It is often tempting to put the internal; communication interface (helper classes, extra functions, etc) in the public; module header file. Don't do this!. If you really need to do something like this, put a private header file in the; same directory as the source files, and include it locally. This ensures that; your private interface remains private and undisturbed by outsiders. .. note::. It's okay to put extra implementation methods in a public class itself. Just; make them private (or protected) and all is well. Use Namespace Qualifiers to Implement Previously Declared Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When providing an out of line implementation of a function in a source file, do; not open namespace blocks in the source file. Instead, use namespace qualifiers; to help ensure that your definition matches an existing declaration. Do this:. .. code-block:: c++. // Foo.h; namespace llvm {; int foo(const char *s);; }. // Foo.cpp; #include ""Foo.h""; using namespace llvm;; int llvm::foo(const char *s) {; // ...; }. Doing this helps to avoid bugs where the definition does not match the; declaration from the header. For example, the following C++ code defines a new; overload of ``llvm::foo`` instead of providing a definition for the existing; function declared in the header:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45414,Integrability,message,message,45414,"ere are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46777,Integrability,message,message,46777,"rn Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:53727,Integrability,depend,depend,53727,"icit iterator-based loop, pay close attention to whether; ``end()`` is re-evaluated on each loop iteration. One common mistake is to; write a loop in this style:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(); I != BB->end(); ++I); ... use I ... The problem with this construct is that it evaluates ""``BB->end()``"" every time; through the loop. Instead of writing the loop like this, we strongly prefer; loops to be written so that they evaluate it once before the loop starts. A; convenient way to do this is like so:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(), E = BB->end(); I != E; ++I); ... use I ... The observant may quickly point out that these two loops may have different; semantics: if the container (a basic block in this case) is being mutated, then; ""``BB->end()``"" may change its value every time through the loop and the second; loop may not in fact be correct. If you actually do depend on this behavior,; please write the loop in the first form and add a comment indicating that you; did it intentionally. Why do we prefer the second form (when correct)? Writing the loop in the first; form has two problems. First it may be less efficient than evaluating it at the; start of the loop. In this case, the cost is probably minor --- a few extra; loads every time through the loop. However, if the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55163,Integrability,inject,inject,55163,"f the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:58626,Integrability,wrap,wrapping,58626,"son for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is useful; because we want code to `fit into 80 columns`_ without excessive wrapping, but; also because it makes it easier to understand the code. To facilitate this and; avoid some insanely deep nesting on occasion, don't indent namespaces. If it; helps readability, feel free to add a comment indicating what namespace is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:646,Modifiability,extend,extending,646,"=====================; LLVM Coding Standards; =====================. .. contents::; :local:. Introduction; ============. This document describes coding standards that are used in the LLVM project.; Although no coding standards should be regarded as absolute requirements to be; followed in all instances, coding standards are; particularly important for large-scale code bases that follow a library-based; design (like LLVM). While this document may provide guidance for some mechanical formatting issues,; whitespace, or other ""microscopic details"", these are not fixed standards.; Always follow the golden rule:. .. _Golden Rule:. **If you are extending, enhancing, or bug fixing already implemented code,; use the style that is already being used so that the source is uniform and; easy to follow.**. Note that some code bases (e.g. ``libc++``) have special reasons to deviate; from the coding standards. For example, in the case of ``libc++``, this is; because the naming and other conventions are dictated by the C++ standard. There are some conventions that are not uniformly followed in the code base; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:1667,Modifiability,maintainab,maintainability,1667,"nding, enhancing, or bug fixing already implemented code,; use the style that is already being used so that the source is uniform and; easy to follow.**. Note that some code bases (e.g. ``libc++``) have special reasons to deviate; from the coding standards. For example, in the case of ``libc++``, this is; because the naming and other conventions are dictated by the C++ standard. There are some conventions that are not uniformly followed in the code base; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:2112,Modifiability,portab,portable,2112,"; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`). Each toolchain provides a good reference for what it accepts:. * Clang: https://clang.llvm.org/cxx_status.html. * libc++: https://libcxx.llvm.org/Status/Cxx17.html. * GCC: https://gcc.gnu.org/projects/cxx-status.html#cxx17. * libstdc++: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017. * MSVC: https://msdn.microsoft.com/en-us/library/hh567368.aspx. C++ Standard Library; --------------------. Instead of implementing custom dat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6836,Modifiability,maintainab,maintainability,6836,". When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to document:. .. _header file comment:. File Headers; """""""""""""""""""""""". Every source file should have a header on it that describes the basic purpose of; the file. The standard header looks like this:. .. code-block:: c++. //===-- llvm/Instruction.h - Instruction class definition -------*- C++ -*-===//; //; // Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.; // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// This file contains the declaration of the Instruction class, which is the; /// base class for all of the VM instructions.; ///",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:18085,Modifiability,config,configured,18085,"de ``lldb`` headers first, followed by ``clang`` headers, followed by; ``llvm`` headers, to reduce the possibility (for example) of an LLDB header; accidentally picking up a missing include due to the previous inclusion of that; header in the main source file or some earlier header file. clang should; similarly include its own headers before including llvm headers. This rule; applies to all LLVM subprojects. .. _fit into 80 columns:. Source Code Width; ^^^^^^^^^^^^^^^^^. Write your code to fit within 80 columns. There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Also many other projects have; standardized on 80 columns, so some people have already configured their editors; for it (vs something else, like 90 columns). Whitespace; ^^^^^^^^^^. In all cases, prefer spaces to tabs in source files. People have different; preferred indentation levels, and different styles of indentation that they; like; this is fine. What isn't fine is that different editors/viewers expand; tabs out to different tab stops. This can cause your code to look completely; unreadable, and it is not worth dealing with. As always, follow the `Golden Rule`_ above: follow the style of existing code; if you are modifying and extending it. Do not add trailing whitespace. Some common editors will automatically remove; trailing whitespace when saving a file which causes unrelated changes to appear; in diffs and commits. Format Lambdas Like Blocks Of Code; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". When formatting a multi-line lambda, format it like a block of code. If there; is only one multi-line lambda in a statement, and there are no expressions; lexically afte",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:18639,Modifiability,extend,extending,18639," There must be some limit to the width of the code in; order to allow developers to have multiple files side-by-side in; windows on a modest display. If you are going to pick a width limit, it is; somewhat arbitrary but you might as well pick something standard. Going with 90; columns (for example) instead of 80 columns wouldn't add any significant value; and would be detrimental to printing out code. Also many other projects have; standardized on 80 columns, so some people have already configured their editors; for it (vs something else, like 90 columns). Whitespace; ^^^^^^^^^^. In all cases, prefer spaces to tabs in source files. People have different; preferred indentation levels, and different styles of indentation that they; like; this is fine. What isn't fine is that different editors/viewers expand; tabs out to different tab stops. This can cause your code to look completely; unreadable, and it is not worth dealing with. As always, follow the `Golden Rule`_ above: follow the style of existing code; if you are modifying and extending it. Do not add trailing whitespace. Some common editors will automatically remove; trailing whitespace when saving a file which causes unrelated changes to appear; in diffs and commits. Format Lambdas Like Blocks Of Code; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". When formatting a multi-line lambda, format it like a block of code. If there; is only one multi-line lambda in a statement, and there are no expressions; lexically after it in the statement, drop the indent to the standard two space; indent for a block of code, as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20464,Modifiability,variab,variables,20464,"turn true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20549,Modifiability,variab,variables,20549,"nction object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22070,Modifiability,portab,portable,22070,"MContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * Whe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22115,Modifiability,portab,portable,22115,"lvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:22949,Modifiability,variab,variables,22949," = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce code and executable size, LLVM does not use exceptions; or RTTI (`runtime type information; <https://en.wikipedia.org/wiki/Run-time_type_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors and destructors (e.g., global variables whose types have a; constructor or destructor) should not be added to the code base, and should be; removed wherever possible. Globals in different source files are initialized in `arbitrary order; <https://yosefk.com/c++fqa/ctors.html#fqa-10.12>`_, making the code more; difficult to reason about. Static constructors have negative impact on launch time of programs that use; LLVM as a library. We would really like for there to be zero cost for linking; in an additional LLVM target or other library into an application, but static; constructors undermine this goal. Use of ``class`` and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:23346,Modifiability,variab,variables,23346,"ype_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors and destructors (e.g., global variables whose types have a; constructor or destructor) should not be added to the code base, and should be; removed wherever possible. Globals in different source files are initialized in `arbitrary order; <https://yosefk.com/c++fqa/ctors.html#fqa-10.12>`_, making the code more; difficult to reason about. Static constructors have negative impact on launch time of programs that use; LLVM as a library. We would really like for there to be zero cost for linking; in an additional LLVM target or other library into an application, but static; constructors undermine this goal. Use of ``class`` and ``struct`` Keywords; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In C++, the ``class`` and ``struct`` keywords can be used almost; interchangeably. The only difference is when they are used to declare a class:; ``class`` makes all members private by default while ``struct`` makes all; members public by default. * All declarations and definitions of a given ``class`` or ``struct`` must use; the same keyword. For example:. .. code-block:: c++. // Avoid if `Example",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:26195,Modifiability,variab,variable,26195,"logic or if you care that you're calling some; *particular* constructor. Those should look like function calls using; parentheses rather than like aggregate initialization. Similarly, if you need; to explicitly name the type and call its constructor to create a temporary,; don't use a braced initializer list. Instead, use a braced initializer list; (without any type for temporaries) when doing aggregate initialization or; something notionally equivalent. Examples:. .. code-block:: c++. class Foo {; public:; // Construct a Foo by reading data from the disk in the whizbang format, ...; Foo(std::string filename);. // Construct a Foo by looking up the Nth element of some global data ...; Foo(int N);. // ...; };. // The Foo constructor call is reading a file, don't use braces to call it.; std::fill(foo.begin(), foo.end(), Foo(""name""));. // The pair is being constructed like an aggregate, use braces.; bar_map.insert({my_key, my_value});. If you use a braced initializer list when initializing a variable, use an equals before the open curly brace:. .. code-block:: c++. int data[] = {0, 1, 2, 3};. Use ``auto`` Type Deduction to Make Code More Readable; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some are advocating a policy of ""almost always ``auto``"" in C++11, however LLVM; uses a more moderate stance. Use ``auto`` if and only if it makes the code more; readable or easier to maintain. Don't ""almost always"" use ``auto``, but do use; ``auto`` with initializers like ``cast<Foo>(...)`` or other places where the; type is already obvious from the context. Another time when ``auto`` works well; for these purposes is when the type would have been abstracted away anyways,; often behind a container's typedef such as ``std::vector<T>::iterator``. Similarly, C++14 adds generic lambda expressions where parameter types can be; ``auto``. Use these where you would have used a template. Beware unnecessary copies with ``auto``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The convenie",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:29518,Modifiability,refactor,refactoring,29518,"ter; keys. Beware of non-deterministic sorting order of equal elements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``std::sort`` uses a non-stable sorting algorithm in which the order of equal; elements is not guaranteed to be preserved. Thus using ``std::sort`` for a; container having equal elements may result in non-deterministic behavior.; To uncover such instances of non-determinism, LLVM has introduced a new; llvm::sort wrapper function. For an EXPENSIVE_CHECKS build this will randomly; shuffle the container before sorting. Default to using ``llvm::sort`` instead; of ``std::sort``. Style Issues; ============. The High-Level Issues; ---------------------. Self-contained Headers; ^^^^^^^^^^^^^^^^^^^^^^. Header files should be self-contained (compile on their own) and end in ``.h``.; Non-header files that are meant for inclusion should end in ``.inc`` and be; used sparingly. All header files should be self-contained. Users and refactoring tools should; not have to adhere to special conditions to include the header. Specifically, a; header should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such files with the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:32050,Modifiability,inherit,inherit,32050,"is doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:43567,Modifiability,variab,variables,43567,"isLValue()``). Different kinds of declarations have different rules:. * **Type names** (including classes, structs, enums, typedefs, etc) should be; nouns and start with an upper-case letter (e.g. ``TextFileReader``). * **Variable names** should be nouns (as they represent state). The name should; be camel case, and start with an upper case letter (e.g. ``Leader`` or; ``Boats``). * **Function names** should be verb phrases (as they represent actions), and; command-like function should be imperative. The name should be camel case,; and start with a lower case letter (e.g. ``openFile()`` or ``isFoo()``). * **Enum declarations** (e.g. ``enum Foo {...}``) are types, so they should; follow the naming conventions for types. A common use for enums is as a; discriminator for a union, or an indicator of a subclass. When an enum is; used for something like this, it should have a ``Kind`` suffix; (e.g. ``ValueKind``). * **Enumerators** (e.g. ``enum { Foo, Bar }``) and **public member variables**; should start with an upper-case letter, just like types. Unless the; enumerators are defined in their own small namespace or inside a class,; enumerators should have a prefix corresponding to the enum declaration name.; For example, ``enum ValueKind { ... };`` may contain enumerators like; ``VK_Argument``, ``VK_BasicBlock``, etc. Enumerators that are just; convenience constants are exempt from the requirement for a prefix. For; instance:. .. code-block:: c++. enum {; MaxSize = 42,; Density = 12; };. As an exception, classes that mimic STL classes can have member names in STL's; style of lower-case words separated by underscores (e.g. ``begin()``,; ``push_back()``, and ``empty()``). Classes that provide multiple; iterators should add a singular prefix to ``begin()`` and ``end()``; (e.g. ``global_begin()`` and ``use_begin()``). Here are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Bet",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:49452,Modifiability,portab,portable,49452,"g. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'),",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:49549,Modifiability,portab,portability,49549,".insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'), but should not use any others. Provide a Virtual Method Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60080,Modifiability,variab,variables,60080,"nderstanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:61845,Modifiability,maintainab,maintainability,61845," char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-reference; faraway places in the file to tell that the function is local. Don't Use Braces on Simple Single-Statement Bodies of if/else/loop Statements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When writing the body of an ``if``, ``else``, or for/while loop statement, we; prefer to omit the braces to avoid unnecessary line noise. However, braces; should be used in cases where the omission of braces harm the readability and; maintainability of the code. We consider that readability is harmed when omitting the brace in the presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20004,Performance,load,loads,20004," only one multi-line lambda in a statement, and there are no expressions; lexically after it in the statement, drop the indent to the standard two space; indent for a block of code, as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20196,Performance,perform,perform,20196," as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:31895,Performance,perform,performance,31895,"s specified on its command line and; never revisits a library. In this way, no circular dependencies between; libraries can exist. This doesn't fully enforce all inter-library dependencies, and importantly; doesn't enforce header file circular dependencies created by inline functions.; A good way to answer the ""is this layered correctly"" would be to consider; whether a Unix linker would succeed at linking the program if all inline; functions were defined out-of-line. (& for all valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include y",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:54092,Performance,load,loads,54092,"t is that it evaluates ""``BB->end()``"" every time; through the loop. Instead of writing the loop like this, we strongly prefer; loops to be written so that they evaluate it once before the loop starts. A; convenient way to do this is like so:. .. code-block:: c++. BasicBlock *BB = ...; for (auto I = BB->begin(), E = BB->end(); I != E; ++I); ... use I ... The observant may quickly point out that these two loops may have different; semantics: if the container (a basic block in this case) is being mutated, then; ""``BB->end()``"" may change its value every time through the loop and the second; loop may not in fact be correct. If you actually do depend on this behavior,; please write the loop in the first form and add a comment indicating that you; did it intentionally. Why do we prefer the second form (when correct)? Writing the loop in the first; form has two problems. First it may be less efficient than evaluating it at the; start of the loop. In this case, the cost is probably minor --- a few extra; loads every time through the loop. However, if the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55434,Performance,perform,performing,55434,"ven have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations and constant references; to ``raw_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:59933,Performance,optimiz,optimization,59933,"is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:2430,Safety,avoid,avoid,2430,"On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`). Each toolchain provides a good reference for what it accepts:. * Clang: https://clang.llvm.org/cxx_status.html. * libc++: https://libcxx.llvm.org/Status/Cxx17.html. * GCC: https://gcc.gnu.org/projects/cxx-status.html#cxx17. * libstdc++: https://gcc.gnu.org/onlinedocs/libstdc++/manual/status.html#status.iso.2017. * MSVC: https://msdn.microsoft.com/en-us/library/hh567368.aspx. C++ Standard Library; --------------------. Instead of implementing custom data structures, we encourage the use of C++; standard library facilities or LLVM support libraries whenever they are; available for a particular task. LLVM and related projects emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:4129,Safety,avoid,avoid,4129,"es or LLVM support libraries whenever they are; available for a particular task. LLVM and related projects emphasize and rely; on the standard library facilities and the LLVM support libraries as much as; possible. LLVM support libraries (for example, `ADT; <https://github.com/llvm/llvm-project/tree/main/llvm/include/llvm/ADT>`_); implement specialized data structures or functionality missing in the standard; library. Such libraries are usually implemented in the ``llvm`` namespace and; follow the expected standard interface, when there is one. When both C++ and the LLVM support libraries provide similar functionality, and; there isn't a specific reason to favor the C++ implementation, it is generally; preferable to use the LLVM library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like the I/O streams, and instead; use LLVM's streams library (raw_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5196,Safety,avoid,avoid,5196,"w_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:5346,Safety,avoid,avoid,5346,"nd the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:21269,Safety,predict,predictable,21269,"raries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if`` condition is often a typo:. .. code-block:: c++. if (V = getValue()) {; ...; }. Several compilers will print a warning for the code above. It can be suppressed; by adding parentheses:. .. code-block:: c++. if ((V = getValue())) {; ...; }. Write Portable Code; ^^^^^^^^^^^^^^^^^^^. In almost all cases, it is possible to write completely portable code. When; you need to rely on non-portable code, put it behind a well-defined and; well-documented interface. Do not use RTTI or Exceptions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In an effort to reduce cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:34321,Safety,avoid,avoid,34321,"le header file. Don't do this!. If you really need to do something like this, put a private header file in the; same directory as the source files, and include it locally. This ensures that; your private interface remains private and undisturbed by outsiders. .. note::. It's okay to put extra implementation methods in a public class itself. Just; make them private (or protected) and all is well. Use Namespace Qualifiers to Implement Previously Declared Functions; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When providing an out of line implementation of a function in a source file, do; not open namespace blocks in the source file. Instead, use namespace qualifiers; to help ensure that your definition matches an existing declaration. Do this:. .. code-block:: c++. // Foo.h; namespace llvm {; int foo(const char *s);; }. // Foo.cpp; #include ""Foo.h""; using namespace llvm;; int llvm::foo(const char *s) {; // ...; }. Doing this helps to avoid bugs where the definition does not match the; declaration from the header. For example, the following C++ code defines a new; overload of ``llvm::foo`` instead of providing a definition for the existing; function declared in the header:. .. code-block:: c++. // Foo.cpp; #include ""Foo.h""; namespace llvm {; int foo(char *s) { // Mismatch between ""const char *"" and ""char *""; }; } // namespace llvm. This error will not be caught until the build is nearly complete, when the; linker fails to find a definition for any uses of the original function. If the; function were instead defined with a namespace qualifier, the error would have; been caught immediately when the definition was compiled. Class method implementations must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and ho",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:36823,Safety,avoid,avoid,36823,"..; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; predicate isn't true; you have to read to the end of the function to know that; it returns null. It is much preferred to format the code like this:. .. code-block:: c++. Value *doSomething(Instruction *I) {; // Terminators never need 'something' done to them because ...; if (I->isTerminator()); return 0;. // We conservatively avoid transforming instructions with multiple uses; // because goats like cheese.; if (!I->hasOneUse()); return 0;. // This is really just here for example.; if (!doOtherThing(I)); return 0;. ... some long code ....; }. This fixes these problems. A similar problem frequently happens in ``for``; loops. A silly example is something like this:. .. code-block:: c++. for (Instruction &I : BB) {; if (auto *BO = dyn_cast<BinaryOperator>(&I)) {; Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS != RHS) {; ...; }; }; }. When you have very, very small loops, this sort of structure is fine. But if it; exceeds more than 10-15 lines, it becomes difficult for people to read and; understand at a glance. The problem with this sort of code is that it gets very; nested very quickly. Meaning that the reader of the code has to keep a lot of; context in their brain to remember what is going immediately on in the loop,; because they don't know if/when the ``if`` conditions will have ``else``\s etc.; It is strongl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47047,Safety,abort,abort,47047," ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47551,Safety,recover,recoverable,47551,"sertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:51451,Safety,avoid,avoid,51451,"od Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a header file and has a vtable (either it has virtual; methods or it derives from classes with virtual methods), it must always have at; least one out-of-line virtual method in the class. Without this, the compiler; will copy the vtable and RTTI into every ``.o`` file that ``#include``\s the; header, bloating ``.o`` file sizes and increasing link times. Don't use default labels in fully covered switches over enumerations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``-Wswitch`` warns if a switch, without a default label, over an enumeration; does not cover every enumeration value. If you write a default label on a fully; covered switch over an enumeration then the ``-Wswitch`` warning won't fire; when new elements are added to that enumeration. To help avoid adding these; kinds of defaults, Clang has the warning ``-Wcovered-switch-default`` which is; off by default but turned on when building LLVM with a version of Clang that; supports the warning. A knock-on effect of this stylistic requirement is that when building LLVM with; GCC you may get warnings related to ""control may reach end of non-void function""; if you return from each case of a covered switch-over-enum because GCC assumes; that the enum expression may take any representable value, not just those of; individual enumerators. To suppress this warning, use ``llvm_unreachable`` after; the switch. Use range-based ``for`` loops wherever possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The introduction of range-based ``for`` loops in C++11 means that explicit; manipulation of iterators is rarely necessary. We use range-based ``for``; loops wherever possible for all newly added code. For example:. .. code-block:: c++. BasicBlock *BB = ...; for (Instruction &I : *BB); ... use I ... Usage of ``std::for_each()``/``llvm::for_each()`` functions is discouraged,; unles",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:58721,Safety,avoid,avoid,58721,"ons flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is useful; because we want code to `fit into 80 columns`_ without excessive wrapping, but; also because it makes it easier to understand the code. To facilitate this and; avoid some insanely deep nesting on occasion, don't indent namespaces. If it; helps readability, feel free to add a comment indicating what namespace is; being closed by a ``}``. For example:. .. code-block:: c++. namespace llvm {; namespace knowledge {. /// This class represents things that Smith can have an intimate; /// understanding of and contains the data associated with it.; class Grokable {; ...; public:; explicit Grokable() { ... }; virtual ~Grokable() = 0;. ... };. } // namespace knowledge; } // namespace llvm. Feel free to skip the closing comment when the namespace being closed is; obvious for any reason. For example, the outer-most namespace in a header file; is rarely a source of confusion. But namespaces both anonymous and named in; source files that are being closed half way through the file probably could use; clarification. .. _static:. Anonymous Namespaces; ^^^^^^^^^^^^^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anony",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:61719,Safety,avoid,avoid,61719,"clarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-reference; faraway places in the file to tell that the function is local. Don't Use Braces on Simple Single-Statement Bodies of if/else/loop Statements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When writing the body of an ``if``, ``else``, or for/while loop statement, we; prefer to omit the braces to avoid unnecessary line noise. However, braces; should be used in cases where the omission of braces harm the readability and; maintainability of the code. We consider that readability is harmed when omitting the brace in the presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is har",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:62830,Safety,avoid,avoid,62830,"ability and; maintainability of the code. We consider that readability is harmed when omitting the brace in the presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``if``; would help to avoid running into a ""dangling else"" situation. .. code-block:: c++. // Omit the braces since the body is simple and clearly associated with the; // `if`.; if (isa<FunctionDecl>(D)); handleFunctionDecl(D);; else if (isa<VarDecl>(D)); handleVarDecl(D);. // Here we document the condition itself and not the body.; if (isa<VarDecl>(D)) {; // It is necessary that we explain the situation with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (shouldProcessAttr(A)); handleAttr(A);; }. // Use braces for the `if` block to keep it uniform with the `else` block.; if (isa<FunctionDecl>(D)) {; handleFunctionDecl(D);; } else {; // In this `else` case, it i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:63545,Safety,avoid,avoid,63545,"s, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``if``; would help to avoid running into a ""dangling else"" situation. .. code-block:: c++. // Omit the braces since the body is simple and clearly associated with the; // `if`.; if (isa<FunctionDecl>(D)); handleFunctionDecl(D);; else if (isa<VarDecl>(D)); handleVarDecl(D);. // Here we document the condition itself and not the body.; if (isa<VarDecl>(D)) {; // It is necessary that we explain the situation with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (shouldProcessAttr(A)); handleAttr(A);; }. // Use braces for the `if` block to keep it uniform with the `else` block.; if (isa<FunctionDecl>(D)) {; handleFunctionDecl(D);; } else {; // In this `else` case, it is necessary that we explain the situation with; // this surprisingly long comment, so it would be unclear without the braces; // whether the following statement is in the scope of the `if`.; handleOtherDecl(D);; }. // This should also omit braces. The `for` loop contains only a single; // statement, so it shouldn't have braces. The `if` also only contains a; // single simple statement (the `for` loop), so it also should omit braces.; if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()); handleAttr(A);. // Use braces for a `do-while` loop and its enclosing statement.; if (Tok->is(tok::l_brace)) {; do {; Tok = Tok->Next;; } while (Tok);; }. // Use braces for the outer `if` since the nested `for` is braced.; if (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:65121,Safety,avoid,avoid,65121," situation with; // this surprisingly long comment, so it would be unclear without the braces; // whether the following statement is in the scope of the `if`.; handleOtherDecl(D);; }. // This should also omit braces. The `for` loop contains only a single; // statement, so it shouldn't have braces. The `if` also only contains a; // single simple statement (the `for` loop), so it also should omit braces.; if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()); handleAttr(A);. // Use braces for a `do-while` loop and its enclosing statement.; if (Tok->is(tok::l_brace)) {; do {; Tok = Tok->Next;; } while (Tok);; }. // Use braces for the outer `if` since the nested `for` is braced.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()) {; // In this `for` loop body, it is necessary that we explain the situation; // with this surprisingly long comment, forcing braces on the `for` block.; handleAttr(A);; }; }. // Use braces on the outer block because there are more than two levels of; // nesting.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()); for (ssize_t i : llvm::seq<ssize_t>(count)); handleAttrOnDecl(D, A, i);; }. // Use braces on the outer block because of a nested `if`; otherwise the; // compiler would warn: `add explicit braces to avoid dangling else`; if (auto *D = dyn_cast<FunctionDecl>(D)) {; if (shouldProcess(D)); handleVarDecl(D);; else; markAsIgnored(D);; }. See Also; ========. A lot of these comments and recommendations have been culled from other sources.; Two particularly important books for our work are:. #. `Effective C++; <https://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0321334876>`_; by Scott Meyers. Also interesting and useful are ""More Effective C++"" and; ""Effective STL"" by the same author. #. `Large-Scale C++ Software Design; <https://www.amazon.com/Large-Scale-Software-Design-John-Lakos/dp/0201633620>`_; by John Lakos. If you get some free time, and you haven't read them: do so, you might learn; something.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:49631,Security,expose,expose,49631,".insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'), but should not use any others. Provide a Virtual Method Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55163,Security,inject,inject,55163,"f the base expression is more; complex, then the cost can rise quickly. I've seen loops where the end; expression was actually something like: ""``SomeMap[X]->end()``"" and map lookups; really aren't cheap. By writing it in the second form consistently, you; eliminate the issue entirely and don't even have to think about it. The second (even bigger) issue is that writing the loop in the first form hints; to the reader that the loop is mutating the container (a fact that a comment; would handily confirm!). If you write the loop in the second form, it is; immediately obvious without even looking at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6149,Testability,test,test,6149,"s PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to document:. .. _header file comment:. File Headers; """"""""""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6205,Testability,test,test,6205," For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to document:. .. _header file comment:. File Headers; """""""""""""""""""""""". Every source file should have a h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:6261,Testability,test,test,6261,"hough it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which currently only supports formatting entire files. Here are some quick examples, but see the black and darker documentation for; details:. .. code-block:: bash. $ pip install black=='23.*' darker # install black 23.x and darker; $ darker test.py # format uncommitted changes; $ darker -r HEAD^ test.py # also format changes from last commit; $ black test.py # format entire file. Instead of individual file names, you can specify directories to; darker, and it will find the changed files. However, if a directory is; large, like a clone of the LLVM repository, darker can be painfully; slow. In that case, you might wish to use git to list changed files.; For example:. .. code-block:: bash. $ darker -r HEAD^ $(git diff --name-only --diff-filter=d HEAD^). Mechanical Source Issues; ========================. Source Code Formatting; ----------------------. Commenting; ^^^^^^^^^^. Comments are important for readability and maintainability. When writing comments,; write them as English prose, using proper capitalization, punctuation, etc.; Aim to describe what the code is trying to do and why, not *how* it does it at; a micro level. Here are a few important things to document:. .. _header file comment:. File Headers; """""""""""""""""""""""". Every source file should have a header on it that describes the basic purpose of; the fil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:25192,Testability,log,logic,25192,"lt while ``struct`` makes all; members public by default. * All declarations and definitions of a given ``class`` or ``struct`` must use; the same keyword. For example:. .. code-block:: c++. // Avoid if `Example` is defined as a struct.; class Example;. // OK.; struct Example;. struct Example { ... };. * ``struct`` should be used when *all* members are declared public. .. code-block:: c++. // Avoid using `struct` here, use `class` instead.; struct Foo {; private:; int Data;; public:; Foo() : Data(0) { }; int getData() const { return Data; }; void setData(int D) { Data = D; }; };. // OK to use `struct`: all members are public.; struct Bar {; int Data;; Bar() : Data(0) { }; };. Do not use Braced Initializer Lists to Call a Constructor; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Starting from C++11 there is a ""generalized initialization syntax"" which allows; calling constructors using braced initializer lists. Do not use these to call; constructors with non-trivial logic or if you care that you're calling some; *particular* constructor. Those should look like function calls using; parentheses rather than like aggregate initialization. Similarly, if you need; to explicitly name the type and call its constructor to create a temporary,; don't use a braced initializer list. Instead, use a braced initializer list; (without any type for temporaries) when doing aggregate initialization or; something notionally equivalent. Examples:. .. code-block:: c++. class Foo {; public:; // Construct a Foo by reading data from the disk in the whizbang format, ...; Foo(std::string filename);. // Construct a Foo by looking up the Nth element of some global data ...; Foo(int N);. // ...; };. // The Foo constructor call is reading a file, don't use braces to call it.; std::fill(foo.begin(), foo.end(), Foo(""name""));. // The pair is being constructed like an aggregate, use braces.; bar_map.insert({my_key, my_value});. If you use a braced initializer list when initializing a varia",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:44987,Testability,assert,assert,44987," a prefix. For; instance:. .. code-block:: c++. enum {; MaxSize = 42,; Density = 12; };. As an exception, classes that mimic STL classes can have member names in STL's; style of lower-case words separated by underscores (e.g. ``begin()``,; ``push_back()``, and ``empty()``). Classes that provide multiple; iterators should add a singular prefix to ``begin()`` and ``end()``; (e.g. ``global_begin()`` and ``use_begin()``). Here are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45153,Testability,assert,assertion,45153,"at mimic STL classes can have member names in STL's; style of lower-case words separated by underscores (e.g. ``begin()``,; ``push_back()``, and ``empty()``). Classes that provide multiple; iterators should add a singular prefix to ``begin()`` and ``end()``; (e.g. ``global_begin()`` and ``use_begin()``). Here are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45430,Testability,assert,assertion,45430,"ere are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45475,Testability,assert,assertion,45475,"ere are some examples:. .. code-block:: c++. class VehicleMaker {; ...; Factory<Tire> F; // Avoid: a non-descriptive abbreviation.; Factory<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45548,Testability,assert,assertion,45548,"<Tire> Factory; // Better: more descriptive.; Factory<Tire> TireFactory; // Even better: if VehicleMaker has more than one; // kind of factories.; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45714,Testability,assert,assert,45714,"; };. Vehicle makeVehicle(VehicleType Type) {; VehicleMaker M; // Might be OK if scope is small.; Tire Tmp1 = M.makeTire(); // Avoid: 'Tmp1' provides no information.; Light Headlight = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45846,Testability,assert,assert,45846,"light = M.makeLight(""head""); // Good: descriptive.; ...; }. Assert Liberally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45916,Testability,assert,assert,45916,"ally; ^^^^^^^^^^^^^^^^. Use the ""``assert``"" macro to its fullest. Check all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip gener",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:45990,Testability,assert,assert,45990,"ck all of your preconditions and; assumptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46056,Testability,assert,assert,46056,"mptions, you never know when a bug (not necessarily even yours) might be; caught early by an assertion, which reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" impleme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46134,Testability,assert,assert,46134,"ich reduces debugging time dramatically. The; ""``<cassert>``"" header file is probably already included by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46232,Testability,assert,asserts,46232,"cluded by the header files you; are using, so it doesn't cost anything to use it. To further assist with debugging, make sure to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46363,Testability,assert,assert,46363," to put some kind of error message in; the assertion statement, which is printed if the assertion is tripped. This; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46502,Testability,assert,assertion,46502,"; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46561,Testability,assert,assertions,46561,"; helps the poor debugger make sense of why an assertion is being made and; enforced, and hopefully what to do about it. Here is one complete example:. .. code-block:: c++. inline Value *getOperand(unsigned I) {; assert(I < Operands.size() && ""getOperand() out of range!"");; return Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46733,Testability,assert,assertions,46733,"rn Operands[I];; }. Here are more examples:. .. code-block:: c++. assert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:46839,Testability,assert,assertions,46839,"ert(Ty->isPointerType() && ""Can't allocate a non-pointer type!"");. assert((Opcode == Shl || Opcode == Shr) && ""ShiftInst Opcode invalid!"");. assert(idx < getNumSuccessors() && ""Successor # out of range!"");. assert(V1.getType() == V2.getType() && ""Constant types must be identical!"");. assert(isa<PHINode>(Succ->front()) && ""Only works on PHId BBs!"");. You get the idea. In the past, asserts were used to indicate a piece of code that should not be; reached. These were typically of the form:. .. code-block:: c++. assert(0 && ""Invalid radix for integer literal"");. This has a few issues, the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For exampl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47399,Testability,assert,assert,47399,"the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47432,Testability,test,testable,47432,"the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47469,Testability,assert,assert,47469,"the main one being that some compilers might not; understand the assertion, or warn about a missing return in builds where; assertions are compiled out. Today, we have something much better: ``llvm_unreachable``:. .. code-block:: c++. llvm_unreachable(""Invalid radix for integer literal"");. When assertions are enabled, this will print the message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47759,Testability,assert,assertions,47759,"message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47815,Testability,assert,assertions,47815,"message if it's ever reached; and then exit the program. When assertions are disabled (i.e. in release; builds), ``llvm_unreachable`` becomes a hint to compilers to skip generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:47923,Testability,assert,assert,47923,"generating; code for this branch. If the compiler does not support this, it will fall back; to the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rath",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48019,Testability,assert,assert,48019," the ""abort"" implementation. Use ``llvm_unreachable`` to mark a specific point in code that should never be; reached. This is especially desirable for addressing warnings about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48192,Testability,assert,assert,48192,"s about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48236,Testability,assert,assertions,48236,"s about unreachable; branches, etc., but can be used whenever reaching a particular code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48306,Testability,assert,assert,48306,"lar code path is; unconditionally a bug (not originating from user input; see below) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using expli",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48396,Testability,assert,assert,48396,"ow) of some kind.; Use of ``assert`` should always include a testable predicate (as opposed to; ``assert(false)``). If the error condition can be triggered by user input then the; recoverable error mechanism described in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately ob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48578,Testability,assert,assert,48578,"cribed in :doc:`ProgrammersManual` should be; used instead. In cases where this is not practical, ``report_fatal_error`` may; be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important bec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:48694,Testability,assert,assert,48694,"be used. Another issue is that values used only by assertions will produce an ""unused; value"" warning when assertions are disabled. For example, this code will warn:. .. code-block:: c++. unsigned Size = V.size();; assert(Size > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value);; assert(NewToSet && ""The value shouldn't be in the set yet"");. These are two interesting different cases. In the first case, the call to; ``V.size()`` is only useful for the assert, and we don't want it executed when; assertions are disabled. Code like this should move the call into the assert; itself. In the second case, the side effects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:57536,Testability,assert,assert,57536," probably have no reason to flush the output stream, so; it's better to use a literal ``'\n'``. Don't use ``inline`` when defining a function in a class definition; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A member function defined in a class definition is implicitly inline, so don't; put the ``inline`` keyword in this case. Don't:. .. code-block:: c++. class Foo {; public:; inline void bar() {; // ...; }; };. Do:. .. code-block:: c++. class Foo {; public:; void bar() {; // ...; }; };. Microscopic Details; -------------------. This section describes preferred low-level formatting guidelines along with; reasoning on why we prefer them. Spaces Before Parentheses; ^^^^^^^^^^^^^^^^^^^^^^^^^. Put a space before an open parenthesis only in control flow statements, but not; in normal function call expressions and function-like macros. For example:. .. code-block:: c++. if (X) ...; for (I = 0; I != 100; ++I) ...; while (LLVMRocks) ... somefunc(42);; assert(3 != 4 && ""laws of math are failing me"");. A = foo(42, 92) + bar(X);. The reason for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But for iterators, it can be a huge; issue (for example, some iterators contains stack and set objects in them...; copying an iterator could invoke the copy ctor's of these as well). In general,; get in the habit of always using preincrement, and you won't have a problem. Namespace Indentation; ^^^^^^^^^^^^^^^^^^^^^. In general, we strive to reduce indentation wherever possible. This is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:458,Usability,guid,guidance,458,"=====================; LLVM Coding Standards; =====================. .. contents::; :local:. Introduction; ============. This document describes coding standards that are used in the LLVM project.; Although no coding standards should be regarded as absolute requirements to be; followed in all instances, coding standards are; particularly important for large-scale code bases that follow a library-based; design (like LLVM). While this document may provide guidance for some mechanical formatting issues,; whitespace, or other ""microscopic details"", these are not fixed standards.; Always follow the golden rule:. .. _Golden Rule:. **If you are extending, enhancing, or bug fixing already implemented code,; use the style that is already being used so that the source is uniform and; easy to follow.**. Note that some code bases (e.g. ``libc++``) have special reasons to deviate; from the coding standards. For example, in the case of ``libc++``, this is; because the naming and other conventions are dictated by the C++ standard. There are some conventions that are not uniformly followed in the code base; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:1620,Usability,guid,guidelines,1620,"nding, enhancing, or bug fixing already implemented code,; use the style that is already being used so that the source is uniform and; easy to follow.**. Note that some code bases (e.g. ``libc++``) have special reasons to deviate; from the coding standards. For example, in the case of ``libc++``, this is; because the naming and other conventions are dictated by the C++ standard. There are some conventions that are not uniformly followed in the code base; (e.g. the naming convention). This is because they are relatively new, and a; lot of code was written before they were put in place. Our long term goal is; for the entire codebase to follow the convention, but we explicitly *do not*; want patches that do large-scale reformatting of existing code. On the other; hand, it is reasonable to rename the methods of a class if you're about to; change it in some other way. Please commit such changes separately to; make code review easier. The ultimate goal of these guidelines is to increase the readability and; maintainability of our common source base. Languages, Libraries, and Standards; ===================================. Most source code in LLVM and other LLVM projects using these coding standards; is C++ code. There are some places where C code is used either due to; environment restrictions, historical restrictions, or due to third-party source; code imported into the tree. Generally, our preference is for standards; conforming, modern, and portable C++ code as the implementation language of; choice. For automation, build-systems and utility scripts Python is preferred and; is widely used in the LLVM repository already. C++ Standard Versions; ---------------------. Unless otherwise documented, LLVM subprojects are written using standard C++17; code and avoid unnecessary vendor-specific extensions. Nevertheless, we restrict ourselves to features which are available in the; major toolchains supported as host compilers (see :doc:`GettingStarted` page,; section `Software`).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:4929,Usability,guid,guidelines,4929,"M library. For example, ``llvm::DenseMap`` should; almost always be used instead of ``std::map`` or ``std::unordered_map``, and; ``llvm::SmallVector`` should usually be used instead of ``std::vector``. We explicitly avoid some standard facilities, like the I/O streams, and instead; use LLVM's streams library (raw_ostream_). More detailed information on these; subjects is available in the :doc:`ProgrammersManual`. For more information about LLVM's data structures and the tradeoffs they make,; please consult `that section of the programmer's manual; <https://llvm.org/docs/ProgrammersManual.html#picking-the-right-data-structure-for-a-task>`_. Python version and Source Code Formatting; -----------------------------------------. The current minimum version of Python required is documented in the :doc:`GettingStarted`; section. Python code in the LLVM repository should only use language features; available in this version of Python. The Python code within the LLVM repository should adhere to the formatting guidelines; outlined in `PEP 8 <https://peps.python.org/pep-0008/>`_. For consistency and to limit churn, code should be automatically formatted with; the `black <https://github.com/psf/black>`_ utility, which is PEP 8 compliant.; Use its default rules. For example, avoid specifying ``--line-length`` even; though it does not default to 80. The default rules can change between major; versions of black. In order to avoid unnecessary churn in the formatting rules,; we currently use black version 23.x in LLVM. When contributing a patch unrelated to formatting, you should format only the; Python code that the patch modifies. For this purpose, use the `darker; <https://pypi.org/project/darker/>`_ utility, which runs default black rules; over only the modified Python code. Doing so should ensure the patch will pass; the Python format checks in LLVM's pre-commit CI, which also uses darker. When; contributing a patch specifically for reformatting Python files, use black,; which c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:8431,Usability,clear,clear,8431," // See https://llvm.org/LICENSE.txt for license information.; // SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception; //; //===----------------------------------------------------------------------===//; ///; /// \file; /// This file contains the declaration of the Instruction class, which is the; /// base class for all of the VM instructions.; ///; //===----------------------------------------------------------------------===//. A few things to note about this particular format: The ""``-*- C++ -*-``"" string; on the first line is there to tell Emacs that the source file is a C++ file, not; a C file (Emacs assumes ``.h`` files are C files by default). .. note::. This tag is not necessary in ``.cpp`` files. The name of the file is also; on the first line, along with a very short description of the purpose of the; file. The next section in the file is a concise note that defines the license that the; file is released under. This makes it perfectly clear what terms the source; code can be distributed under and should not be modified in any way. The main body is a `Doxygen <http://www.doxygen.nl/>`_ comment (identified by; the ``///`` comment marker instead of the usual ``//``) describing the purpose; of the file. The first sentence (or a passage beginning with ``\brief``) is; used as an abstract. Any additional information should be separated by a blank; line. If an algorithm is based on a paper or is described in another source,; provide a reference. Header Guard; """""""""""""""""""""""". The header file's guard should be the all-caps path that a user of this header; would #include, using '_' instead of path separator and extension marker.; For example, the header file; ``llvm/include/llvm/Analysis/Utils/Local.h`` would be ``#include``-ed as; ``#include ""llvm/Analysis/Utils/Local.h""``, so its guard is; ``LLVM_ANALYSIS_UTILS_LOCAL_H``. Class overviews; """""""""""""""""""""""""""""". Classes are a fundamental part of an object-oriented design. As such, a; class definition should have a comm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:10761,Usability,clear,clear,10761,"ses is all that is necessary here.; The reader should be able to understand how to use interfaces without reading; the code itself. Good things to talk about here are what happens when something unexpected; happens, for instance, does the method return null?. Comment Formatting; ^^^^^^^^^^^^^^^^^^. In general, prefer C++-style comments (``//`` for normal comments, ``///`` for; ``doxygen`` documentation comments). There are a few cases when it is; useful to use C-style (``/* */``) comments however:. #. When writing C code to be compatible with C89. #. When writing a header file that may be ``#include``\d by a C source file. #. When writing a source file that is used by a tool that only accepts C-style; comments. #. When documenting the significance of constants used as actual parameters in; a call. This is most helpful for ``bool`` parameters, or passing ``0`` or; ``nullptr``. The comment should contain the parameter name, which ought to be; meaningful. For example, it's not clear what the parameter means in this call:. .. code-block:: c++. Object.emitName(nullptr);. An in-line C-style comment makes the intent obvious:. .. code-block:: c++. Object.emitName(/*Prefix=*/nullptr);. Commenting out large blocks of code is discouraged, but if you really have to do; this (for documentation purposes or as a suggestion for debug printing), use; ``#if 0`` and ``#endif``. These nest properly and are better behaved in general; than C style comments. Doxygen Use in Documentation Comments; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use the ``\file`` command to turn the standard file header into a file-level; comment. Include descriptive paragraphs for all public interfaces (public classes,; member and non-member functions). Avoid restating the information that can; be inferred from the API name. The first sentence (or a paragraph beginning; with ``\brief``) is used as an abstract. Try to use a single sentence as the; ``\brief`` adds visual clutter. Put detailed discussion into separate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:15689,Usability,guid,guidelines,15689,"er 3 is corrupt. Size is 10 when it should be 20. This is a bad message, since it does not provide useful information and uses the; wrong style:. .. code-block:: none. error: file.o: Corrupt section header. As with other coding standards, individual projects, such as the Clang Static; Analyzer, may have preexisting styles that do not conform to this. If a; different formatting scheme is used consistently throughout the project, use; that style instead. Otherwise, this standard applies to all LLVM tools,; including clang, clang-tidy, and so on. If the tool or project does not have existing functions to emit warnings or; errors, use the error and warning handlers provided in ``Support/WithColor.h``; to ensure they are printed in the appropriate style, rather than printing to; stderr directly. When using ``report_fatal_error``, follow the same standards for the message as; regular error messages. Assertion messages and ``llvm_unreachable`` calls do not; necessarily need to follow these same styles as they are automatically; formatted, and thus these guidelines may not be suitable. ``#include`` Style; ^^^^^^^^^^^^^^^^^^. Immediately after the `header file comment`_ (and include guards if working on a; header file), the `minimal list of #includes`_ required by the file should be; listed. We prefer these ``#include``\s to be listed in this order:. .. _Main Module Header:; .. _Local/Private Headers:. #. Main Module Header; #. Local/Private Headers; #. LLVM project/subproject headers (``clang/...``, ``lldb/...``, ``llvm/...``, etc); #. System ``#include``\s. and each category should be sorted lexicographically by the full path. The `Main Module Header`_ file applies to ``.cpp`` files which implement an; interface defined by a ``.h`` file. This ``#include`` should always be included; **first** regardless of where it lives on the file system. By including a; header file first in the ``.cpp`` files that implement the interfaces, we ensure; that the header does not have any hid",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20688,Usability,simpl,simple,20688,"arameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llvm.org/docs/ClangFormat.html. Language and Compiler Issues; ----------------------------. Treat Compiler Warnings Like Errors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Compiler warnings are often useful and help improve the code. Those that are; not useful, can be often suppressed with a small code change. For example, an; assignment in the ``if``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:27739,Usability,clear,clear,27739," already obvious from the context. Another time when ``auto`` works well; for these purposes is when the type would have been abstracted away anyways,; often behind a container's typedef such as ``std::vector<T>::iterator``. Similarly, C++14 adds generic lambda expressions where parameter types can be; ``auto``. Use these where you would have used a template. Beware unnecessary copies with ``auto``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The convenience of ``auto`` makes it easy to forget that its default behavior; is a copy. Particularly in range-based ``for`` loops, careless copies are; expensive. Use ``auto &`` for values and ``auto *`` for pointers unless you need to make a; copy. .. code-block:: c++. // Typically there's no reason to copy.; for (const auto &Val : Container) observe(Val);; for (auto &Val : Container) Val.change();. // Remove the reference if you really want a new copy.; for (auto Val : Container) { Val.change(); saveSomewhere(Val); }. // Copy pointers, but make it clear that they're pointers.; for (const auto *Ptr : Container) observe(*Ptr);; for (auto *Ptr : Container) Ptr->change();. Beware of non-determinism due to ordering of pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In general, there is no relative ordering among pointers. As a result,; when unordered containers like sets and maps are used with pointer keys; the iteration order is undefined. Hence, iterating such containers may; result in non-deterministic code generation. While the generated code; might work correctly, non-determinism can make it harder to reproduce bugs and; debug the compiler. In case an ordered result is expected, remember to; sort an unordered container before iteration. Or use ordered containers; like ``vector``/``MapVector``/``SetVector`` if you want to iterate pointer; keys. Beware of non-deterministic sorting order of equal elements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``std::sort`` uses a non-stable sorting algorith",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:32328,Usability,simpl,simply,32328,"valid orderings of dependencies; - since linking resolution is linear, it's possible that some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; you'll find out about later. Keep ""Internal"" Headers Private; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Many modules have a complex implementation that causes them to use more than one; implementation (``.cpp``) file. It is often tempting to put the internal; communication interface (helper classes, extra functions, etc) in the public; module header file. Do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:32450,Usability,simpl,simply,32450," some implicit; dependencies can sneak through: A depends on B and C, so valid orderings are; ""C B A"" or ""B C A"", in both cases the explicit dependencies come before their; use. But in the first case, B could still link successfully if it implicitly; depended on C, or the opposite in the second case). .. _minimal list of #includes:. ``#include`` as Little as Possible; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``#include`` hurts compile time performance. Don't do it unless you have to,; especially in header files. But wait! Sometimes you need to have the definition of a class to use it, or to; inherit from it. In these cases go ahead and ``#include`` that header file. Be; aware however that there are many cases where you don't need to have the full; definition of a class. If you are using a pointer or reference to a class, you; don't need the header file. If you are simply returning a class instance from a; prototyped function or method, you don't need it. In fact, for most cases, you; simply don't need the definition of a class. And not ``#include``\ing speeds up; compilation. It is easy to try to go too overboard on this recommendation, however. You; **must** include all of the header files that you are using --- you can include; them either directly or indirectly through another header file. To make sure; that you don't accidentally forget to include a header file in your module; header, make sure to include your module header **first** in the implementation; file (as mentioned above). This way there won't be any hidden dependencies that; you'll find out about later. Keep ""Internal"" Headers Private; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Many modules have a complex implementation that causes them to use more than one; implementation (``.cpp``) file. It is often tempting to put the internal; communication interface (helper classes, extra functions, etc) in the public; module header file. Don't do this!. If you really need to do something like this, put a private header file in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:36012,Usability,clear,clear,36012,"tions must already name the class and new overloads; cannot be introduced out of line, so this recommendation does not apply to them. .. _early exits:. Use Early Exits and ``continue`` to Simplify Code; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When reading code, keep in mind how much state and how many previous decisions; have to be remembered by the reader to understand a block of code. Aim to; reduce indentation where possible when it doesn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasOneUse() && doOtherThing(I)) {; ... some long code ....; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; predicate isn't true; you have to read to the end of the function to know that; it returns null. It is much preferred to format the code like this:. .. code-block:: c++. Value *doSomething(Instruction *I) {; // Terminators never need 'something' done to them because ...; if (I->isTerminator()); return 0;. // We conservatively avoid transforming instructions with multiple uses; // because goats like cheese.; if (!I->hasOneUse()); return 0;. // This is really just here for example.; if (!doOtherThing(I)); return 0;. ... some long code ....; }. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:36462,Usability,clear,clear,36462,"esn't make it more difficult to; understand the code. One great way to do this is by making use of early exits; and the ``continue`` keyword in long loops. Consider this code that does not; use an early exit:. .. code-block:: c++. Value *doSomething(Instruction *I) {; if (!I->isTerminator() &&; I->hasOneUse() && doOtherThing(I)) {; ... some long code ....; }. return 0;; }. This code has several problems if the body of the ``'if'`` is large. When; you're looking at the top of the function, it isn't immediately clear that this; *only* does interesting things with non-terminator instructions, and only; applies to things with the other predicates. Second, it is relatively difficult; to describe (in comments) why these predicates are important because the ``if``; statement makes it difficult to lay out the comments. Third, when you're deep; within the body of the code, it is indented an extra level. Finally, when; reading the top of the function, it isn't clear what the result is if the; predicate isn't true; you have to read to the end of the function to know that; it returns null. It is much preferred to format the code like this:. .. code-block:: c++. Value *doSomething(Instruction *I) {; // Terminators never need 'something' done to them because ...; if (I->isTerminator()); return 0;. // We conservatively avoid transforming instructions with multiple uses; // because goats like cheese.; if (!I->hasOneUse()); return 0;. // This is really just here for example.; if (!doOtherThing(I)); return 0;. ... some long code ....; }. This fixes these problems. A similar problem frequently happens in ``for``; loops. A silly example is something like this:. .. code-block:: c++. for (Instruction &I : BB) {; if (auto *BO = dyn_cast<BinaryOperator>(&I)) {; Value *LHS = BO->getOperand(0);; Value *RHS = BO->getOperand(1);; if (LHS != RHS) {; ...; }; }; }. When you have very, very small loops, this sort of structure is fine. But if it; exceeds more than 10-15 lines, it becomes difficult f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:49332,Usability,clear,clearer,49332,"ects of the call must happen whether; the assert is enabled or not. In this case, the value should be cast to void to; disable the warning. To be specific, it is preferred to write the code like; this:. .. code-block:: c++. assert(V.size() > 42 && ""Vector smaller than it should be"");. bool NewToSet = Myset.insert(Value); (void)NewToSet;; assert(NewToSet && ""The value shouldn't be in the set yet"");. Do Not Use ``using namespace std``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In LLVM, we prefer to explicitly prefix all identifiers from the standard; namespace with an ""``std::``"" prefix, rather than rely on ""``using namespace; std;``"". In header files, adding a ``'using namespace XXX'`` directive pollutes the; namespace of any source file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:50094,Usability,clear,clearer,50094,"urce file that ``#include``\s the header, creating; maintenance issues. In implementation files (e.g. ``.cpp`` files), the rule is more of a stylistic; rule, but is still important. Basically, using explicit namespace prefixes; makes the code **clearer**, because it is immediately obvious what facilities; are being used and where they are coming from. And **more portable**, because; namespace clashes cannot occur between LLVM code and other namespaces. The; portability rule is important because different standard library implementations; expose different symbols (potentially ones they shouldn't), and future revisions; to the C++ standard will add more symbols to the ``std`` namespace. As such, we; never use ``'using namespace std;'`` in LLVM. The exception to the general rule (i.e. it's not an exception for the ``std``; namespace) is for implementation files. For example, all of the code in the; LLVM project implements code that lives in the 'llvm' namespace. As such, it is; ok, and actually clearer, for the ``.cpp`` files to have a ``'using namespace; llvm;'`` directive at the top, after the ``#include``\s. This reduces; indentation in the body of the file for source editors that indent based on; braces, and keeps the conceptual context cleaner. The general form of this rule; is that any ``.cpp`` file that implements code in any namespace may use that; namespace (and its parents'), but should not use any others. Provide a Virtual Method Anchor for Classes in Headers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If a class is defined in a header file and has a vtable (either it has virtual; methods or it derives from classes with virtual methods), it must always have at; least one out-of-line virtual method in the class. Without this, the compiler; will copy the vtable and RTTI into every ``.o`` file that ``#include``\s the; header, bloating ``.o`` file sizes and increasing link times. Don't use default labels in fully covered switches over enumerations; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:55710,Usability,simpl,simple,55710,"ing at the body of the loop that the; container isn't being modified, which makes it easier to read the code and; understand what it does. While the second form of the loop is a few extra keystrokes, we do strongly; prefer it. ``#include <iostream>`` is Forbidden; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The use of ``#include <iostream>`` in library files is hereby **forbidden**,; because many common implementations transparently inject a `static constructor`_; into every translation unit that includes it. Note that using the other stream headers (``<sstream>`` for example) is not; problematic in this regard --- just ``<iostream>``. However, ``raw_ostream``; provides various APIs that are better performing for almost every use than; ``std::ostream`` style APIs. .. note::. New code should always use `raw_ostream`_ for writing, or the; ``llvm::MemoryBuffer`` API for reading files. .. _raw_ostream:. Use ``raw_ostream``; ^^^^^^^^^^^^^^^^^^^. LLVM includes a lightweight, simple, and efficient stream implementation in; ``llvm/Support/raw_ostream.h``, which provides all of the common features of; ``std::ostream``. All new code should use ``raw_ostream`` instead of; ``ostream``. Unlike ``std::ostream``, ``raw_ostream`` is not a template and can be forward; declared as ``class raw_ostream``. Public headers should generally not include; the ``raw_ostream`` header, but use forward declarations and constant references; to ``raw_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these are equivalent:. .. code-block:: c++. std::cout << std::endl;; std::cout << '\n' << std::flush;. Most of the time, you probably have no reason to flush the output stream, so; it's better to use a literal ``'\n'``. Don't use ``inline`` when defining a function in a class definition; ^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:57167,Usability,guid,guidelines,57167,"w_ostream`` instances. Avoid ``std::endl``; ^^^^^^^^^^^^^^^^^^^. The ``std::endl`` modifier, when used with ``iostreams`` outputs a newline to; the output stream specified. In addition to doing this, however, it also; flushes the output stream. In other words, these are equivalent:. .. code-block:: c++. std::cout << std::endl;; std::cout << '\n' << std::flush;. Most of the time, you probably have no reason to flush the output stream, so; it's better to use a literal ``'\n'``. Don't use ``inline`` when defining a function in a class definition; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A member function defined in a class definition is implicitly inline, so don't; put the ``inline`` keyword in this case. Don't:. .. code-block:: c++. class Foo {; public:; inline void bar() {; // ...; }; };. Do:. .. code-block:: c++. class Foo {; public:; void bar() {; // ...; }; };. Microscopic Details; -------------------. This section describes preferred low-level formatting guidelines along with; reasoning on why we prefer them. Spaces Before Parentheses; ^^^^^^^^^^^^^^^^^^^^^^^^^. Put a space before an open parenthesis only in control flow statements, but not; in normal function call expressions and function-like macros. For example:. .. code-block:: c++. if (X) ...; for (I = 0; I != 100; ++I) ...; while (LLVMRocks) ... somefunc(42);; assert(3 != 4 && ""laws of math are failing me"");. A = foo(42, 92) + bar(X);. The reason for doing this is not completely arbitrary. This style makes control; flow operators stand out more, and makes expressions flow better. Prefer Preincrement; ^^^^^^^^^^^^^^^^^^^. Hard fast rule: Preincrement (``++X``) may be no slower than postincrement; (``X++``) and could very well be a lot faster than it. Use preincrementation; whenever possible. The semantics of postincrement include making a copy of the value being; incremented, returning it, and then preincrementing the ""work value"". For; primitive types, this isn't a big deal. But ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60582,Usability,simpl,simple,60582,"^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-reference; faraway places in the file to tell that the function is local. Don't Use Braces on Simple Single-Statement Bodies of if/else/loop Statements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When writin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:60589,Usability,guid,guideline,60589,"^^^^^^^^. After talking about namespaces in general, you may be wondering about anonymous; namespaces in particular. Anonymous namespaces are a great language feature; that tells the C++ compiler that the contents of the namespace are only visible; within the current translation unit, allowing more aggressive optimization and; eliminating the possibility of symbol name collisions. Anonymous namespaces are; to C++ as ""static"" is to C functions and global variables. While ""``static``""; is available in C++, anonymous namespaces are more general: they can make entire; classes private to a file. The problem with anonymous namespaces is that they naturally want to encourage; indentation of their body, and they reduce locality of reference: if you see a; random function definition in a C++ file, it is easy to see if it is marked; static, but seeing if it is in an anonymous namespace requires scanning a big; chunk of the file. Because of this, we have a simple guideline: make anonymous namespaces as small; as possible, and only use them for class declarations. For example:. .. code-block:: c++. namespace {; class StringSort {; ...; public:; StringSort(...); bool operator<(const char *RHS) const;; };; } // namespace. static void runHelper() {; ...; }. bool StringSort::operator<(const char *RHS) const {; ...; }. Avoid putting declarations other than classes into anonymous namespaces:. .. code-block:: c++. namespace {. // ... many declarations ... void runHelper() {; ...; }. // ... many declarations ... } // namespace. When you are looking at ""``runHelper``"" in the middle of a large C++ file,; you have no immediate way to tell if this function is local to the file. In; contrast, when the function is marked static, you don't need to cross-reference; faraway places in the file to tell that the function is local. Don't Use Braces on Simple Single-Statement Bodies of if/else/loop Statements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. When writin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:62645,Usability,guid,guidelines,62645,"body of an ``if``, ``else``, or for/while loop statement, we; prefer to omit the braces to avoid unnecessary line noise. However, braces; should be used in cases where the omission of braces harm the readability and; maintainability of the code. We consider that readability is harmed when omitting the brace in the presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``if``; would help to avoid running into a ""dangling else"" situation. .. code-block:: c++. // Omit the braces since the body is simple and clearly associated with the; // `if`.; if (isa<FunctionDecl>(D)); handleFunctionDecl(D);; else if (isa<VarDecl>(D)); handleVarDecl(D);. // Here we document the condition itself and not the body.; if (isa<VarDecl>(D)) {; // It is necessary that we explain the situation with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (should",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:62936,Usability,simpl,simple,62936,"he presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``if``; would help to avoid running into a ""dangling else"" situation. .. code-block:: c++. // Omit the braces since the body is simple and clearly associated with the; // `if`.; if (isa<FunctionDecl>(D)); handleFunctionDecl(D);; else if (isa<VarDecl>(D)); handleVarDecl(D);. // Here we document the condition itself and not the body.; if (isa<VarDecl>(D)) {; // It is necessary that we explain the situation with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (shouldProcessAttr(A)); handleAttr(A);; }. // Use braces for the `if` block to keep it uniform with the `else` block.; if (isa<FunctionDecl>(D)) {; handleFunctionDecl(D);; } else {; // In this `else` case, it is necessary that we explain the situation with; // this surprisingly long comment, so it would be unclear wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:62947,Usability,clear,clearly,62947,"he presence; of a single statement that is accompanied by a comment (assuming the comment; can't be hoisted above the ``if`` or loop statement, see below). Similarly, braces should be used when a single-statement body is complex enough; that it becomes difficult to see where the block containing the following; statement began. An ``if``/``else`` chain or a loop is considered a single; statement for this rule, and this rule applies recursively. This list is not exhaustive. For example, readability is also harmed if an; ``if``/``else`` chain does not use braced bodies for either all or none of its; members, or has complex conditionals, deep nesting, etc. The examples below; intend to provide some guidelines. Maintainability is harmed if the body of an ``if`` ends with a (directly or; indirectly) nested ``if`` statement with no ``else``. Braces on the outer ``if``; would help to avoid running into a ""dangling else"" situation. .. code-block:: c++. // Omit the braces since the body is simple and clearly associated with the; // `if`.; if (isa<FunctionDecl>(D)); handleFunctionDecl(D);; else if (isa<VarDecl>(D)); handleVarDecl(D);. // Here we document the condition itself and not the body.; if (isa<VarDecl>(D)) {; // It is necessary that we explain the situation with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (shouldProcessAttr(A)); handleAttr(A);; }. // Use braces for the `if` block to keep it uniform with the `else` block.; if (isa<FunctionDecl>(D)) {; handleFunctionDecl(D);; } else {; // In this `else` case, it is necessary that we explain the situation with; // this surprisingly long comment, so it would be unclear wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:64203,Usability,simpl,simple,64203,"n with this surprisingly long; // comment, so it would be unclear without the braces whether the following; // statement is in the scope of the `if`.; // Because the condition is documented, we can't really hoist this; // comment that applies to the body above the `if`.; handleOtherDecl(D);; }. // Use braces on the outer `if` to avoid a potential dangling `else`; // situation.; if (isa<VarDecl>(D)) {; if (shouldProcessAttr(A)); handleAttr(A);; }. // Use braces for the `if` block to keep it uniform with the `else` block.; if (isa<FunctionDecl>(D)) {; handleFunctionDecl(D);; } else {; // In this `else` case, it is necessary that we explain the situation with; // this surprisingly long comment, so it would be unclear without the braces; // whether the following statement is in the scope of the `if`.; handleOtherDecl(D);; }. // This should also omit braces. The `for` loop contains only a single; // statement, so it shouldn't have braces. The `if` also only contains a; // single simple statement (the `for` loop), so it also should omit braces.; if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()); handleAttr(A);. // Use braces for a `do-while` loop and its enclosing statement.; if (Tok->is(tok::l_brace)) {; do {; Tok = Tok->Next;; } while (Tok);; }. // Use braces for the outer `if` since the nested `for` is braced.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()) {; // In this `for` loop body, it is necessary that we explain the situation; // with this surprisingly long comment, forcing braces on the `for` block.; handleAttr(A);; }; }. // Use braces on the outer block because there are more than two levels of; // nesting.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()); for (ssize_t i : llvm::seq<ssize_t>(count)); handleAttrOnDecl(D, A, i);; }. // Use braces on the outer block because of a nested `if`; otherwise the; // compiler would warn: `add explicit braces to avoid dangling else`; if (auto *D = dyn_cast<FunctionDecl>(D)) {; if (shouldProcess(D)); handl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:65844,Usability,learn,learn,65844," situation with; // this surprisingly long comment, so it would be unclear without the braces; // whether the following statement is in the scope of the `if`.; handleOtherDecl(D);; }. // This should also omit braces. The `for` loop contains only a single; // statement, so it shouldn't have braces. The `if` also only contains a; // single simple statement (the `for` loop), so it also should omit braces.; if (isa<FunctionDecl>(D)); for (auto *A : D.attrs()); handleAttr(A);. // Use braces for a `do-while` loop and its enclosing statement.; if (Tok->is(tok::l_brace)) {; do {; Tok = Tok->Next;; } while (Tok);; }. // Use braces for the outer `if` since the nested `for` is braced.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()) {; // In this `for` loop body, it is necessary that we explain the situation; // with this surprisingly long comment, forcing braces on the `for` block.; handleAttr(A);; }; }. // Use braces on the outer block because there are more than two levels of; // nesting.; if (isa<FunctionDecl>(D)) {; for (auto *A : D.attrs()); for (ssize_t i : llvm::seq<ssize_t>(count)); handleAttrOnDecl(D, A, i);; }. // Use braces on the outer block because of a nested `if`; otherwise the; // compiler would warn: `add explicit braces to avoid dangling else`; if (auto *D = dyn_cast<FunctionDecl>(D)) {; if (shouldProcess(D)); handleVarDecl(D);; else; markAsIgnored(D);; }. See Also; ========. A lot of these comments and recommendations have been culled from other sources.; Two particularly important books for our work are:. #. `Effective C++; <https://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0321334876>`_; by Scott Meyers. Also interesting and useful are ""More Effective C++"" and; ""Effective STL"" by the same author. #. `Large-Scale C++ Software Design; <https://www.amazon.com/Large-Scale-Software-Design-John-Lakos/dp/0201633620>`_; by John Lakos. If you get some free time, and you haven't read them: do so, you might learn; something.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CodingStandards.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1424,Availability,error,error,1424,"he value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2141,Availability,error,error,2141," which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2847,Availability,down,down,2847,"s to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:2987,Availability,avail,available,2987,"e parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLine is... #. Extensible: It is very simple to add a new argument type to CommandLine.; Simply specify the parser that you want to use with the command line option; when you declare it. `Custom parsers`_ are no problem. #. Labor Saving: The CommandLine library cuts down on the amount of grunt work; that you, the user, have to do. For example, it automatically provides a; ``-help`` option that shows the available command line options for your tool.; Additionally, it does most of the basic correctness checking for you. #. Capable: The CommandLine library can handle lots of different forms of; options often found in real programs. For example, `positional`_ arguments,; ``ls`` style `grouping`_ options (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine hea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:5723,Availability,avail,available,5723,"ation to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:6484,Availability,avail,available,6484,"e optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie, not ``-filename.c``). To support this style of; argument, the CommandLine library allows for `positional`_ arguments to be; specified for the program. These positional arguments are filled with command; line parameters that are not in option form. We use this feature like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. This declaration indicates that the first positional argument should be treated; as the input filename. Here we use the `cl::init`_ option to specify an initial; value for the command line option, which is used if the option is not specified; (if you do not specify a `cl::init`_ modifier for an option, then the default; constructor for the data type is used to initialize the value)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:8208,Availability,error,error,8208,"me. Here we use the `cl::init`_ option to specify an initial; value for the command line option, which is used if the option is not specified; (if you do not specify a `cl::init`_ modifier for an option, then the default; constructor for the data type is used to initialize the value). Command line; options default to being optional, so if we would like to require that the user; always specify an input filename, we would add the `cl::Required`_ flag, and we; could eliminate the `cl::init`_ modifier, like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::Required);. Again, the CommandLine library does not require the options to be specified in; any particular order, so the above declaration is equivalent to:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::Required, cl::desc(""<input file>""));. By simply adding the `cl::Required`_ flag, the CommandLine library will; automatically issue an error if the argument is not specified, which shifts all; of the command line option verification code out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:8655,Availability,avail,available,8655,"uired`_ flag, and we; could eliminate the `cl::init`_ modifier, like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::Required);. Again, the CommandLine library does not require the options to be specified in; any particular order, so the above declaration is equivalent to:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::Required, cl::desc(""<input file>""));. By simply adding the `cl::Required`_ flag, the CommandLine library will; automatically issue an error if the argument is not specified, which shifts all; of the command line option verification code out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11114,Availability,avail,available,11114,"o we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the following inputs:. ::. compiler -f # No value, 'Force' == true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11430,Availability,avail,available,11430,"= true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15799,Availability,avail,available,15799," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18545,Availability,avail,available,18545,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21249,Availability,error,error,21249,""". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optim",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:22001,Availability,redundant,redundant,22001,":desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. To test to see if ``instsimplify`` was specified, we can use the ``cl:bits::isSet``; function:. .. code-block:: c++. if (OptimizationBits.isSet(instsimplify)) {; ...; }. It's also possible to get the raw bit vector using the ``cl::bits::getBits``; function:. .. code-block:: c++. unsigned bits = OptimizationBits.getBits();. Finally, if external storage is used, then the location specified must be of; **type** ``unsigned``. In all other ways a `cl::bits`_ option is equivalent to a; `cl::list`_ option. .. _additional extra text:. Adding f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:24029,Availability,avail,available,24029,"am grows and becomes more mature, we may decide to put summary; information about what it does into the help output. The help output is styled; to look similar to a Unix ``man`` page, providing concise information about a; program. Unix ``man`` pages, however often have a description about what the; program does. To add this to your CommandLine program, simply pass a third; argument to the `cl::ParseCommandLineOptions`_ call in main. This additional; argument is then printed as the overview information for your program, allowing; you to include any additional information that you want. For example:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv, "" CommandLine compiler example\n\n""; "" This program blah blah blah...\n"");; ...; }. would yield the help output:. ::. **OVERVIEW: CommandLine compiler example. This program blah blah blah...**. USAGE: compiler [options] <input file>. OPTIONS:; ...; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. .. _grouping options into categories:. Grouping options into categories; --------------------------------. If our program has a large number of options it may become difficult for users; of our tool to navigate the output of ``-help``. To alleviate this problem we; can put our options into categories. This can be done by declaring option; categories (`cl::OptionCategory`_ objects) and then placing our options into; these categories using the `cl::cat`_ option attribute. For example:. .. code-block:: c++. cl::OptionCategory StageSelectionCat(""Stage Selection Options"",; ""These control which stages are run."");. cl::opt<bool> Preprocessor(""E"",cl::desc(""Run preprocessor stage.""),; cl::cat(StageSelectionCat));. cl::opt<bool> NoLink(""c"",cl::desc(""Run all stages except linking.""),; cl::cat(StageSelectionCat));. The output of ``-help`` will become categorized if an option category is; declared. The output looks something like ::. OVERVIEW: This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:25185,Availability,avail,available,25185,"as a large number of options it may become difficult for users; of our tool to navigate the output of ``-help``. To alleviate this problem we; can put our options into categories. This can be done by declaring option; categories (`cl::OptionCategory`_ objects) and then placing our options into; these categories using the `cl::cat`_ option attribute. For example:. .. code-block:: c++. cl::OptionCategory StageSelectionCat(""Stage Selection Options"",; ""These control which stages are run."");. cl::opt<bool> Preprocessor(""E"",cl::desc(""Run preprocessor stage.""),; cl::cat(StageSelectionCat));. cl::opt<bool> NoLink(""c"",cl::desc(""Run all stages except linking.""),; cl::cat(StageSelectionCat));. The output of ``-help`` will become categorized if an option category is; declared. The output looks something like ::. OVERVIEW: This is a small program to demo the LLVM CommandLine API; USAGE: Sample [options]. OPTIONS:. General options:. -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more). Stage Selection Options:; These control which stages are run. -E - Run preprocessor stage.; -c - Run all stages except linking. In addition to the behaviour of ``-help`` changing when an option category is; declared, the command line option ``-help-list`` becomes visible which will; print the command line options as uncategorized list. Note that Options that are not explicitly categorized will be placed in the; ``cl::getGeneralCategory()`` category. .. _Reference Guide:. Reference Guide; ===============. Now that you know the basics of how to use the CommandLine library, this section; will give you the detailed information you need to tune how command line options; work, as well as information on more ""advanced"" command line option processing; capabilities. .. _positional:; .. _positional argument:; .. _Positional Arguments:; .. _Positional arguments section:; .. _positional options:. Positional Arguments; -----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:25257,Availability,avail,available,25257,"as a large number of options it may become difficult for users; of our tool to navigate the output of ``-help``. To alleviate this problem we; can put our options into categories. This can be done by declaring option; categories (`cl::OptionCategory`_ objects) and then placing our options into; these categories using the `cl::cat`_ option attribute. For example:. .. code-block:: c++. cl::OptionCategory StageSelectionCat(""Stage Selection Options"",; ""These control which stages are run."");. cl::opt<bool> Preprocessor(""E"",cl::desc(""Run preprocessor stage.""),; cl::cat(StageSelectionCat));. cl::opt<bool> NoLink(""c"",cl::desc(""Run all stages except linking.""),; cl::cat(StageSelectionCat));. The output of ``-help`` will become categorized if an option category is; declared. The output looks something like ::. OVERVIEW: This is a small program to demo the LLVM CommandLine API; USAGE: Sample [options]. OPTIONS:. General options:. -help - Display available options (-help-hidden for more); -help-list - Display list of available options (-help-list-hidden for more). Stage Selection Options:; These control which stages are run. -E - Run preprocessor stage.; -c - Run all stages except linking. In addition to the behaviour of ``-help`` changing when an option category is; declared, the command line option ``-help-list`` becomes visible which will; print the command line options as uncategorized list. Note that Options that are not explicitly categorized will be placed in the; ``cl::getGeneralCategory()`` category. .. _Reference Guide:. Reference Guide; ===============. Now that you know the basics of how to use the CommandLine library, this section; will give you the detailed information you need to tune how command line options; work, as well as information on more ""advanced"" command line option processing; capabilities. .. _positional:; .. _positional argument:; .. _Positional Arguments:; .. _Positional arguments section:; .. _positional options:. Positional Arguments; -----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:27083,Availability,avail,available,27083,".. _positional argument:; .. _Positional Arguments:; .. _Positional arguments section:; .. _positional options:. Positional Arguments; --------------------. Positional arguments are those arguments that are not named, and are not; specified with a hyphen. Positional arguments should be used when an option is; specified by its position alone. For example, the standard Unix ``grep`` tool; takes a regular expression argument, and an optional filename to search through; (which defaults to standard input if a filename is not specified). Using the; CommandLine library, this would be specified as:. .. code-block:: c++. cl::opt<string> Regex (cl::Positional, cl::desc(""<regular expression>""), cl::Required);; cl::opt<string> Filename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. Given these two option declarations, the ``-help`` output for our grep; replacement would look like this:. ::. USAGE: spiffygrep [options] <regular expression> <input file>. OPTIONS:; -help - display available options (-help-hidden for more). ... and the resultant program could be used just like the standard ``grep``; tool. Positional arguments are sorted by their order of construction. This means that; command line options will be ordered according to how they are listed in a .cpp; file, but will not have an ordering defined if the positional arguments are; defined in multiple .cpp files. The fix for this problem is simply to define; all of your positional arguments in one .cpp file. Specifying positional options with hyphens; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Sometimes you may want to specify a value to your positional argument that; starts with a hyphen (for example, searching for '``-foo``' in a file). At; first, you will have trouble doing this, because it will try to find an argument; named '``-foo``', and will fail (and single quotes will not save you). Note; that the system ``grep`` has the same problem:. ::. $ spiffygrep '-foo' test.txt; Unknown command line argument '-f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:32150,Availability,avail,available,32150,"eter arguments that are not interpreted by the command; line argument. As a concrete example, lets say we are developing a replacement for the standard; Unix Bourne shell (``/bin/sh``). To run ``/bin/sh``, first you specify options; to the shell itself (like ``-x`` which turns on trace output), then you specify; the name of the script to run, then you specify arguments to the script. These; arguments to the script are parsed by the Bourne shell command line option; processor, but are not interpreted as options to the shell itself. Using the; CommandLine library, we would specify this as:. .. code-block:: c++. cl::opt<string> Script(cl::Positional, cl::desc(""<input script>""), cl::init(""-""));; cl::list<string> Argv(cl::ConsumeAfter, cl::desc(""<program arguments>...""));; cl::opt<bool> Trace(""x"", cl::desc(""Enable trace output""));. which automatically provides the help output:. ::. USAGE: spiffysh [options] <input script> <program arguments>... OPTIONS:; -help - display available options (-help-hidden for more); -x - Enable trace output. At runtime, if we run our new shell replacement as ```spiffysh -x test.sh -a -x; -y bar``', the ``Trace`` variable will be set to true, the ``Script`` variable; will be set to ""``test.sh``"", and the ``Argv`` list will contain ``[""-a"", ""-x"",; ""-y"", ""bar""]``, because they were specified after the last positional argument; (which is the script name). There are several limitations to when ``cl::ConsumeAfter`` options can be; specified. For example, only one ``cl::ConsumeAfter`` can be specified per; program, there must be at least one `positional argument`_ specified, there must; not be any `cl::list`_ positional arguments, and the ``cl::ConsumeAfter`` option; should be a `cl::list`_ option. .. _can be changed:; .. _Internal vs External Storage:. Internal vs External Storage; ----------------------------. By default, all command line options automatically hold the value that they; parse from the command line. This is very convenient in the co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:36704,Availability,error,error,36704,"ion is; specified in simple double quotes:. .. code-block:: c++. cl::opt<bool> Quiet(""quiet"");. .. _cl::desc(...):. * The **cl::desc** attribute specifies a description for the option to be; shown in the ``-help`` output for the program. This attribute supports; multi-line descriptions with lines separated by '\n'. .. _cl::value_desc:. * The **cl::value_desc** attribute specifies a string that can be used to; fine tune the ``-help`` output for a command line option. Look `here`_ for an; example. .. _cl::init:. * The **cl::init** attribute specifies an initial value for a `scalar`_; option. If this attribute is not specified then the command line option value; defaults to the value created by the default constructor for the; type. .. warning::. If you specify both **cl::init** and **cl::location** for an option, you; must specify **cl::location** first, so that when the command-line parser; sees **cl::init**, it knows where to put the initial value. (You will get an; error at runtime if you don't put them in the right order.). .. _cl::location:. * The **cl::location** attribute where to store the value for a parsed command; line option if using external storage. See the section on `Internal vs; External Storage`_ for more information. .. _cl::aliasopt:. * The **cl::aliasopt** attribute specifies which option a `cl::alias`_ option is; an alias for. .. _cl::values:. * The **cl::values** attribute specifies the string-to-value mapping to be used; by the generic parser. It takes a list of (option, value, description); triplets that specify the option name, the value mapped to, and the; description shown in the ``-help`` for the tool. Because the generic parser; is used most frequently with enum values, two macros are often useful:. #. The **clEnumVal** macro is used as a nice simple way to specify a triplet; for an enum. This macro automatically makes the option name be the same as; the enum name. The first option to the macro is the enum, the second is; the description f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:38013,Availability,error,error,38013,"es which option a `cl::alias`_ option is; an alias for. .. _cl::values:. * The **cl::values** attribute specifies the string-to-value mapping to be used; by the generic parser. It takes a list of (option, value, description); triplets that specify the option name, the value mapped to, and the; description shown in the ``-help`` for the tool. Because the generic parser; is used most frequently with enum values, two macros are often useful:. #. The **clEnumVal** macro is used as a nice simple way to specify a triplet; for an enum. This macro automatically makes the option name be the same as; the enum name. The first option to the macro is the enum, the second is; the description for the command line option. #. The **clEnumValN** macro is used to specify macro options where the option; name doesn't equal the enum name. For this macro, the first argument is; the enum value, the second is the flag name, and the second is the; description. You will get a compile time error if you try to use cl::values with a parser; that does not support it. .. _cl::multi_val:. * The **cl::multi_val** attribute specifies that this option takes has multiple; values (example: ``-sectalign segname sectname sectvalue``). This attribute; takes one unsigned argument - the number of values for the option. This; attribute is valid only on ``cl::list`` options (and will fail with compile; error if you try to use it with other option types). It is allowed to use all; of the usual modifiers on multi-valued options (besides; ``cl::ValueDisallowed``, obviously). .. _cl::cat:. * The **cl::cat** attribute specifies the option category that the option; belongs to. The category should be a `cl::OptionCategory`_ object. .. _cl::callback:. * The **cl::callback** attribute specifies a callback function that is; called when an option is seen, and can be used to set other options,; as in option B implies option A. If the option is a `cl::list`_,; and `cl::CommaSeparated`_ is also specified, the callback will ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:38417,Availability,error,error,38417,"arser; is used most frequently with enum values, two macros are often useful:. #. The **clEnumVal** macro is used as a nice simple way to specify a triplet; for an enum. This macro automatically makes the option name be the same as; the enum name. The first option to the macro is the enum, the second is; the description for the command line option. #. The **clEnumValN** macro is used to specify macro options where the option; name doesn't equal the enum name. For this macro, the first argument is; the enum value, the second is the flag name, and the second is the; description. You will get a compile time error if you try to use cl::values with a parser; that does not support it. .. _cl::multi_val:. * The **cl::multi_val** attribute specifies that this option takes has multiple; values (example: ``-sectalign segname sectname sectvalue``). This attribute; takes one unsigned argument - the number of values for the option. This; attribute is valid only on ``cl::list`` options (and will fail with compile; error if you try to use it with other option types). It is allowed to use all; of the usual modifiers on multi-valued options (besides; ``cl::ValueDisallowed``, obviously). .. _cl::cat:. * The **cl::cat** attribute specifies the option category that the option; belongs to. The category should be a `cl::OptionCategory`_ object. .. _cl::callback:. * The **cl::callback** attribute specifies a callback function that is; called when an option is seen, and can be used to set other options,; as in option B implies option A. If the option is a `cl::list`_,; and `cl::CommaSeparated`_ is also specified, the callback will fire; once for each value. This could be used to validate combinations or; selectively set other options. .. code-block:: c++. cl::opt<bool> OptA(""a"", cl::desc(""option a""));; cl::opt<bool> OptB(; ""b"", cl::desc(""option b -- This option turns on option a""),; cl::callback([&](const bool &) { OptA = true; }));; cl::list<std::string, cl::list<std::string>> List(; ""lis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:40270,Availability,error,error,40270,"option turns on option a""),; cl::callback([&](const bool &) { OptA = true; }));; cl::list<std::string, cl::list<std::string>> List(; ""list"",; cl::desc(""option list -- This option turns on options a when ""; ""'foo' is included in list""),; cl::CommaSeparated,; cl::callback([&](const std::string &Str) {; if (Str == ""foo""); OptA = true;; }));. Option Modifiers; ----------------. Option modifiers are the flags and expressions that you pass into the; constructors for `cl::opt`_ and `cl::list`_. These modifiers give you the; ability to tweak how options are parsed and how ``-help`` output is generated to; fit your application well. These options fall into five main categories:. #. Hiding an option from ``-help`` output. #. Controlling the number of occurrences required and allowed. #. Controlling whether or not a value must be specified. #. Controlling other formatting options. #. Miscellaneous option modifiers. It is not possible to specify two options from the same category (you'll get a; runtime error) to a single option, except for options in the miscellaneous; category. The CommandLine library specifies defaults for all of these settings; that are the most useful in practice and the most common, which mean that you; usually shouldn't have to worry about these. Hiding an option from ``-help`` output; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::NotHidden``, ``cl::Hidden``, and ``cl::ReallyHidden`` modifiers are; used to control whether or not an option appears in the ``-help`` and; ``-help-hidden`` output for the compiled program:. .. _cl::NotHidden:. * The **cl::NotHidden** modifier (which is the default for `cl::opt`_ and; `cl::list`_ options) indicates the option is to appear in both help; listings. .. _cl::Hidden:. * The **cl::Hidden** modifier (which is the default for `cl::alias`_ options); indicates that the option should not appear in the ``-help`` output, but; should appear in the ``-help-hidden`` output. .. _cl::ReallyHidden:. * The **cl::ReallyHidden** m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:41675,Availability,error,error,41675,"::Hidden``, and ``cl::ReallyHidden`` modifiers are; used to control whether or not an option appears in the ``-help`` and; ``-help-hidden`` output for the compiled program:. .. _cl::NotHidden:. * The **cl::NotHidden** modifier (which is the default for `cl::opt`_ and; `cl::list`_ options) indicates the option is to appear in both help; listings. .. _cl::Hidden:. * The **cl::Hidden** modifier (which is the default for `cl::alias`_ options); indicates that the option should not appear in the ``-help`` output, but; should appear in the ``-help-hidden`` output. .. _cl::ReallyHidden:. * The **cl::ReallyHidden** modifier indicates that the option should not appear; in any help output. Controlling the number of occurrences required and allowed; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This group of options is used to control how many time an option is allowed (or; required) to be specified on the command line of your program. Specifying a; value for this setting allows the CommandLine library to do error checking for; you. The allowed values for this option group are:. .. _cl::Optional:. * The **cl::Optional** modifier (which is the default for the `cl::opt`_ and; `cl::alias`_ classes) indicates that your program will allow either zero or; one occurrence of the option to be specified. .. _cl::ZeroOrMore:. * The **cl::ZeroOrMore** modifier (which is the default for the `cl::list`_; class) indicates that your program will allow the option to be specified zero; or more times. .. _cl::Required:. * The **cl::Required** modifier indicates that the specified option must be; specified exactly one time. .. _cl::OneOrMore:. * The **cl::OneOrMore** modifier indicates that the option must be specified at; least one time. * The **cl::ConsumeAfter** modifier is described in the `Positional arguments; section`_. If an option is not specified, then the value of the option is equal to the; value specified by the `cl::init`_ attribute. If the ``cl::init`` attribute is; not",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:44366,Availability,error,error,44366,"*cl::ValueOptional** modifier (which is the default for ``bool`` typed; options) specifies that it is acceptable to have a value, or not. A boolean; argument can be enabled just by appearing on the command line, or it can have; an explicit '``-foo=true``'. If an option is specified with this mode, it is; illegal for the value to be provided without the equal sign. Therefore; '``-foo true``' is illegal. To get this behavior, you must use; the `cl::ValueRequired`_ modifier. .. _cl::ValueRequired:. * The **cl::ValueRequired** modifier (which is the default for all other types; except for `unnamed alternatives using the generic parser`_) specifies that a; value must be provided. This mode informs the command line library that if an; option is not provides with an equal sign, that the next argument provided; must be the value. This allows things like '``-o a.out``' to work. .. _cl::ValueDisallowed:. * The **cl::ValueDisallowed** modifier (which is the default for `unnamed; alternatives using the generic parser`_) indicates that it is a runtime error; for the user to specify a value. This can be provided to disallow users from; providing options to boolean options (like '``-foo=true``'). In general, the default values for this option group work just like you would; want them to. As mentioned above, you can specify the `cl::ValueDisallowed`_; modifier to a boolean argument to restrict your command line parser. These; options are mostly useful when `extending the library`_. .. _formatting option:. Controlling other formatting options; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The formatting option group is used to specify that the command line option has; special abilities and is otherwise different from other command line arguments.; As usual, you can only specify one of these arguments at most. .. _cl::NormalFormatting:. * The **cl::NormalFormatting** modifier (which is the default all options); specifies that this option is ""normal"". .. _cl::Positional:. * The **cl::Positiona",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:46968,Availability,error,error,46968,"sing odd; arguments like ``-lmalloc`` and ``-L/usr/lib`` in a linker tool or; ``-DNAME=value`` in a compiler tool. Here, the '``l``', '``D``' and '``L``'; options are normal string (or list) options, that have the **cl::Prefix**; modifier added to allow the CommandLine library to recognize them. Note that; **cl::Prefix** options must not have the **cl::ValueDisallowed** modifier; specified. .. _grouping:; .. _cl::Grouping:. Controlling options grouping; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The **cl::Grouping** modifier can be combined with any formatting types except; for `cl::Positional`_. It is used to implement Unix-style tools (like ``ls``); that have lots of single letter arguments, but only require a single dash.; For example, the '``ls -labF``' command actually enables four different options,; all of which are single letters. Note that **cl::Grouping** options can have values only if they are used; separately or at the end of the groups. For `cl::ValueRequired`_, it is; a runtime error if such an option is used elsewhere in the group. The CommandLine library does not restrict how you use the **cl::Prefix** or; **cl::Grouping** modifiers, but it is possible to specify ambiguous argument; settings. Thus, it is possible to have multiple letter options that are prefix; or grouping options, and they will still work as designed. To do this, the CommandLine library uses a greedy algorithm to parse the input; option into (potentially multiple) prefix and grouping options. The strategy; basically looks like this:. ::. parse(string OrigInput) {. 1. string Input = OrigInput;; 2. if (isOption(Input)) return getOption(Input).parse(); // Normal option; 3. while (!Input.empty() && !isOption(Input)) Input.pop_back(); // Remove the last letter; 4. while (!Input.empty()) {; string MaybeValue = OrigInput.substr(Input.length()); if (getOption(Input).isPrefix()); return getOption(Input).parse(MaybeValue); if (!MaybeValue.empty() && MaybeValue[0] == '='); return getOption(Input).parse(May",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:48038,Availability,error,error,48038,"library does not restrict how you use the **cl::Prefix** or; **cl::Grouping** modifiers, but it is possible to specify ambiguous argument; settings. Thus, it is possible to have multiple letter options that are prefix; or grouping options, and they will still work as designed. To do this, the CommandLine library uses a greedy algorithm to parse the input; option into (potentially multiple) prefix and grouping options. The strategy; basically looks like this:. ::. parse(string OrigInput) {. 1. string Input = OrigInput;; 2. if (isOption(Input)) return getOption(Input).parse(); // Normal option; 3. while (!Input.empty() && !isOption(Input)) Input.pop_back(); // Remove the last letter; 4. while (!Input.empty()) {; string MaybeValue = OrigInput.substr(Input.length()); if (getOption(Input).isPrefix()); return getOption(Input).parse(MaybeValue); if (!MaybeValue.empty() && MaybeValue[0] == '='); return getOption(Input).parse(MaybeValue.substr(1)); if (!getOption(Input).isGrouping()); return error(); getOption(Input).parse(); Input = OrigInput = MaybeValue; while (!Input.empty() && !isOption(Input)) Input.pop_back();; if (!Input.empty() && !getOption(Input).isGrouping()); return error(); }; 5. if (!OrigInput.empty()) error();. }. Miscellaneous option modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The miscellaneous option modifiers are the only flags where you can specify more; than one flag from the set: they are not mutually exclusive. These flags; specify boolean properties that modify the option. .. _cl::CommaSeparated:. * The **cl::CommaSeparated** modifier indicates that any commas specified for an; option's value should be used to split the value up into multiple values for; the option. For example, these two options are equivalent when; ``cl::CommaSeparated`` is specified: ""``-foo=a -foo=b -foo=c``"" and; ""``-foo=a,b,c``"". This option only makes sense to be used in a case where the; option is allowed to accept one or more values (i.e. it is a `cl::list`_; option). .. _cl::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:48229,Availability,error,error,48229,"e letter options that are prefix; or grouping options, and they will still work as designed. To do this, the CommandLine library uses a greedy algorithm to parse the input; option into (potentially multiple) prefix and grouping options. The strategy; basically looks like this:. ::. parse(string OrigInput) {. 1. string Input = OrigInput;; 2. if (isOption(Input)) return getOption(Input).parse(); // Normal option; 3. while (!Input.empty() && !isOption(Input)) Input.pop_back(); // Remove the last letter; 4. while (!Input.empty()) {; string MaybeValue = OrigInput.substr(Input.length()); if (getOption(Input).isPrefix()); return getOption(Input).parse(MaybeValue); if (!MaybeValue.empty() && MaybeValue[0] == '='); return getOption(Input).parse(MaybeValue.substr(1)); if (!getOption(Input).isGrouping()); return error(); getOption(Input).parse(); Input = OrigInput = MaybeValue; while (!Input.empty() && !isOption(Input)) Input.pop_back();; if (!Input.empty() && !getOption(Input).isGrouping()); return error(); }; 5. if (!OrigInput.empty()) error();. }. Miscellaneous option modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The miscellaneous option modifiers are the only flags where you can specify more; than one flag from the set: they are not mutually exclusive. These flags; specify boolean properties that modify the option. .. _cl::CommaSeparated:. * The **cl::CommaSeparated** modifier indicates that any commas specified for an; option's value should be used to split the value up into multiple values for; the option. For example, these two options are equivalent when; ``cl::CommaSeparated`` is specified: ""``-foo=a -foo=b -foo=c``"" and; ""``-foo=a,b,c``"". This option only makes sense to be used in a case where the; option is allowed to accept one or more values (i.e. it is a `cl::list`_; option). .. _cl::DefaultOption:. * The **cl::DefaultOption** modifier is used to specify that the option is a; default that can be overridden by application specific parsers. For example,; the ``-help``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:48268,Availability,error,error,48268,"ng options, and they will still work as designed. To do this, the CommandLine library uses a greedy algorithm to parse the input; option into (potentially multiple) prefix and grouping options. The strategy; basically looks like this:. ::. parse(string OrigInput) {. 1. string Input = OrigInput;; 2. if (isOption(Input)) return getOption(Input).parse(); // Normal option; 3. while (!Input.empty() && !isOption(Input)) Input.pop_back(); // Remove the last letter; 4. while (!Input.empty()) {; string MaybeValue = OrigInput.substr(Input.length()); if (getOption(Input).isPrefix()); return getOption(Input).parse(MaybeValue); if (!MaybeValue.empty() && MaybeValue[0] == '='); return getOption(Input).parse(MaybeValue.substr(1)); if (!getOption(Input).isGrouping()); return error(); getOption(Input).parse(); Input = OrigInput = MaybeValue; while (!Input.empty() && !isOption(Input)) Input.pop_back();; if (!Input.empty() && !getOption(Input).isGrouping()); return error(); }; 5. if (!OrigInput.empty()) error();. }. Miscellaneous option modifiers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The miscellaneous option modifiers are the only flags where you can specify more; than one flag from the set: they are not mutually exclusive. These flags; specify boolean properties that modify the option. .. _cl::CommaSeparated:. * The **cl::CommaSeparated** modifier indicates that any commas specified for an; option's value should be used to split the value up into multiple values for; the option. For example, these two options are equivalent when; ``cl::CommaSeparated`` is specified: ""``-foo=a -foo=b -foo=c``"" and; ""``-foo=a,b,c``"". This option only makes sense to be used in a case where the; option is allowed to accept one or more values (i.e. it is a `cl::list`_; option). .. _cl::DefaultOption:. * The **cl::DefaultOption** modifier is used to specify that the option is a; default that can be overridden by application specific parsers. For example,; the ``-help`` alias, ``-h``, is registered this way, so ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:50264,Availability,error,error,50264,"c parsers. For example,; the ``-help`` alias, ``-h``, is registered this way, so it can be overridden; by applications that need to use the ``-h`` option for another purpose,; either as a regular option or an alias for another option. .. _cl::PositionalEatsArgs:. * The **cl::PositionalEatsArgs** modifier (which only applies to positional; arguments, and only makes sense for lists) indicates that positional argument; should consume any strings after it (including strings that start with a ""-""); up until another recognized positional argument. For example, if you have two; ""eating"" positional arguments, ""``pos1``"" and ""``pos2``"", the string ""``-pos1; -foo -bar baz -pos2 -bork``"" would cause the ""``-foo -bar -baz``"" strings to; be applied to the ""``-pos1``"" option and the ""``-bork``"" string to be applied; to the ""``-pos2``"" option. .. _cl::Sink:. * The **cl::Sink** modifier is used to handle unknown options. If there is at; least one option with ``cl::Sink`` modifier specified, the parser passes; unrecognized option strings to it as values instead of signaling an error. As; with ``cl::CommaSeparated``, this modifier only makes sense with a `cl::list`_; option. .. _response files:. Response files; ^^^^^^^^^^^^^^. Some systems, such as certain variants of Microsoft Windows and some older; Unices have a relatively low limit on command-line length. It is therefore; customary to use the so-called 'response files' to circumvent this; restriction. These files are mentioned on the command-line (using the ""@file""); syntax. The program reads these files and inserts the contents into argv,; thereby working around the command-line length limits. Top-Level Classes and Functions; -------------------------------. Despite all of the built-in flexibility, the CommandLine option library really; only consists of one function `cl::ParseCommandLineOptions`_ and three main; classes: `cl::opt`_, `cl::list`_, and `cl::alias`_. This section describes; these three classes in detail. .. _cl::getR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:53244,Availability,avail,available,53244,"tions"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is designed to be called directly from; ``main`` and *before* ``cl::ParseCommandLineOptions``. Its use is optional. It; simply arranges for a function to be called in response to the ``--version``; option instead of having the ``CommandLine`` library print out the usual version; string for LLVM. This is useful for programs that are not part of LLVM but wish; to use the ``CommandLine`` facilities. Such programs should just define a small; function that takes no arguments and returns ``void`` and that prints out; whatever version information i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:59690,Availability,error,error,59690,"aken from the command line is translated; into a typed value, suitable for use in a C++ program. By default, the; CommandLine library uses an instance of ``parser<type>`` if the command line; option specifies that it uses values of type '``type``'. Because of this,; custom option processing is specified with specializations of the '``parser``'; class. The CommandLine library provides the following builtin parser specializations,; which are sufficient for most applications. It can, however, also be extended to; work with new data types and new ways of interpreting the same data. See the; `Writing a Custom Parser`_ for more details on this type of library extension. .. _enums:; .. _cl::parser:. * The generic ``parser<t>`` parser can be used to map strings values to any data; type, through the use of the `cl::values`_ property, which specifies the; mapping information. The most common use of this parser is for parsing enum; values, which allows you to use the CommandLine library for all of the error; checking to make sure that only valid enum values are specified (as opposed to; accepting arbitrary strings). Despite this, however, the generic parser class; can be used for any data type. .. _boolean flags:; .. _bool parser:. * The **parser<bool> specialization** is used to convert boolean strings to a; boolean value. Currently accepted strings are ""``true``"", ""``TRUE``"",; ""``True``"", ""``1``"", ""``false``"", ""``FALSE``"", ""``False``"", and ""``0``"". * The **parser<boolOrDefault> specialization** is used for cases where the value; is boolean, but we also need to know whether the option was specified at all.; boolOrDefault is an enum with 3 values, BOU_UNSET, BOU_TRUE and BOU_FALSE.; This parser accepts the same strings as **``parser<bool>``**. .. _strings:. * The **parser<string> specialization** simply stores the parsed string into the; string value specified. No conversion or modification of the data is; performed. .. _integers:; .. _int:. * The **parser<int> specialization*",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:63472,Availability,error,error,63472,"proach is that it; doesn't work if your fundamental data type is something that is already; supported. #. Write an independent class, using it explicitly from options that need it. This approach works well in situations where you would line to parse an; option using special syntax for a not-very-special data-type. The drawback; of this approach is that users of your parser have to be aware that they are; using your parser instead of the builtin ones. To guide the discussion, we will discuss a custom parser that accepts file; sizes, specified with an optional unit after the numeric size. For example, we; would like to parse ""102kb"", ""41M"", ""1G"" into the appropriate integer value. In; this case, the underlying data type we want to parse into is '``unsigned``'. We; choose approach #2 above because we don't want to make this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:64280,Availability,error,error,64280,"ake this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; int",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:64784,Availability,error,error,64784," parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65054,Availability,error,error,65054,"ed whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./tes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65105,Availability,error,error,65105,"tion name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65426,Availability,error,error,65426,"l FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65447,Availability,error,error,65447,"l FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65507,Availability,error,error,65507,"l FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65834,Availability,avail,available,65834,"at; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage locatio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66296,Availability,error,error,66296,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:12553,Deployability,update,updates,12553,"alar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------. So far we have seen how the CommandLine library handles builtin types like; ``std::string``, ``bool`` and ``int``, but how does it handle things it doesn't; know about, like enums or '``int*``'s?. The answer ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:21341,Energy Efficiency,reduce,reduces,21341," switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `cl::OneOrMore`_ modifier to inform the CommandLine library that it is an error; if the user does not specify any ``.o`` files on our command line. Again, this; just reduces the amount of checking we have to do. Collecting options as a set of flags; ------------------------------------. Instead of collecting sets of options in a list, it is also possible to gather; information for enum values in a **bit vector**. The representation used by the; `cl::bits`_ class is an ``unsigned`` integer. An enum value is represented by a; 0/1 in the enum's ordinal value bit position. 1 indicating that the enum was; specified, 0 otherwise. As each specified value is parsed, the resulting enum's; bit is set in the option's bit vector:. .. code-block:: c++. bits |= 1 << (unsigned)enum;. Options that are specified multiple times are redundant. Any instances after; the first are discarded. Reworking the above list example, we could replace `cl::list`_ with `cl::bits`_:. .. code-block:: c++. cl::bits<Opts> OptimizationBits(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumVal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:6290,Integrability,interface,interface,6290," argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie, not ``-filename.c``). To support this style of; argument, the CommandLine library allows for `positional`_ arguments to be; specified for the program. These positional arguments are filled with command; line parameters that are not in option form. We use this feature like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. This declaration indicates that the first positional argument should be treated; as the input filen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:6454,Integrability,depend,dependencies,6454,"are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. Because we specified that the command line option should parse using the; ``string`` data type, the variable declared is automatically usable as a real; string in all contexts that a normal C++ string object may be used. For; example:. .. code-block:: c++. ...; std::ofstream Output(OutputFilename.c_str());; if (Output.good()) ...; ... There are many different options that you can use to customize the command line; option handling library, but the above example shows the general interface to; these options. The options can be specified in any order, and are specified; with helper functions like `cl::desc(...)`_, so there are no positional; dependencies to remember. The available options are discussed in detail in the; `Reference Guide`_. Continuing the example, we would like to have our compiler take an input; filename as well as an output filename, but we do not want the input filename to; be specified with a hyphen (ie, not ``-filename.c``). To support this style of; argument, the CommandLine library allows for `positional`_ arguments to be; specified for the program. These positional arguments are filled with command; line parameters that are not in option form. We use this feature like this:. .. code-block:: c++. cl::opt<string> InputFilename(cl::Positional, cl::desc(""<input file>""), cl::init(""-""));. This declaration indicates that the first positional argument should be treated; as the input filename. Here we use the `cl::init`_ option to specify an initial; value for the command line option, which is used if the option is not specified; (if you do not specify a `cl::init`_ modifier for an option, then the defau",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:9330,Integrability,message,messages,9330,"e out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevents it from being shown by the standard ""``-help``"" output (note; that it is still shown in the ""``-help-hidden``"" output). The CommandLine library uses a `different parser`_ for different data types.; For example, in the string case, the argument passed to the option is copied; literally into the content of the string variable... we obviously cannot do that; in the boolean case, however, so we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the followi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:9406,Integrability,message,messages,9406,"e out of your application into the; library. This is just one example of how using flags can alter the default; behaviour of the library, on a per-option basis. By adding one of the; declarations above, the ``-help`` option synopsis is now extended to:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -h - Alias for -help; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename. ... indicating that an input filename is expected. Boolean Arguments; -----------------. In addition to input and output filenames, we would like the compiler example to; support three boolean flags: ""``-f``"" to force writing binary output to a; terminal, ""``--quiet``"" to enable quiet mode, and ""``-q``"" for backwards; compatibility with some of our users. We can support these by declaring options; of boolean type like this:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Enable binary output on terminals""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::opt<bool> Quiet2(""q"", cl::desc(""Don't print informational messages""), cl::Hidden);. This does what you would expect: it declares three boolean variables; (""``Force``"", ""``Quiet``"", and ""``Quiet2``"") to recognize these options. Note; that the ""``-q``"" option is specified with the ""`cl::Hidden`_"" flag. This; modifier prevents it from being shown by the standard ""``-help``"" output (note; that it is still shown in the ""``-help-hidden``"" output). The CommandLine library uses a `different parser`_ for different data types.; For example, in the string case, the argument passed to the option is copied; literally into the content of the string variable... we obviously cannot do that; in the boolean case, however, so we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the followi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11088,Integrability,message,messages,11088,"o we must use a smarter parser. In the case of; the boolean parser, it allows no options (in which case it assigns the value of; true to the variable), or it allows the values ""``true``"" or ""``false``"" to be; specified, allowing any of the following inputs:. ::. compiler -f # No value, 'Force' == true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11359,Integrability,message,messages,11359,"= true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:11404,Integrability,message,messages,11404,"= true; compiler -f=true # Value specified, 'Force' == true; compiler -f=TRUE # Value specified, 'Force' == true; compiler -f=FALSE # Value specified, 'Force' == false. ... you get the idea. The `bool parser`_ just turns the string values into; boolean values, and rejects things like '``compiler -f=foo``'. Similarly, the; `float`_, `double`_, and `int`_ parsers work like you would expect, using the; '``strtol``' and '``strtod``' C library calls to parse the string value into the; specified data type. With the declarations above, ""``compiler -help``"" emits this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). and ""``compiler -help-hidden``"" prints this:. ::. USAGE: compiler [options] <input file>. OPTIONS:; -f - Enable binary output on terminals; -o - Override output filename; -q - Don't print informational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:12371,Integrability,message,messages,12371,"rmational messages; -quiet - Don't print informational messages; -help - display available options (-help-hidden for more). This brief example has shown you how to use the '`cl::opt`_' class to parse; simple scalar command line arguments. In addition to simple scalar arguments,; the CommandLine library also provides primitives to support CommandLine option; `aliases`_, and `lists`_ of options. .. _aliases:. Argument Aliases; ----------------. So far, the example works well, except for the fact that we need to check the; quiet condition like this now:. .. code-block:: c++. ...; if (!Quiet && !Quiet2) printInformationalMessage(...);; ... ... which is a real pain! Instead of defining two values for the same; condition, we can use the ""`cl::alias`_"" class to make the ""``-q``"" option an; **alias** for the ""``-quiet``"" option, instead of providing a value itself:. .. code-block:: c++. cl::opt<bool> Force (""f"", cl::desc(""Overwrite output files""));; cl::opt<bool> Quiet (""quiet"", cl::desc(""Don't print informational messages""));; cl::alias QuietA(""q"", cl::desc(""Alias for -quiet""), cl::aliasopt(Quiet));. The third line (which is the only one we modified from above) defines a ""``-q``""; alias that updates the ""``Quiet``"" variable (as specified by the `cl::aliasopt`_; modifier) whenever it is specified. Because aliases do not hold state, the only; thing the program has to query is the ``Quiet`` variable now. Another nice; feature of aliases is that they automatically hide themselves from the ``-help``; output (although, again, they are still visible in the ``-help-hidden output``). Now the application code can simply use:. .. code-block:: c++. ...; if (!Quiet) printInformationalMessage(...);; ... ... which is much nicer! The ""`cl::alias`_"" can be used to specify an; alternative name for any variable type, and has many uses. .. _unnamed alternatives using the generic parser:. Selecting an alternative from a set of possibilities; ----------------------------------------------------.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15918,Integrability,message,messages,15918," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:17997,Integrability,interface,interface,17997,"that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option name. For this case,; the code looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most approp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18664,Integrability,message,messages,18664,"e looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimpl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:57561,Integrability,message,message,57561," }. This class works the exact same as the `cl::list`_ class, except that the second; argument must be of **type** ``unsigned`` if external storage is used. .. _cl::alias:. The ``cl::alias`` class; ^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::alias`` class is a nontemplated class that is used to form aliases for; other arguments. .. code-block:: c++. namespace cl {; class alias;; }. The `cl::aliasopt`_ attribute should be used to specify which option this is an; alias for. Alias arguments default to being `cl::Hidden`_, and use the aliased; options parser to do the conversion from string to data. .. _cl::extrahelp:. The ``cl::extrahelp`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::extrahelp`` class is a nontemplated class that allows extra help text; to be printed out for the ``-help`` option. .. code-block:: c++. namespace cl {; struct extrahelp;; }. To use the extrahelp, simply construct one with a ``const char*`` parameter to; the constructor. The text passed to the constructor will be printed at the; bottom of the help message, verbatim. Note that multiple ``cl::extrahelp``; **can** be used, but this practice is discouraged. If your tool needs to print; additional help information, put all that help into a single ``cl::extrahelp``; instance. For example:. .. code-block:: c++. cl::extrahelp(""\nADDITIONAL HELP:\n\n This is the extra help\n"");. .. _cl::OptionCategory:. The ``cl::OptionCategory`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::OptionCategory`` class is a simple class for declaring; option categories. .. code-block:: c++. namespace cl {; class OptionCategory;; }. An option category must have a name and optionally a description which are; passed to the constructor as ``const char*``. Note that declaring an option category and associating it with an option before; parsing options (e.g. statically) will change the output of ``-help`` from; uncategorized to categorized. If an option category is declared but not; associated with an option then it will be hidden",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:64286,Integrability,message,message,64286,"ake this the default for all; ``unsigned`` options. To start out, we declare our new ``FileSizeParser`` class:. .. code-block:: c++. struct FileSizeParser : public cl::parser<unsigned> {; // parse - Return true on error.; bool parse(cl::Option &O, StringRef ArgName, const std::string &ArgValue,; unsigned &Val);; };. Our new class inherits from the ``cl::parser`` template class to fill in; the default, boiler plate code for us. We give it the data type that we parse; into, the last argument to the ``parse`` method, so that clients of our custom; parser know what object type to pass in to the parse method. (Here we declare; that we parse into '``unsigned``' variables.). For most purposes, the only method that must be implemented in a custom parser; is the ``parse`` method. The ``parse`` method is called whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; int",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65060,Integrability,message,message,65060,"ed whenever the option is; invoked, passing in the option itself, the option name, the string to parse, and; a reference to a return value. If the string to parse is not well-formed, the; parser should output an error message and return true. Otherwise it should; return false and set '``Val``' to the parsed value. In our example, we; implement ``parse`` as:. .. code-block:: c++. bool FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./tes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65432,Integrability,message,message,65432,"l FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:65513,Integrability,message,message,65513,"l FileSizeParser::parse(cl::Option &O, StringRef ArgName,; const std::string &Arg, unsigned &Val) {; const char *ArgStart = Arg.c_str();; char *End;. // Parse integer part, leaving 'End' pointing to the first non-integer char; Val = (unsigned)strtol(ArgStart, &End, 0);. while (1) {; switch (*End++) {; case 0: return false; // No error; case 'i': // Ignore the 'i' in KiB if people use that; case 'b': case 'B': // Ignore B suffix; break;. case 'g': case 'G': Val *= 1024*1024*1024; break;; case 'm': case 'M': Val *= 1024*1024; break;; case 'k': case 'K': Val *= 1024; break;. default:; // Print an error message if unrecognized character!; return O.error(""'"" + Arg + ""' value invalid for file size argument!"");; }; }; }. This function implements a very simple parser for the kinds of strings we are; interested in. Although it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66302,Integrability,message,message,66302,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:66394,Integrability,wrap,wraps,66394,"hough it has some holes (it allows ""``123KKK``"" for example),; it is good enough for this example. Note that we use the option itself to print; out the error message (the ``error`` method always returns true) in order to get; a nice error message (shown below). Now that we have our parser class, we can; use it like this:. .. code-block:: c++. static cl::opt<unsigned, false, FileSizeParser>; MFS(""max-file-size"", cl::desc(""Maximum file size to accept""),; cl::value_desc(""size""));. Which adds this to the output of our program:. ::. OPTIONS:; -help - display available options (-help-hidden for more); ...; -max-file-size=<size> - Maximum file size to accept. And we can test that our parse works correctly now (the test program just prints; out the max-file-size argument value):. ::. $ ./test; MFS: 0; $ ./test -max-file-size=123MB; MFS: 128974848; $ ./test -max-file-size=3G; MFS: 3221225472; $ ./test -max-file-size=dog; -max-file-size option: 'dog' value invalid for file size argument!. It looks like it works. The error message that we get is nice and helpful, and; we seem to accept reasonable file sizes. This wraps up the ""custom parser""; tutorial. Exploiting external storage; ---------------------------. Several of the LLVM libraries define static ``cl::opt`` instances that will; automatically be included in any program that links with that library. This is; a feature. However, sometimes it is necessary to know the value of the command; line option outside of the library. In these cases the library does or should; provide an external storage location that is accessible to users of the; library. Examples of this include the ``llvm::DebugFlag`` exported by the; ``lib/Support/Debug.cpp`` file and the ``llvm::TimePassesIsEnabled`` flag; exported by the ``lib/IR/PassManager.cpp`` file. .. todo::. TODO: complete this section. .. _dynamically loaded options:. Dynamically adding command line options; ---------------------------------------. .. todo::. TODO: fill in this section; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1109,Modifiability,variab,variables,1109,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1157,Modifiability,variab,variable,1157,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1562,Modifiability,variab,variables,1562,"ibraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types directly, meaning that; there is less error and more security built into the library. You don't have; to worry about whether your integral command line argument accidentally got; assigned a value that is not valid for your enum type. #. Powerful: The CommandLine library supports many different types of arguments,; from simple `boolean flags`_ to `scalars arguments`_ (`strings`_,; `integers`_, `enums`_, `doubles`_), to `lists of arguments`_. This is; possible because CommandLin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:4300,Modifiability,variab,variable,4300,"ions (to allow processing '``ls -lad``'; naturally), ``ld`` style `prefix`_ options (to parse '``-lmalloc; -L/usr/lib``'), and interpreter style options. This document will hopefully let you jump in and start using CommandLine in your; utility quickly and painlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine header file into your program:. .. code-block:: c++. #include ""llvm/Support/CommandLine.h"". Additionally, you need to add this as the first line of your main program:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; global variable declaration to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:4566,Modifiability,variab,variable,4566,"inlessly. Additionally it should be a simple reference; manual to figure out how stuff works. Quick Start Guide; =================. This section of the manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine header file into your program:. .. code-block:: c++. #include ""llvm/Support/CommandLine.h"". Additionally, you need to add this as the first line of your main program:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; global variable declaration to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:4725,Modifiability,variab,variable,4725," manual runs through a simple CommandLine'ification of a; basic compiler tool. This is intended to show you how to jump into using the; CommandLine library in your own program, and show you some of the cool things it; can do. To start out, you need to include the CommandLine header file into your program:. .. code-block:: c++. #include ""llvm/Support/CommandLine.h"". Additionally, you need to add this as the first line of your main program:. .. code-block:: c++. int main(int argc, char **argv) {; cl::ParseCommandLineOptions(argc, argv);; ...; }. ... which actually parses the arguments and fills in the variable declarations. Now that you are ready to support command line arguments, we need to tell the; system which ones we want, and what type of arguments they are. The CommandLine; library uses a declarative syntax to model command line arguments with the; global variable declarations that capture the parsed values. This means that; for every command line option that you would like to support, there should be a; global variable declaration to capture the result. For example, in a compiler,; we would like to support the Unix-standard '``-o <filename>``' option to specify; where to put the output. With the CommandLine library, this is represented like; this:. .. _scalars arguments:; .. _here:. .. code-block:: c++. cl::opt<string> OutputFilename(""o"", cl::desc(""Specify output filename""), cl::value_desc(""filename""));. This declares a global variable ""``OutputFilename``"" that is used to capture the; result of the ""``o``"" argument (first parameter). We specify that this is a; simple scalar option by using the ""``cl::opt``"" template (as opposed to the; ""``cl::list``"" template), and tell the CommandLine library that the data; type that we are parsing is a string. The second and third parameters (which are optional) are used to specify what to; output for the ""``-help``"" option. In this case, we get a line that looks like; this:. ::. USAGE: compiler [options]. OPTIONS:; -h - Alia",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandLine.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst
