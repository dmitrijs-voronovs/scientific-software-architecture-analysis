id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://root.cern/root/html532/TMultiDimFit.html:27365,Energy Efficiency,power,power,27365," This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:31642,Energy Efficiency,power,powers,31642,"method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""p",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:32848,Energy Efficiency,power,powers,32848,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:32915,Energy Efficiency,power,powers,32915,"eParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. voi",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:33572,Energy Efficiency,power,powers,33572,"mula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34143,Energy Efficiency,power,powers,34143,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34168,Energy Efficiency,power,power,34168,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:943,Integrability,depend,dependent,943,". TMultiDimFit. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. ",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:1113,Integrability,depend,dependence,1113," Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:1319,Integrability,depend,dependent,1319,"ltiDimFit. class TMultiDimFit: public TNamed. /*. Multidimensional Fits in ROOT. Overview. A common problem encountered in different fields of applied science is; to find an expression for one physical quantity in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2233,Integrability,depend,dependent,2233,"e; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified f",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2271,Integrability,depend,depends,2271,"e; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified f",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2478,Integrability,depend,dependent,2478,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:4049,Integrability,depend,dependent,4049," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:5951,Integrability,depend,dependent,5951," will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspac",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10330,Integrability,depend,dependence,10330," (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameteri",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10498,Integrability,depend,dependent,10498,"inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11923,Integrability,depend,dependent,11923,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:21764,Integrability,depend,dependent,21764,"tual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; Byte_tfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; T",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:22659,Integrability,depend,dependent,22659,"tual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; Byte_tfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; T",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:22938,Integrability,depend,dependent,22938,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:23104,Integrability,depend,dependent,23104,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24029,Integrability,depend,dependent,24029,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24367,Integrability,depend,dependent,24367,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24613,Integrability,depend,dependent,24613,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25576,Integrability,depend,dependent,25576,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25637,Integrability,depend,dependent,25637,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25995,Integrability,depend,dependent,25995," Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26184,Integrability,depend,dependent,26184,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26245,Integrability,depend,dependent,26245,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26510,Integrability,depend,dependent,26510," Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameter",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29746,Integrability,message,message,29746,"ed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29919,Integrability,depend,dependent,29919,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29986,Integrability,depend,dependent,29986,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:30081,Integrability,depend,dependent,30081,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:32757,Integrability,message,message,32757,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:1508,Modifiability,variab,variables,1508,"ty in terms of several; others, which are directly measurable. An example in high energy physics is the evaluation of the momentum of; a charged particle from the observation of its trajectory in a magnetic; field. The problem is to relate the momentum of the particle to the; observations, which may consists of of positional measurements at; intervals along the particle trajectory. The exact functional relationship between the measured quantities; (e.g., the space-points) and the dependent quantity (e.g., the; momentum) is in general not known, but one possible way of solving the; problem, is to find an expression which reliably approximates the; dependence of the momentum on the observations. This explicit function of the observations can be obtained by a; least squares fitting procedure applied to a representive; sample of the data, for which the dependent quantity (e.g., momentum); and the independent observations are known. The function can then be; used to compute the quantity of interest for new observations of the; independent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2444,Modifiability,variab,variables,2444,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2572,Modifiability,parameteriz,parameterization,2572,"dent variables. This class TMultiDimFit implements such a procedure in; ROOT. It is largely based on the CERNLIB MUDIFI package; [2]. Though the basic concepts are still sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-kno",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:2705,Modifiability,variab,variable,2705,"l sound, and; therefore kept, a few implementation details have changed, and this; class can take advantage of MINUIT [4] to improve the errors; of the fitting, thanks to the class TMinuit. In [5] and [6] H. Wind demonstrates the utility; of this procedure in the context of tracking, magnetic field; parameterisation, and so on. The outline of the method used in this; class is based on Winds discussion, and I refer these two excellents; text for more information. And example of usage is given in; $ROOTSYS/tutorials/fit/multidimfit.C. The Method. Let by the dependent quantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to pro",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:3260,Modifiability,variab,variable,3260,"uantity of interest, which depends smoothly; on the observable quantities ; , which we'll denote by. . Given a training sample of tuples of the form,; (TMultiDimFit::AddRow). where ; are independent; variables, is the known, quantity dependent at ; ,; and is the square error in , the class; TMultiDimFit; will; try to find the parameterization. (1). such that. (2). is minimal. Here ; are monomials, or Chebyshev or Legendre; polynomials, labelled ; , in each variable; , ; . So what TMultiDimFit does, is to determine the number of; terms , and then terms (or functions) , and the ; coefficients , so that is minimal; (TMultiDimFit::FindParameterization). Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a ",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:3867,Modifiability,variab,variable,3867,"Of course it's more than a little unlikely that will ever become; exact zero as a result of the procedure outlined below. Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The func",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:4002,Modifiability,variab,variable,4002," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:4518,Modifiability,variab,variable,4518,"lways possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; ",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:5527,Modifiability,variab,variables,5527,"e leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; finding the most significant [1]. We can, however, do; better then that. By applying the modified Gram-Schmidt; orthogonalisation algorithm [5] [3] to the; functions , we can evaluate the contribution to the reduction of; from each function in turn, and we may delay the actual inversion; of the curvature-matrix; (TMultiDimFit::MakeGramSchmidt). So we are let to consider an matrix ; , an; element of which is given by.    with. (3). where labels the rows in the training sample and labels; functions of variables, and . That is, is; the term (or function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Bas",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:8810,Modifiability,parameteriz,parameterization,8810," of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolat",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:9915,Modifiability,variab,variables,9915,"the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a li",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10077,Modifiability,variab,variables,10077," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10118,Modifiability,variab,variables,10118," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10218,Modifiability,variab,variable,10218," an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not indepe",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10372,Modifiability,variab,variables,10372," (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameteri",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11232,Modifiability,variab,variables,11232,"le as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlati",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11390,Modifiability,parameteriz,parameterization,11390,"the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; sam",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11652,Modifiability,parameteriz,parameterization,11652," Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevin",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11758,Modifiability,parameteriz,parameterization,11758,"e values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11901,Modifiability,variab,variables,11901,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:12005,Modifiability,parameteriz,parameterization,12005," a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Fun",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:13044,Modifiability,parameteriz,parameterization,13044,"y ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(const TMultiDimFit&); TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); virtual~TMultiDimFit(); voidTObject::AbstractMethod(const char* method) const; virtual voidAddRow(const Double_t* x, Double_t D, Double_t E = 0); virtual voidAddTestRow(const Double_t* x, Double_t D, Double_t E = 0); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidClear(Option_t* option = """")MENU ; virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTName",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:17341,Modifiability,Inherit,InheritsFrom,17341,"PowerIndex() const; Double_tGetPowerLimit() const; const Int_t*GetPowers() const; Double_tGetPrecision() const; const TVectorD*GetQuantity() const; Double_tGetResidualMax() const; Int_tGetResidualMaxRow() const; Double_tGetResidualMin() const; Int_tGetResidualMinRow() const; Double_tGetResidualSumSq() const; Double_tGetRMS() const; Int_tGetSampleSize() const; const TVectorD*GetSqError() const; Double_tGetSumSqAvgQuantity() const; Double_tGetSumSqQuantity() const; Double_tGetTestError() const; Double_tGetTestPrecision() const; const TVectorD*GetTestQuantity() const; Int_tGetTestSampleSize() const; const TVectorD*GetTestSqError() const; const TVectorD*GetTestVariables() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; const TVectorD*GetVariables() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; static TMultiDimFit*Instance(); voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tIsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTNamed::ls(Option_t* option = """") const; virtual Double_tMakeChi2(const Double_t* coeff = 0); virtual voidMakeCode(const char* functionName = ""MDF"", Option_t* option = """")MENU ; virtual voidMakeHistograms(Option_t* option = ""A"")MENU ; virtual voidMakeMethod(const Char_t* className = ""MDF"", Option_t* option = """")MENU ; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); stati",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:17407,Modifiability,Inherit,InheritsFrom,17407,"Powers() const; Double_tGetPrecision() const; const TVectorD*GetQuantity() const; Double_tGetResidualMax() const; Int_tGetResidualMaxRow() const; Double_tGetResidualMin() const; Int_tGetResidualMinRow() const; Double_tGetResidualSumSq() const; Double_tGetRMS() const; Int_tGetSampleSize() const; const TVectorD*GetSqError() const; Double_tGetSumSqAvgQuantity() const; Double_tGetSumSqQuantity() const; Double_tGetTestError() const; Double_tGetTestPrecision() const; const TVectorD*GetTestQuantity() const; Int_tGetTestSampleSize() const; const TVectorD*GetTestSqError() const; const TVectorD*GetTestVariables() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; const TVectorD*GetVariables() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; static TMultiDimFit*Instance(); voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tIsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTNamed::ls(Option_t* option = """") const; virtual Double_tMakeChi2(const Double_t* coeff = 0); virtual voidMakeCode(const char* functionName = ""MDF"", Option_t* option = """")MENU ; virtual voidMakeHistograms(Option_t* option = ""A"")MENU ; virtual voidMakeMethod(const Char_t* className = ""MDF"", Option_t* option = """")MENU ; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTO",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:21723,Modifiability,variab,variables,21723,"tual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; Byte_tfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; T",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:21774,Modifiability,variab,variables,21774,"tual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; Byte_tfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; T",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:22054,Modifiability,parameteriz,parameterization,22054,"tual Bool_tTestFunction(Double_t squareResidual, Double_t dResidur). Data Members; public:. enum EMDFPolyType { kMonomials; kChebyshev; kLegendre; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. Int_tfBinVarXNumber of bin in independent variables; Int_tfBinVarYNumber of bin in dependent variables; Double_tfChi2Chi square of fit; TVectorDfCoefficientsVector of the final coefficients; TVectorDfCoefficientsRMSVector of RMS of coefficients; Double_tfCorrelationCoeffMulti Correlation coefficient; TMatrixDfCorrelationMatrixCorrelation matrix; Double_tfErrorError from parameterization; TVirtualFitter*fFitter! Fit object (MINUIT); Int_t*fFunctionCodes[fMaxFunctions] acceptance code; TMatrixDfFunctionsFunctions evaluated over sample; Byte_tfHistogramMaskBit pattern of hisograms used; TList*fHistogramsList of histograms; Bool_tfIsUserFunctionFlag for user defined function; Bool_tfIsVerbose; Double_tfMaxAngleMax angle for acepting new function; Int_tfMaxFuncNVfMaxFunctions*fNVariables; Int_tfMaxFunctionsmax number of functions; Int_t*fMaxPowers[fNVariables] maximum powers; Int_t*fMaxPowersFinal[fNVariables] maximum powers from fit;; Double_tfMaxQuantityMax value of dependent quantity; Double_tfMaxResidualMax redsidual value; Int_tfMaxResidualRowRow giving max residual; Int_tfMaxStudymax functions to study; Int_tfMaxTermsMax terms expected in final expr.; TVectorDfMaxVariablesmax value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; T",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:22898,Modifiability,variab,variables,22898,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:23006,Modifiability,variab,variables,23006,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:23310,Modifiability,variab,variables,23310,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:23411,Modifiability,variab,variables,23411,,MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24773,Modifiability,variab,variables,24773,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24866,Modifiability,variab,variables,24866,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24948,Modifiability,Inherit,Inheritance,24948,"e precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24961,Modifiability,Inherit,Inherited,24961,"e precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25553,Modifiability,variab,variables,25553,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25700,Modifiability,parameteriz,parameterization,25700,"VectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrow",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:25735,Modifiability,variab,variables,25735,"dent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables. private:. static TMultiDimFit*fgInstanceStatic instance. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiDimFit(); Empty CTOR. Do not use. TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """"); Constructor; Second argument is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26161,Modifiability,variab,variables,26161,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26316,Modifiability,parameteriz,parameterization,26316,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26703,Modifiability,variab,variables,26703,"mple to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Opt",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26790,Modifiability,parameteriz,parameterization,26790,"ulated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:27010,Modifiability,parameteriz,parameterization,27010,"value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); C",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:27376,Modifiability,variab,variable,27376," This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:27453,Modifiability,parameteriz,parameterization,27453,"ven Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementatio",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:28580,Modifiability,variab,variables,28580,"tion. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoefficients; Double_t gDMean; Double_t gXMean[]; Double_t gXMin[]; Double_t gXMax[]; Double_t gCoefficient[]; Int_t gPower[]. are initialized. The only ROOT header file needed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this a",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29829,Modifiability,parameteriz,parameterization,29829,"ed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature matrix of the non-orthogonal functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29897,Modifiability,variab,variables,29897,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29929,Modifiability,variab,variables,29929,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29965,Modifiability,variab,variables,29965,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:29996,Modifiability,variab,variables,29996,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:30050,Modifiability,variab,variables,30050,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:30091,Modifiability,variab,variable,30091,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:31231,Modifiability,variab,variables,31231,"method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""p",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:31947,Modifiability,parameteriz,parameterization,31947,"lized, and assumed to exist. The class declaration is; assumed to be in <classname>.h and assumed to be provided by the; user. See TMultiDimFit::MakeRealCode for a list of options. The minimal class definition is:. class <classname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For exa",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:32239,Modifiability,parameteriz,parameterization,32239,"assname> {; public:; Int_t <classname>::fgNVariables; // Number of variables; Int_t <classname>::fgNCoefficients; // Number of terms; Double_t <classname>::fgDMean; // Mean from training sample; Double_t <classname>::fgXMean[]; // Mean from training sample; Double_t <classname>::fgXMin[]; // Min from training sample; Double_t <classname>::fgXMax[]; // Max from training sample; Double_t <classname>::fgCoefficient[]; // Coefficients; Int_t <classname>::fgPower[]; // Function powers. Double_t Eval(Double_t *x);; };. Whether the method <classname>::Eval should be static or not, is; up to the user. void MakeNormalized(); PRIVATE METHOD:; Normalize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vec",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:32859,Modifiability,variab,variables,32859,"lize data to the interval [-1;1]. This is needed for the; classes method to work. void MakeParameterization(); PRIVATE METHOD:; Find the parameterization over the training sample. A full account; of the algorithm is given in the; class description. void MakeRealCode(const char* filename, const char* classname, Option_t* option = """"); PRIVATE METHOD:; This is the method that actually generates the code for the; evaluation the parameterization on some point.; It's called by TMultiDimFit::MakeCode and TMultiDimFit::MakeMethod. The options are: NONE so far. void Print(Option_t* option = ""ps"") const; Print statistics etc.; Options are; P Parameters; S Statistics; C Coefficients; R Result of parameterisation; F Result of fit; K Correlation Matrix; M Pretty print formula. Bool_t Select(const Int_t* iv); Selection method. User can override this method for specialized; selection of acceptable functions in fit. Default is to select; all. This message is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:33835,Modifiability,variab,variable,33835," is sent during the build-up of the function; candidates table once for each set of powers in; variables. Notice, that the argument array contains the powers; PLUS ONE. For example, to De select the function; f = x1^2 * x2^4 * x3^5,; this method should return kFALSE if given the argument; { 3, 4, 6 }. void SetMaxAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; {",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34064,Modifiability,variab,variable,34064,"xAngle(Double_t angle = 0); Set the max angle (in degrees) between the initial data vector to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fH",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34212,Modifiability,variab,variable,34212,"r to; be fitted, and the new candidate function to be included in the; fit. By default it is 0, which automatically chooses another; selection criteria. See also; class description. void SetMinAngle(Double_t angle = 1); Set the min angle (in degrees) between a new candidate function; and the subspace spanned by the previously accepted; functions. See also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions(",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:4020,Performance,perform,perform,4020," Therefore, the; user is asked to provide a minimum relative error ; (TMultiDimFit::SetMinRelativeError), and ; will be considered minimized when. Optionally, the user may impose a functional expression by specifying; the powers of each variable in specified functions ; (TMultiDimFit::SetPowers). In that case, only the; coefficients is calculated by the class. Limiting the Number of Terms. As always when dealing with fits, there's a real chance of; over fitting. As is well-known, it's always possible to fit an; polynomial in to points with ; , but; the polynomial is not likely to fit new data at all; [1]. Therefore, the user is asked to provide an upper; limit, to the number of terms in ; (TMultiDimFit::SetMaxTerms). However, since there's an infinite number of to choose from, the; user is asked to give the maximum power. , of each variable; to be considered in the minimization of ; (TMultiDimFit::SetMaxPowers). One way of obtaining values for the maximum power in variable , is; to perform a regular fit to the dependent quantity , using a; polynomial only in . The maximum power is is then the; power that does not significantly improve the one-dimensional; least-square fit over to [5]. There are still a huge amount of possible choices for ; in fact; there are ; possible; choices. Obviously we need to limit this. To this end, the user is; asked to set a power control limit, ; (TMultiDimFit::SetPowerLimit), and a function; is only accepted if. where is the leading power of variable in function; . (TMultiDimFit::MakeCandidates). So the number of; functions increase with (1, 2 is fine, 5 is way out). Gram-Schmidt Orthogonalisation. To further reduce the number of functions in the final expression,; only those functions that significantly reduce is chosen. What; `significant' means, is chosen by the user, and will be; discussed below (see 2.3). The functions are generally not orthogonal, which means one will; have to evaluate all possible 's over all data-points before; fi",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:6564,Performance,perform,performed,6564,"r function) numbered evaluated at the data point; . We have to normalise ; to for this to; succeed [5]; (TMultiDimFit::MakeNormalized). We then define a; matrix ; of which the columns ; are given by. (4). (5). and ; is the component of ; orthogonal; to ; . Hence we obtain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data ve",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:8150,Performance,perform,performing,8150," length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper tri",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:8551,Performance,perform,perform,8551,"tween ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the cu",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:9982,Performance,perform,perform,9982,"the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper triangle matrix, which can be; readily inverted. So we now evaluate. (17). The model ; can therefore be written as. The original model ; is therefore identical with; this if. (18). The reason we use ; rather then. is to save storage, since. can be stored in the same matrix as. (TMultiDimFit::MakeCoefficients). The errors in; the coefficients is calculated by inverting the curvature matrix; of the non-orthogonal functions [1]; (TMultiDimFit::MakeCoefficientErrors). Considerations. It's important to realize that the training sample should be; representive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a li",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10875,Performance,Perform,Perform,10875,"ent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11031,Performance,Perform,Perform,11031,"f linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The rel",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:17231,Security,Hash,Hash,17231,"c Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetPolyType() const; Int_t*GetPowerIndex() const; Double_tGetPowerLimit() const; const Int_t*GetPowers() const; Double_tGetPrecision() const; const TVectorD*GetQuantity() const; Double_tGetResidualMax() const; Int_tGetResidualMaxRow() const; Double_tGetResidualMin() const; Int_tGetResidualMinRow() const; Double_tGetResidualSumSq() const; Double_tGetRMS() const; Int_tGetSampleSize() const; const TVectorD*GetSqError() const; Double_tGetSumSqAvgQuantity() const; Double_tGetSumSqQuantity() const; Double_tGetTestError() const; Double_tGetTestPrecision() const; const TVectorD*GetTestQuantity() const; Int_tGetTestSampleSize() const; const TVectorD*GetTestSqError() const; const TVectorD*GetTestVariables() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; const TVectorD*GetVariables() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; static TMultiDimFit*Instance(); voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tIsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTNamed::ls(Option_t* option = """") const; virtual Double_tMakeChi2(const Double_t* coeff = 0); virtual voidMakeCode(const char* functionName = ""MDF"", Option_t* option = """")MENU ; virtual voidMakeHistograms(Option_t* option = ""A"")MENU ; virtual voidMakeMethod(const Char_t* className = ""MDF"", Option_t* option = """")MENU ; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* metho",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:6816,Testability,test,test,6816,"tain; [3],.    if. (6). We now take as a new model ; . We thus want to; minimize. (7). where ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically re",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:6922,Testability,Test,Test,6922,"ere ; is a vector of the; dependent quantity in the sample. Differentiation with respect to; gives, using (6),. (8). or. (9). Let be the sum of squares of residuals when taking functions; into account. Then. (10). Using (9), we see that.  ;  .  ;  . (11). So for each new function included in the model, we get a; reduction of the sum of squares of residuals of ; ,; where ; is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selec",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:7265,Testability,test,test,7265,"is given by (4) and by; (9). Thus, using the Gram-Schmidt orthogonalisation, we; can decide if we want to include this function in the final model,; before the matrix inversion. Function Selection Based on Residual. Supposing that steps of the procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from t",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:7541,Testability,Test,Test,7541," procedure have been performed, the; problem now is to consider the ; function. The sum of squares of residuals can be written as. (12). where the relation (9) have been taken into account. The; contribution of the ; function to the reduction of S, is; given by. (13). Two test are now applied to decide whether this . function is to be included in the final expression, or not. Test 1. Denoting by the subspace spanned by. the function ; is; by construction (see (4)) the projection of the function; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more diffi",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:8086,Testability,Test,TestFunction,8086,"on; onto the direction perpendicular to . Now, if the; length of ; (given by ; ); is very small compared to the length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To de",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:8173,Testability,test,test,8173," length of ; this new; function can not contribute much to the reduction of the sum of; squares of residuals. The test consists then in calculating the angle; between the two vectors ; and . (see also figure 1) and requiring that it's; greater then a threshold value which the user must set; (TMultiDimFit::SetMinAngle). Figure 1:; (a) Angle between ; and; ; , (b) angle between ; and; . ; Test 2. Let ; be the data vector to be fitted. As illustrated in; figure 1, the ; function . will contribute significantly to the reduction of , if the angle. between ; and ; is smaller than; an upper limit , defined by the user; (TMultiDimFit::SetMaxAngle). However, the method automatically readjusts the value of this angle; while fitting is in progress, in order to make the selection criteria; less and less difficult to be fulfilled. The result is that the; functions contributing most to the reduction of are chosen first; (TMultiDimFit::TestFunction). In case isn't defined, an alternative method of; performing this second test is used: The ; function. is accepted if (refer also to equation (13)). (14). where is the sum of the first residuals from the; functions previously accepted; and is the total number; of functions allowed in the final expression of the fit (defined by; user). >From this we see, that by restricting -- the number of; terms in the final model -- the fit is more difficult to perform,; since the above selection criteria is more limiting. The more coefficients we evaluate, the more the sum of squares of; residuals will be reduced. We can evaluate before inverting. as shown below. Coefficients and Coefficient Errors. Having found a parameterization, that is the 's and , that; minimizes , we still need to determine the coefficients; . However, it's a feature of how we choose the significant; functions, that the evaluation of the 's becomes trivial; [5]. To derive ; , we first note that; equation (4) can be written as. (15). where. (16). Consequently, ; is an upper tri",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11334,Testability,Test,Test,11334,"the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; sam",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11640,Testability,Test,Testing,11640," Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevin",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11712,Testability,test,testing,11712,"e values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:11834,Testability,test,test,11834,"ponent Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Comput",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:12059,Testability,test,test,12059," a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Fun",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:12119,Testability,test,test,12119,"ng themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Da",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:12573,Testability,test,test,12573,"ermind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functionality for testing the, over the; training sample, found parameterization; (TMultiDimFit::Fit). This is done by passing; the class a test sample of tuples of the form ; , where ; are the independent; variables, the known, dependent quantity, and is; the square error in ; (TMultiDimFit::AddTestRow). The parameterization is then evaluated at every ; in the; test sample, and. is evaluated. The relative error over the test sample. should not be to low or high compared to from the training; sample. Also, multiple correlation coefficient from both samples should; be fairly close, otherwise one of the samples is not representive of; the problem. A large difference in the reduced over the two; samples indicate an over fit, and the maximum number of terms in the; parameterisation should be reduced. It's possible to use Minuit; [4] to further improve the fit, using the test sample. Christian Holm; November 2000, NBI. Bibliography; 1. Philip R. Bevington and D. Keith Robinson.; Data Reduction and Error Analysis for the Physical Sciences.; McGraw-Hill, 2 edition, 1992.; 2. René Brun et al.; Mudifi.; Long writeup DD/75-23, CERN, 1980.; 3. Gene H. Golub and Charles F. van Loan.; Matrix Computations.; John Hopkins Univeristy Press, Baltimore, 3 edition, 1996.; 4. F. James.; Minuit.; Long writeup D506, CERN, 1998.; 5. H. Wind.; Function parameterization.; In Proceedings of the 1972 CERN Computing and Data Processing; School, volume 72-21 of Yellow report. CERN, 1972.; 6. H. Wind.; 1. principal component analysis, 2. pattern recognition for track; finding, 3. interpolation and functional representation.; Yellow report EP/81-12, CERN, 1981. */. Function Members (Methods); public:. TMultiDimFit(); TMultiDimFit(const TMultiDimFit&); TMultiDimFit(Int_t dimension, TMultiDimFit::EMDFPolyType type = kMonomials, Option_t* option = """");",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:20273,Testability,Test,TestBit,20273," sz); void*TObject::operator new[](size_t sz, void* vp); TMultiDimFit&operator=(const TMultiDimFit&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* option = ""ps"") constMENU ; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBinVarX(Int_t nbbinvarx); voidSetBinVarY(Int_t nbbinvary); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxAngle(Double_t angle = 0); voidSetMaxFunctions(Int_t n); voidSetMaxPowers(const Int_t* powers); voidSetMaxStudy(Int_t n); voidSetMaxTerms(Int_t terms); voidSetMinAngle(Double_t angle = 1); voidSetMinRelativeError(Double_t error); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); voidSetPowerLimit(Double_t limit = 1e-3); virtual voidSetPowers(const Int_t* powers, Int_t terms); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:20312,Testability,Test,TestBits,20312," sz); void*TObject::operator new[](size_t sz, void* vp); TMultiDimFit&operator=(const TMultiDimFit&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* option = ""ps"") constMENU ; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBinVarX(Int_t nbbinvarx); voidSetBinVarY(Int_t nbbinvary); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxAngle(Double_t angle = 0); voidSetMaxFunctions(Int_t n); voidSetMaxPowers(const Int_t* powers); voidSetMaxStudy(Int_t n); voidSetMaxTerms(Int_t terms); voidSetMinAngle(Double_t angle = 1); voidSetMinRelativeError(Double_t error); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); voidSetPowerLimit(Double_t limit = 1e-3); virtual voidSetPowers(const Int_t* powers, Int_t terms); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24523,Testability,test,test,24523,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24573,Testability,test,test,24573,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:24661,Testability,test,test,24661,"x value of independent variables; Double_tfMeanQuantityMean of dependent quantity; TVectorDfMeanVariablesmean value of independent variables; Double_tfMinAngleMin angle for acepting new function; Double_tfMinQuantityMin value of dependent quantity; Double_tfMinRelativeErrorMin relative error accepted; Double_tfMinResidualMin redsidual value; Int_tfMinResidualRowRow giving min residual; TVectorDfMinVariablesmin value of independent variables; Int_tfNCoefficientsDimension of model coefficients; Int_tfNVariablesNumber of independent variables; TStringTNamed::fNameobject identifier; TVectorDfOrthCoefficientsThe model coefficients; TMatrixDfOrthCurvatureMatrixModel matrix; TVectorDfOrthFunctionNormsNorm of the evaluated functions; TMatrixDfOrthFunctionsAs above, but orthogonalised; Int_tfParameterisationCodeExit code of parameterisation; TMultiDimFit::EMDFPolyTypefPolyTypeType of polynomials to use; Int_t*fPowerIndex[fMaxTerms] Index of accepted powers; Double_tfPowerLimitControl parameter; Int_t*fPowers[fMaxFuncNV] where fMaxFuncNV = fMaxFunctions*fNVariables; Double_tfPrecisionRelative precision of param; TVectorDfQuantityTraining sample, dependent quantity; Double_tfRMSRoot mean square of fit; TVectorDfResidualsVector of the final residuals; Int_tfSampleSizeSize of training sample; Bool_tfShowCorrelationprint correlation matrix; TVectorDfSqErrorTraining sample, error in quantity; Double_tfSumSqAvgQuantitySum of squares away from mean; Double_tfSumSqQuantitySumSquare of dependent quantity; Double_tfSumSqResidualSum of Square residuals; Double_tfTestCorrelationCoeffMulti Correlation coefficient; Double_tfTestErrorError from test; Double_tfTestPrecisionRelative precision of test; TVectorDfTestQuantityTest sample, dependent quantity; Int_tfTestSampleSizeSize of test sample; TVectorDfTestSqErrorTest sample, Error in quantity; TVectorDfTestVariablesTest sample, independent variables; TStringTNamed::fTitleobject title; TVectorDfVariablesTraining sample, independent variables.",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26272,Testability,test,test,26272,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26304,Testability,test,test,26304,"ent is the type of polynomials to use in; parameterisation, one of:; TMultiDimFit::kMonomials; TMultiDimFit::kChebyshev; TMultiDimFit::kLegendre. Options:; K Compute (k)correlation matrix; V Be verbose. Default is no options. ~TMultiDimFit(); Destructor. void AddRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the training sample to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* po",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:27659,Testability,test,test,27659,"he TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoeffic",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:28022,Testability,test,test,28022,"ff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Options; M use Minuit to improve coefficients. Also, refer to; class description. TMultiDimFit* Instance(); Return the static instance. void MakeCandidates(); PRIVATE METHOD:; Create list of candidate functions for the parameterisation. See; also; class description. Double_t MakeChi2(const Double_t* coeff = 0); Calculate Chi square over either the test sample. The optional; argument coeff is a vector of coefficients to use in the; evaluation of the parameterisation. If coeff == 0, then the found; coefficients is used.; Used my MINUIT for fit (see TMultDimFit::Fit). void MakeCode(const char* functionName = ""MDF"", Option_t* option = """"); Generate the file <filename> with .C appended if argument doesn't; end in .cxx or .C. The contains the implementation of the; function:. Double_t <funcname>(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the static variables:. Int_t gNVariables; Int_t gNCoefficients; Double_t gDMean; Double_t gXMean[]; Double_t gXMin[]; Double_t gXMax[]; Double_t gCoefficient[]; Int_t gPower[]. are initialized. The only ROOT header file needed is Rtypes.h. See TMultiDimFit::MakeRealCode for a list of options. void MakeCoefficientErrors(); PRIVATE METHOD:; Compute the errors on the coefficients. For this to be done, the; curvature ",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:30168,Testability,test,test,30168,"l functions, is computed. void MakeCoefficients(); PRIVATE METHOD:; Invert the model matrix B, and compute final coefficients. For a; more thorough discussion of what this means, please refer to the; class description. First we invert the lower triangle matrix fOrthCurvatureMatrix; and store the inverted matrix in the upper triangle. void MakeCorrelation(); PRIVATE METHOD:; Compute the correlation matrix. Double_t MakeGramSchmidt(Int_t function); PRIVATE METHOD:; Make Gram-Schmidt orthogonalisation. The class description gives; a thorough account of this algorithm, as well as; references. Please refer to the; class description. void MakeHistograms(Option_t* option = ""A""); Make histograms of the result of the analysis. This message; should be sent after having read all data points, but before; finding the parameterization. Options:; A All the below; X Original independent variables; D Original dependent variables; N Normalised independent variables; S Shifted dependent variables; R1 Residuals versus normalised independent variables; R2 Residuals versus dependent variable; R3 Residuals computed on training sample; R4 Residuals computed on test sample. For a description of these quantities, refer to; class description. void MakeMethod(const Char_t* className = ""MDF"", Option_t* option = """"); Generate the file <classname>MDF.cxx which contains the; implementation of the method:. Double_t <classname>::MDF(Double_t *x). which does the same as TMultiDimFit::Eval. Please refer to this; method. Further, the public static members:. Int_t <classname>::fgNVariables; Int_t <classname>::fgNCoefficients; Double_t <classname>::fgDMean; Double_t <classname>::fgXMean[] //[fgNVariables]; Double_t <classname>::fgXMin[] //[fgNVariables]; Double_t <classname>::fgXMax[] //[fgNVariables]; Double_t <classname>::fgCoefficient[] //[fgNCoeffficents]; Int_t <classname>::fgPower[] //[fgNCoeffficents*fgNVariables]. are initialized, and assumed to exist. The class declaration is; assumed to be in <",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34447,Testability,Test,TestFunction,34447,"ee also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions() const; { return fMaxFunctions; }. Int_t* GetMaxPowers() const; { return fMaxPowers; }. Double_t GetMaxQuantity() const; { return fMaxQuantity; }. Int_t GetMaxStudy() const; { return fMaxStudy; }. Int_t GetMaxTerms() const; { return fMaxTerms; }. const TVectorD* GetMaxVariables() const; { return &fMaxVariables; }. Double_t GetMeanQuantity() const;",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:34522,Testability,Test,Test,34522,"ee also; class description. void SetPowers(const Int_t* powers, Int_t terms); Define a user function. The input array must be of the form; (p11, ..., p1N, ... ,pL1, ..., pLN); Where N is the dimension of the data sample, L is the number of; terms (given in terms) and the first number, labels the term, the; second the variable. More information is given in the; class description. void SetPowerLimit(Double_t limit = 1e-3); Set the user parameter for the function selection. The bigger the; limit, the more functions are used. The meaning of this variable; is defined in the; class description. void SetMaxPowers(const Int_t* powers); Set the maximum power to be considered in the fit for each; variable. See also; class description. void SetMinRelativeError(Double_t error); Set the acceptable relative error for when sum of square; residuals is considered minimized. For a full account, refer to; the; class description. Bool_t TestFunction(Double_t squareResidual, Double_t dResidur); PRIVATE METHOD:; Test whether the currently considered function contributes to the; fit. See also; class description. TMultiDimFit(). void Draw(Option_t* = ""d""); { }. Double_t GetChi2() const; { return fChi2; }. const TMatrixD* GetCorrelationMatrix() const; { return &fCorrelationMatrix; }. const TVectorD* GetCoefficients() const; { return &fCoefficients; }. Double_t GetError() const; { return fError; }. Int_t* GetFunctionCodes() const; { return fFunctionCodes; }. const TMatrixD* GetFunctions() const; { return &fFunctions; }. TList* GetHistograms() const; { return fHistograms; }. Double_t GetMaxAngle() const; { return fMaxAngle; }. Int_t GetMaxFunctions() const; { return fMaxFunctions; }. Int_t* GetMaxPowers() const; { return fMaxPowers; }. Double_t GetMaxQuantity() const; { return fMaxQuantity; }. Int_t GetMaxStudy() const; { return fMaxStudy; }. Int_t GetMaxTerms() const; { return fMaxTerms; }. const TVectorD* GetMaxVariables() const; { return &fMaxVariables; }. Double_t GetMeanQuantity() const;",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:10707,Usability,simpl,simple,10707,"sentive of the problem at hand, in particular along the borders; of the region of interest. This is because the algorithm presented; here, is a interpolation, rahter then a extrapolation; [5]. Also, the independent variables need to be linear; independent, since the procedure will perform poorly if they are not; [5]. One can find an linear transformation from ones; original variables to a set of linear independent variables; , using a Principal Components Analysis; (see TPrincipal), and; then use the transformed variable as input to this class [5]; [6]. H. Wind also outlines a method for parameterising a multidimensional; dependence over a multidimensional set of variables. An example; of the method from [5], is a follows (please refer to; [5] for a full discussion):. Define ; are the 5 dependent; quantities that define a track. Compute, for different values of ; , the tracks; through the magnetic field, and determine the corresponding; ; . Use the simulated observations to determine, with a simple; approximation, the values of ; . We call these values; ; . Determine from ; a set of at least five relevant; coordinates ; , using contrains, or; alternative:. Perform a Principal Component Analysis (using; TPrincipal), and use; to get a linear transformation; ; , so that; ; are constrained and linear independent. Perform a Principal Component Analysis on; ; , to get linear; indenpendent (among themselves, but not independent of; ; ) quantities . For each component ; make a mutlidimensional fit,; using ; as the variables, thus determing a set of; coefficents ; . To process data, using this parameterisation, do. Test wether the observation ; within the domain of; the parameterization, using the result from the Principal Component; Analysis. Determine ; as before. Detetmine ; as before. Use the result of the fit to determind ; . Transform back to ; from ; , using; the result from the Principal Component Analysis. Testing the parameterization. The class also provides functio",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26643,Usability,Clear,Clear,26643,"mple to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Opt",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiDimFit.html:26673,Usability,Clear,Clear,26673,"mple to be used for the; parameterization.; The mean of the variables and quantity is calculated on the fly,; as outlined in TPrincipal::AddRow.; This sample should be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void AddTestRow(const Double_t* x, Double_t D, Double_t E = 0); Add a row consisting of fNVariables independent variables, the; known, dependent quantity, and optionally, the square error in; the dependent quantity, to the test sample to be used for the; test of the parameterization.; This sample needn't be representive of the problem at hand.; Please note, that if no error is given Poisson statistics is; assumed and the square error is set to the value of dependent; quantity. See also the; class description. void Browse(TBrowser* b); Browse the TMultiDimFit object in the TBrowser. void Clear(Option_t* option = """"); Clear internal structures and variables. Double_t Eval(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalError(const Double_t* x, const Double_t* coeff = 0) const; Evaluate parameterization error at point x. Optional argument coeff is; a vector of coefficients for the parameterisation, fNCoefficients; elements long. Double_t EvalControl(const Int_t* powers) const; PRIVATE METHOD:; Calculate the control parameter from the passed powers. Double_t EvalFactor(Int_t p, Double_t x) const; PRIVATE METHOD:; Evaluate function with power p at variable value x. void FindParameterization(Option_t* option = """"); Find the parameterization. Options:; None so far. For detailed description of what this entails, please refer to the; class description. void Fit(Option_t* option = """"); Try to fit the found parameterisation to the test sample. Opt",MatchSource.WIKI,root/html532/TMultiDimFit.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiDimFit.html
https://root.cern/root/html532/TMultiGraph.html:7024,Availability,Error,Error,7024,,MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:7153,Availability,error,error,7153,"ject::AbstractMethod(const char* method) const; virtual voidAdd(TGraph* graph, Option_t* chopt = """"); virtual voidAdd(TMultiGraph* multigraph, Option_t* chopt = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* chopt = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual TFitResultPtrFit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); virtual TFitResultPtrFit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFuncti",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:7237,Availability,error,error,7237,"n_t* chopt = """"); virtual voidAdd(TMultiGraph* multigraph, Option_t* chopt = """"); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidBrowse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTNamed::Clear(Option_t* option = """"); virtual TObject*TNamed::Clone(const char* newname = """") const; virtual Int_tTNamed::Compare(const TObject* obj) const; virtual voidTNamed::Copy(TObject& named) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tDistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* chopt = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual voidTNamed::FillBuffer(char*& buffer); virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual TFitResultPtrFit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); virtual TFitResultPtrFit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFunctions() const; TList*GetListOfGraphs() const; virtual const char*TNamed::GetName() con",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:14662,Availability,error,errors,14662," If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. Use GetDrawOption to return the option specified; when drawing the TMultiGraph. TFitResultPtr Fit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); Fit this graph with function with name fname. interface to TF1::Fit(TF1 *f1... TFitResultPtr Fit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); Fit this multigraph with function f1. In this function all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitted function to the list of fitted functions; (by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::P",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:15503,Availability,robust,robust,15503,"unction all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitted function to the list of fitted functions; (by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::Paint for a complete; list of these options. In order to use the Range option, one must first create a function; with the expression to be fitted. For example, if your graph; has a defined range between -4 and 4 and you want to fit a gaussian; only in the interval 1 to 3, you can do:; TF1 *f1 = new TF1(""f1"",""gaus"",1,3);; graph->Fit(""f1"",""R"");. who is calling this function. Note that this function is called when calling TGraphErrors::Fit; or TGraphAsymmErrors::Fit ot TGraphBentErrors::Fit; see the discussion below on the errors calulation. Setting initial conditions. Parameters must b",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:16320,Availability,error,errors,16320,"by default, any previous function is deleted); = ""C"" In case of linear fitting, not calculate the chisquare; (saves time); = ""F"" If fitting a polN, switch to minuit fitter; = ""ROB"" In case of linear fitting, compute the LTS regression; coefficients (robust(resistant) regression), using; the default fraction of good points; ""ROB=0.x"" - compute the LTS regression coefficients, using; 0.x as a fraction of good points. When the fit is drawn (by default), the parameter goption may be used; to specify a list of graphics options. See TGraph::Paint for a complete; list of these options. In order to use the Range option, one must first create a function; with the expression to be fitted. For example, if your graph; has a defined range between -4 and 4 and you want to fit a gaussian; only in the interval 1 to 3, you can do:; TF1 *f1 = new TF1(""f1"",""gaus"",1,3);; graph->Fit(""f1"",""R"");. who is calling this function. Note that this function is called when calling TGraphErrors::Fit; or TGraphAsymmErrors::Fit ot TGraphBentErrors::Fit; see the discussion below on the errors calulation. Setting initial conditions. Parameters must be initialized before invoking the Fit function.; The setting of the parameter initial values is automatic for the; predefined functions : poln, expo, gaus, landau. One can however disable; this automatic computation by specifying the option ""B"".; You can specify boundary limits for some or all parameters via; f1->SetParLimits(p_number, parmin, parmax);; if parmin>=parmax, the parameter is fixed; Note that you are not forced to fix the limits for all parameters.; For example, if you fit a function with 6 parameters, you can do:; func->SetParameters(0,3.1,1.e-6,0.1,-8,100);; func->SetParLimits(4,-10,-4);; func->SetParLimits(5, 1,1);; With this setup, parameters 0->3 can vary freely; Parameter 4 has boundaries [-10,-4] with initial value -8; Parameter 5 is fixed to 100. Fit range. The fit range can be specified in two ways:; - specify rxmax > rxmin (default is ",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:18576,Availability,error,error,18576,"::EvaluateChi2.; In case of TGraphErrors an effective chi2 is used; (see TGraphErrors fit in TGraph::Fit) and is implemented in; FitUtil::EvaluateChi2Effective; To specify a User defined fitting function, specify option ""U"" and; call the following functions:; TVirtualFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParErr",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:18743,Availability,error,error,18743,"lFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; prin",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:19521,Availability,error,error,19521,"GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel fo",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:19780,Availability,error,errors,19780,"e retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exp",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:19984,Availability,error,errors,19984,"ctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParError(0); //error on first parameter. Fit Statistics. You can change the statistics box to display the fit parameters with; the TStyle::SetOptFit(mode) method. This mode has four digits.; mode = pcev (default = 0111); v = 1; print name/values of parameters; e = 1; print errors (if e=1, v must be 1); c = 1; print Chisquare/Number of degress of freedom; p = 1; print Probability. For example: gStyle->SetOptFit(1011);; prints the fit probability, parameter names/values, and errors.; You can change the position of the statistics box with these lines; (where g is a pointer to the TGraph):. Root > TPaveStats *st = (TPaveStats*)g->GetListOfFunctions()->FindObject(""stats""); Root > st->SetX1NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exponential. void InitPolynom(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a polynom. void LeastSquareFit(Int_t m, Double_t*",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:3626,Deployability,Update,Update,3626,"iGraph *mg = new TMultiGraph();. // create first graph; const Int_t n1 = 10;; Double_t x1[] = {-0.1, 0.05, 0.25, 0.35, 0.5, 0.61,0.7,0.85,0.89,0.95};; Double_t y1[] = {-1,2.9,5.6,7.4,9,9.6,8.7,6.3,4.5,1};; Double_t ex1[] = {.05,.1,.07,.07,.04,.05,.06,.07,.08,.05};; Double_t ey1[] = {.8,.7,.6,.5,.4,.4,.5,.6,.7,.8};; TGraphErrors *gr1 = new TGraphErrors(n1,x1,y1,ex1,ey1);; gr1->SetMarkerColor(kBlue);; gr1->SetMarkerStyle(21);; gr1->Fit(""pol6"",""q"");; mg->Add(gr1);. // create second graph; const Int_t n2 = 10;; Float_t x2[] = {-0.28, 0.005, 0.19, 0.29, 0.45, 0.56,0.65,0.80,0.90,1.01};; Float_t y2[] = {2.1,3.86,7,9,10,10.55,9.64,7.26,5.42,2};; Float_t ex2[] = {.04,.12,.08,.06,.05,.04,.07,.06,.08,.04};; Float_t ey2[] = {.6,.8,.7,.4,.3,.3,.4,.5,.6,.7};; TGraphErrors *gr2 = new TGraphErrors(n2,x2,y2,ex2,ey2);; gr2->SetMarkerColor(kRed);; gr2->SetMarkerStyle(20);; gr2->Fit(""pol5"",""q"");; ; mg->Add(gr2);; ; mg->Draw(""ap"");; ; //force drawing of canvas to generate the fit TPaveStats; c1->Update();; TPaveStats *stats1 = (TPaveStats*)gr1->GetListOfFunctions()->FindObject(""stats"");; TPaveStats *stats2 = (TPaveStats*)gr2->GetListOfFunctions()->FindObject(""stats"");; stats1->SetTextColor(kBlue); ; stats2->SetTextColor(kRed); ; stats1->SetX1NDC(0.12); stats1->SetX2NDC(0.32); stats1->SetY1NDC(0.75);; stats2->SetX1NDC(0.72); stats2->SetX2NDC(0.92); stats2->SetY1NDC(0.78);; c1->Modified();; return c1;; }. The axis limits can be changed the like for TGraph. The same methods apply on; the multigraph.; Note the two differents ways to change limits on X and Y axis. Picture; Source. {; TCanvas *c2 = new TCanvas(""c2"",""c2"",600,400);. TGraph *g[3];; Double_t x[10] = {0,1,2,3,4,5,6,7,8,9};; Double_t y[10] = {1,2,3,4,5,5,4,3,2,1};; TMultiGraph *mg = new TMultiGraph();; for (int i=0; i<3; i++) {; g[i] = new TGraph(10, x, y);; g[i]->SetMarkerStyle(20);; g[i]->SetMarkerColor(i+2);; for (int j=0; j<10; j++) y[j] = y[j]-1;; mg->Add(g[i]);; }; mg->Draw(""APL"");; mg->GetXaxis()->SetTitle(""E_{#gamma} (GeV)",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:14192,Integrability,interface,interface,14192,"Multigraph is still active. void Add(TMultiGraph* multigraph, Option_t* chopt = """"); add all the graphs in ""multigraph"" to the list of graphs. void Browse(TBrowser* b); Browse multigraph. Int_t DistancetoPrimitive(Int_t px, Int_t py); Compute distance from point px,py to each graph. void Draw(Option_t* chopt = """"); Draw this multigraph with its current attributes. Options to draw a graph are described in TGraph::PaintGraph. The drawing option for each TGraph may be specified as an optional; second argument of the Add function. You can use GetGraphDrawOption; to return this option.; If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. Use GetDrawOption to return the option specified; when drawing the TMultiGraph. TFitResultPtr Fit(const char* formula, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); Fit this graph with function with name fname. interface to TF1::Fit(TF1 *f1... TFitResultPtr Fit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); Fit this multigraph with function f1. In this function all graphs of the multigraph are fitted simultaneously. f1 is an already predefined function created by TF1.; Predefined functions such as gaus, expo and poln are automatically; created by ROOT. The list of fit options is given in parameter option.; option = ""W"" Set all errors to 1; = ""U"" Use a User specified fitting algorithm (via SetFCN); = ""Q"" Quiet mode (minimum printing); = ""V"" Verbose mode (default is between Q and V); = ""B"" Use this option when you want to fix one or more parameters; and the fitting function is like ""gaus"",""expo"",""poln"",""landau"".; = ""R"" Use the Range specified in the function range; = ""N"" Do not store the graphics function, do not draw; = ""0"" Do not plot the result of the fit. By default the fitted function; is drawn unless the option""N"" above is specified.; = ""+"" Add this new fitt",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:21186,Integrability,rout,routine,21186,"NDC(newx1); //new x start position; Root > st->SetX2NDC(newx2); //new x end position. void FitPanel(); -*-*-*-*-*Display a panel with all histogram fit options*-*-*-*-*-*. See class TFitPanel for example. Option_t * GetGraphDrawOption(const TGraph* gr) const; Return the draw option for the TGraph gr in this TMultiGraph; The return option is the one specified when calling TMultiGraph::Add(gr,option). void InitGaus(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a gaussian. void InitExpo(Double_t xmin, Double_t xmax); Compute Initial values of parameters for an exponential. void InitPolynom(Double_t xmin, Double_t xmax); Compute Initial values of parameters for a polynom. void LeastSquareFit(Int_t m, Double_t* a, Double_t xmin, Double_t xmax); Least squares lpolynomial fitting without weights. m number of parameters; a array of parameters; first 1st point number to fit (default =0); last last point number to fit (default=fNpoints-1). based on CERNLIB routine LSQ: Translated to C++ by Rene Brun. void LeastSquareLinearFit(Int_t ndata, Double_t& a0, Double_t& a1, Int_t& ifail, Double_t xmin, Double_t xmax); Least square linear fit without weights. Fit a straight line (a0 + a1*x) to the data in this graph.; ndata: number of points to fit; first: first point number to fit; last: last point to fit O(ndata should be last-first; ifail: return parameter indicating the status of the fit (ifail=0, fit is OK). extracted from CERNLIB LLSQ: Translated to C++ by Rene Brun. Int_t IsInside(Double_t x, Double_t y) const; Return 1 if the point (x,y) is inside one of the graphs 0 otherwise. TH1F * GetHistogram() const; Returns a pointer to the histogram used to draw the axis; Takes into account the two following cases.; 1- option 'A' was specified in TMultiGraph::Draw. Return fHistogram; 2- user had called TPad::DrawFrame. return pointer to hframe histogram. TF1 * GetFunction(const char* name) const; Return pointer to function with name. Functions such as TGraph::",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:8712,Modifiability,Inherit,InheritsFrom,8712,"* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFunctions() const; TList*GetListOfGraphs() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; TAxis*GetXaxis() const; TAxis*GetYaxis() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInitExpo(Double_t xmin, Double_t xmax); virtual voidInitGaus(Double_t xmin, Double_t xmax); virtual voidInitPolynom(Double_t xmin, Double_t xmax); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; virtual Int_tIsInside(Double_t x, Double_t y) const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidLeastSquareFit(Int_t m, Double_t* a, Double_t xmin, Double_t xmax); virtual voidLeastSquareLinearFit(Int_t ndata, Double_t& a0, Double_t& a1, Int_t& ifail, Double_t xmin, Double_t xmax); virtual voidTNamed::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, co",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:8778,Modifiability,Inherit,InheritsFrom,8778,"= 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFunctions() const; TList*GetListOfGraphs() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; TAxis*GetXaxis() const; TAxis*GetYaxis() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInitExpo(Double_t xmin, Double_t xmax); virtual voidInitGaus(Double_t xmin, Double_t xmax); virtual voidInitPolynom(Double_t xmin, Double_t xmax); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; virtual Int_tIsInside(Double_t x, Double_t y) const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidLeastSquareFit(Int_t m, Double_t* a, Double_t xmin, Double_t xmax); virtual voidLeastSquareLinearFit(Int_t ndata, Double_t& a0, Double_t& a1, Int_t& ifail, Double_t xmin, Double_t xmax); virtual voidTNamed::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voi",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:12585,Modifiability,Inherit,Inheritance,12585," = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. TMultiGraph(const TMultiGraph&); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(); TMultiGraph&operator=(const TMultiGraph&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*fFunctionsPointer to list of functions (fits and user); TList*fGraphsPointer to list of TGraphs; TH1F*fHistogramPointer to histogram used for drawing axis; Double_tfMaximumMaximum value for plotting along y; Double_tfMinimumMinimum value for plotting along y; TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiGraph(); TMultiGraph default constructor. TMultiGraph(const char* name, const char* title); constructor with name and title. TMultiGraph(const TMultiGraph& ); copy constructor. TMultiGraph& operator=(const TMultiGraph& ); assignement operator. ~TMultiGraph(); TMultiGraph destructor. void Add(TGraph* graph, Option_t* chopt = """"); add a new graph to the list of graphs; note that the graph is now owned by the TMultigraph.; Deleting the TMultiGraph object will automatically delete the graphs.; You should not delete the graphs when the TMultigraph is still active. void Add(TMultiGraph* multigraph, Option_t* chopt = """"); add all the graphs in ""multigraph"" to the list of graphs. void Browse(TBrowser* b); Browse multigraph. Int_t DistancetoPrimitive(Int_t px, Int_t py); Compute distance from point px,py to each graph. void Draw(Option_t* chopt = """"); Draw this multigraph with its current attributes. Options to draw a graph are described ",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:12598,Modifiability,Inherit,Inherited,12598," = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. TMultiGraph(const TMultiGraph&); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(); TMultiGraph&operator=(const TMultiGraph&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TList*fFunctionsPointer to list of functions (fits and user); TList*fGraphsPointer to list of TGraphs; TH1F*fHistogramPointer to histogram used for drawing axis; Double_tfMaximumMaximum value for plotting along y; Double_tfMinimumMinimum value for plotting along y; TStringTNamed::fNameobject identifier; TStringTNamed::fTitleobject title. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiGraph(); TMultiGraph default constructor. TMultiGraph(const char* name, const char* title); constructor with name and title. TMultiGraph(const TMultiGraph& ); copy constructor. TMultiGraph& operator=(const TMultiGraph& ); assignement operator. ~TMultiGraph(); TMultiGraph destructor. void Add(TGraph* graph, Option_t* chopt = """"); add a new graph to the list of graphs; note that the graph is now owned by the TMultigraph.; Deleting the TMultiGraph object will automatically delete the graphs.; You should not delete the graphs when the TMultigraph is still active. void Add(TMultiGraph* multigraph, Option_t* chopt = """"); add all the graphs in ""multigraph"" to the list of graphs. void Browse(TBrowser* b); Browse multigraph. Int_t DistancetoPrimitive(Int_t px, Int_t py); Compute distance from point px,py to each graph. void Draw(Option_t* chopt = """"); Draw this multigraph with its current attributes. Options to draw a graph are described ",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:747,Performance,perform,performed,747,". TMultiGraph. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » HIST; » HIST; » TMultiGraph. class TMultiGraph: public TNamed. TMultiGraph class; A TMultiGraph is a collection of TGraph (or derived) objects. It allows to; manipulate a set of graphs as a single entity. In particular, when drawn,; the X and Y axis ranges are automatically computed such as all the graphs; will be visible. TMultiGraph::Add should be used to add a new graph to the list. The TMultiGraph owns the objects in the list. The drawing options are the same as for TGraph.; Like for TGraph, the painting is performed thanks to the; TGraphPainter; class. All details about the various painting options are given in; this class.; Example:. TGraph *gr1 = new TGraph(...; TGraphErrors *gr2 = new TGraphErrors(...; TMultiGraph *mg = new TMultiGraph();; mg->Add(gr1,""lp"");; mg->Add(gr2,""cp"");; mg->Draw(""a"");. The number of graphs in a multigraph can be retrieve with:. mg->GetListOfGraphs()->GetSize();. The drawing option for each TGraph may be specified as an optional; second argument of the Add function. If a draw option is specified, it will be used to draw the graph,; otherwise the graph will be drawn with the option specified in; TMultiGraph::Draw. The following example shows how to fit a TMultiGraph. Picture; Source. {; TCanvas *c1 = new TCanvas(""c1"",""c1"",600,400);. Double_t x1[2] = {2.,4.};; Double_t dx1[2] = {0.1,0.1};; Double_t y1[2] = {2.1,4.0};; Double_t dy1[2] = {0.3,0.2};. Double_t x2[2] = {3.,5.};; Double_t dx2[2] = {0.1,0.1};; Double_t y2[2] = {3.2,4.8};; Double_t dy2[2] = {0.3,0.2};. gStyle->SetOptFit(0001);. TGraphErrors *g1 = new TGraphErrors(2,x1,y1,dx1,dy1);; g1->SetMarkerStyle(21);; g1->SetMarkerColor(2);. TGraphErrors *g2 = new TGraphErrors(2,x2,y2,dx2,dy2);; g2->SetMarkerStyle(22);; g2->SetMarkerColor(3);. TMultiGraph *g = new",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:8602,Security,Hash,Hash,8602,"la, Option_t* option = """", Option_t* goption = """", Axis_t xmin = 0, Axis_t xmax = 0); virtual TFitResultPtrFit(TF1* f1, Option_t* option = """", Option_t* goption = """", Axis_t rxmin = 0, Axis_t rxmax = 0); virtual voidFitPanel()MENU ; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TF1*GetFunction(const char* name) const; virtual Option_t*GetGraphDrawOption(const TGraph* gr) const; TH1F*GetHistogram() const; virtual const char*TObject::GetIconName() const; TList*GetListOfFunctions(); const TList*GetListOfFunctions() const; TList*GetListOfGraphs() const; virtual const char*TNamed::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TNamed::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; TAxis*GetXaxis() const; TAxis*GetYaxis() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTNamed::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInitExpo(Double_t xmin, Double_t xmax); virtual voidInitGaus(Double_t xmin, Double_t xmax); virtual voidInitPolynom(Double_t xmin, Double_t xmax); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; virtual Int_tIsInside(Double_t x, Double_t y) const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTNamed::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidLeastSquareFit(Int_t m, Double_t* a, Double_t xmin, Double_t xmax); virtual voidLeastSquareLinearFit(Int_t ndata, Double_t& a0, Double_t& a1, Int_t& ifail, Double_t xmin, Double_t xmax); virtual voidTNamed::ls(Option_t* option = """") const; voidTObject::",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:17966,Security,Access,Access,17966,"mits(4,-10,-4);; func->SetParLimits(5, 1,1);; With this setup, parameters 0->3 can vary freely; Parameter 4 has boundaries [-10,-4] with initial value -8; Parameter 5 is fixed to 100. Fit range. The fit range can be specified in two ways:; - specify rxmax > rxmin (default is rxmin=rxmax=0); - specify the option ""R"". In this case, the function will be taken; instead of the full graph range. Changing the fitting function. By default a chi2 fitting function is used for fitting the TGraphs's.; The function is implemented in FitUtil::EvaluateChi2.; In case of TGraphErrors an effective chi2 is used; (see TGraphErrors fit in TGraph::Fit) and is implemented in; FitUtil::EvaluateChi2Effective; To specify a User defined fitting function, specify option ""U"" and; call the following functions:; TVirtualFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:18422,Security,access,access,18422,"::EvaluateChi2.; In case of TGraphErrors an effective chi2 is used; (see TGraphErrors fit in TGraph::Fit) and is implemented in; FitUtil::EvaluateChi2Effective; To specify a User defined fitting function, specify option ""U"" and; call the following functions:; TVirtualFitter::Fitter(mygraph)->SetFCN(MyFittingFunction); where MyFittingFunction is of type:; extern void MyFittingFunction(Int_t &npar, Double_t *gin, Double_t &f, Double_t *u, Int_t flag);. Access to the fit result. The function returns a TFitResultPtr which can hold a pointer to a TFitResult object.; By default the TFitResultPtr contains only the status of the fit and it converts; automatically to an integer. If the option ""S"" is instead used, TFitResultPtr contains; the TFitResult and behaves as a smart pointer to it. For example one can do:; TFitResultPtr r = graph->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t par0 = r->Parameter(0); // retrieve the value for the parameter 0; Double_t err0 = r->ParError(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. The fit parameters, error and chi2 (but not covariance matrix) can be retrieved also; from the fitted function. Associated functions. One or more object (typically a TF1*) can be added to the list; of functions (fFunctions) associated to each graph.; When TGraph::Fit is invoked, the fitted function is added to this list.; Given a graph gr, one can retrieve an associated function; with: TF1 *myfunc = gr->GetFunction(""myfunc"");. If the graph is made persistent, the list of; associated functions is also persistent. Given a pointer (see above); to an associated function myfunc, one can retrieve the function/fit; parameters with calls such as:; Double_t chi2 = myfunc->GetChisquare();; Double_t par0 = myfunc->GetParameter(0); //value of 1st parameter; Double_t err0 = myfunc->GetParErr",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:11367,Testability,Test,TestBit,11367," asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidPaint(Option_t* chopt = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* chopt = """") const; virtual Int_tTObject::Read(const char* name); virtual voidRecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidSavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetMaximum(Double_t maximum = -1111); virtual voidSetMinimum(Double_t minimum = -1111); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:11406,Testability,Test,TestBits,11406," asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidPaint(Option_t* chopt = """"); virtual voidTObject::Pop(); virtual voidPrint(Option_t* chopt = """") const; virtual Int_tTObject::Read(const char* name); virtual voidRecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidSavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); virtual voidSetMaximum(Double_t maximum = -1111); virtual voidSetMinimum(Double_t minimum = -1111); virtual voidTNamed::SetName(const char* name)MENU ; virtual voidTNamed::SetNameTitle(const char* name, const char* title); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTNamed::SetTitle(const char* title = """")MENU ; virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual Int_tTNamed::Sizeof() const; virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiGraph.html:6500,Usability,Clear,Clear,6500,,MatchSource.WIKI,root/html532/TMultiGraph.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiGraph.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:981,Availability,avail,available,981,"erceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial mo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:1681,Availability,error,errors,1681,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3588,Availability,error,error,3588,"ver a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3630,Availability,error,error,3630,"tor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The p",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3697,Availability,error,error,3697,"tor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The p",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3818,Availability,error,error,3818," made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch le",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4216,Availability,error,errors,4216,"ear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8276,Availability,avail,available,8276,"; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:10906,Availability,Error,Error,10906,"d, const char* extF = """", const char* extD = """"); virtual~TMultiLayerPerceptron(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName(",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:11090,Availability,error,error,11090,"n = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStri",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:11174,Availability,error,error,11174,"nst char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStringGetStructure() const; Double_tGetTau() const; virtual const char*TObject::GetTitle",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23514,Availability,Avail,Available,23514,"""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); S",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25238,Availability,error,error,25238,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25315,Availability,error,error,25315,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25378,Availability,avail,available,25378,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25565,Availability,Error,Error,25565,"Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the fir",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25666,Availability,Error,Error,25666,"scent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25730,Availability,Error,Error,25730," and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalise",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25823,Availability,error,error,25823,"nt_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayer",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25924,Availability,error,error,25924,"terations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3344,Deployability,continuous,continuous,3344,"LPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimi",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4482,Deployability,update,updated,4482,"methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients wi",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4872,Deployability,update,updated,4872,"ights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8129,Deployability,update,update,8129,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8172,Deployability,update,update,8172,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8327,Deployability,update,update,8327,"ne them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD =",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25042,Deployability,update,update,25042,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25084,Deployability,update,update,25084,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27000,Deployability,update,updates,27000," output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:28729,Deployability,update,updated,28729,"pWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:28833,Deployability,update,updated,28833,"filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:29187,Deployability,update,updated,29187,"non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(TMatrixD& , TMatrixD& , Double_t* ); Sets the gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}) vectors; Gamma is computed here, so ComputeDEDw cannot have been called before,; and delta is a direct translation of buffer into a TMatrixD. Double_t DerivDir(Double_t* ); scalar product between gradient and direction; = derivative along direction. void BFGSDir(TMatrixD& ,",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:29641,Deployability,update,update,29641," void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used by a later stochastic step.; It returns true if the line search fails. void ConjugateGradientsDir(Double_t* , Double_t ); Sets the search direction to conjugate gradient direction; beta should be:; ||g_{(t+1)}||^2 / ||g_{(t)}||^2 (Fletcher-Reeves); g_{(t+1)} (g_{(t+1)}-g_{(t)}) / ||g_{(t)}||^2 (Ribiere-Polak). bool GetBFGSH(TMatrixD& , TMatrixD& , TMatrixD& ); Computes the hessian matrix using the BFGS update algorithm.; from gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}).; It returns true if such a direction could not be found; (if gamma and delta are orthogonal). void SetGammaDelta(TMatrixD& , TMatrixD& , Double_t* ); Sets the gamma (g_{(t+1)}-g_{(t)}) and delta (w_{(t+1)}-w_{(t)}) vectors; Gamma is computed here, so ComputeDEDw cannot have been called before,; and delta is a direct translation of buffer into a TMatrixD. Double_t DerivDir(Double_t* ); scalar product between gradient and direction; = derivative along direction. void BFGSDir(TMatrixD& , Double_t* ); Computes the direction for the BFGS algorithm as the product; between the Hessian estimate (bfgsh) and the dir. void Draw(Option_t* option = """"); Draws the network structure.; Neurons are depicted by a blue disk, and synapses by; lines connecting neurons.; The line width is proportionnal to the weight. TMultiLayerPerceptron(). Double_t GetEta() const; { return fEta; }. Doubl",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:5879,Energy Efficiency,power,powerful,5879,"nimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:28219,Integrability,depend,dependant,28219,"moid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_Line(Double_t* , Double_t* , Double_t ); Sets the weights to a point along a line; Weights are set to [origin + (dist * dir)]. void SteepestDir(Double_t* ); Sets the search direction to steepest descent. bool LineSearch(Double_t* , Double_t* ); Search along the line defined by direction.; buffer is not used but is updated with the new dw; so that it can be used b",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:1315,Modifiability,layers,layers,1315,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:1368,Modifiability,layers,layers,1368,"eurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2518,Modifiability,flexible,flexible,2518,"f; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3240,Modifiability,layers,layers,3240,"iscrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computatio",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6341,Modifiability,layers,layers,6341," line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TC",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6430,Modifiability,layers,layers,6430,"the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning m",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6487,Modifiability,layers,layers,6487," Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8979,Modifiability,layers,layers,8979,"e; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); virtua",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:12453,Modifiability,Inherit,InheritsFrom,12453,"me) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStringGetStructure() const; Double_tGetTau() const; virtual const char*TObject::GetTitle() const; TNeuron::ENeuronTypeGetType() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; voidLoadWeights(Option_t* filename = """"); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TO",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:12519,Modifiability,Inherit,InheritsFrom,12519," const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStringGetStructure() const; Double_tGetTau() const; virtual const char*TObject::GetTitle() const; TNeuron::ENeuronTypeGetType() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; voidLoadWeights(Option_t* filename = """"); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](siz",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:18748,Modifiability,Inherit,Inheritance,18748,"er*fManager! TTreeFormulaManager for the weight and neurons; TObjArrayfNetworkCollection of all the neurons in the network; TNeuron::ENeuronTypefOutTypeType of output neurons; Int_tfReset! number of epochs between two resets of the search direction to the steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter metho",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:18761,Modifiability,Inherit,Inherited,18761,"er*fManager! TTreeFormulaManager for the weight and neurons; TObjArrayfNetworkCollection of all the neurons in the network; TNeuron::ENeuronTypefOutTypeType of output neurons; Int_tfReset! number of epochs between two resets of the search direction to the steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter metho",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19123,Modifiability,layers,layers,19123,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19198,Modifiability,layers,layers,19198,"rch - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: """,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19255,Modifiability,layers,layers,19255,"fining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' i",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19348,Modifiability,variab,variable,19348," flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20049,Modifiability,layers,layers,20049,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20124,Modifiability,layers,layers,20124,"giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20181,Modifiability,layers,layers,20181,"dden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20274,Modifiability,variab,variable,20274,"ers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be fol",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20980,Modifiability,layers,layers,20980,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21055,Modifiability,layers,layers,21055,"g; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just desc",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21112,Modifiability,layers,layers,21112,"layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are s",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21205,Modifiability,variab,variable,21205,"re separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepende",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21981,Modifiability,layers,layers,21981,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22056,Modifiability,layers,layers,22056,"bed by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. vo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22113,Modifiability,layers,layers,22113,"parated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets th",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22206,Modifiability,variab,variable,22206," by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimizati",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:26228,Modifiability,layers,layers,26228," canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:26850,Modifiability,layers,layers,26850," for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Opti",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27022,Modifiability,layers,layers,27022," output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24777,Performance,Load,Load,24777,"tion; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:26401,Performance,perform,performance,26401,"ble. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27813,Performance,Load,LoadWeights,27813,"HiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27851,Performance,Load,Loads,27851,"HiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for stochastic training. void MLP_Stochastic(Double_t* ); One step for the stochastic method; buffer should contain the previous dw vector and will be updated. void MLP_Batch(Double_t* ); One step for the batch (stochastic) method.; DEDw should have been updated before calling this. void MLP_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2023,Safety,predict,predictions,2023,"ion, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:12343,Security,Hash,Hash,12343,"idTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta() const; Double_tGetEtaDecay() const; virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; Int_tGetReset() const; TStringGetStructure() const; Double_tGetTau() const; virtual const char*TObject::GetTitle() const; TNeuron::ENeuronTypeGetType() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; voidLoadWeights(Option_t* filename = """"); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](voi",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:753,Testability,test,test,753,". TMultiLayerPerceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6991,Testability,test,test,6991," direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the n",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:7223,Testability,test,test,7223,"uctor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations;",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:9222,Testability,test,test,9222,,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:9416,Testability,test,test,9416,,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:9645,Testability,test,test,9645,,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:9859,Testability,test,test,9859,,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:10782,Testability,test,test,10782,"layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); virtual~TMultiLayerPerceptron(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); voidExport(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; Double_tGetDelta() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); Double_tGetEpsilon() const; Double_tGetError(Int_t event) const; Double_tGetError(TMultiLayerPerceptron::EDataSet set) const; Double_tGetEta",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:14604,Testability,test,test,14604,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:14642,Testability,test,test,14642,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:14990,Testability,Test,TestBit,14990,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:15029,Testability,Test,TestBits,15029,"ator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidRandomize() const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tResult(Int_t event, Int_t index = 0) const; virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetData(TTree*); voidSetDelta(Double_t delta); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetEpsilon(Double_t eps); voidSetEta(Double_t eta); voidSetEtaDecay(Double_t ed); voidSetEventWeight(const char*); voidSetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); static voidTObject::SetObjectStat(Bool_t stat); voidSetReset(Int_t reset); voidSetTau(Double_t tau); voidSetTestDataSet(TEventList* test); voidSetTestDataSet(const char* test); voidSetTrainingDataSet(TEventList* train); voidSetTrainingDataSet(const char* train); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrain(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:18292,Testability,test,test,18292,"FirstLayerCollection of the input neurons; subset of fNetwork; Double_tfLastAlpha! internal parameter used in line search; TObjArrayfLastLayerCollection of the output neurons; subset of fNetwork; TMultiLayerPerceptron::ELearningMethodfLearningMethod! The Learning Method; TTreeFormulaManager*fManager! TTreeFormulaManager for the weight and neurons; TObjArrayfNetworkCollection of all the neurons in the network; TNeuron::ENeuronTypefOutTypeType of output neurons; Int_tfReset! number of epochs between two resets of the search direction to the steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:18960,Testability,test,test,18960,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19576,Testability,test,test,19576,"ing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and th",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19886,Testability,test,test,19886,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20502,Testability,test,test,20502,"ven as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testin",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20812,Testability,test,test,20812,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21433,Testability,test,test,21433,"rgument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21533,Testability,test,testing,21533,"rgument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21813,Testability,test,test,21813,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22434,Testability,test,test,22434,"vents; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod met",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22534,Testability,test,testing,22534,"vents; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod met",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22976,Testability,test,test,22976,"output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constru",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:22992,Testability,Test,Test,22992,"output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constru",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23272,Testability,test,test,23272,"!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= E",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23288,Testability,Test,Test,23288,"!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= E",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:25328,Testability,test,test,25328,"ay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27351,Testability,test,test,27351,"ince this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or T",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:27534,Testability,test,test,27534,"ldNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the weights to a text file.; Set filename to ""-"" (default) to dump to the standard output. void LoadWeights(Option_t* filename = """"); Loads the weights from a text file conforming to the format; defined by DumpWeights. Double_t Evaluate(Int_t index, Double_t* params) const; Returns the Neural Net for a given set of input parameters; #parameters must equal #input neurons. void Export(Option_t* filename = ""NNfunction"", Option_t* language = ""C++"") const; Exports the NN as a function for any non-ROOT-dependant code; Supported languages are: only C++ , FORTRAN and Python (yet); This feature is also usefull if you want to plot the NN as; a function (TF1 or TF2). void Shuffle(Int_t* , Int_t ) const; Shuffle the Int_t index[n] in input.; Input:; index: the array to shuffle; n: the size of the array; Output:; index: the shuffled indexes; This method is used for st",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:960,Usability,learn,learning,960,"erceptron. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » MATH; » MLP; » TMultiLayerPerceptron. class TMultiLayerPerceptron: public TObject. TMultiLayerPerceptron. This class describes a neural network.; There are facilities to train the network and use the output. The input layer is made of inactive neurons (returning the; optionaly normalized input) and output neurons are linear.; The type of hidden neurons is free, the default being sigmoids.; (One should still try to pass normalized inputs, e.g. between [0.,1]). The basic input is a TTree and two (training and test) TEventLists.; Input and output neurons are assigned a value computed for each event; with the same possibilities as for TTree::Draw().; Events may be weighted individualy or via TTree::SetWeight().; 6 learning methods are available: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS. This implementation, written by C. Delaere, is *inspired* from; the mlpfit package from J.Schwindling et al. with some extensions:; * the algorithms are globally the same; * in TMultilayerPerceptron, there is no limitation on the number of; layers/neurons, while MLPFIT was limited to 2 hidden layers; * TMultilayerPerceptron allows you to save the network in a root file, and; provides more export functionalities; * TMultilayerPerceptron gives more flexibility regarding the normalization of; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial mo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2508,Usability,clear,clear,2508,"f; inputs/outputs; * TMultilayerPerceptron provides, thanks to Andrea Bocci, the possibility to; use cross-entropy errors, which allows to train a network for pattern; classification based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:2729,Usability,simpl,simple,2729,"cation based on Bayesian posterior probability. . Introduction. Neural Networks are more and more used in various fields for data; analysis and classification, both for research and commercial; institutions. Some randomly choosen examples are:. image analysis; financial movements predictions and analysis; sales forecast and product shipping optimisation; in particles physics: mainly for classification tasks (signal; over background discrimination). More than 50% of neural networks are multilayer perceptrons. This; implementation of multilayer perceptrons is inspired from the; MLPfit; package originaly written by Jerome Schwindling. MLPfit remains; one of the fastest tool for neural networks studies, and this ROOT; add-on will not try to compete on that. A clear and flexible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3512,Usability,Learn,Learning,3512,"exible Object; Oriented implementation has been choosen over a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:3546,Usability,learn,learning,3546,"ver a faster but more; difficult to maintain code. Nevertheless, the time penalty does not; exceed a factor 2. The; MLP. The multilayer perceptron is a simple feed-forward network with; the following structure:. It is made of neurons characterized by a bias and weighted links; between them (let's call those links synapses). The input neurons; receive the inputs, normalize them and forward them to the first; hidden layer. Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being; linear for output neurons or a sigmoid for hidden layers. This is; useful because of two theorems:. A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4275,Usability,learn,learning,4275,". A linear combination of sigmoids can approximate any; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4361,Usability,learn,learning,4361,"; continuous function.; Trained with output = 1 for the signal and 0 for the; background, the approximated function of inputs X is the probability; of signal, knowing X. Learning; methods. The aim of all learning methods is to minimize the total error on; a set of weighted examples. The error is defined as the sum in; quadrature, devided by two, of the error on each individual output; neuron.; In all methods implemented, one needs to compute; the first derivative of that error with respect to the weights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum alo",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:4793,Usability,learn,learning,4793,"ights.; Exploiting the well-known properties of the derivative, especialy the; derivative of compound functions, one can write:. for a neuton: product of the local derivative with the; weighted sum on the outputs of the derivatives.; for a synapse: product of the input with the local derivative; of the output neuron. This computation is called back-propagation of the errors. A; loop over all examples is called an epoch.; Six learning methods are implemented.; Stochastic minimization: This; is the most trivial learning method. This is the Robbins-Monro; stochastic approximation applied to multilayer perceptrons. The; weights are updated after each example according to the formula:; $w_{ij}(t+1) = w_{ij}(t) + \Delta w_{ij}(t)$. with. $\Delta w_{ij}(t) = - \eta(\d e_p / \d w_{ij} +; \delta) + \epsilon \Deltaw_{ij}(t-1)$; The parameters for this method are Eta, EtaDecay, Delta and; Epsilon.; Steepest descent with fixed step size; (batch learning): It is the same as the stochastic; minimization, but the weights are updated after considering all the; examples, with the total derivative dEdw. The parameters for this; method are Eta, EtaDecay, Delta and Epsilon.; Steepest descent algorithm: Weights; are set to the minimum along the line defined by the gradient. The; only parameter for this method is Tau. Lower tau = higher precision =; slower search. A value Tau = 3 seems reasonable.; Conjugate gradients with the; Polak-Ribiere updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:6308,Usability,simpl,simple,6308," line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Conjugate gradients with the; Fletcher-Reeves updating formula: Weights are set to the; minimum along the line defined by the conjugate gradient. Parameters; are Tau and Reset, which defines the epochs where the direction is; reset to the steepes descent.; Broyden, Fletcher, Goldfarb, Shanno; (BFGS) method: Implies the computation of a NxN matrix; computation, but seems more powerful at least for less than 300; weights. Parameters are Tau and Reset, which defines the epochs where; the direction is reset to the steepes descent. How; to use it... TMLP is build from 3 classes: TNeuron, TSynapse and; TMultiLayerPerceptron. Only TMultiLayerPerceptron should be used; explicitely by the user.; TMultiLayerPerceptron will take examples from a TTree; given in the constructor. The network is described by a simple; string: The input/output layers are defined by giving the expression for; each neuron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TC",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:7359,Usability,learn,learning,7359,"uron, separated by comas. Hidden layers are just described; by the number of neurons. The layers are separated by colons.; In addition, input/output layer formulas can be preceded by '@' (e.g ""@out""); if one wants to also normalize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:7442,Usability,Learn,Learning,7442,"malize the data from the TTree.; Input and outputs are taken from the TTree given as second argument.; Expressions are evaluated as for TTree::Draw(), arrays are expended in; distinct neurons, one for each index.; This can only be done for fixed-size arrays.; If the formula ends with ""!"", softmax functions are used for the output layer.; One defines the training and test datasets by TEventLists. Example:; TMultiLayerPerceptron(""x,y:10:5:f"",inputTree);; Both the TTree and the TEventLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exac",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8058,Usability,simpl,simple,8058,"tLists can be defined in; the constructor, or later with the suited setter method. The lists; used for training and test can be defined either explicitely, or via; a string containing the formula to be used to define them, exactly as; for a TCut.; The learning method is defined using the; TMultiLayerPerceptron::SetLearningMethod() . Learning methods are :; TMultiLayerPerceptron::kStochastic, ; TMultiLayerPerceptron::kBatch,; TMultiLayerPerceptron::kSteepestDescent,; TMultiLayerPerceptron::kRibierePolak,; TMultiLayerPerceptron::kFletcherReeves,; TMultiLayerPerceptron::kBFGS; A weight can be assigned to events, either in the constructor, either; with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptr",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8652,Usability,learn,learning,8652," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:8860,Usability,learn,learning,8860," with TMultiLayerPerceptron::SetEventWeight(). In addition, the TTree weight; is taken into account.; Finally, one starts the training with; TMultiLayerPerceptron::Train(Int_t nepoch, Option_t* options). The; first argument is the number of epochs while option is a string that; can contain: ""text"" (simple text output) , ""graph""; (evoluting graphical training curves), ""update=X"" (step for; the text/graph output update) or ""+"" (will skip the; randomisation and start from the previous values). All combinations; are available. . Example:; net.Train(100,""text, graph, update=10"").; When the neural net is trained, it can be used; directly ( TMultiLayerPerceptron::Evaluate() ) or exported to a; standalone C++ code ( TMultiLayerPerceptron::Export() ).; Finaly, note that even if this implementation is inspired from the mlpfit code,; the feature lists are not exactly matching:. mlpfit hybrid learning method is not implemented; output neurons can be normalized, this is not the case for mlpfit; the neural net is exported in C++, FORTRAN or PYTHON; the drawResult() method allows a fast check of the learning procedure. In addition, the paw version of mlpfit had additional limitations on the number of neurons, hidden layers and inputs/outputs that does not apply to TMultiLayerPerceptron. Function Members (Methods); public:. TMultiLayerPerceptron(); TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLa",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:10235,Usability,Clear,Clear,10235,"on::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); virtual~TMultiLayerPerceptron(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; voidComputeDEDw() const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidDraw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; voidDrawResult(Int_t index = 0, Option_t* option = ""test"") const; virtual voidTObject::Dump() constMENU ; voidDumpWeights(Option_t* filename = ""-"") const; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEvaluate(Int_t index, Double_t* params) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:17739,Usability,Learn,Learning,17739, };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Int_tfCurrentTree! index of the current tree in a chain; Double_tfCurrentTreeWeight! weight of the current tree in a chain; TTree*fData! pointer to the tree used as datasource; Double_tfDelta! Delta - used in stochastic minimisation - Default=0.; Double_tfEpsilon! Epsilon - used in stochastic minimisation - Default=0.; Double_tfEta! Eta - used in stochastic minimisation - Default=0.1; Double_tfEtaDecay! EtaDecay - Eta *= EtaDecay at each epoch - Default=1.; TTreeFormula*fEventWeight! formula representing the event weight; TObjArrayfFirstLayerCollection of the input neurons; subset of fNetwork; Double_tfLastAlpha! internal parameter used in line search; TObjArrayfLastLayerCollection of the output neurons; subset of fNetwork; TMultiLayerPerceptron::ELearningMethodfLearningMethod! The Learning Method; TTreeFormulaManager*fManager! TTreeFormulaManager for the weight and neurons; TObjArrayfNetworkCollection of all the neurons in the network; TNeuron::ENeuronTypefOutTypeType of output neurons; Int_tfReset! number of epochs between two resets of the search direction to the steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentati,MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:19090,Usability,simpl,simple,19090,"steepest descent - Default=50; TStringfStructureString containing the network structure; TObjArrayfSynapsesCollection of all the synapses in the network; Double_tfTau! Tau - used in line search - Default=3.; TEventList*fTest! EventList defining the events in the test dataset; Bool_tfTestOwner! internal flag whether one has to delete fTest or not; TEventList*fTraining! EventList defining the events in the training dataset; Bool_tfTrainingOwner! internal flag whether one has to delete fTraining or not; TNeuron::ENeuronTypefTypeType of hidden neurons; TStringfWeightString containing the event weight; TStringfextDString containing the derivative name; TStringfextFString containing the function name. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMultiLayerPerceptron(); Default constructor. TMultiLayerPerceptron(const char* layout, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20016,Usability,simpl,simple,20016,"g, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data, TEventList* training, TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:20947,Usability,simpl,simple,20947,"TEventList* test, TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are the two TEventLists defining events; to be used during the neural net training.; Both the TTree and the TEventLists can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, con",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:21948,Usability,simpl,simple,21948,"oid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. TMultiLayerPerceptron(const char* layout, const char* weight, TTree* data = 0, const char* training = ""Entry$%2==0"", const char* test = """", TNeuron::ENeuronType type = TNeuron::kSigmoid, const char* extF = """", const char* extD = """"); The network is described by a simple string:; The input/output layers are defined by giving; the branch names separated by comas.; Hidden layers are just described by the number of neurons.; The layers are separated by colons.; Ex: ""x,y:10:5:f""; The output can be prepended by '@' if the variable has to be; normalized.; The output can be followed by '!' to use Softmax neurons for the; output layer only.; Ex: ""x,y:10:5:c1,c2,c3!""; Input and outputs are taken from the TTree given as second argument.; training and test are two cuts (see TTreeFormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23496,Usability,learn,learning,23496,"ormula) defining events; to be used during the neural net training and testing.; Example: ""Entry$%2"", ""(Entry$+1)%2"".; Both the TTree and the cut can be defined in the constructor,; or later with the suited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constru",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23678,Usability,learn,learning,23678,"uited setter method. ~TMultiLayerPerceptron(); Destructor. void SetData(TTree* ); Set the data source. void SetEventWeight(const char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:23841,Usability,learn,learning,23841," char* ); Set the event weight. void SetTrainingDataSet(TEventList* train); Sets the Training dataset.; Those events will be used for the minimization. void SetTestDataSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry in",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24012,Usability,learn,learning,24012,"aSet(TEventList* test); Sets the Test dataset.; Those events will not be used for the minimization but for control. void SetTrainingDataSet(const char* train); Sets the Training dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; -",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24181,Usability,learn,learning,24181,"raining dataset.; Those events will be used for the minimization.; Note that the tree must be already defined. void SetTestDataSet(const char* test); Sets the Test dataset.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24351,Usability,learn,learning,24351,"t.; Those events will not be used for the minimization but for control.; Note that the tree must be already defined. void SetLearningMethod(TMultiLayerPerceptron::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24502,Usability,learn,learning,24502,"n::ELearningMethod method); Sets the learning method.; Available methods are: kStochastic, kBatch,; kSteepestDescent, kRibierePolak, kFletcherReeves and kBFGS.; (look at the constructor for the complete description; of learning methods and parameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the outpu",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24714,Usability,learn,learning,24714,"arameters). void SetEta(Double_t eta); Sets Eta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEpsilon(Double_t eps); Sets Epsilon - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:24969,Usability,simpl,simple,24969,"d SetDelta(Double_t delta); Sets Delta - used in stochastic minimisation; (look at the constructor for the complete description; of learning methods and parameters). void SetEtaDecay(Double_t ed); Sets EtaDecay - Eta *= EtaDecay at each epoch; (look at the constructor for the complete description; of learning methods and parameters). void SetTau(Double_t tau); Sets Tau - used in line search; (look at the constructor for the complete description; of learning methods and parameters). void SetReset(Int_t reset); Sets number of epochs between two resets of the; search direction to the steepest descent.; (look at the constructor for the complete description; of learning methods and parameters). void GetEntry(Int_t ) const; Load an entry into the network. void Train(Int_t nEpoch, Option_t* option = ""text"", Double_t minE = 0); Train the network.; nEpoch is the number of iterations.; option can contain:; - ""text"" (simple text output); - ""graph"" (evoluting graphical training curves); - ""update=X"" (step for the text/graph output update); - ""+"" will skip the randomisation and start from the previous values.; - ""current"" (draw in the current canvas); - ""minErrorTrain"" (stop when NN error on the training sample gets below minE; - ""minErrorTest"" (stop when NN error on the test sample gets below minE; All combinations are available. Double_t Result(Int_t event, Int_t index = 0) const; Computes the output for a given event.; Look at the output neuron designed by index. Double_t GetError(Int_t event) const; Error on the output for a given event. Double_t GetError(TMultiLayerPerceptron::EDataSet set) const; Error on the whole dataset. Double_t GetSumSquareError() const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMultiLayerPerceptron.html:26763,Usability,simpl,simple,26763,") const; Error on the output for a given event. Double_t GetCrossEntropyBinary() const; Cross entropy error for sigmoid output neurons, for a given event. Double_t GetCrossEntropy() const; Cross entropy error for a softmax output neuron, for a given event. void ComputeDEDw() const; Compute the DEDw = sum on all training events of dedw for each weight; normalized by the number of events. void Randomize() const; Randomize the weights. void AttachData(); Connects the TTree to Neurons in input and output; layers. The formulas associated to each neuron are created; and reported to the network formula manager.; By default, the branch is not normalised since this would degrade; performance for classification jobs.; Normalisation can be requested by putting '@' in front of the formula. void ExpandStructure(); Expand the structure of the first layer. void BuildNetwork(); Instanciates the network from the description. void BuildFirstLayer(TString& ); Instanciates the neurons in input; Inputs are normalised and the type is set to kOff; (simple forward of the formula value). void BuildHiddenLayers(TString& ); Builds hidden layers. void BuildOneHiddenLayer(const TString& sNumNodes, Int_t& layer, Int_t& prevStart, Int_t& prevStop, Bool_t lastLayer); Builds a hidden layer, updates the number of layers. void BuildLastLayer(TString& , Int_t ); Builds the output layer; Neurons are linear combinations of input, by defaul.; If the structure ends with ""!"", neurons are set up for classification,; ie. with a sigmoid (1 neuron) or softmax (more neurons) activation function. void DrawResult(Int_t index = 0, Option_t* option = ""test"") const; Draws the neural net output; It produces an histogram with the output for the two datasets.; Index is the number of the desired output neuron.; ""option"" can contain:; - test or train to select a dataset; - comp to produce a X-Y comparison plot; - nocanv to not create a new TCanvas for the plot. void DumpWeights(Option_t* filename = ""-"") const; Dumps the ",MatchSource.WIKI,root/html532/TMultiLayerPerceptron.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMultiLayerPerceptron.html
https://root.cern/root/html532/TMutex.html:1381,Availability,Error,Error,1381," TMutex(Bool_t recursive = kFALSE); virtual~TMutex(); voidTObject::AbstractMethod(const char* method) const; Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:1510,Availability,error,error,1510," = kFALSE); virtual~TMutex(); voidTObject::AbstractMethod(const char* method) const; Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virt",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:1594,Availability,error,error,1594," Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject:",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5769,Availability,error,error,5769,"onst char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5917,Availability,error,error,5917,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:6063,Availability,error,error,6063,"const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMutex& ). virtual ~TMutex(); { delete fMutexImp; }. » Author: Fons Rademakers 26/06/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutex.h 29797 2009-08-17 14:35:51Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:3857,Deployability,Release,Release,3857,"ap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); Int_tTVirtualMutex::Release(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = ",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:2532,Modifiability,Inherit,InheritsFrom,2532,"ect::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[]",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:2598,Modifiability,Inherit,InheritsFrom,2598,"; virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); vi",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5514,Modifiability,Inherit,Inheritance,5514,"tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMu",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:5527,Modifiability,Inherit,Inherited,5527,"tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). private:. TMutex(const TMutex&); TMutex&operator=(const TMutex&). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TMutexImp*fMutexImppointer to mutex implementation. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; TMutex(Bool_t recursive = kFALSE); Create a mutex lock. The actual mutex implementation will be; provided via the TThreadFactory. Int_t Lock(); Lock the mutex. Returns 0 when no error, EDEADLK when mutex was already; locked by this thread and this mutex is not reentrant. Int_t TryLock(); Try to lock mutex. Returns 0 when no error, EDEADLK when mutex was; already locked by this thread and this mutex is not reentrant. Int_t UnLock(); Unlock the mutex. Returns 0 when no error, EPERM when mutex was already; unlocked by this thread. Int_t CleanUp(); Clean up of mutex. TVirtualMutex * Factory(Bool_t recursive = kFALSE); Create mutex and return pointer to it. Calling function must care; about proper deletion. The function is intended to be used in connection; with the R__LOCKGUARD2 macro for local thread protection. Since ""new"" is; used the TStorage class has to be protected by gGlobalMutex. TMutex(const TMutex& ). TMutex& operator=(const TMu",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:2422,Security,Hash,Hash,2422,"t) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); vo",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:4549,Testability,Test,TestBit,4549,"Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); Int_tTVirtualMutex::Release(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:4588,Testability,Test,TestBits,4588,"Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); Int_tTVirtualMutex::Release(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutex.html:841,Usability,Clear,Clear,841," TMutex(Bool_t recursive = kFALSE); virtual~TMutex(); voidTObject::AbstractMethod(const char* method) const; Int_tTVirtualMutex::Acquire(); virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual Int_tCleanUp(); virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual TVirtualMutex*Factory(Bool_t recursive = kFALSE); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::",MatchSource.WIKI,root/html532/TMutex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutex.html
https://root.cern/root/html532/TMutexImp.html:543,Availability,avail,available,543,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:1381,Availability,Error,Error,1381," virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:1510,Availability,error,error,1510," virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:1594,Availability,error,error,1594," voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:333,Integrability,interface,interface,333,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:353,Integrability,depend,dependent,353,". TMutexImp. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » CORE; » THREAD; » TMutexImp. class TMutexImp: public TObject. TMutexImp. This class provides an abstract interface to the OS dependent mutex; classes (TPosixMutex and TWin32Mutex). Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:2474,Modifiability,Inherit,InheritsFrom,2474,"d, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[]",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:2540,Modifiability,Inherit,InheritsFrom,2540,"cute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TM",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:5336,Modifiability,Inherit,Inheritance,5336,"irtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~TMutexImp(); { }. Int_t Lock(). Int_t TryLock(). Int_t UnLock(). » Author: Fons Rademakers 01/07/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutexImp.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:5349,Modifiability,Inherit,Inherited,5349,"irtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTObject::MakeZombie(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~TMutexImp(); { }. Int_t Lock(). Int_t TryLock(). Int_t UnLock(). » Author: Fons Rademakers 01/07/97 » Copyright (C) 1995-2000, Rene Brun and Fons Rademakers. *; » Last changed: root/thread:$Id: TMutexImp.h 20882 2007-11-19 11:31:26Z rdm $ » Last generated: 2011-11-03 20:20; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:2364,Security,Hash,Hash,2364,"l voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*TObject::GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual Int_tLock(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); vo",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:4499,Testability,Test,TestBit,4499,"k(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMutexImp&operator=(const TMutexImp&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:4538,Testability,Test,TestBits,4538,"k(); virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMutexImp&operator=(const TMutexImp&); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual Int_tTObject::Read(const char* name); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); static voidTObject::SetObjectStat(Bool_t stat); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual Int_tTryLock(); virtual Int_tUnLock(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const.",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMutexImp.html:841,Usability,Clear,Clear,841," virtual~TMutexImp(); voidTObject::AbstractMethod(const char* method) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() c",MatchSource.WIKI,root/html532/TMutexImp.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMutexImp.html
https://root.cern/root/html532/TMVA.html:332,Modifiability,Config,Config,332," categorizing the phase space. Function Members (Methods); public:. TMVA::Config&gConfig(); TMVA::Tools&gTools(); Bool_toperator<(const TMVA::GeneticGenes&, const TMVA::GeneticGenes&); ostream&operator<<(ostream& os, const TMVA::Node& node); ostream&operator<<(ostream& os, const TMVA::Node* node); ostream&operator<<(ostream& os, const TMVA::BinaryTree& tree); ostream&operator<<(ostream& os, const TMVA::Event& event); ostream&operator<<(ostream& os, const TMVA::Rule& rule); ostream&operator<<(ostream& os, const TMVA::RuleEnsemble& event); ostream&operator<<(ostream& os, const TMVA::PDF& tree); ostream&operator<<(ostream& os, const TMVA::Node& node); ostream&operator<<(ostream& os, const TMVA::Node* node); ostream&operator<<(ostream& os, const TMVA::BinaryTree& tree); ostream&operator<<(ostream& os, const TMVA::Event& event); ostream&operator<<(ostream& os, const TMVA::PDF& tree); ostream&operator<<(ostream& os, const TMVA::Node& node); ostream&operator<<(ostream& os, const TMVA::Node* node); ostream&operator<<(ostream& os, const TMVA::BinaryTree& tree); ostream&operator<<(ostream& os, const TMVA::Event& event); ostream&operator<<(ostream& os, const TMVA::Event& event); ostream&operator<<(ostream& os, const TMVA::Node& node); ostream&operator<<(ostream& os, const TMVA::Node* node); ostream&operator<<(ostream& os, const TMVA::BinaryTree& tree); ostream&operator<<(ostream& os, const TMVA::Rule& rule); ostream&operator<<(ostream& os, const TMVA::RuleEnsemble& event); ostream&operator<<(ostream& os, const TMVA::PDF& tree); istream&operator>>(istream& istr, TMVA::BinaryTree& tree); istream&operator>>(istream& istr, TMVA::PDF& tree); istream&operator>>(istream& istr, TMVA::BinaryTree& tree); istream&operator>>(istream& istr, TMVA::PDF& tree); istream&operator>>(istream& istr, TMVA::BinaryTree& tree); istream&operator>>(istream& istr, TMVA::BinaryTree& tree); istream&operator>>(istream& istr, TMVA::PDF& tree). Data Members. Class Charts; Function documentation. » Author: Andr",MatchSource.WIKI,root/html532/TMVA.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA.html
https://root.cern/root/html532/TMVA_Index.html:742,Deployability,configurat,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:1768,Integrability,Interface,Interface,1768,"onfig::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TMVA ANNs; TMVA::MethodBDT Analysis of Boosted Decision Trees; TMVA::MethodBase Virtual base class for all TMVA method; TMVA::MethodBayesClassifier Friedman's BayesClassifier method ; TMVA::MethodBoost ; TMVA::MethodCFMlpANN Interface for Clermond-Ferrand artificial neural network; TMVA::MethodCFMlpANN_Utils Implementation of Clermond-Ferrand artificial neural network; TMVA::MethodCategory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple compari",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:2224,Integrability,Interface,Interface,2224,"; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TMVA ANNs; TMVA::MethodBDT Analysis of Boosted Decision Trees; TMVA::MethodBase Virtual base class for all TMVA method; TMVA::MethodBayesClassifier Friedman's BayesClassifier method ; TMVA::MethodBoost ; TMVA::MethodCFMlpANN Interface for Clermond-Ferrand artificial neural network; TMVA::MethodCFMlpANN_Utils Implementation of Clermond-Ferrand artificial neural network; TMVA::MethodCategory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator r",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3382,Integrability,interface,interface,3382,"gory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoa",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3492,Integrability,Wrap,Wrapper,3492,"ltivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimato",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3782,Integrability,Interface,Interface,3782,"ared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapp",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4109,Integrability,interface,interface,4109,ility density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Fr,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4364,Integrability,interface,interface,4364,mentation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in tr,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4782,Integrability,wrap,wrapper,4782,rface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation f,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4955,Integrability,Interface,Interface,4955,ion tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuro,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:5316,Integrability,Interface,Interface,5316,ty; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuro,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:5552,Integrability,Interface,Interface,5552,r; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6026,Integrability,Interface,Interface,6026,::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableR,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:708,Modifiability,Config,Config,708," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:742,Modifiability,config,configuration,742," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:772,Modifiability,Config,Config,772," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:796,Modifiability,Config,Config,796," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:804,Modifiability,Variab,VariablePlotting,804," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:829,Modifiability,Config,Configurable,829," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:4854,Modifiability,variab,variables,4854,:PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TMVA::PDF PDF wrapper for histograms; TMVA::Ranking Method-specific ranking for input variables ; TMVA::Reader Interpret the trained MVAs in an analysis context; TMVA::RegressionVariance Interface to different separation critiera used in training algorithms; TMVA::RootFinder Root finding using Brents algorithm; TMVA::RuleFit Calculations for Friedman's RuleFit method; TMVA::RuleFitAPI Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6655,Modifiability,Variab,VariableDecorrTransform,6655,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6679,Modifiability,Variab,Variable,6679,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6725,Modifiability,Variab,VariableGaussTransform,6725,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6748,Modifiability,Variab,Variable,6748,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6801,Modifiability,Variab,VariableIdentityTransform,6801,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6827,Modifiability,Variab,Variable,6827,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6868,Modifiability,Variab,VariableNormalizeTransform,6868,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6895,Modifiability,Variab,Variable,6895,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6941,Modifiability,Variab,VariablePCATransform,6941,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:6962,Modifiability,Variab,Variable,6962,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:7022,Modifiability,Variab,VariableRearrangeTransform,7022,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:7049,Modifiability,Variab,Variable,7049,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:7095,Modifiability,Variab,VariableTransformBase,7095,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:7132,Modifiability,variab,variable,7132,Friedman's RuleFit method; TMVA::SVEvent Event for SVM; TMVA::SdivSqrtSplusB Implementation of the SdivSqrtSplusB as separation criterion; TMVA::SeparationBase Interface to different separation critiera used in training algorithms; TMVA::SimulatedAnnealing Base class for Simulated Annealing fitting; TMVA::SimulatedAnnealingFitter Fitter using a Simulated Annealing Algorithm; TMVA::TActivation Interface for TNeuron activation function classes; TMVA::TActivationChooser Class for choosing activation functions; TMVA::TActivationIdentity Identity activation function for TNeuron; TMVA::TActivationRadial Radial basis activation function for TNeuron; TMVA::TActivationSigmoid Sigmoid activation function for TNeuron; TMVA::TActivationTanh Tanh sigmoid activation function for TNeuron; TMVA::TNeuron Neuron class used by MethodANNBase derivative ANNs; TMVA::TNeuronInput Interface for TNeuron input calculation classes; TMVA::TNeuronInputAbs Calculates the sum of the absolute values of the weighted inputs; TMVA::TNeuronInputChooser Class for choosing neuron input functions ; TMVA::TNeuronInputSqSum Calculates square of weighted sum of neuron inputs; TMVA::TNeuronInputSum Calculates weighted sum of neuron inputs; TMVA::TSpline1 Linear interpolation class; TMVA::TSpline2 Quadratic interpolation class (using quadrax); TMVA::TSynapse Synapse class used by MethodANNBase and derivatives; TMVA::Timer Timing information for training and evaluation of MVA methods; TMVA::Tools ; TMVA::Types ; TMVA::VariableDecorrTransform Variable transformation: decorrelation; TMVA::VariableGaussTransform Variable transformation: Gauss transformation; TMVA::VariableIdentityTransform Variable transformation: identity; TMVA::VariableNormalizeTransform Variable transformation: normalization; TMVA::VariablePCATransform Variable transformation: Principal Value Composition; TMVA::VariableRearrangeTransform Variable transformation: normalization; TMVA::VariableTransformBase Base class for variable transformations.,MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:1154,Performance,perform,performs,1154," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3757,Performance,Optimiz,OptimizeConfigParameters,3757,"parison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class for Target density; TMVA::PDEFoamVect n-dimensional vector with dynamical allocation; TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:1182,Testability,test,testing,1182," TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:3679,Testability,log,logging,3679,"t (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::OptimizeConfigParameters Interface to different separation critiera used in training algorithms; TMVA::PDEFoam Tree of PDEFoamCells; TMVA::PDEFoamCell Single cell of FOAM; TMVA::PDEFoamDecisionTree Decision tree like PDEFoam; TMVA::PDEFoamDecisionTreeDensity Class for decision tree like PDEFoam density; TMVA::PDEFoamDensityBase PDEFoam event density interface; TMVA::PDEFoamDiscriminant Tree of PDEFoamCells; TMVA::PDEFoamDiscriminantDensity Class for Discriminant density; TMVA::PDEFoamEvent Tree of PDEFoamCells; TMVA::PDEFoamEventDensity Class for Event density; TMVA::PDEFoamKernelBase PDEFoam kernel interface; TMVA::PDEFoamKernelGauss Gaussian PDEFoam kernel estimator; TMVA::PDEFoamKernelLinN next neighbor PDEFoam kernel estimator; TMVA::PDEFoamKernelTrivial trivial PDEFoam kernel estimator; TMVA::PDEFoamMultiTarget Tree of PDEFoamCells; TMVA::PDEFoamTarget Tree of PDEFoamCells; TMVA::PDEFoamTargetDensity Class f",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:262,Usability,Guid,Guide,262,". Index of TMVA. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. ROOT; » TMVA. Index of TMVA; This directory contains the TMVA Multi-Variate-Analysis classes.; See:. The full description of the Multi Variate Analysis package; ; The TMVA Users Guide; The TMVA Options Reference. Class Index; Jump to; T; TMVA:; TMVA::I; TMVA::M; TMVA::Me; TMVA::MethodS; TMVA::P; TMVA::PDEFoamM; TMVA::S; TMVA::T; TMVA::TS; TMVA::V. TMVA ; TMVA::BDTEventWrapper ; TMVA::BinarySearchTree Binary search tree including volume search method ; TMVA::BinarySearchTreeNode Node for the BinarySearchTree; TMVA::BinaryTree Base class for BinarySearch and Decision Trees; TMVA::CCPruner ; TMVA::CCTreeWrapper ; TMVA::Config Singleton class for global configuration settings; TMVA::Config::IONames ; TMVA::Config::VariablePlotting ; TMVA::Configurable Virtual base class for all TMVA method; TMVA::CostComplexityPruneTool ; TMVA::CrossEntropy Implementation of the CrossEntropy as separation criterion; TMVA::DecisionTree implementation of a Decision Tree; TMVA::DecisionTreeNode Node for the Decision Tree ; TMVA::Factory The factory creates all MVA methods, and performs their training and testing; TMVA::FitterBase Baseclass for fitters; TMVA::GeneticAlgorithm Genetic algorithm controller; TMVA::GeneticFitter Fitter using a Genetic Algorithm; TMVA::GeneticGenes Genes definition for genetic algorithm; TMVA::GeneticPopulation Population definition for genetic algorithm; TMVA::GeneticRange Range definition for genetic algorithm; TMVA::GiniIndex Implementation of the GiniIndex as separation criterion; TMVA::GiniIndexWithLaplace Implementation of the GiniIndexWithLaplace as separation criterion; TMVA::IFitterTarget base class for a fitter ""target""; TMVA::IMethod Method Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TM",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA_Index.html:2759,Usability,simpl,simple,2759,"ethod Interface; TMVA::Interval Interval definition, continous and discrete; TMVA::KDEKernel Kernel density estimator for PDF smoothing; TMVA::MCFitter Fitter using Monte Carlo sampling of parameters ; TMVA::MethodANNBase Base class for TMVA ANNs; TMVA::MethodBDT Analysis of Boosted Decision Trees; TMVA::MethodBase Virtual base class for all TMVA method; TMVA::MethodBayesClassifier Friedman's BayesClassifier method ; TMVA::MethodBoost ; TMVA::MethodCFMlpANN Interface for Clermond-Ferrand artificial neural network; TMVA::MethodCFMlpANN_Utils Implementation of Clermond-Ferrand artificial neural network; TMVA::MethodCategory ; TMVA::MethodCommittee Analysis of Boosted MVA methods; TMVA::MethodCompositeBase ; TMVA::MethodCuts Multivariate optimisation of signal efficiency; TMVA::MethodDT Analysis of Decision Trees ; TMVA::MethodFDA Function Discriminant Analysis; TMVA::MethodFisher Analysis of Fisher discriminant (Fisher or Mahalanobis approach) ; TMVA::MethodHMatrix H-Matrix method, a simple comparison of chi-squared estimators for signal and background; TMVA::MethodKNN k Nearest Neighbour classifier; TMVA::MethodLD Linear discriminant analysis; TMVA::MethodLikelihood Likelihood analysis (""non-parametric approach"") ; TMVA::MethodMLP Multi-layer perceptron implemented specifically for TMVA; TMVA::MethodPDEFoam Multi-dimensional probability density estimator using TFoam (PDE-Foam); TMVA::MethodPDERS Multi-dimensional probability density estimator range search (PDERS) method; TMVA::MethodRuleFit Friedman's RuleFit method; TMVA::MethodSVM Support Vector Machine; TMVA::MethodTMlpANN Implementation of interface for TMultiLayerPerceptron; TMVA::MinuitFitter Fitter using a Genetic Algorithm; TMVA::MinuitWrapper Wrapper around TMinuit; TMVA::MisClassificationError Implementation of the MisClassificationError as separation criterion; TMVA::MsgLogger Ostringstream derivative to redirect and format logging output; TMVA::Node Node for the BinarySearch or Decision Trees; TMVA::Optimi",MatchSource.WIKI,root/html532/TMVA_Index.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA_Index.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:955,Modifiability,variab,variable,955,". TMVA::BDTEventWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; Th",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:990,Modifiability,Inherit,Inheritance,990,"tWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1003,Modifiability,Inherit,Inherited,1003,"tWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1578,Modifiability,variab,variable,1578,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1631,Modifiability,variab,variable,1631,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1741,Modifiability,variab,variable,1741,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BDTEventWrapper.html:1795,Modifiability,variab,variable,1795,". Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BDTEventWrapper. class TMVA::BDTEventWrapper. Function Members (Methods); public:. ~BDTEventWrapper(); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::Event*); TMVA::BDTEventWrapperBDTEventWrapper(const TMVA::BDTEventWrapper&); Double_tGetCumulativeWeight(Bool_t type) const; Double_tGetVal() const; const TMVA::Event*operator*() const; Bool_toperator<(const TMVA::BDTEventWrapper& other) const; voidSetCumulativeWeight(Bool_t type, Double_t weight); static voidSetVarIndex(Int_t iVar). Data Members; private:. Double_tfBkgWeightcumulative background weight for splitting; const TMVA::Event*fEventpointer to the event; Double_tfSigWeightsame for the signal weights; static Int_tfVarIndexindex of the variable to sort on. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BDTEventWrapper(const Event* e); constuctor. ~BDTEventWrapper(); destructor. void SetCumulativeWeight(Bool_t type, Double_t weight); Set the accumulated weight, for sorted signal/background events. * @param fType - true for signal, false for background; * @param weight - the total weight. Double_t GetCumulativeWeight(Bool_t type) const; Get the accumulated weight. Bool_t operator<(const TMVA::BDTEventWrapper& other) const. BDTEventWrapper( const Event* ). void SetVarIndex(Int_t iVar); Set the index of the variable to compare on. * @param iVar - index of the variable in fEvent to use. { if (iVar >= 0) fVarIndex = iVar; }. Double_t GetVal() const; Return the value of variable fVarIndex for this event. * @return value of variable fVarIndex for this event. { return fEvent->GetValue(fVarIndex); }. const Event* operator*() const; { return fEvent; }. » Last changed: Thu Nov 3 20:19:22 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BDTEventWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BDTEventWrapper.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:3882,Modifiability,variab,variable,3882,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4003,Modifiability,variab,variable,4003,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4077,Modifiability,variab,variable,4077,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4148,Modifiability,variab,variable,4148,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4347,Modifiability,variab,variables,4347,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4420,Modifiability,variab,variable,4420,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4598,Modifiability,variab,variable,4598,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4759,Modifiability,variab,variable,4759,"terator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Eve",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4783,Modifiability,Inherit,Inheritance,4783,"ool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theTy",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:4796,Modifiability,Inherit,Inherited,4796,"ool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events (weigthed) counted during filling; vector<Double_t>fSumSq[2]Squared Sum for signal and background for each variable. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTree(const TMVA::BinarySearchTree& b); default constructor. BinarySearchTree(const TMVA::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theTy",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6026,Modifiability,variab,variables,6026,"::BinarySearchTree& b); copy constructor that creates a true copy, i.e. a completely independent tree. ~BinarySearchTree( void ); destructor. TMVA::BinarySearchTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6196,Modifiability,variab,variables,6196,"e, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. void Insert(const TMVA::Event* ); insert a new ""event"" in the binary tree. void Insert(const TMVA::Event* , TMVA::Node* ); private internal function to insert a event (node) at the proper position. TMVA::BinarySearchTreeNode* Search(TMVA::Event* event) const; search the tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basi",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7182,Modifiability,variab,variable,7182,"create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSig",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7718,Modifiability,variab,variables,7718,"nts that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Ste",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7801,Modifiability,variab,variables,7801,"lume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7935,Modifiability,variab,variable,7935,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8093,Modifiability,variab,variable,8093," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8253,Modifiability,variab,variable,8253," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8413,Modifiability,variab,variable,8413," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8518,Modifiability,variab,variable,8518," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7885,Security,access,access,7885,"es and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has bee",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8044,Security,access,access,8044," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8200,Security,access,access,8200," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8360,Security,access,access,8360," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:8495,Security,access,access,8495," if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Types::ESBType sb, UInt_t var); access to RMS for signal and background for each variable. { return fRMS[sb==Types::kSignal?0:1][var]; }. Float_t Min(TMVA::Types::ESBType sb, UInt_t var); access to Minimum for signal and background for each variable. { return fMin[sb==Types::kSignal?0:1][var]; }. Float_t Max(TMVA::Types::ESBType sb, UInt_t var); access to Maximum for signal and background for each variable. { return fMax[sb==Types::kSignal?0:1][var]; }. Float_t RMS(UInt_t var); access to RMS for each variable. { return fRMS[0][var]; }. void SetNormalize(Bool_t norm); { fCanNormalize = norm; }. void DestroyNode(TMVA::BinarySearchTreeNode* ). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:2911,Testability,Log,Log,2911,"arySearchTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; virtual voidTMVA::BinaryTree::Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidTMVA::BinaryTree::ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Float_tRMS(UInt_t var); Float_tRMS(TMVA::Types::ESBType sb, UInt_t var); TMVA::BinarySearchTreeNode*Search(TMVA::Event* event) const; Double_tSearchVolume(TMVA::Volume*, vector<const TMVA::BinarySearchTreeNode*>* events = 0); Int_tSearchVolumeWithMaxLimit(TMVA::Volume*, vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); voidSetNormalize(Bool_t norm); voidSetPeriode(Int_t p); voidTMVA::BinaryTree::SetRoot(TMVA::Node* r); voidTMVA::BinaryTree::SetTotalTreeDepth(Int_t depth); voidTMVA::BinaryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. voidDestroyNode(TMVA::BinarySearchTreeNode*); voidInsert(const TMVA::Event*, TMVA::Node*); Bool_tInVolume(const vector<Float_t>&, TMVA::Volume*) const; voidNormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthint",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:3762,Testability,log,logger,3762,"aryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. voidDestroyNode(TMVA::BinarySearchTreeNode*); voidInsert(const TMVA::Event*, TMVA::Node*); Bool_tInVolume(const vector<Float_t>&, TMVA::Volume*) const; voidNormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator, UInt_t); TMVA::BinarySearchTreeNode*Search(TMVA::Event*, TMVA::Node*) const; Double_tSearchVolume(TMVA::Node*, TMVA::Volume*, Int_t, vector<const TMVA::BinarySearchTreeNode*>* events). Data Members; protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. Bool_tfCanNormalizethe tree can be normalised; UInt_tfCurrentDepthinternal variable, counting the depth of the tree during insertion ; vector<Float_t>fMax[2]RMS for signal and background for each variable; vector<Float_t>fMeans[2]mean for signal and background for each variable; vector<Float_t>fMin[2]RMS for signal and background for each variable; Double_tfNEventsW[2]Number of events per class, taking into account event weights; vector<std::pair<Double_t,const TMVA::Event*> >fNormalizeTreeTable; UInt_tfPeriodperiode (number of event variables); vector<Float_t>fRMS[2]RMS for signal and background for each variable; Bool_tfStatisticsIsValidflag if last stat calculation is still valid, set to false if new node is insert; vector<Double_t>fSum[2]Sum for signal and background for each variable; Double_tfSumOfWeightsTotal number of events",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:7023,Testability,test,test,7023,"ng ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(); }. BinaryTree* CreateTree() const; { return new BinarySearchTree(); }. const char* ClassName() const; { return ""BinarySearchTree""; }. void SetPeriode(Int_t p); set the periode (number of variables). { fPeriod = p; }. UInt_t GetPeriode( void ); return periode (number of variables). { return fPeriod; }. Float_t Mean(TMVA::Types::ESBType sb, UInt_t var); access to mean for signal and background for each variable. { return fMeans[sb==Types::kSignal?0:1][var]; }. Float_t RMS(TMVA::Typ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:348,Usability,simpl,simple,348,". TMVA::BinarySearchTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTree. class TMVA::BinarySearchTree: public TMVA::BinaryTree. BinarySearchTree. A simple Binary search tree including a volume search method. Function Members (Methods); public:. virtual~BinarySearchTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeBinarySearchTree(); TMVA::BinarySearchTreeBinarySearchTree(const TMVA::BinarySearchTree& b); voidCalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); static TClass*Class(); virtual const char*ClassName() const; voidClear(TMVA::Node* n = 0); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::BinarySearchTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::Node*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; Double_tFill(const vector<TMVA::Event*>& events, Int_t theType = -1); Double_tFill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; UInt_tGetPeriode() const; TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*TMVA::BinaryTree::GetRoot() const; Double_tGetSumOfWeights() const; Double_tGetSumOfWeights(Int_t theType) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; voidInsert(const TMVA::Event*); virtual TClass*IsA() const; Float_tMax(TMVA::Types::ESBType sb, UInt_t var); Float_tMean(TMVA::Types::ESBType sb, UInt_t var); Float_tMin(TMVA::Types::ESBType sb, UInt_t var); voidNormalizeTree(); TMVA::BinarySearchTree&operator=(const TMVA::BinarySearchTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; virtual voidTMVA::BinaryTree::Read(istream& istr, UI",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6512,Usability,Clear,Clear,6512,"he tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTree.html:6538,Usability,clear,clear,6538,"he tree to find the node matching ""event"". TMVA::BinarySearchTreeNode* Search(TMVA::Event* , TMVA::Node* ) const; Private, recursive, function for searching. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t GetSumOfWeights(Int_t theType) const; return the sum of event (node) weights. Double_t Fill(const vector<TMVA::Event*>& events, const vector<Int_t>& theVars, Int_t theType = -1); create the search tree from the event collection; using ONLY the variables specified in ""theVars"". Double_t Fill(const vector<TMVA::Event*>& events, Int_t theType = -1); create the search tree from the events in a TTree; using ALL the variables specified included in the Event. void NormalizeTree(vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , vector<pair<double,const TMVA::Event*>,allocator<pair<double,const TMVA::Event*> > >::iterator , UInt_t ). void NormalizeTree(); Normalisation of tree. void Clear(TMVA::Node* n = 0); clear nodes. Double_t SearchVolume(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0); search the whole tree and add up all weigths of events that; lie within the given voluem. Double_t SearchVolume(TMVA::Node* , TMVA::Volume* , Int_t , vector<const TMVA::BinarySearchTreeNode*>* events); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume. Bool_t InVolume(const vector<Float_t>& , TMVA::Volume* ) const; test if the data points are in the given volume. void CalcStatistics(TMVA::Node* n = 0, Int_t signalClass = 0); calculate basic statistics (mean, rms for each variable). Int_t SearchVolumeWithMaxLimit(TMVA::Volume* , vector<const TMVA::BinarySearchTreeNode*>* events = 0, Int_t = -1); recursively walk through the daughter nodes and add up all weigths of events that; lie within the given volume a maximum number of events can be given. Node * CreateNode(UInt_t ) const; { return new BinarySearchTreeNode(",MatchSource.WIKI,root/html532/TMVA__BinarySearchTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTree.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:570,Modifiability,variab,variable,570,". TMVA::BinarySearchTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinarySearchTreeNode. class TMVA::BinarySearchTreeNode: public TMVA::Node. Node for the BinarySearch or Decision Trees. for the binary search tree, it basically consists of the EVENT, and; pointers to the parent and daughters. in case of the Decision Tree, it specifies parent and daughters, as; well as ""which variable is used"" in the selection of this node, including; the respective cut value. Function Members (Methods); public:. virtual~BinarySearchTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; void*TMVA::Node::AddXMLTo(void* parent) const; TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); TMVA::BinarySearchTreeNodeBinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); static TClass*Class(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; virtual Bool_tEqualsMe(const TMVA::Event&) const; UInt_tGetClass() const; intTMVA::Node::GetCount(); UInt_tTMVA::Node::GetDepth() const; const vector<Float_t>&GetEventV() const; virtual TMVA::Node*TMVA::Node::GetLeft() const; virtual TMVA::Node*TMVA::Node::GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Node::GetPos() const; virtual TMVA::Node*TMVA::Node::GetRight() const; Short_tGetSelector() const; const vector<Float_t>&GetTargets() const; Float_tGetWeight() const; virtual Bool_tGoesLeft(const TMVA::Event&) const; virtual Bool_tGoesRight(const TMVA::Event&) const; virtual TClass*IsA() const; TMVA::BinarySearchTreeNode&operator=(const TMVA::",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:3376,Modifiability,variab,variable,3376,"::Node::SetPos(char s); virtual voidTMVA::Node::SetRight(TMVA::Node* r); voidSetSelector(Short_t i); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; protected:. UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes. private:. UInt_tfClass; vector<Float_t>fEventV; Short_tfSelectorindex of variable used in node selection (decision tree) ; vector<Float_t>fTargets; Float_tfWeight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); constructor of a node for the search tree. BinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); constructor of a daughter node as a daughter of 'p'. BinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the e",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:3481,Modifiability,Inherit,Inheritance,3481,"Members(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; protected:. UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes. private:. UInt_tfClass; vector<Float_t>fEventV; Short_tfSelectorindex of variable used in node selection (decision tree) ; vector<Float_t>fTargets; Float_tfWeight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); constructor of a node for the search tree. BinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); constructor of a daughter node as a daughter of 'p'. BinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ost",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:3494,Modifiability,Inherit,Inherited,3494,"Members(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; protected:. UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes. private:. UInt_tfClass; vector<Float_t>fEventV; Short_tfSelectorindex of variable used in node selection (decision tree) ; vector<Float_t>fTargets; Float_tfWeight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; BinarySearchTreeNode(const TMVA::Event* e = NULL, UInt_t signalClass = 0); constructor of a node for the search tree. BinarySearchTreeNode(TMVA::BinarySearchTreeNode* parent, char pos); constructor of a daughter node as a daughter of 'p'. BinarySearchTreeNode(const TMVA::BinarySearchTreeNode& n, TMVA::BinarySearchTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ost",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:5121,Modifiability,variab,variable,5121,"e node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html:5233,Modifiability,variab,variable,5233,"e node and recursively all it's daughters. ~BinarySearchTreeNode(); node destructor. Bool_t GoesRight(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the right daughter. Bool_t GoesLeft(const TMVA::Event& ) const; check if the event fed into the node goes/decends to the left daughter. Bool_t EqualsMe(const TMVA::Event& ) const; check if the event fed into the node actually equals the event; that forms the node (in case of a search tree). void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void AddAttributesToNode(void* node) const; adding attributes to tree node. void AddContentToNode(stringstream& s) const; adding attributes to tree node. void ReadContent(stringstream& s); read events from node. Node* CreateNode() const; { return new BinarySearchTreeNode(); }. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. const std::vector<Float_t> & GetEventV() const; { return fEventV; }. Float_t GetWeight() const; { return fWeight; }. UInt_t GetClass() const; Bool_t IsSignal() const { return (fClass == fSignalClass); }. { return fClass; }. const std::vector<Float_t> & GetTargets() const; { return fTargets; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: BinarySearchTreeNode.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__BinarySearchTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinarySearchTreeNode.html
https://root.cern/root/html532/TMVA__BinaryTree.html:479,Availability,avail,available,479,". TMVA::BinaryTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::BinaryTree. class TMVA::BinaryTree. BinaryTree. Base class for BinarySearch and Decision Trees. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~BinaryTree(); virtual void*AddXMLTo(void* parent) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCountNodes(TMVA::Node* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recurs",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:2706,Integrability,depend,depends,2706,"fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an input stream.; The input stream format depends on the tree type,; it is defined be the node of the tree. void SetTotalTreeDepth( Node *n); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. Node* CreateNode(UInt_t size = 0) const. BinaryTree* CreateTree() const; virtual BinaryTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE) = 0;. const char* ClassName() const. void SetRoot(TMVA::Node* r); set the root node of the tree. { fRoot = r; }. Node* GetRoot() const; Retrieves the address of the root node. { return fRoot; }. UInt_t GetNNodes() const; get number of Nodes in the Tree as counted while booking the nodes;. { return fNNodes; }. UInt_t GetTotalTreeDepth() const; { return fDepth; }. void SetTotalTreeDepth(Int_t depth); { fDepth = depth; }. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: BinaryTree.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This ",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:1790,Modifiability,Inherit,Inheritance,1790,"* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an input stream.; The input stream format depends on the tree type,; it is defined be the node of the tree. void SetTotalTreeDepth( Node *n); descend a ",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:1803,Modifiability,Inherit,Inherited,1803,"* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an input stream.; The input stream format depends on the tree type,; it is defined be the node of the tree. void SetTotalTreeDepth( Node *n); descend a ",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:1519,Testability,Log,Log,1519,"; public:. virtual~BinaryTree(); virtual void*AddXMLTo(void* parent) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCountNodes(TMVA::Node* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tm",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__BinaryTree.html:1741,Testability,log,logger,1741,"* n = NULL); virtual TMVA::Node*CreateNode(UInt_t size = 0) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::Node*GetLeftDaughter(TMVA::Node* n); UInt_tGetNNodes() const; TMVA::Node*GetRightDaughter(TMVA::Node* n); virtual TMVA::Node*GetRoot() const; UInt_tGetTotalTreeDepth() const; virtual TClass*IsA() const; TMVA::BinaryTree&operator=(const TMVA::BinaryTree&); virtual voidPrint(ostream& os) const; virtual voidRead(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetRoot(TMVA::Node* r); voidSetTotalTreeDepth(Int_t depth); voidSetTotalTreeDepth(TMVA::Node* n = NULL); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. voidDeleteNode(TMVA::Node*); TMVA::MsgLogger&Log() const. Data Members; protected:. UInt_tfDepthmaximal depth in tree reached; UInt_tfNNodestotal number of nodes in the tree (counted); TMVA::Node*fRootthe root node of the tree; static TMVA::MsgLogger*fgLoggermessage logger, static to save resources . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~BinaryTree( void ); destructor (deletes the nodes and ""events"" if owned by the tree. void DeleteNode(TMVA::Node* ); protected, recursive, function used by the class destructor and when Pruning. TMVA::Node* GetLeftDaughter(TMVA::Node* n); get left daughter node current node ""n"". TMVA::Node* GetRightDaughter(TMVA::Node* n); get right daughter node current node ""n"". UInt_t CountNodes(TMVA::Node* n = NULL); return the number of nodes in the tree. (make a new count --> takes time). void Print(ostream& os) const; recursively print the tree. void* AddXMLTo(void* parent) const; add attributes to XML. void ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); read attributes from XML. void Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the binary tree from an",MatchSource.WIKI,root/html532/TMVA__BinaryTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__BinaryTree.html
https://root.cern/root/html532/TMVA__CCPruner.html:1713,Modifiability,Inherit,Inheritance,1713,"neStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:1726,Modifiability,Inherit,Inherited,1726,"neStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:2028,Performance,Optimiz,Optimize,2028,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:459,Security,validat,validationSample,459,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:592,Security,validat,validationSample,592,". TMVA::CCPruner. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCPruner. class TMVA::CCPruner. Function Members (Methods); public:. ~CCPruner(); TMVA::CCPrunerCCPruner(const TMVA::CCPruner&); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::CCPruner::EventList* validationSample, TMVA::SeparationBase* qualityIndex = NULL); TMVA::CCPrunerCCPruner(TMVA::DecisionTree* t_max, const TMVA::DataSet* validationSample, TMVA::SeparationBase* qualityIndex = NULL); vector<TMVA::DecisionTreeNode*>GetOptimalPruneSequence() const; Float_tGetOptimalPruneStrength() const; Float_tGetOptimalQualityIndex() const; voidOptimize(); voidSetPruneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); cons",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:1838,Security,validat,validationSample,1838,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:1947,Security,validat,validationSample,1947,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:2301,Security,validat,validationSample,2301,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCPruner.html:2432,Security,validat,validation,2432,"uneStrength(Float_t alpha = -1.0). Data Members; private:. Float_tfAlpha! regularization parameter in CC pruning; Bool_tfDebug! debug flag; Int_tfOptimalK! index of the optimal tree in the pruned tree sequence; Bool_tfOwnQIndex! flag indicates if fQualityIndex is owned by this; vector<TMVA::DecisionTreeNode*>fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Float_t>fPruneStrengthList! map of alpha -> pruning index; TMVA::SeparationBase*fQualityIndex! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }; vector<Float_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::DecisionTree*fTree! (pruned) decision tree; const TMVA::DataSet*fValidationDataSet! the event sample to select the optimally-pruned tree; const TMVA::CCPruner::EventList*fValidationSample! the event sample to select the optimally-pruned tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex ); constructor. CCPruner( DecisionTree* t_max, const DataSet* validationSample, SeparationBase* qualityIndex ); constructor. ~CCPruner(). void Optimize(); determine the pruning sequence. std::vector<DecisionTreeNode*> GetOptimalPruneSequence() const; return the prune strength (=alpha) corresponding to the prune sequence. void SetPruneStrength(Float_t alpha = -1.0). CCPruner( DecisionTree* t_max, const EventList* validationSample, SeparationBase* qualityIndex = NULL ). Float_t GetOptimalQualityIndex() const; return the quality index from the validation sample for the optimal subtree T'. Float_t GetOptimalPruneStrength() const; return the prune strength (=alpha) corresponding to the prune sequence. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCPruner.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCPruner.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1156,Integrability,wrap,wrapped,1156,"x; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::S",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1194,Modifiability,Inherit,Inheritance,1194,"ss charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last ge",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1207,Modifiability,Inherit,Inherited,1207,"ss charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last ge",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:840,Security,validat,validationSample,840,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:904,Security,validat,validationSample,904,". TMVA::CCTreeWrapper. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CCTreeWrapper. class TMVA::CCTreeWrapper. Function Members (Methods); public:. ~CCTreeWrapper(); TMVA::CCTreeWrapperCCTreeWrapper(const TMVA::CCTreeWrapper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree out",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1617,Security,validat,validationSample,1617,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1694,Security,validat,validation,1694,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1780,Security,validat,validationSample,1780,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1857,Security,validat,validation,1857,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1583,Testability,Test,TestTreeQuality,1583,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__CCTreeWrapper.html:1748,Testability,Test,TestTreeQuality,1748,"apper&); TMVA::CCTreeWrapperCCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); Double_tCheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); TMVA::CCTreeWrapper::CCTreeNode*GetRoot(); voidInitTree(TMVA::CCTreeWrapper::CCTreeNode* t); TMVA::CCTreeWrapper&operator=(const TMVA::CCTreeWrapper&); voidPruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); Double_tTestTreeQuality(const TMVA::CCTreeWrapper::EventList* validationSample); Double_tTestTreeQuality(const TMVA::DataSet* validationSample). Data Members; private:. TMVA::DecisionTree*fDTParent! pointer to underlying DecisionTree; TMVA::SeparationBase*fQualityIndex! pointer to the used quality index calculator; TMVA::CCTreeWrapper::CCTreeNode*fRoot! the root node of the (wrapped) decision Tree. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex); constructor. ~CCTreeWrapper(); destructor. void InitTree(TMVA::CCTreeWrapper::CCTreeNode* t); initialize the node t and all its descendants. void PruneNode(TMVA::CCTreeWrapper::CCTreeNode* t); remove the branch rooted at node t. Double_t TestTreeQuality( const EventList* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using an EventList. Double_t TestTreeQuality( const DataSet* validationSample ); return the misclassification rate of a pruned tree for a validation event sample; using the DataSet. Double_t CheckEvent(const TMVA::Event& e, Bool_t useYesNoLeaf = false); return the decision tree output for an event. CCTreeWrapper(TMVA::DecisionTree* T, TMVA::SeparationBase* qualityIndex). CCTreeNode* GetRoot(); return the root node for this tree. { return fRoot; }. » Last changed: Thu Nov 3 20:19:24 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CCTreeWrapper.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CCTreeWrapper.html
https://root.cern/root/html532/TMVA__Config.html:8,Modifiability,Config,Config,8,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:245,Modifiability,Config,Config,245,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:265,Modifiability,Config,Config,265,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:339,Modifiability,Config,ConfigConfig,339,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:364,Modifiability,Config,Config,364,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:441,Modifiability,Config,Config,441,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:477,Modifiability,Config,Config,477,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:485,Modifiability,Variab,VariablePlotting,485,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:538,Modifiability,Config,Config,538,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:615,Modifiability,Config,Config,615,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:644,Modifiability,Config,Config,644,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bo,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:988,Modifiability,Config,ConfigConfig,988,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. B,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1062,Modifiability,Config,Config,1062,der viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptions,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1128,Modifiability,Config,Config,1128,der viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptions,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1136,Modifiability,Variab,VariablePlottingfVariablePlottingCustomisable,1136,der viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptions,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1446,Modifiability,Config,Configurable,1446,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1514,Modifiability,Config,Config,1514,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1548,Modifiability,Inherit,Inheritance,1548,"sA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 ",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1561,Modifiability,Inherit,Inherited,1561,"sA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 ",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1625,Modifiability,Config,Config,1625,"(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; T",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1733,Modifiability,Config,Config,1733,"sReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please sen",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:2271,Modifiability,Variab,VariablePlotting,2271,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:2388,Modifiability,Config,Config,2388,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:2548,Modifiability,Config,Config,2548,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { return fIONames; }. Config(); private constructor. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1020,Testability,Log,Log,1020,. TMVA::Config. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config. class TMVA::Config. Function Members (Methods); public:. static TClass*Class(); TMVA::ConfigConfig(const TMVA::Config&); static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. B,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1316,Testability,log,logger,1316,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Config.html:1240,Usability,progress bar,progress bar,1240,; static voidDestroyInstance(); Bool_tDrawProgressBar() const; TMVA::Config::IONames&GetIONames(); TMVA::Config::VariablePlotting&GetVariablePlotting(); static TMVA::Config&Instance(); virtual TClass*IsA() const; Bool_tIsSilent() const; TMVA::Config&operator=(const TMVA::Config&); voidSetDrawProgressBar(Bool_t d); voidSetSilent(Bool_t s); voidSetUseColor(Bool_t uc); voidSetWriteOptionsReference(Bool_t w); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Bool_tUseColor() const; Bool_tWriteOptionsReference() const. private:. (unknown)(); TMVA::ConfigConfig(); TMVA::MsgLogger&Log() const. Data Members; public:. TMVA::Config::IONamesfIONamesCustomisable weight file properties; TMVA::Config::VariablePlottingfVariablePlottingCustomisable plotting properties. private:. Bool_tfDrawProgressBardraw progress bar to indicate training evolution; TMVA::MsgLogger*fLoggermessage logger; Bool_tfSilentno output at all; Bool_tfUseColoredConsolecoloured standard output; Bool_tfWriteOptionsReferenceif set true: Configurable objects write file with option reference; static TMVA::Config*fgConfigPtr. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Config(); constructor - set defaults. void DestroyInstance(); static function: destroy TMVA instance. TMVA::Config& Instance(); static function: returns TMVA instance. Bool_t UseColor() const; { return fUseColoredConsole; }. void SetUseColor(Bool_t uc); { fUseColoredConsole = uc; }. Bool_t IsSilent() const; { return fSilent; }. void SetSilent(Bool_t s); { fSilent = s; }. Bool_t WriteOptionsReference() const; { return fWriteOptionsReference; }. void SetWriteOptionsReference(Bool_t w); { fWriteOptionsReference = w; }. Bool_t DrawProgressBar() const; { return fDrawProgressBar; }. void SetDrawProgressBar(Bool_t d); { fDrawProgressBar = d; }. VariablePlotting& GetVariablePlotting(); { return fVariablePlotting; }. IONames& GetIONames(); { retur,MatchSource.WIKI,root/html532/TMVA__Config.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config.html
https://root.cern/root/html532/TMVA__Configurable.html:1345,Availability,Error,Error,1345," virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:1474,Availability,error,error,1474," voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const cha",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:1558,Availability,error,error,1558,"ption = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6183,Integrability,message,message,6183,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:8136,Integrability,message,message,8136,"oid SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fConfigName; }. const char* GetConfigDescription() const; { return fConfigDescription; }. void SetConfigName(const char* n); { fConfigName = TString(n); }. void SetConfigDescription(const char* d); { fConfigDescription = TString(d); }. const TString& GetOptions() const; { return fOptions; }. void SetOptions(const TString& s); { fOptions = s; }. Bool_t LooseOptionCheckingEnabled() const; { return fLooseOptionCheckingEnabled; }. void EnableLooseOptions(Bool_t b = kTRUE); { fLooseOptionCheckingEnabled = b; }. const TString& GetReferenceFile() const; { return fReferenceFile; }. void SetMsgType(TMVA::EMsgType t); set message type. { fLogger->SetMinType(t); }. Log(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Configurable.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:8,Modifiability,Config,Configurable,8,". TMVA::Configurable. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Configurable. class TMVA::Configurable: public TObject. Base Class for all classes that need option parsing; . Function Members (Methods); public:. virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:251,Modifiability,Config,Configurable,251,". TMVA::Configurable. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Configurable. class TMVA::Configurable: public TObject. Base Class for all classes that need option parsing; . Function Members (Methods); public:. virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:277,Modifiability,Config,Configurable,277,". TMVA::Configurable. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Configurable. class TMVA::Configurable: public TObject. Base Class for all classes that need option parsing; . Function Members (Methods); public:. virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:407,Modifiability,Config,Configurable,407," virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:892,Modifiability,Config,ConfigurableConfigurable,892," virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:2538,Modifiability,Inherit,InheritsFrom,2538,"arams, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TOb",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:2604,Modifiability,Inherit,InheritsFrom,2604,"event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operat",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6001,Modifiability,config,configurable,6001,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6050,Modifiability,config,configurable,6050,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6365,Modifiability,Inherit,Inheritance,6365,"ool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6378,Modifiability,Inherit,Inherited,6378,"ool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6442,Modifiability,Config,Configurable,6442,"ogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetCon",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6501,Modifiability,Config,Configurable,6501,"; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fC",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:8295,Modifiability,Config,Configurable,8295,"oid SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fConfigName; }. const char* GetConfigDescription() const; { return fConfigDescription; }. void SetConfigName(const char* n); { fConfigName = TString(n); }. void SetConfigDescription(const char* d); { fConfigDescription = TString(d); }. const TString& GetOptions() const; { return fOptions; }. void SetOptions(const TString& s); { fOptions = s; }. Bool_t LooseOptionCheckingEnabled() const; { return fLooseOptionCheckingEnabled; }. void EnableLooseOptions(Bool_t b = kTRUE); { fLooseOptionCheckingEnabled = b; }. const TString& GetReferenceFile() const; { return fReferenceFile; }. void SetMsgType(TMVA::EMsgType t); set message type. { fLogger->SetMinType(t); }. Log(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Configurable.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:2428,Security,Hash,Hash,2428,"st char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator ",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:4826,Testability,Test,TestBit,4826,"ject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidPrintOptions() const; virtual Int_tTObject::Read(const char* name); voidReadOptionsFromStream(istream& istr); voidReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetConfigDescription(const char* d); voidSetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidSetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:4865,Testability,Test,TestBits,4865,"ject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidPrintOptions() const; virtual Int_tTObject::Read(const char* name); voidReadOptionsFromStream(istream& istr); voidReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidSetConfigDescription(const char* d); voidSetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidSetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:5464,Testability,Log,Log,5464,"tDtorOnly(void* obj); voidSetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidSetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documen",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:6191,Testability,log,logger,6191,"ption = 0, Int_t bufsize = 0) const; voidWriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidEnableLooseOptions(Bool_t b = kTRUE); const TString&GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tLooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidResetSetFlag(); voidWriteOptionsReferenceToFile(). private:. voidSplitOptions(const TString& theOpt, TList& loo) const. Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. TStringfConfigDescriptiondescription of this configurable; TStringfConfigNamethe name of this configurable; TMVA::OptionBase*fLastDeclaredOption! last declared option; TListfListOfOptions! option list; TMVA::MsgLogger*fLogger! message logger; Bool_tfLooseOptionCheckingEnabled! checker for option string; TStringfOptions! options string; TStringfReferenceFilereference file for options writing. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Configurable(const TString& theOption = """"); constructor. ~Configurable(); default destructur. void SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:8179,Testability,Log,Log,8179,"oid SplitOptions(const TString& theOpt, TList& loo) const; splits the option string at ':' and fills the list 'loo' with the primitive strings. void ResetSetFlag(); resets the IsSet falg for all declare options; to be called before options are read from stream. void ParseOptions(); options parser. void CheckForUnusedOptions() const; checks for unused options in option string. void PrintOptions() const; prints out the options set in the options string and the defaults. void WriteOptionsToStream(ostream& o, const TString& prefix) const; write options to output stream (e.g. in writing the MVA weight files. void AddOptionsXMLTo(void* parent) const; write options to XML file. void ReadOptionsFromXML(void* node). void WriteOptionsReferenceToFile(); write complete options to output stream. void ReadOptionsFromStream(istream& istr); read option back from the weight file. const char* GetName() const; { return GetConfigName(); }. const char* GetConfigName() const; { return fConfigName; }. const char* GetConfigDescription() const; { return fConfigDescription; }. void SetConfigName(const char* n); { fConfigName = TString(n); }. void SetConfigDescription(const char* d); { fConfigDescription = TString(d); }. const TString& GetOptions() const; { return fOptions; }. void SetOptions(const TString& s); { fOptions = s; }. Bool_t LooseOptionCheckingEnabled() const; { return fLooseOptionCheckingEnabled; }. void EnableLooseOptions(Bool_t b = kTRUE); { fLooseOptionCheckingEnabled = b; }. const TString& GetReferenceFile() const; { return fReferenceFile; }. void SetMsgType(TMVA::EMsgType t); set message type. { fLogger->SetMinType(t); }. Log(). » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Configurable.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Configurable.html:742,Usability,Clear,Clear,742," virtual~Configurable(); voidTObject::AbstractMethod(const char* method) const; voidAddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidCheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableConfigurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*GetConfigDescription() const; const char*GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virt",MatchSource.WIKI,root/html532/TMVA__Configurable.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Configurable.html
https://root.cern/root/html532/TMVA__Config__IONames.html:311,Deployability,configurat,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:8,Modifiability,Config,Config,8,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:230,Modifiability,Config,Config,230,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:259,Modifiability,Config,Config,259,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:276,Modifiability,Config,Config,276,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:311,Modifiability,config,configuration,311,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:403,Modifiability,Config,Config,403,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:435,Modifiability,Config,Config,435,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:470,Modifiability,Config,Config,470,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:495,Modifiability,Config,Config,495,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:533,Modifiability,Config,Config,533,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:674,Modifiability,Inherit,Inheritance,674,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:687,Modifiability,Inherit,Inherited,687,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__IONames.html:880,Modifiability,Config,Config,880,". TMVA::Config::IONames. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::IONames. class TMVA::Config::IONames. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~IONames(); TMVA::Config::IONamesIONames(); TMVA::Config::IONamesIONames(const TMVA::Config::IONames&); TMVA::Config::IONames&operator=(const TMVA::Config::IONames&). Data Members; public:. TStringfOptionsReferenceFileDir; TStringfWeightFileDir; TStringfWeightFileExtension. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__IONames.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__IONames.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:338,Deployability,configurat,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:8,Modifiability,Config,Config,8,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:16,Modifiability,Variab,VariablePlotting,16,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:239,Modifiability,Config,Config,239,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:247,Modifiability,Variab,VariablePlotting,247,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:277,Modifiability,Config,Config,277,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:285,Modifiability,Variab,VariablePlotting,285,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:303,Modifiability,Config,Config,303,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:338,Modifiability,config,configuration,338,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:413,Modifiability,Variab,VariablePlotting,413,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:439,Modifiability,Config,Config,439,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:447,Modifiability,Variab,VariablePlotting,447,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:486,Modifiability,Config,Config,486,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:494,Modifiability,Variab,VariablePlotting,494,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:520,Modifiability,Config,Config,520,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:528,Modifiability,Variab,VariablePlottingVariablePlotting,528,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:570,Modifiability,Config,Config,570,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:578,Modifiability,Variab,VariablePlottingVariablePlotting,578,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:623,Modifiability,Config,Config,623,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:631,Modifiability,Variab,VariablePlotting,631,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:829,Modifiability,Inherit,Inheritance,829,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:842,Modifiability,Inherit,Inherited,842,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__Config__VariablePlotting.html:1035,Modifiability,Config,Config,1035,". TMVA::Config::VariablePlotting. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; ; viewVC header . Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Config::VariablePlotting. class TMVA::Config::VariablePlotting. Config. Singleton class for global configuration settings used by TMVA. Function Members (Methods); public:. ~VariablePlotting(); TMVA::Config::VariablePlotting&operator=(const TMVA::Config::VariablePlotting&); TMVA::Config::VariablePlottingVariablePlotting(); TMVA::Config::VariablePlottingVariablePlotting(const TMVA::Config::VariablePlotting&). Data Members; public:. Int_tfMaxNumOfAllowedVariablesForScatterPlots; Int_tfNbins1D; Int_tfNbins2D; Int_tfNbinsMVAoutput; Int_tfNbinsXOfROCCurve; Float_tfTimesRMS. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation. » Author: Andreas Hoecker, Joerg Stelzer, Fredrik Tegenfeldt, Helge Voss » Copyright (c) 2006: *; » Last changed: root/tmva $Id: Config.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Config__VariablePlotting.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Config__VariablePlotting.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2134,Availability,down,down,2134,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2462,Availability,error,error,2462,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1567,Modifiability,Inherit,Inheritance,1567,"; TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( Sepa",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1580,Modifiability,Inherit,Inherited,1580,"; TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( Sepa",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2178,Performance,Optimiz,Optimize,2178,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:545,Testability,test,testEvents,545,". TMVA::CostComplexityPruneTool. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(T",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:944,Testability,Log,Log,944,". TMVA::CostComplexityPruneTool. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(T",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1084,Testability,log,logging,1084,"wVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CostComplexityPruneTool. class TMVA::CostComplexityPruneTool: public TMVA::IPruneTool. Function Members (Methods); public:. virtual~CostComplexityPruneTool(); virtual TMVA::PruningInfo*CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE); TMVA::CostComplexityPruneToolCostComplexityPruneTool(TMVA::SeparationBase* qualityIndex = NULL); TMVA::CostComplexityPruneToolCostComplexityPruneTool(const TMVA::CostComplexityPruneTool&); TMVA::CostComplexityPruneTool&operator=(const TMVA::CostComplexityPruneTool&). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc.",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:1922,Testability,test,testEvents,1922,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html:2436,Testability,test,test,2436,"). private:. voidInitTreePruningMetaData(TMVA::DecisionTreeNode* n); TMVA::MsgLogger&Log() const; voidOptimize(TMVA::DecisionTree* dt, Double_t weights). Data Members; private:. TMVA::MsgLogger*fLogger! output stream to save logging information; Int_tfOptimalK! the optimal index of the prune sequence; vector<TMVA::DecisionTreeNode*,allocator<TMVA::DecisionTreeNode*> >fPruneSequence! map of weakest links (i.e., branches to prune) -> pruning index; vector<Double_t>fPruneStrengthList! map of alpha -> pruning index; vector<Double_t>fQualityIndexList! map of R(T) -> pruning index; TMVA::SeparationBase*fQualityIndexTool! the quality index used to calculate R(t), R(T) = sum[t in ~T]{ R(t) }. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; CostComplexityPruneTool( SeparationBase* qualityIndex ); the constructor for the cost complexity prunig. ~CostComplexityPruneTool(); the destructor for the cost complexity prunig. CalculatePruningInfo(TMVA::DecisionTree* dt, const vector<TMVA::Event*,allocator<TMVA::Event*> >* testEvents = NULL, Bool_t isAutomatic = kFALSE). void InitTreePruningMetaData(TMVA::DecisionTreeNode* n); initialise ""meta data"" for the pruning, like the ""costcomplexity"", the; critical alpha, the minimal alpha down the tree, etc... for each node!!. void Optimize(TMVA::DecisionTree* dt, Double_t weights); after the critical alpha values (at which the corresponding nodes would; be pruned away) had been established in the ""InitMetaData"" we need now:; automatic pruning:; find the value of ""alpha"" for which the test sample gives minimal error,; on the tree with all nodes pruned that have alpha_critital < alpha,; fixed parameter pruning. CostComplexityPruneTool( SeparationBase* qualityIndex = NULL ). » Last changed: Thu Nov 3 20:19:25 2011 » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CostComplexityPruneTool.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CostComplexityPruneTool.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1233,Modifiability,Inherit,Inheritance,1233,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1246,Modifiability,Inherit,Inherited,1246,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:383,Testability,log,log,383,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:398,Testability,log,log,398,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1406,Testability,log,log,1406,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__CrossEntropy.html:1421,Testability,log,log,1421,". TMVA::CrossEntropy. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::CrossEntropy. class TMVA::CrossEntropy: public TMVA::SeparationBase. Implementation of the CrossEntropy as separation criterion; -p log (p) - (1-p)log(1-p); p=purity. Function Members (Methods); public:. virtual~CrossEntropy(); static TClass*Class(); TMVA::CrossEntropyCrossEntropy(); TMVA::CrossEntropyCrossEntropy(const TMVA::CrossEntropy& g); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); virtual TClass*IsA() const; TMVA::CrossEntropy&operator=(const TMVA::CrossEntropy&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Cross Entropy defined as; -p log (p) - (1-p)log(1-p); p=purity = s/(s+b). CrossEntropy(); default constructor. { fName = ""CE""; }. CrossEntropy(const TMVA::CrossEntropy& g); copy constructor. {}. virtual ~CrossEntropy(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: CrossEntropy.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__CrossEntropy.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__CrossEntropy.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11858,Availability,down,down,11858,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:526,Modifiability,variab,variable,526,". TMVA::DecisionTree. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& even",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:1062,Modifiability,variab,variable,1062,"h. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTree. class TMVA::DecisionTree: public TMVA::BinaryTree. Implementation of a Decision Tree. In a decision tree successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:3745,Modifiability,variab,variableMap,3745,,MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6529,Modifiability,variab,variables,6529,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6817,Modifiability,variab,variable,6817,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6964,Modifiability,variab,variables,6964,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7334,Modifiability,variab,variables,7334,"on(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Librari",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7680,Modifiability,variab,variables,7680," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:7881,Modifiability,variab,variables,7881," cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8174,Modifiability,variab,variables,8174,"_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further splitting, the; number of bins in the grid used in applying the cut for the node; splitting. DecisionTree(const TMVA::DecisionTree& d",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8371,Modifiability,Inherit,Inheritance,8371,"ition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further splitting, the; number of bins in the grid used in applying the cut for the node; splitting. DecisionTree(const TMVA::DecisionTree& d); copy constructor that creates a true copy, i.e. a completely independent tree; the node copy will recursively copy all the nodes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); de",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8384,Modifiability,Inherit,Inherited,8384,"ition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further splitting, the; number of bins in the grid used in applying the cut for the node; splitting. DecisionTree(const TMVA::DecisionTree& d); copy constructor that creates a true copy, i.e. a completely independent tree; the node copy will recursively copy all the nodes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); de",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10978,Modifiability,variab,variable,10978,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11171,Modifiability,variab,variables,11171,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11535,Modifiability,variab,variable,11535,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12957,Modifiability,variab,variableMap,12957,"ere from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13134,Modifiability,variab,variables,13134,"ing validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFA",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13229,Modifiability,variab,variable,13229," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13393,Modifiability,variab,variables,13393,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13481,Modifiability,variab,variables,13481,"rune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the pu",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13737,Modifiability,variab,variables,13737,"Long_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The impor",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14550,Modifiability,variab,variable,14550,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14590,Modifiability,variab,variables,14590,"tFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Doub",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14702,Modifiability,variab,variable,14702,"ents for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() c",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:14854,Modifiability,variab,variable,14854,"mple, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events ends up. I.e. the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePuri",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:15352,Modifiability,variab,variable,15352,". the result of the classification if; the event for this decision tree. Double_t SamplePurity(TMVA::DecisionTree::EventList eventSample); calculates the purity S/(S+B) of a given event sample. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); returns the relative improtance of variable ivar. DecisionTreeNode* GetRoot() const; Retrieves the address of the root node. { return dynamic_cast<TMVA::DecisionTreeNode*>(fRoot); }. DecisionTreeNode * CreateNode(UInt_t ) const; { return new DecisionTreeNode(); }. BinaryTree* CreateTree() const; { return new DecisionTree(); }. const char* ClassName() const; { return ""DecisionTree""; }. Double_t TrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); determine the way how a node is split (which variable, which cut value). { return TrainNodeFast( eventSample, node ); }. void SetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); { fPruneMethod = m; }. void SetPruneStrength(Double_t p); manage the pruning strength parameter (iff < 0 -> automate the pruning process). { fPruneStrength = p; }. Double_t GetPruneStrength() const; { return fPruneStrength; }. void SetNodePurityLimit(Double_t p); { fNodePurityLimit = p; }. Double_t GetNodePurityLimit() const; { return fNodePurityLimit; }. void SetTreeID(Int_t treeID); {fTreeID = treeID;}. Int_t GetTreeID(); {return fTreeID;}. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. void SetAnalysisType(TMVA::Types::EAnalysisType t); { fAnalysisType = t;}. Types::EAnalysisType GetAnalysisType( void ); { return fAnalysisType;}. void SetUseFisherCuts(Bool_t t = kTRUE); { fUseFisherCuts = t;}. void SetMinLinCorrForFisher(Double_t min); {fM",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6647,Performance,perform,perform,6647,"ist& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables alre",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:13303,Performance,perform,performed,13303," to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; possible multivariate split. std::vector<Double_t> GetFisherCoefficients(const TMVA::DecisionTree::EventList& eventSample, UInt_t nFisherVars, UInt_t* mapVarInFisher); calculate the fisher coefficients for the event sample and the variables used. Double_t TrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). TMVA::DecisionTreeNode* GetEventNode(const TMVA::Event& e) const; get the pointer to the leaf node where a particular event ends up in...; (used in gradient boosting). Double_t CheckEvent(const TMVA::Event& , Bool_t UseYesNoLeaf = kFALSE) const; the event e is put into the decision tree (starting at the root node); and the output is NodeType (signal) or (background) of the final node (basket); in which the given events",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10888,Safety,avoid,avoid,10888,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:1919,Security,validat,validationSample,1919,"constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Function Members (Methods); public:. virtual~DecisionTree(); virtual void*TMVA::BinaryTree::AddXMLTo(void* parent) const; voidApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tBuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); Double_tCheckEvent(const TMVA::Event&, Bool_t UseYesNoLeaf = kFALSE) const; voidCheckEventWithPrunedTree(const TMVA::Event&) const; static TClass*Class(); virtual const char*ClassName() const; UInt_tCleanTree(TMVA::DecisionTreeNode* node = NULL); voidClearTree(); UInt_tCountLeafNodes(TMVA::Node* n = NULL); UInt_tTMVA::BinaryTree::CountNodes(TMVA::Node* n = NULL); static TMVA::DecisionTree*CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual TMVA::DecisionTreeNode*CreateNode(UInt_t) const; virtual TMVA::BinaryTree*CreateTree() const; TMVA::DecisionTreeDecisionTree(); TMVA::DecisionTreeDecisionTree(const TMVA::DecisionTree& d); TMVA::DecisionTreeDecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); voidDescendTree(TMVA::Node* n = NULL); Bool_tDoRegression() const; voidFillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); voidFillTree(TMVA::DecisionTree::EventList& eventSample); TMVA::Types::EAnalysisTypeGetAnalysisType(); TMVA::DecisionTreeNode*GetEventNode(const TMVA::Event& e) const; vector<Double_t>GetFisherCoefficients(const TMVA::DecisionT",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:3943,Security,validat,validationSample,3943,,MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:4409,Security,validat,validationSample,4409," UInt_t nFisherVars, UInt_t* mapVarInFisher); TMVA::Node*TMVA::BinaryTree::GetLeftDaughter(TMVA::Node* n); UInt_tTMVA::BinaryTree::GetNNodes() const; TMVA::Node*GetNode(ULong_t sequence, UInt_t depth); Double_tGetNodePurityLimit() const; Double_tGetPruneStrength() const; voidGetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars); TMVA::Node*TMVA::BinaryTree::GetRightDaughter(TMVA::Node* n); virtual TMVA::DecisionTreeNode*GetRoot() const; Double_tGetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; UInt_tTMVA::BinaryTree::GetTotalTreeDepth() const; Int_tGetTreeID(); vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); virtual TClass*IsA() const; TMVA::DecisionTree&operator=(const TMVA::DecisionTree&); virtual voidTMVA::BinaryTree::Print(ostream& os) const; voidPruneNode(TMVA::DecisionTreeNode* node); voidPruneNodeInPlace(TMVA::DecisionTreeNode* node); Double_tPruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); virtual voidTMVA::BinaryTree::Read(istream& istr, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidTMVA::BinaryTree::ReadXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); voidSetAnalysisType(TMVA::Types::EAnalysisType t); voidSetMinLinCorrForFisher(Double_t min); voidSetNodePurityLimit(Double_t p); voidSetPairNegWeightsInNode(); voidSetParentTreeInNodes(TMVA::Node* n = NULL); voidSetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); voidSetPruneStrength(Double_t p); voidTMVA::BinaryTree::SetRoot(TMVA::Node* r); voidTMVA::BinaryTree::SetTotalTreeDepth(Int_t depth); voidTMVA::BinaryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); voidSetTreeID(Int_t treeID); voidSetUseExclusiveVars(Bool_t t = kTRUE); voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10807,Security,validat,validationSample,10807,"r of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill i",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11067,Security,validat,validationSample,11067,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11100,Security,validat,validation,11100,"TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sam",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11273,Security,validat,validation,11273,"nd up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11797,Security,validat,validation,11797,"t rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patt",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12021,Security,validat,validationSample,12021,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12095,Security,validat,validation,12095,"TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::Ev",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:5836,Testability,Log,Log,5836,"tTreeInNodes(TMVA::Node* n = NULL); voidSetPruneMethod(TMVA::DecisionTree::EPruneMethod m = kCostComplexityPruning); voidSetPruneStrength(Double_t p); voidTMVA::BinaryTree::SetRoot(TMVA::Node* r); voidTMVA::BinaryTree::SetTotalTreeDepth(Int_t depth); voidTMVA::BinaryTree::SetTotalTreeDepth(TMVA::Node* n = NULL); voidSetTreeID(Int_t treeID); voidSetUseExclusiveVars(Bool_t t = kTRUE); voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; Double_tTrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber o",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:6297,Testability,log,logger,6297," voidSetUseFisherCuts(Bool_t t = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); Double_tTestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; Double_tTrainNode(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Double_tTrainNodeFull(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node). protected:. voidTMVA::BinaryTree::DeleteNode(TMVA::Node*); TMVA::MsgLogger&TMVA::BinaryTree::Log() const. private:. Double_tSamplePurity(TMVA::DecisionTree::EventList eventSample). Data Members; public:. enum EPruneMethod { kExpectedErrorPruning; kCostComplexityPruning; kNoPruning; };. protected:. UInt_tTMVA::BinaryTree::fDepthmaximal depth in tree reached; UInt_tTMVA::BinaryTree::fNNodestotal number of nodes in the tree (counted); TMVA::Node*TMVA::BinaryTree::fRootthe root node of the tree; static TMVA::MsgLogger*TMVA::BinaryTree::fgLoggermessage logger, static to save resources . private:. TMVA::Types::EAnalysisTypefAnalysisTypekClassification(=0=false) or kRegression(=1=true); UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; Double_tfMinSepGainmin number of separation gain to perform node splitting; Double_tfMinSizemin number of events in node; TRandom3*fMyTrandomrandom number generator for randomised trees; Int_tfNCutsnumber of grid point in variable cut scans; UInt_tfNNodesMaxmax # of nodes; Double_tfNodePurityLimitpurity limit to decide whether a node is signal; UInt_tfNvarsnumber of variables used to separate S and B; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_t",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11364,Testability,Test,TestPrunedTreeQuality,11364,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11610,Testability,test,testing,11610,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:11641,Testability,test,test,11641,"this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later used; when asking for the ""tree quality"" .. Double_t TestPrunedTreeQuality(const TMVA::DecisionTreeNode* dt = NULL, Int_t mode = 0) const; return the misclassification rate of a pruned tree; a ""pruned tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:12526,Testability,test,testing,12526,"runed tree"" may have set the variable ""IsTerminal"" to ""arbitrary"" at; any node, hence this tree quality testing will stop there, hence test; the pruned tree (while the full tree is still in place for normal/later use). void CheckEventWithPrunedTree(const TMVA::Event& ) const; pass a single validation event throught a pruned decision tree; on the way down the tree, fill in all the ""intermediate"" information; that would normally be there from training. Double_t GetSumWeights(const TMVA::DecisionTree::EventList* validationSample) const; calculate the normalization factor for a pruning validation sample. UInt_t CountLeafNodes(TMVA::Node* n = NULL); return the number of terminal nodes in the sub-tree below Node n. void DescendTree(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes. void PruneNode(TMVA::DecisionTreeNode* node); prune away the subtree below the node. void PruneNodeInPlace(TMVA::DecisionTreeNode* node); prune a node temporaily (without actually deleting its decendants; which allows testing the pruned tree quality for many different; pruning stages without ""touching"" the tree. TMVA::Node* GetNode(ULong_t sequence, UInt_t depth); retrieve node from the tree. Its position (up to a maximal tree depth of 64); is coded as a sequence of left-right moves starting from the root, coded as; 0-1 bit patterns stored in the ""long-integer"" (i.e. 0:left ; 1:right. void GetRandomisedVariables(Bool_t* useVariable, UInt_t* variableMap, UInt_t& nVars). Double_t TrainNodeFast(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node); Decide how to split a node using one of the variables that gives; the best separation of signal/background. In order to do this, for each; variable a scan of the different cut values in a grid (grid = fNCuts) is; performed and the resulting separation gains are compared.; in addition to the individual variables, one can also ask for a fisher; discriminant being built out of (some) of the variables and used as a; p",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:8078,Usability,simpl,simple,8078," with neg. and pos. weights in node and don't boost them; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig ; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted ; Bool_tfRandomisedTreechoose at each node splitting a random set of variables ; TMVA::RegressionVariance*fRegTypethe separation crition used in Regression; TMVA::SeparationBase*fSepTypethe separation crition; UInt_tfSigClassclass which is treated as signal when building the tree; Int_tfTreeIDjust an ID number given to the tree.. makes debugging easier as tree knows who he is.; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; Int_tfUseNvarsthe number of variables used in randomised trees;; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseSearchTreecut scan done with binary trees or simple event loop.; vector<Double_t>fVariableImportancethe relative importance of the different variables ; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc.; static const Int_tfgRandomSeedset nonzero for debugging and zero for random seeds. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTree(); default constructor using the GiniIndex as separation criterion,; no restrictions on minium number of events in a leave note or the; separation gain in the node splitting. DecisionTree(TMVA::SeparationBase* sepType, Int_t minSize, Int_t nCuts, UInt_t cls = 0, Bool_t randomisedTree = kFALSE, Int_t useNvars = 0, Bool_t usePoissonNvars = kFALSE, UInt_t nNodesMax = 999999, UInt_t nMaxDepth = 9999999, Int_t iSeed = fgRandomSeed, Float_t purityLimit = 0.5, Int_t treeID = 0); constructor specifying the separation type, the min number of; events in a no that is still subjected to further s",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10266,Usability,Clear,ClearTree,10266,"odes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. TMVA::DecisionTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. UInt_t BuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); building the decision tree by recursively calling the splitting of; one (root-) node into two daughter nodes (returns the number of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTree.html:10279,Usability,clear,clear,10279,"odes. ~DecisionTree(); destructor. void SetParentTreeInNodes(TMVA::Node* n = NULL); descend a tree to find all its leaf nodes, fill max depth reached in the; tree at the same time. TMVA::DecisionTree* CreateFromXML(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); re-create a new tree (decision tree or search tree) from XML. UInt_t BuildTree(const TMVA::DecisionTree::EventList& eventSample, TMVA::DecisionTreeNode* node = NULL); building the decision tree by recursively calling the splitting of; one (root-) node into two daughter nodes (returns the number of nodes). void FillTree(TMVA::DecisionTree::EventList& eventSample); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void FillEvent(TMVA::Event& event, TMVA::DecisionTreeNode* node); fill the existing the decision tree structure by filling event; in from the top node and see where they happen to end up. void ClearTree(); clear the tree nodes (their S/N, Nevents etc), just keep the structure of the tree. UInt_t CleanTree(TMVA::DecisionTreeNode* node = NULL); remove those last splits that result in two leaf nodes that; are both of the type (i.e. both signal or both background); this of course is only a reasonable thing to do when you use; ""YesOrNo"" leafs, while it might loose s.th. if you use the; purity information in the nodes.; --> hence I don't call it automatically in the tree building. Double_t PruneTree(TMVA::DecisionTree::EventList* validationSample = NULL); prune (get rid of internal nodes) the Decision tree to avoid overtraining; serveral different pruning methods can be applied as selected by the; variable ""fPruneMethod"". void ApplyValidationSample(const TMVA::DecisionTree::EventList* validationSample) const; run the validation sample through the (pruned) tree and fill in the nodes; the variables NSValidation and NBValidadtion (i.e. how many of the Signal; and Background events from the validation sample. This is then later ",MatchSource.WIKI,root/html532/TMVA__DecisionTree.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTree.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:373,Modifiability,variab,variable,373,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:416,Modifiability,variab,variable,416,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:513,Modifiability,enhance,enhanced,513,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:543,Modifiability,enhance,enhanced,543,". TMVA::DecisionTreeNode. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::DecisionTreeNode. class TMVA::DecisionTreeNode: public TMVA::Node. Node for the Decision Tree. The node specifies ONE variable out of the given set of selection variable; that is used to split the sample which ""arrives"" at the node, into a left; (background-enhanced) and a right (signal-enhanced) sample. Function Members (Methods); public:. virtual~DecisionTreeNode(); virtual voidAddAttributesToNode(void* node) const; virtual voidAddContentToNode(stringstream& s) const; voidAddToSumTarget(Float_t t); voidAddToSumTarget2(Float_t t2); void*TMVA::Node::AddXMLTo(void* parent) const; static TClass*Class(); voidClearNodeAndAllDaughters(); Int_tTMVA::Node::CountMeAndAllDaughters() const; virtual TMVA::Node*CreateNode() const; TMVA::DecisionTreeNodeDecisionTreeNode(); TMVA::DecisionTreeNodeDecisionTreeNode(TMVA::Node* p, char pos); TMVA::DecisionTreeNodeDecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); Double_tGetAlpha() const; Double_tGetAlphaMinSubtree() const; Double_tGetCC() const; intTMVA::Node::GetCount(); Bool_tGetCutType() const; Float_tGetCutValue() const; UInt_tTMVA::Node::GetDepth() const; Double_tGetFisherCoeff(Int_t ivar) const; virtual TMVA::DecisionTreeNode*GetLeft() const; Float_tGetNBkgEvents() const; Float_tGetNBkgEvents_unweighted() const; Double_tGetNBValidation() const; Float_tGetNEvents() const; Float_tGetNEvents_unweighted() const; UInt_tGetNFisherCoeff() const; Double_tGetNodeR() const; Int_tGetNodeType() const; Float_tGetNSigEvents() const; Float_tGetNSigEvents_unweighted() const; Double_tGetNSValidation() const; Int_tGetNTerminal() const; virtual TMVA::DecisionTreeNode*GetParent() const; virtual TMVA::BinaryTree*TMVA::Node::GetParentTree() const; charTMVA::Nod",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:4712,Modifiability,variab,variable,4712,"ouble_t s); voidSetNTerminal(Int_t n); virtual voidSetParent(TMVA::Node* p); virtual voidTMVA::Node::SetParentTree(TMVA::BinaryTree* t); voidTMVA::Node::SetPos(char s); voidSetPurity(); voidSetResponse(Float_t r); virtual voidSetRight(TMVA::Node* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRigh",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:4814,Modifiability,variab,variable,4814,"e* r); voidSetRMS(Float_t r); voidSetSampleMax(UInt_t ivar, Float_t xmax); voidSetSampleMin(UInt_t ivar, Float_t xmin); voidSetSelector(Short_t i); voidSetSeparationGain(Float_t sep); voidSetSeparationIndex(Float_t sep); voidSetSubTreeR(Double_t r); voidSetSumTarget(Float_t t); voidSetSumTarget2(Float_t t2); voidSetTerminal(Bool_t s = kTRUE); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. virtual voidReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); virtual voidReadContent(stringstream& s); virtual Bool_tReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). Data Members; public:. static boolfgIsTrainingstatic variable to flag training phase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:5791,Modifiability,variab,variable,5791,"hase in which we need fTrainInfo. protected:. Bool_tfCutTypetrue: if event variable > cutValue ==> signal , false otherwise; Float_tfCutValuecut value appplied on this node to discriminate bkg against sig; UInt_tTMVA::Node::fDepthdepth of the node within the tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; RE",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:5972,Modifiability,Inherit,Inheritance,5972," tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:5985,Modifiability,Inherit,Inherited,5985," tree (seen from root node); vector<Double_t>fFisherCoeffthe fisher coeff (offset at the last element); Bool_tfIsTerminalNode! flag to set node as terminal (i.e., without deleting its descendants); TMVA::Node*TMVA::Node::fLeftpointers to the two ""daughter"" nodes; Int_tfNodeTypeType of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal; TMVA::Node*TMVA::Node::fParentthe previous (parent) node; TMVA::BinaryTree*TMVA::Node::fParentTreepointer to the parent tree to which the Node belongs ; charTMVA::Node::fPosposition, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7656,Modifiability,variab,variable,7656,"to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used i",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7790,Modifiability,variab,variable,7790,"round nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* C",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7926,Modifiability,variab,variable,7926,"st; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFis",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:8062,Modifiability,variab,variable,8062,"MVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coeffic",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9146,Modifiability,variab,variable,9146,"butes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResp",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9258,Modifiability,variab,variable,9258,"d attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher coefficients. void AddContentToNode(stringstream& s) const; adding attributes to tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:9558,Modifiability,variab,variable,9558," we don't..). void ReadContent(stringstream& s); reading attributes from tree node (well, was used in BinarySearchTree,; and somehow I guess someone programmed it such that we need this in; this tree too, although we don't..). Node* CreateNode() const; { return new DecisionTreeNode(); }. void SetNFisherCoeff(Int_t nvars); {fFisherCoeff.resize(nvars);}. UInt_t GetNFisherCoeff() const; set fisher coefficients. { return fFisherCoeff.size();}. Double_t GetFisherCoeff(Int_t ivar) const; get fisher coefficients. {return fFisherCoeff.at(ivar);}. void SetSelector(Short_t i); set index of variable used for discrimination at this node. { fSelector = i; }. Short_t GetSelector() const; return index of variable used for discrimination at this node. { return fSelector; }. void SetCutValue(Float_t c); set the cut value applied at this node. { fCutValue = c; }. Float_t GetCutValue( void ); return the cut value applied at this node. { return fCutValue; }. void SetCutType(Bool_t t); set true: if event variable > cutValue ==> signal , false otherwise. { fCutType = t; }. Bool_t GetCutType( void ); return kTRUE: Cuts select signal, kFALSE: Cuts select bkg. { return fCutType; }. void SetNodeType(Int_t t); set node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { fNodeType = t;}. Int_t GetNodeType( void ); return node type: 1 signal node, -1 bkg leave, 0 intermediate Node. { return fNodeType; }. Float_t GetPurity( void ); return S/(S+B) (purity) at this node (from training). { return fPurity;}. void SetResponse(Float_t r); set the response of the node (for regression). { fResponse = r;}. Float_t GetResponse( void ); return the response of the node (for regression). { return fResponse;}. void SetRMS(Float_t r); set the RMS of the response of the node (for regression). { fRMS = r;}. Float_t GetRMS( void ); return the RMS of the response of the node (for regression). { return fRMS;}. void SetNSigEvents(Float_t s); set the sum of the signal weights in the node. { fTrainInfo->fNSigEve",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7349,Security,validat,validation,7349,"node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* node, UInt_t tmva_Version_Code = TMVA_VERSION_CODE). void AddAttributesToNode(void* node) const; add attribute to xml. void SetFisherCoeff(Int_t ivar, Double_t coeff); set fisher co",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:15154,Security,validat,validation,15154,"ionTreeNode*>(p);}. void SetNodeR(Double_t r); the node resubstitution estimate, R(t), for Cost Complexity pruning. { fTrainInfo->fNodeR = r; }. Double_t GetNodeR() const; { return fTrainInfo->fNodeR; }. void SetSubTreeR(Double_t r); the resubstitution estimate, R(T_t), of the tree rooted at this node. { fTrainInfo->fSubTreeR = r; }. Double_t GetSubTreeR() const; { return fTrainInfo->fSubTreeR; }. void SetAlpha(Double_t alpha); R(t) - R(T_t); the critical point alpha = -------------; |~T_t| - 1. { fTrainInfo->fAlpha = alpha; }. Double_t GetAlpha() const; { return fTrainInfo->fAlpha; }. void SetAlphaMinSubtree(Double_t g); the minimum alpha in the tree rooted at this node. { fTrainInfo->fG = g; }. Double_t GetAlphaMinSubtree() const; { return fTrainInfo->fG; }. void SetNTerminal(Int_t n); number of terminal nodes in the subtree rooted here. { fTrainInfo->fNTerminal = n; }. Int_t GetNTerminal() const; { return fTrainInfo->fNTerminal; }. void SetNBValidation(Double_t b); number of background/signal events from the pruning validation sample. { fTrainInfo->fNB = b; }. void SetNSValidation(Double_t s); { fTrainInfo->fNS = s; }. Double_t GetNBValidation() const; { return fTrainInfo->fNB; }. Double_t GetNSValidation() const; { return fTrainInfo->fNS; }. void SetSumTarget(Float_t t); {fTrainInfo->fSumTarget = t; }. void SetSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 = t2; }. void AddToSumTarget(Float_t t); {fTrainInfo->fSumTarget += t; }. void AddToSumTarget2(Float_t t2); {fTrainInfo->fSumTarget2 += t2; }. Float_t GetSumTarget() const; {return fTrainInfo? fTrainInfo->fSumTarget : -9999;}. Float_t GetSumTarget2() const; {return fTrainInfo? fTrainInfo->fSumTarget2: -9999;}. Bool_t IsTerminal() const; flag indicates whether this node is terminal. { return fIsTerminalNode; }. void SetTerminal(Bool_t s = kTRUE); { fIsTerminalNode = s; }. Double_t GetCC() const; {return (fTrainInfo? fTrainInfo->fCC : -1.);}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss, Eckha",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:6507,Testability,test,test,6507,"tion, i.e. it is a left (l) or right (r) daughter ; Float_tfPuritythe node purity; Float_tfRMSresponse RMS of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) con",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:6612,Testability,test,test,6612,"S of the regression node; Float_tfResponseresponse value in case of regression; TMVA::Node*TMVA::Node::fRightpointers to the two ""daughter"" nodes; Short_tfSelectorindex of variable used in node selection (decision tree); TMVA::DTNodeTrainingInfo*fTrainInfo; static TMVA::MsgLogger*fgLoggerstatic because there is a huge number of nodes... Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; DecisionTreeNode(); constructor of an essentially ""empty"" node floating in space. DecisionTreeNode(TMVA::Node* p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7109,Usability,Clear,ClearNodeAndAllDaughters,7109," p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* ",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__DecisionTreeNode.html:7137,Usability,clear,clear,7137," p, char pos); constructor of a daughter node as a daughter of 'p'. DecisionTreeNode(const TMVA::DecisionTreeNode& n, TMVA::DecisionTreeNode* parent = NULL); copy constructor of a node. It will result in an explicit copy of; the node and recursively all it's daughters. ~DecisionTreeNode(); destructor. Bool_t GoesRight(const TMVA::Event& ) const; test event if it decends the tree at this node to the right. Bool_t GoesLeft(const TMVA::Event& ) const; test event if it decends the tree at this node to the left. void SetPurity( void ); return the S/(S+B) (purity) for the node; REM: even if nodes with purity 0.01 are very PURE background nodes, they still; get a small value of the purity. void Print(ostream& os) const; print the node. void PrintRec(ostream& os) const; recursively print the node and its daughters (--> print the 'tree'). Bool_t ReadDataRecord(istream& is, UInt_t tmva_Version_Code = TMVA_VERSION_CODE); Read the data block. void ClearNodeAndAllDaughters(); clear the nodes (their S/N, Nevents etc), just keep the structure of the tree. void ResetValidationData(); temporary stored node values (number of events, etc.) that originate; not from the training but from the validation data (used in pruning). void PrintPrune(ostream& os) const; printout of the node (can be read in with ReadDataRecord). void PrintRecPrune(ostream& os) const; recursive printout of the node and its daughters. void SetCC(Double_t cc). Float_t GetSampleMin(UInt_t ivar) const; return the minimum of variable ivar from the training sample; that pass/end up in this node. Float_t GetSampleMax(UInt_t ivar) const; return the maximum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMin(UInt_t ivar, Float_t xmin); set the minimum of variable ivar from the training sample; that pass/end up in this node. void SetSampleMax(UInt_t ivar, Float_t xmax); set the maximum of variable ivar from the training sample; that pass/end up in this node. void ReadAttributes(void* ",MatchSource.WIKI,root/html532/TMVA__DecisionTreeNode.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__DecisionTreeNode.html
https://root.cern/root/html532/TMVA__Event.html:1618,Energy Efficiency,charge,charge,1618,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:1991,Energy Efficiency,Charge,Charge,1991,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:1157,Modifiability,variab,variable,1157,escription; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //N,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:2881,Modifiability,variab,variables,2881,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:4972,Modifiability,variab,variables,4972,"_tGetNVariables() const; Double_tGetOriginalWeight() const; Float_tGetSpectator(UInt_t ivar) const; vector<Float_t>&GetSpectators() const; Float_tGetTarget(UInt_t itgt) const; vector<Float_t>&GetTargets() const; Float_tGetValue(UInt_t ivar) const; const vector<Float_t>&GetValues() const; Double_tGetWeight() const; Bool_tIsDynamic() const; TMVA::Event&operator=(const TMVA::Event&); voidPrint(ostream& o) const; voidScaleBoostWeight(Double_t s); voidScaleWeight(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5228,Modifiability,Inherit,Inheritance,5228,"onst; Bool_tIsDynamic() const; TMVA::Event&operator=(const TMVA::Event&); voidPrint(ostream& o) const; voidScaleBoostWeight(Double_t s); voidScaleWeight(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValu",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5241,Modifiability,Inherit,Inherited,5241,"onst; Bool_tIsDynamic() const; TMVA::Event&operator=(const TMVA::Event&); voidPrint(ostream& o) const; voidScaleBoostWeight(Double_t s); voidScaleWeight(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValu",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5409,Modifiability,variab,variable,5409,"(Double_t s); voidSetBoostWeight(Double_t w); voidSetClass(UInt_t t); voidSetDoNotBoost(); voidSetSpectator(UInt_t ivar, Float_t value); voidSetTarget(UInt_t itgt, Float_t value); voidSetVal(UInt_t ivar, Float_t val); voidSetWeight(Double_t w). Data Members; private:. Double_tfBoostWeightinternal weight to be set by boosting algorithm; UInt_tfClassclass number; Bool_tfDoNotBoostmark event as not to be boosted (used to compensate for events with negative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<F",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:2902,Performance,perform,performance,2902,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); static voidClearDynamicVariables(); voidCopyVarValues(const TMVA::Event& other); TMVA::EventEvent(); TMVA::EventEvent(const TMVA::Event&); TMVA::EventEvent(const vector<Float_t*>*&, UInt_t nvar); TMVA::EventEvent(const vector<Float_t>&, UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); TMVA::EventEvent(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0); Double_tGetBoostWeight() const; UInt_tGetClass() const; UInt_tGetNSpectators(",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:5866,Security,access,accessors,5866,"ative event weights; Bool_tfDynamicis set when the dynamic values are taken; vector<Float_t>fSpectators""visisting"" variables not used in MVAs; vector<Float_t>fTargetstarget values for regression; vector<Float_t>fValuesthe event values; vector<Float_t*>*fValuesDynamicthe event values; Double_tfWeightevent weight (product of global and individual weights). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(); constructors. Event(const TMVA::Event& ). explicit Event(const vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<Float_t>& GetTargets() const; { return fTargets; }. Float_t GetSpectator(UInt_t ivar) const. std::vector<Float_t>& GetSpectators() const; { return fSpectators; }. void ScaleWeight(Double_t s); { fWeight*=s; }. void SetWeight(Double_t w); { fWeight=w; }. void SetBoostWeight(Double_t w); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight=w; }. void ScaleBoostWeight(Double_t s); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight *= s; }. void SetClass",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:230,Testability,TEST,TEST,230,. TMVA::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of ,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:322,Usability,simpl,simple,322,. TMVA::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::Event. class TMVA::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of ,MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Event.html:7068,Usability,Clear,ClearDynamicVariables,7068," vector<Float_t>& values, const vector<Float_t>& targetValues, const vector<Float_t>& spectatorValues, UInt_t theClass = 0, Double_t weight = 1.0, Double_t boostweight = 1.0). explicit Event(const vector<Float_t>& , UInt_t theClass, Double_t weight = 1.0, Double_t boostweight = 1.0). Bool_t IsDynamic() const; accessors. {return fDynamic; }. Double_t GetWeight() const; { return fWeight*fBoostWeight; }. Double_t GetOriginalWeight() const; { return fWeight; }. Double_t GetBoostWeight() const; { return TMath::Max(Double_t(0.0001),fBoostWeight); }. UInt_t GetClass() const; { return fClass; }. UInt_t GetNVariables() const. UInt_t GetNTargets() const. UInt_t GetNSpectators() const. Float_t GetValue(UInt_t ivar) const. const std::vector<Float_t>& GetValues() const. Float_t GetTarget(UInt_t itgt) const; { return fTargets.at(itgt); }. std::vector<Float_t>& GetTargets() const; { return fTargets; }. Float_t GetSpectator(UInt_t ivar) const. std::vector<Float_t>& GetSpectators() const; { return fSpectators; }. void ScaleWeight(Double_t s); { fWeight*=s; }. void SetWeight(Double_t w); { fWeight=w; }. void SetBoostWeight(Double_t w); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight=w; }. void ScaleBoostWeight(Double_t s); { fDoNotBoost ? fDoNotBoost = kFALSE : fBoostWeight *= s; }. void SetClass(UInt_t t); { fClass=t; }. void SetVal(UInt_t ivar, Float_t val). void SetTarget(UInt_t itgt, Float_t value). void SetSpectator(UInt_t ivar, Float_t value). void SetDoNotBoost(); { fDoNotBoost = kTRUE; }. void ClearDynamicVariables(); {}. void CopyVarValues(const TMVA::Event& other). void Print(ostream& o) const. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Event.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Event.html
https://root.cern/root/html532/TMVA__Factory.html:4336,Availability,Error,Error,4336,"theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual cha",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:4539,Availability,error,error,4539,"nst; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:4623,Availability,error,error,4623,"oidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18639,Deployability,configurat,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18848,Deployability,configurat,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:13061,Integrability,message,message,13061,"t; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19658,Integrability,message,message,19658,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19796,Integrability,message,message,19796,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:289,Modifiability,Config,Configurable,289,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:1385,Modifiability,Config,Configurable,1385,"::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TTree* signal, Double_t weight, const TString& treetype); voidAddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min =",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:3502,Modifiability,Config,Configurable,3502,,MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:3788,Modifiability,Config,ConfigurableTMVA,3788,"ssName, Double_t weight, const TCut& cut, const TString& treeType); voidAddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); voidAddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); virtual voidTObject::AppendPad(Option_t* option = """"); TMVA::MethodBase*BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtua",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:3806,Modifiability,Config,Configurable,3806," weight, const TCut& cut, const TString& treeType); voidAddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); voidAddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); virtual voidTObject::AppendPad(Option_t* option = """"); TMVA::MethodBase*BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::F",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:3820,Modifiability,Config,Configurable,3820," TCut& cut, const TString& treeType); voidAddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); voidAddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); virtual voidTObject::AppendPad(Option_t* option = """"); TMVA::MethodBase*BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); TMVA::MethodBase*BookMethod(TMVA::Types::EMVA, TString, TString, TMVA::Types::EMVA, TString); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; TTree*CreateEventAssignTrees(const TString& name); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const cha",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5006,Modifiability,Config,Configurable,5006," """")MENU ; voidDeleteAllMethods(); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5067,Modifiability,Config,Configurable,5067,"ancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; voidEvaluateAllMethods(); voidEvaluateAllVariables(TString options = """"); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; vir",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5495,Modifiability,Config,Configurable,5495,"r* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& methodTitle = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* remove",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5804,Modifiability,Inherit,InheritsFrom,5804,"::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& methodTitle = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5870,Modifiability,Inherit,InheritsFrom,5870,"ject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& methodTitle = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:7315,Modifiability,Config,Configurable,7315,"le = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); voidOptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); voidPrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); voidPrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); virtual voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voi",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:7903,Modifiability,Config,Configurable,7903,"nst char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); voidOptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); voidPrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); voidPrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); virtual voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:7995,Modifiability,Config,Configurable,7995,"nst char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); voidOptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); voidPrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); voidPrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); virtual voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:8057,Modifiability,Config,Configurable,8057,"nst char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); voidOptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); voidOptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); voidPrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); voidPrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); voidPrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); virtual voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:8498,Modifiability,variab,variable,8498,"al voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& va",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:8593,Modifiability,Config,Configurable,8593,"al voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& va",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:8654,Modifiability,Config,Configurable,8654,"al voidTObject::Print(Option_t* option = """") const; voidPrintHelpMessage(const TString& methodTitle = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); static TDirectory*RootBaseDir(); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetBackgroundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& va",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9331,Modifiability,Config,Configurable,9331,"roundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; vir",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9433,Modifiability,Config,Configurable,9433,"roundTree(TTree* background, Double_t weight = 1.0); voidSetBackgroundWeightExpression(const TString& variable); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); voidSetCut(const TString& cut, const TString& className = """"); voidSetCut(const TCut& cut, const TString& className = """"); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); voidSetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; vir",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9579,Modifiability,variab,variable,9579,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:9778,Modifiability,variab,variable,9778,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10586,Modifiability,Config,Configurable,10586,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10783,Modifiability,Config,Configurable,10783,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10855,Modifiability,Config,Configurable,10855,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10917,Modifiability,Config,Configurable,10917,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10956,Modifiability,Config,Configurable,10956,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:11043,Modifiability,Config,Configurable,11043,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:11083,Modifiability,Config,Configurable,11083,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:11678,Modifiability,variab,variables,11678,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12005,Modifiability,Variab,VariableTransformBase,12005,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12626,Modifiability,Inherit,Inheritance,12626,". Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12639,Modifiability,Inherit,Inherited,12639,". Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:14342,Modifiability,variab,variables,14342,"A::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalTree(TTree* signal, Double_t weight, const TString& treetype). void AddBackgroundTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of s",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:16534,Modifiability,variab,variable,16534,"om text file. void AddBackgroundTree(TTree* background, Double_t weight, const TString& treetype). void SetSignalTree(TTree* signal, Double_t weight = 1.0). void SetBackgroundTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:16687,Modifiability,variab,variable,16687,"dTree(TTree* background, Double_t weight = 1.0). void SetTree(TTree* tree, const TString& className, Double_t weight); set background tree. void SetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); define the input trees for signal and background; no cuts are applied. void SetInputTrees(const TString& signalFileName, const TString& backgroundFileName, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0). void SetInputTrees(TTree* inputTree, const TCut& SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TSt",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17182,Modifiability,variab,variables,17182," SigCut, const TCut& BgCut); define the input trees for signal and background from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& s",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17251,Modifiability,variab,variable,17251,"ound from single input tree,; containing both signal and background events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal an",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17312,Modifiability,variab,variable,17312,"ckground events distinguished by the type; identifiers: SigCut and BgCut. void AddVariable(const TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17363,Modifiability,variab,variable,17363,"nst TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase*",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18639,Modifiability,config,configuration,18639," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18848,Modifiability,config,configurations,18848," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18825,Performance,perform,performance,18825," AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; ite",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19119,Performance,Optimiz,OptimizeAllMethods,19119,"t trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETr",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:20503,Performance,Optimiz,OptimizeAllMethodsForClassification,20503,"sed; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void TrainAllMethodsForClassification( void ); { TrainAllMethods(); }. void TrainAllMethodsForRegression( void ); { TrainAllMethods(); }. Bool_t Verbose( void ); { return fVerbose; }. TDirectory* RootBaseDir(); { return (TDirectory*)fgTargetFile; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Factory.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:20602,Performance,Optimiz,OptimizeAllMethods,20602,"sed; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void TrainAllMethodsForClassification( void ); { TrainAllMethods(); }. void TrainAllMethodsForRegression( void ); { TrainAllMethods(); }. Bool_t Verbose( void ); { return fVerbose; }. TDirectory* RootBaseDir(); { return (TDirectory*)fgTargetFile; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Factory.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:20647,Performance,Optimiz,OptimizeAllMethodsForRegression,20647,"sed; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void TrainAllMethodsForClassification( void ); { TrainAllMethods(); }. void TrainAllMethodsForRegression( void ); { TrainAllMethods(); }. Bool_t Verbose( void ); { return fVerbose; }. TDirectory* RootBaseDir(); { return (TDirectory*)fgTargetFile; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Factory.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:20742,Performance,Optimiz,OptimizeAllMethods,20742,"sed; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void TrainAllMethodsForClassification( void ); { TrainAllMethods(); }. void TrainAllMethodsForRegression( void ); { TrainAllMethods(); }. Bool_t Verbose( void ); { return fVerbose; }. TDirectory* RootBaseDir(); { return (TDirectory*)fgTargetFile; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: Factory.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:5694,Security,Hash,Hash,5694,"t py); TMVA::FactoryFactory(TString theJobName, TFile* theTargetFile, TString theOption = """"); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual const char*TObject::GetIconName() const; TMVA::IMethod*GetMethod(const TString& title) const; virtual const char*GetName() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& methodTitle = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::o",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:407,Testability,test,testing,407,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10051,Testability,Test,TestBit,10051,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10090,Testability,Test,TestBits,10090,"t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputTrees(TTree* signal, TTree* background, Double_t signalWeight = 1.0, Double_t backgroundWeight = 1.0); voidSetInputVariables(vector<TString>* theVariables); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalTree(TTree* signal, Double_t weight = 1.0); voidSetSignalWeightExpression(const TString& variable); voidSetTree(TTree* tree, const TString& className, Double_t weight); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetVerbose(Bool_t v = kTRUE); voidSetWeightExpression(const TString& variable, const TString& className = """"); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable:",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:10931,Testability,Log,Log,10931,"); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; voidTestAllMethods(); Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; voidTrainAllMethods(); voidTrainAllMethodsForClassification(); voidTrainAllMethodsForRegression(); virtual voidTObject::UseCurrentStyle(); Bool_tUserAssignEvents(UInt_t clIndex); Bool_tVerbose() const; virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigni",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12531,Testability,test,test,12531,"vate:. TMVA::DataInputHandler&DataInput(); TMVA::DataSetInfo&DefaultDataSetInfo(); voidGreetings(); voidSetInputTreesFromEventAssignTrees(); voidWriteDataInformation(). Data Members; public:. enum DataAssignType { kUndefined; kAssignTrees; kAssignEvents; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. private:. Float_t*fATreeEventevent variables; Int_tfATreeTypetype of event (=classIndex); Float_tfATreeWeightweight of the event; TMVA::Types::EAnalysisTypefAnalysisType! the training type; TMVA::Factory::DataAssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelco",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:12917,Testability,test,test,12917,"ssignTypefDataAssignType! flags for data assigning; TMVA::DataInputHandler*fDataInputHandler; TMVA::DataSetManager*fDataSetManagerDSMTEST; vector<TMVA::VariableTransformBase*>fDefaultTrfs! list of transformations on default DataSet; TStringfJobName! jobname, used as extension in weight file names; TMVA::Factory::MVectorfMethods! all MVA methods; TStringfOptions! option string given by construction (presently only ""V""); vector<TTree*>fTestAssignTree! for each class: tmp tree if user wants to assign the events directly; vector<TTree*>fTrainAssignTree! for each class: tmp tree if user wants to assign the events directly; TStringfTransformations! List of transformations to test; Bool_tfVerbose! verbose mode; static TFile*fgTargetFile! ROOT output file. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:13697,Testability,test,testing,13697,"ation; Factory(TString theJobName, TFile* theTargetFile, TString theOption = """"); standard constructor; jobname : this name will appear in all weight file names produced by the MVAs; theTargetFile : output ROOT file; the test tree and all evaluation plots; will be stored here; theOption : option string; currently: ""V"" for verbose. void Greetings(); print welcome message; options are: kLogoWelcomeMsg, kIsometricWelcomeMsg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, c",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:14164,Testability,test,test,14164,"Msg, kLeanWelcomeMsg. ~Factory( void ); destructor; delete fATreeEvent;. void DeleteAllMethods( void ); delete methods. void SetVerbose(Bool_t v = kTRUE). TMVA::DataSetInfo& AddDataSet( DataSetInfo &dsi ). TMVA::DataSetInfo& AddDataSet(const TString& ). TTree* CreateEventAssignTrees(const TString& name); create the data assignment tree (for event-wise data assignment by user). void AddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal testing event. void AddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); add signal training event. void AddTrainingEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal training event. void AddTestEvent(const TString& className, const vector<Double_t>& event, Double_t weight); add signal test event. void AddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); add event; vector event : the order of values is: variables + targets + spectators. Bool_t UserAssignEvents(UInt_t clIndex). void SetInputTreesFromEventAssignTrees(); assign event-wise local trees to data set. void AddTree(TTree* tree, const TString& className, Double_t weight, const TCut& cut, const TString& treeType); number of signal events (used to compute significance). void AddTree(TTree* tree, const TString& className, Double_t weight = 1.0, const TCut& cut = """", TMVA::Types::ETreeType tt = Types::kMaxTreeType). void AddSignalTree( TTree* signal, Double_t weight, Types::ETreeType treetype ); number of signal events (used to compute significance). void AddSignalTree(TString datFileS, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); add signal tree from text file. void AddSignalT",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17405,Testability,Log,Log,17405,"nst TString& expression, const TString& title, const TString& unit, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddVariable(const TString& expression, char type = 'F', Double_t min = 0, Double_t max = 0); user inserts discriminating variable in data set info. void AddTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase*",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:17931,Testability,test,test,17931," 0); user inserts target in data set info. void AddSpectator(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of v",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18050,Testability,test,test,18050," user inserts target in data set info. TMVA::DataSetInfo& DefaultDataSetInfo(); default creation. void SetInputVariables(vector<TString>* theVariables); fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put corr",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18195,Testability,test,test,18195," fill input variables in data set. void SetSignalWeightExpression(const TString& variable). void SetBackgroundWeightExpression(const TString& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"",",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:18356,Testability,test,test,18356,"ring& variable). void SetWeightExpression(const TString& variable, const TString& className = """"); Log() << kWarning << DefaultDataSetInfo().GetNClasses() /*fClasses.size()*/ << Endl;. void SetCut(const TString& cut, const TString& className = """"). void SetCut(const TCut& cut, const TString& className = """"). void AddCut(const TString& cut, const TString& className = """"). void AddCut(const TCut& cut, const TString& className = """"). void PrepareTrainingAndTestTree(const TCut& cut, Int_t NsigTrain, Int_t NbkgTrain, Int_t NsigTest, Int_t NbkgTest, const TString& otherOpt = ""SplitMode=Random:!V""); prepare the training and test trees. void PrepareTrainingAndTestTree(const TCut& cut, Int_t Ntrain, Int_t Ntest = -1); prepare the training and test trees; kept for backward compatibility. void PrepareTrainingAndTestTree(const TCut& cut, const TString& splitOpt); prepare the training and test trees; -> same cuts for signal and background. void PrepareTrainingAndTestTree(TCut sigcut, TCut bkgcut, const TString& splitOpt); prepare the training and test trees. TMVA::MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"); Book a classifier or regression method. TMVA::MethodBase* BookMethod(TMVA::Types::EMVA theMethod, TString methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. c",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19563,Testability,Test,TestAllMethods,19563,"ing methodTitle, TString theOption = """"); books MVA method; the option configuration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19706,Testability,test,test,19706,"uration string is custom for each MVA; the TString field ""theNameAppendix"" serves to define (and distinguish); several instances of a given MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:19844,Testability,test,test,19844,"iven MVA, eg, when one wants to compare the; performance of various configurations. TMVA::IMethod* GetMethod(const TString& title) const; returns pointer to MVA that corresponds to given method title. void WriteDataInformation(); put correlations of input data and a few (default + user; selected) transformations into the root file. void OptimizeAllMethods(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); iterates through all booked methods and sees if they use parameter tuning and if so..; does just that i.e. calls ""Method::Train()"" for different parameter setttings and; keeps in mind the ""optimal one""... and that's the one that will later on be used; in the main training loop. void TrainAllMethods(); iterates through all booked methods and calls training. void TestAllMethods(). void MakeClass(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void PrintHelpMessage(const TString& methodTitle = """") const; Print predefined help message of classifier; iterate over methods and test. void EvaluateAllVariables(TString options = """"); iterates over all MVA input varables and evaluates them. void EvaluateAllMethods( void ); iterates over all MVAs that have been booked, and calls their evaluation methods. const char* GetName() const; { return ""Factory""; }. void AddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); special case: regression. void AddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0). MethodBase* BookMethod(TString theMethodName, TString methodTitle, TString theOption = """"). void OptimizeAllMethodsForClassification(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }. void OptimizeAllMethodsForRegression(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); { OptimizeAllMethods(fomType,fitType); }",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:373,Usability,guid,guides,373,". TMVA::Factory. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Factory. class TMVA::Factory: public TMVA::Configurable. This is the main MVA steering class: it creates all MVA methods,; and guides them through the training, testing and evaluation; phases. Function Members (Methods); public:. virtual~Factory(); voidTObject::AbstractMethod(const char* method) const; voidAddBackgroundTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddBackgroundTree(TTree* background, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TString datFileB, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddBackgroundTree(TTree* background, Double_t weight, const TString& treetype); voidAddCut(const TString& cut, const TString& className = """"); voidAddCut(const TCut& cut, const TString& className = """"); TMVA::DataSetInfo&AddDataSet(TMVA::DataSetInfo&); TMVA::DataSetInfo&AddDataSet(const TString&); voidAddEvent(const TString& className, TMVA::Types::ETreeType tt, const vector<Double_t>& event, Double_t weight); voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddRegressionTarget(const TString& expression, const TString& title = """", const TString& unit = """", Double_t min = 0, Double_t max = 0); voidAddRegressionTree(TTree* tree, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTestEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTrainingEvent(const vector<Double_t>& event, Double_t weight = 1.0); voidAddSignalTree(TTree* signal, Double_t weight = 1.0, TMVA::Types::ETreeType treetype = Types::kMaxTreeType); voidAddSignalTree(TString datFileS, Do",MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__Factory.html:3638,Usability,Clear,Clear,3638,,MatchSource.WIKI,root/html532/TMVA__Factory.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Factory.html
https://root.cern/root/html532/TMVA__FitterBase.html:530,Availability,avail,available,530,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1568,Availability,Error,Error,1568,"~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat();",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1754,Availability,error,error,1754,"virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() con",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1838,Availability,error,error,1838,"ons() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash(",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:385,Integrability,interface,interface,385,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7043,Integrability,interface,interface,7043,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7143,Integrability,interface,interface,7143,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:298,Modifiability,Config,Configurable,298,". TMVA::FitterBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::FitterBase. class TMVA::FitterBase: public TMVA::Configurable. FitterBase. Baseclass for TMVA fitters. Also defines generalised fitting interface. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:651,Modifiability,Config,Configurable,651," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:809,Modifiability,Config,Configurable,809," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1095,Modifiability,Config,ConfigurableTMVA,1095," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1113,Modifiability,Config,Configurable,1113," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:1127,Modifiability,Config,Configurable,1127," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:2133,Modifiability,Config,Configurable,2133,"(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClas",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:2194,Modifiability,Config,Configurable,2194,"bject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:2637,Modifiability,Config,Configurable,2637,"ion(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* pt",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:2946,Modifiability,Inherit,InheritsFrom,2946,"har* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TOb",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:3012,Modifiability,Inherit,InheritsFrom,3012,"indObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operat",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4113,Modifiability,Config,Configurable,4113,"t_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::Set",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4238,Modifiability,Config,Configurable,4238,"() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4330,Modifiability,Config,Configurable,4330,"TObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStrea",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4392,Modifiability,Config,Configurable,4392,"ption = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const c",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4830,Modifiability,Config,Configurable,4830,"or new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurab",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:4891,Modifiability,Config,Configurable,4891,"* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) c",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:5053,Modifiability,Config,Configurable,5053,"; void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:5155,Modifiability,Config,Configurable,5155,"; void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:5827,Modifiability,Config,Configurable,5827,"; void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6054,Modifiability,Config,Configurable,6054,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6126,Modifiability,Config,Configurable,6126,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6207,Modifiability,Config,Configurable,6207,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6294,Modifiability,Config,Configurable,6294,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6334,Modifiability,Config,Configurable,6334,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6931,Modifiability,Inherit,Inheritance,6931,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6944,Modifiability,Inherit,Inherited,6944,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:2836,Security,Hash,Hash,2836,"error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*GetName() const; Int_tGetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:7300,Security,access,accessor,7300,"e::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:5454,Testability,Test,TestBit,5454,"; void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:5493,Testability,Test,TestBits,5493,"; void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); Double_tRun(); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6182,Testability,Log,Log,6182,"oidTMVA::Configurable::SetOptions(const TString& s); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function inte",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:6821,Testability,log,logger,6821,"Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidDeclareOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringfClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*fLoggermessage logger; Int_tfNparsnumber of parameters; const vector<TMVA::Interval*>fRangesallowed intervals. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t Run(); estimator function interface for fitting. Double_t EstimatorFunction(vector<Double_t>& parameters); estimator function interface for fitting. virtual ~FitterBase(); {}. Double_t Run(). IFitterTarget& GetFitterTarget() const; { return fFitterTarget; }. Int_t GetNpars() const; accessor. { return fNpars; }. const char* GetName() const; remove namespace in name. { return fClassName; }. void DeclareOptions(); need to implement option declaration. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: FitterBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT ",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__FitterBase.html:945,Usability,Clear,Clear,945," virtual~FitterBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tEstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual T",MatchSource.WIKI,root/html532/TMVA__FitterBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__FitterBase.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:4866,Energy Efficiency,reduce,reduce,4866,"different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s; }. void SetMakeCopies(Bool_t s); { fMakeCopies = s; }. Bool_t GetMakeCopies(); { return fMakeCopies; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticAlgorithm.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2179,Modifiability,Inherit,Inheritance,2179,"amerNVirtual(TBuffer& b). protected:. TMVA::MsgLogger&Log() const. Data Members; public:. Int_tfConvCounterconverging? ... keeps track of the number of improvements. protected:. Double_tfBestFitness; Double_tfConvValuekeeps track of the quantity of improvement; Bool_tfFirstTimeif true its the first time, so no evolution yet; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitn",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2192,Modifiability,Inherit,Inherited,2192,"amerNVirtual(TBuffer& b). protected:. TMVA::MsgLogger&Log() const. Data Members; public:. Int_tfConvCounterconverging? ... keeps track of the number of improvements. protected:. Double_tfBestFitness; Double_tfConvValuekeeps track of the quantity of improvement; Bool_tfFirstTimeif true its the first time, so no evolution yet; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitn",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2700,Modifiability,variab,variable,2700,"rTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; afte",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:4451,Modifiability,variab,variable,4451,"event the new chi-square (newValue) has to be simply; added to the oldValue. this function has to be overridden eventually; it might contain only the following return statement.; return oldValue + newValue;. Double_t CalculateFitness(); starts the evaluation of the fitness of all different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:1258,Testability,Log,Log,1258,"GeneticAlgorithm. class TMVA::GeneticAlgorithm. Base definition for genetic algorithm. Function Members (Methods); public:. virtual~GeneticAlgorithm(); virtual Double_tCalculateFitness(); static TClass*Class(); virtual voidEvolution(); TMVA::GeneticAlgorithmGeneticAlgorithm(const TMVA::GeneticAlgorithm&); TMVA::GeneticAlgorithmGeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); TMVA::GeneticPopulation&GetGeneticPopulation(); Bool_tGetMakeCopies(); Double_tGetSpread() const; virtual Bool_tHasConverged(Int_t steps = 10, Double_t ratio = 0.1); voidInit(); virtual TClass*IsA() const; virtual Double_tNewFitness(Double_t oldValue, Double_t newValue); voidSetMakeCopies(Bool_t s); voidSetSpread(Double_t s); virtual voidShowMembers(TMemberInspector& insp); virtual Double_tSpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. TMVA::MsgLogger&Log() const. Data Members; public:. Int_tfConvCounterconverging? ... keeps track of the number of improvements. protected:. Double_tfBestFitness; Double_tfConvValuekeeps track of the quantity of improvement; Bool_tfFirstTimeif true its the first time, so no evolution yet; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:1688,Testability,log,logger,1688,"pies(); Double_tGetSpread() const; virtual Bool_tHasConverged(Int_t steps = 10, Double_t ratio = 0.1); voidInit(); virtual TClass*IsA() const; virtual Double_tNewFitness(Double_t oldValue, Double_t newValue); voidSetMakeCopies(Bool_t s); voidSetSpread(Double_t s); virtual voidShowMembers(TMemberInspector& insp); virtual Double_tSpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). protected:. TMVA::MsgLogger&Log() const. Data Members; public:. Int_tfConvCounterconverging? ... keeps track of the number of improvements. protected:. Double_tfBestFitness; Double_tfConvValuekeeps track of the quantity of improvement; Bool_tfFirstTimeif true its the first time, so no evolution yet; TMVA::IFitterTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are op",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:2486,Testability,test,tested,2486,"rTarget&fFitterTargetthe fitter target; Double_tfLastResultremembers the last obtained result (for internal use); TMVA::MsgLogger*fLoggermessage logger; Bool_tfMakeCopiesif true, the population will make copies of the first individuals; Bool_tfMirrornew values for mutation are mirror-mapped if outside of constraints; TMVA::GeneticPopulationfPopulationcontains and controls the ""individual""; Int_tfPopulationSizethe size of the population; const vector<TMVA::Interval*>&fRangesparameter ranges; Double_tfSpreadregulates the spread of the value change at mutation (sigma); deque<Int_t>fSuccessListto adjust the stepSize . Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0); Constructor; Parameters:; int populationSize : defines the number of ""Individuals"" which are created and tested; within one Generation (Iteration of the Evolution); vector<TMVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; afte",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:3598,Usability,simpl,simply,3598,"MVA::Interval*> ranges : Interval holds the information of an interval, where the GetMin; gets the low and GetMax gets the high constraint of the variable; the size of ""ranges"" is the number of coefficients which are optimised; Purpose:; Creates a random population with individuals of the size ranges.size(). ~GeneticAlgorithm(); destructor; deletes fLogger. void Init(); calls evolution, but if it is not the first time.; If it's the first time, the random population created by the; constructor is still not evaluated, .. therefore we wait for the; second time init is called. Double_t NewFitness(Double_t oldValue, Double_t newValue); if the ""fitnessFunction"" is called multiple times for one set of; factors (because i.e. each event of a TTree has to be assessed with; each set of Factors proposed by the Genetic Algorithm) the value; of the current calculation has to be added(? or else) to the value; obtained up to now.; example: some chi-square is calculated for every event,; after every event the new chi-square (newValue) has to be simply; added to the oldValue. this function has to be overridden eventually; it might contain only the following return statement.; return oldValue + newValue;. Double_t CalculateFitness(); starts the evaluation of the fitness of all different individuals of; the population. this function calls implicitly (many times) the ""fitnessFunction"" which; has been overridden by the user. void Evolution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticAlgorithm.html:5154,Usability,simpl,simple,5154,"lution(); this function is called from ""init"" and controls the evolution of the; individuals.; the function can be overridden to change the parameters for mutation rate; sexual reproduction and so on. Double_t SpreadControl(Int_t steps, Int_t ofSteps, Double_t factor); this function provides the ability to change the stepSize of a mutation according to; the success of the last generations. Parameters:; int ofSteps : = if OF the number of STEPS given in this variable (ofSteps); int successSteps : >sucessSteps Generations could improve the result; double factor : than multiply the stepSize ( spread ) by this factor; (if ofSteps == successSteps nothing is changed, if ofSteps < successSteps, the spread; is divided by the factor). using this function one can increase the stepSize of the mutation when we have; good success (to pass fast through the easy phase-space) and reduce the stepSize; if we are in a difficult ""territory"" of the phase-space. Bool_t HasConverged(Int_t steps = 10, Double_t ratio = 0.1); gives back true if the last ""steps"" steps have lead to an improvement of the; ""fitness"" of the ""individuals"" of at least ""improvement"". this gives a simple measure of if the fitness of the individuals is; converging and no major improvement is to be expected soon. GeneticAlgorithm(TMVA::IFitterTarget& target, Int_t populationSize, const vector<TMVA::Interval*>& ranges, UInt_t seed = 0). GeneticPopulation& GetGeneticPopulation(); { return fPopulation; }. Double_t GetSpread() const; { return fSpread; }. void SetSpread(Double_t s); { fSpread = s; }. void SetMakeCopies(Bool_t s); { fMakeCopies = s; }. Bool_t GetMakeCopies(); { return fMakeCopies; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticAlgorithm.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticAlgorithm.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticAlgorithm.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:1397,Availability,Error,Error,1397,"neticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObje",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:1601,Availability,error,error,1601,"t::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:1685,Availability,error,error,1685,"c TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::C",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8899,Deployability,configurat,configuration,8899,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:480,Modifiability,Config,Configurable,480," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:638,Modifiability,Config,Configurable,638," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:924,Modifiability,Config,ConfigurableTMVA,924," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:942,Modifiability,Config,Configurable,942," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:956,Modifiability,Config,Configurable,956," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:2129,Modifiability,Config,Configurable,2129,"ncetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() const",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:2190,Modifiability,Config,Configurable,2190,"(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA()",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:2687,Modifiability,Config,Configurable,2687,"0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) c",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:2996,Modifiability,Inherit,InheritsFrom,2996,"IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp);",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:3062,Modifiability,Inherit,InheritsFrom,3062,"erval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator n",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4213,Modifiability,Config,Configurable,4213,"TObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4338,Modifiability,Config,Configurable,4338," Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4430,Modifiability,Config,Configurable,4430,"(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4492,Modifiability,Config,Configurable,4492,"ar* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspec",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4915,Modifiability,Config,Configurable,4915,"TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, In",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:4976,Modifiability,Config,Configurable,4976,"size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* nam",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:5138,Modifiability,Config,Configurable,5138,"or=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:5240,Modifiability,Config,Configurable,5240,"or=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6044,Modifiability,Config,Configurable,6044,"or=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6241,Modifiability,Config,Configurable,6241,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6313,Modifiability,Config,Configurable,6313,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6412,Modifiability,Config,Configurable,6412,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6499,Modifiability,Config,Configurable,6499,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6539,Modifiability,Config,Configurable,6539,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8496,Modifiability,Inherit,Inheritance,8496,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8509,Modifiability,Inherit,Inherited,8509,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:8899,Modifiability,config,configuration,8899,"Nstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are included as ""hints"" in the last cycle of GA calculation); Int_tfSaveBestFromGenerationstore the best individuals from one generation (these are included as ""hints"" in the last cycle of GA calculation); UInt_tfSeedSeed for the random generator (0 takes random seeds); Bool_tfTrimtake care, that the number of individuals is less fPopSize (trimming is done after the fitness of the individuals is assessed). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); declare GA options. void SetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); set GA configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~GeneticFitter(); {}. Double_t NewFitness(Double_t oldF, Double_t newF); { return oldF + newF; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:2886,Security,Hash,Hash,2886,"ame) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; Double_tNewFitness(Double_t oldF, Double_t newF); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator dele",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:5671,Testability,Test,TestBit,5671,"or=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:5710,Testability,Test,TestBits,5710,"or=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles, Int_t nsteps, Int_t popSize, Int_t SC_steps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:6387,Testability,Log,Log,6387,"ps, Int_t SC_rate, Double_t SC_factor, Double_t convCrit); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:7120,Testability,log,logger,7120,"tream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Double_tfConvCritimprovements bigger than fConvCrit are counted as ""improvement""; Int_tfCyclesnumber of (nearly) independent calculation cycles; Int_tfNstepsconvergence criteria: if no improvements > fConvCrit was achieved within the last fNsteps: cycle has ""converged""; Int_tfPopSizenumber of individuals to start with; Double_tfSC_factor... with fSC_factor; if there were less improvements: divide by that factor; if there were exactly fSC_rate improvements, dont change anything; Int_tfSC_rate... fSC_rate improvements, than multiply the sigma of the gaussion which defines how the random numbers are generated ...; Int_tfSC_stepsregulates how strong the mutations for the coordinates are: if within fSC_steps there were more than...; Int_tfSaveBestFromCyclestore the best individuals from one cycle (these are inclu",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticFitter.html:774,Usability,Clear,Clear,774," virtual~GeneticFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::GeneticFitterGeneticFitter(TMVA:",MatchSource.WIKI,root/html532/TMVA__GeneticFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticFitter.html
https://root.cern/root/html532/TMVA__GeneticGenes.html:308,Integrability,interface,interface,308,. TMVA::GeneticGenes. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::GeneticGenes. class TMVA::GeneticGenes. Cut optimisation interface class for genetic algorithm. Function Members (Methods); public:. virtual~GeneticGenes(); static TClass*Class(); TMVA::GeneticGenesGeneticGenes(); TMVA::GeneticGenesGeneticGenes(vector<Double_t>& f); TMVA::GeneticGenesGeneticGenes(const TMVA::GeneticGenes&); vector<Double_t>&GetFactors(); Double_tGetFitness() const; virtual TClass*IsA() const; TMVA::GeneticGenes&operator=(const TMVA::GeneticGenes&); voidSetFitness(Double_t fitness); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. vector<Double_t>fFactorsstores the factors (coefficients) of one individual; Double_tfFitness. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticGenes(vector<Double_t>& f); Constructor:; set the factors of this individual. GeneticGenes(); {}. GeneticGenes(vector<Double_t>& f). virtual ~GeneticGenes(); {}. std::vector<Double_t>& GetFactors(); { return fFactors; }. void SetFitness(Double_t fitness); { fFitness = fitness; }. Double_t GetFitness() const; { return fFitness; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticGenes.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__GeneticGenes.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticGenes.html
https://root.cern/root/html532/TMVA__GeneticGenes.html:1005,Modifiability,Inherit,Inheritance,1005,. TMVA::GeneticGenes. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::GeneticGenes. class TMVA::GeneticGenes. Cut optimisation interface class for genetic algorithm. Function Members (Methods); public:. virtual~GeneticGenes(); static TClass*Class(); TMVA::GeneticGenesGeneticGenes(); TMVA::GeneticGenesGeneticGenes(vector<Double_t>& f); TMVA::GeneticGenesGeneticGenes(const TMVA::GeneticGenes&); vector<Double_t>&GetFactors(); Double_tGetFitness() const; virtual TClass*IsA() const; TMVA::GeneticGenes&operator=(const TMVA::GeneticGenes&); voidSetFitness(Double_t fitness); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. vector<Double_t>fFactorsstores the factors (coefficients) of one individual; Double_tfFitness. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticGenes(vector<Double_t>& f); Constructor:; set the factors of this individual. GeneticGenes(); {}. GeneticGenes(vector<Double_t>& f). virtual ~GeneticGenes(); {}. std::vector<Double_t>& GetFactors(); { return fFactors; }. void SetFitness(Double_t fitness); { fFitness = fitness; }. Double_t GetFitness() const; { return fFitness; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticGenes.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__GeneticGenes.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticGenes.html
https://root.cern/root/html532/TMVA__GeneticGenes.html:1018,Modifiability,Inherit,Inherited,1018,. TMVA::GeneticGenes. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::GeneticGenes. class TMVA::GeneticGenes. Cut optimisation interface class for genetic algorithm. Function Members (Methods); public:. virtual~GeneticGenes(); static TClass*Class(); TMVA::GeneticGenesGeneticGenes(); TMVA::GeneticGenesGeneticGenes(vector<Double_t>& f); TMVA::GeneticGenesGeneticGenes(const TMVA::GeneticGenes&); vector<Double_t>&GetFactors(); Double_tGetFitness() const; virtual TClass*IsA() const; TMVA::GeneticGenes&operator=(const TMVA::GeneticGenes&); voidSetFitness(Double_t fitness); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; private:. vector<Double_t>fFactorsstores the factors (coefficients) of one individual; Double_tfFitness. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticGenes(vector<Double_t>& f); Constructor:; set the factors of this individual. GeneticGenes(); {}. GeneticGenes(vector<Double_t>& f). virtual ~GeneticGenes(); {}. std::vector<Double_t>& GetFactors(); { return fFactors; }. void SetFitness(Double_t fitness); { fFitness = fitness; }. Double_t GetFitness() const; { return fFitness; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticGenes.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ,MatchSource.WIKI,root/html532/TMVA__GeneticGenes.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticGenes.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:1665,Modifiability,Variab,VariableDistribution,1665,"rs); static TClass*Class(); TMVA::GeneticPopulationGeneticPopulation(const TMVA::GeneticPopulation&); TMVA::GeneticPopulationGeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Double_tGetFitness() const; const vector<TMVA::GeneticGenes>&GetGenePool() const; vector<TMVA::GeneticGenes>&GetGenePool(); TMVA::GeneticGenes*GetGenes(Int_t index); Int_tGetPopulationSize() const; const vector<TMVA::GeneticRange*>&GetRanges() const; vector<TMVA::GeneticRange*>&GetRanges(); voidGiveHint(vector<Double_t>& hint, Double_t fitness = 0); virtual TClass*IsA() const; voidMakeChildren(); voidMakeCopies(int number); voidMutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); voidNextGeneration(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t se",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:1709,Modifiability,Variab,VariableDistribution,1709,"rs); static TClass*Class(); TMVA::GeneticPopulationGeneticPopulation(const TMVA::GeneticPopulation&); TMVA::GeneticPopulationGeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Double_tGetFitness() const; const vector<TMVA::GeneticGenes>&GetGenePool() const; vector<TMVA::GeneticGenes>&GetGenePool(); TMVA::GeneticGenes*GetGenes(Int_t index); Int_tGetPopulationSize() const; const vector<TMVA::GeneticRange*>&GetRanges() const; vector<TMVA::GeneticRange*>&GetRanges(); voidGiveHint(vector<Double_t>& hint, Double_t fitness = 0); virtual TClass*IsA() const; voidMakeChildren(); voidMakeCopies(int number); voidMutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); voidNextGeneration(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t se",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:2284,Modifiability,Inherit,Inheritance,2284,"n(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t seed = 0); the random seed of the random generator. void MakeCopies(int number); produces offspring which is are copies of their parents; Parameters:; int number : the number of the last individual to be copied. void MakeChildren(); does what the name says,... it creates children out of members of the; current generation; children have a combination of the coefficients of their parents. TMVA::GeneticGenes MakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female); this function takes two individuals and produces offspring by mixing (recombining) their; coefficients. void Mutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); mutates the individuals in the genePool; Parameters:; double probability : gives the",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:2297,Modifiability,Inherit,Inherited,2297,"n(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t seed = 0); the random seed of the random generator. void MakeCopies(int number); produces offspring which is are copies of their parents; Parameters:; int number : the number of the last individual to be copied. void MakeChildren(); does what the name says,... it creates children out of members of the; current generation; children have a combination of the coefficients of their parents. TMVA::GeneticGenes MakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female); this function takes two individuals and produces offspring by mixing (recombining) their; coefficients. void Mutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); mutates the individuals in the genePool; Parameters:; double probability : gives the",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:4622,Modifiability,Variab,VariableDistribution,4622," ""near"" the old one; (gaussian around the current value); double spread : if near==true, spread gives the sigma of the gaussian; Bool_t mirror : if the new value obtained would be outside of the given constraints; the value is mapped between the constraints again. This can be done either; by a kind of periodic boundary conditions or mirrored at the boundary.; (mirror = true seems more ""natural""). TMVA::GeneticGenes* GetGenes(Int_t index); gives back the ""Genes"" of the population with the given index. void Print(Int_t untilIndex = -1); make a little printout of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. void Print(ostream& out, Int_t utilIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulatio",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:4905,Modifiability,Variab,VariableDistribution,4905,"straints; the value is mapped between the constraints again. This can be done either; by a kind of periodic boundary conditions or mirrored at the boundary.; (mirror = true seems more ""natural""). TMVA::GeneticGenes* GetGenes(Int_t index); gives back the ""Genes"" of the population with the given index. void Print(Int_t untilIndex = -1); make a little printout of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. void Print(ostream& out, Int_t utilIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { retur",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5430,Modifiability,variab,variables,5430,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5481,Modifiability,variab,variables,5481,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:5509,Performance,perform,perform,5509,"lIndex = -1); make a little printout to the stream ""out"" of the individuals up to index ""untilIndex""; this means, .. write out the best ""untilIndex"" individuals. TH1F* VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max); give back a histogram with the distribution of the coefficients; parameters:; int bins : number of bins of the histogram; int min : histogram minimum; int max : maximum value of the histogram. vector<Double_t> VariableDistribution(Int_t varNumber); gives back all the values of coefficient ""varNumber"" of the current generation. void AddPopulation( GeneticPopulation *strangers ); add another population (strangers) to the one of this GeneticPopulation. void AddPopulation( GeneticPopulation &strangers ); add another population (strangers) to the one of this GeneticPopulation. void TrimPopulation(); trim the population to the predefined size. void GiveHint(vector<Double_t>& hint, Double_t fitness = 0); add an individual (a set of variables) to the population; if there is a set of variables which is known to perform good, they can be given as a hint to the population. void Sort(); sort the genepool according to the fitness of the individuals. GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0). Int_t GetPopulationSize() const; { return fGenePool.size(); }. Double_t GetFitness() const; { return fGenePool.size()>0? fGenePool[0].GetFitness() : 0; }. const std::vector<TMVA::GeneticGenes>& GetGenePool() const; { return fGenePool; }. const std::vector<TMVA::GeneticRange*>& GetRanges() const; { return fRanges; }. std::vector<TMVA::GeneticGenes>& GetGenePool(); { return fGenePool; }. std::vector<TMVA::GeneticRange*>& GetRanges(); { return fRanges; }. void NextGeneration(); {}. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GeneticPopulation.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or su",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:1808,Testability,Log,Log,1808,"tGenePool(); TMVA::GeneticGenes*GetGenes(Int_t index); Int_tGetPopulationSize() const; const vector<TMVA::GeneticRange*>&GetRanges() const; vector<TMVA::GeneticRange*>&GetRanges(); voidGiveHint(vector<Double_t>& hint, Double_t fitness = 0); virtual TClass*IsA() const; voidMakeChildren(); voidMakeCopies(int number); voidMutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); voidNextGeneration(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t seed = 0); the random seed of the random generator. void MakeCopies(int number); produces offspring which is are copies of their parents; Parameters:; int number : the number of the last individual to be copied. void MakeChildren(); does what the name says,... it creates children out of members of the; current generation; ",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticPopulation.html:2065,Testability,log,logger,2065,"lass*IsA() const; voidMakeChildren(); voidMakeCopies(int number); voidMutate(Double_t probability = 20, Int_t startIndex = 0, Bool_t near = kFALSE, Double_t spread = 0.1, Bool_t mirror = kFALSE); voidNextGeneration(); TMVA::GeneticPopulation&operator=(const TMVA::GeneticPopulation&); voidPrint(Int_t untilIndex = -1); voidPrint(ostream& out, Int_t utilIndex = -1); voidSetRandomSeed(UInt_t seed = 0); virtual voidShowMembers(TMemberInspector& insp); voidSort(); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); voidTrimPopulation(); vector<Double_t>VariableDistribution(Int_t varNumber); TH1F*VariableDistribution(Int_t varNumber, Int_t bins, Int_t min, Int_t max). private:. TMVA::MsgLogger&Log() const; TMVA::GeneticGenesMakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female). Data Members; private:. vector<TMVA::GeneticGenes>fGenePoolthe ""genePool"" where the individuals of the current generation are stored; TMVA::MsgLogger*fLoggermessage logger; Int_tfPopulationSizeLimit; TRandom3*fRandomGeneratorrandom Generator for this population; vector<TMVA::GeneticRange*>fRangescontains the ranges inbetween the values of the coefficients have to be. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticPopulation(const vector<TMVA::Interval*>& ranges, Int_t size, UInt_t seed = 0); Constructor. ~GeneticPopulation(); destructor. void SetRandomSeed(UInt_t seed = 0); the random seed of the random generator. void MakeCopies(int number); produces offspring which is are copies of their parents; Parameters:; int number : the number of the last individual to be copied. void MakeChildren(); does what the name says,... it creates children out of members of the; current generation; children have a combination of the coefficients of their parents. TMVA::GeneticGenes MakeSex(TMVA::GeneticGenes male, TMVA::GeneticGenes female); this function takes two individuals and produces offspring by mixing (recombining) their; coefficients. v",MatchSource.WIKI,root/html532/TMVA__GeneticPopulation.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticPopulation.html
https://root.cern/root/html532/TMVA__GeneticRange.html:1352,Modifiability,Inherit,Inheritance,1352,"eneticRange(); static TClass*Class(); TMVA::GeneticRangeGeneticRange(const TMVA::GeneticRange&); TMVA::GeneticRangeGeneticRange(TRandom3* rnd, TMVA::Interval* interval); Double_tGetFrom(); Double_tGetTo(); Double_tGetTotalLength(); virtual TClass*IsA() const; TMVA::GeneticRange&operator=(const TMVA::GeneticRange&); Double_tRandom(Bool_t near = kFALSE, Double_t value = 0, Double_t spread = 0.1, Bool_t mirror = kFALSE); Double_tRandomDiscrete(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. Double_tReMap(Double_t val); Double_tReMapMirror(Double_t val). Data Members; private:. Double_tfFrom; TMVA::Interval*fIntervalholds the complete information of the interval; Int_tfNbins; TRandom3*fRandomGeneratorthe randomGenerator for calculating the new values; Double_tfTothe constraints of the coefficient; Double_tfTotalLengththe distance between the lower and upper constraints. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticRange(TRandom3* rnd, TMVA::Interval* interval); defines the ""f"" (from) and ""t"" (to) of the coefficient; and takes a randomgenerator. Double_t RandomDiscrete(); creates a new random value for the coefficient; returns a discrete value. Double_t Random(Bool_t near = kFALSE, Double_t value = 0, Double_t spread = 0.1, Bool_t mirror = kFALSE); creates a new random value for the coefficient; Parameters:; Bool_t near : takes a random value near the current value; double value : this is the current value; double spread : the sigma of the gaussian which is taken to calculate the new value; Bool_t mirror : if the new value would be outside of the range, mirror = false; maps the value between the constraints by periodic boundary conditions.; With mirror = true, the value gets ""reflected"" on the boundaries. Double_t ReMap(Double_t val); remapping the value to the allowed space. Double_t ReMapMirror(Double_t val); remapping the value to the a",MatchSource.WIKI,root/html532/TMVA__GeneticRange.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticRange.html
https://root.cern/root/html532/TMVA__GeneticRange.html:1365,Modifiability,Inherit,Inherited,1365,"eneticRange(); static TClass*Class(); TMVA::GeneticRangeGeneticRange(const TMVA::GeneticRange&); TMVA::GeneticRangeGeneticRange(TRandom3* rnd, TMVA::Interval* interval); Double_tGetFrom(); Double_tGetTo(); Double_tGetTotalLength(); virtual TClass*IsA() const; TMVA::GeneticRange&operator=(const TMVA::GeneticRange&); Double_tRandom(Bool_t near = kFALSE, Double_t value = 0, Double_t spread = 0.1, Bool_t mirror = kFALSE); Double_tRandomDiscrete(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. Double_tReMap(Double_t val); Double_tReMapMirror(Double_t val). Data Members; private:. Double_tfFrom; TMVA::Interval*fIntervalholds the complete information of the interval; Int_tfNbins; TRandom3*fRandomGeneratorthe randomGenerator for calculating the new values; Double_tfTothe constraints of the coefficient; Double_tfTotalLengththe distance between the lower and upper constraints. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; GeneticRange(TRandom3* rnd, TMVA::Interval* interval); defines the ""f"" (from) and ""t"" (to) of the coefficient; and takes a randomgenerator. Double_t RandomDiscrete(); creates a new random value for the coefficient; returns a discrete value. Double_t Random(Bool_t near = kFALSE, Double_t value = 0, Double_t spread = 0.1, Bool_t mirror = kFALSE); creates a new random value for the coefficient; Parameters:; Bool_t near : takes a random value near the current value; double value : this is the current value; double spread : the sigma of the gaussian which is taken to calculate the new value; Bool_t mirror : if the new value would be outside of the range, mirror = false; maps the value between the constraints by periodic boundary conditions.; With mirror = true, the value gets ""reflected"" on the boundaries. Double_t ReMap(Double_t val); remapping the value to the allowed space. Double_t ReMapMirror(Double_t val); remapping the value to the a",MatchSource.WIKI,root/html532/TMVA__GeneticRange.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GeneticRange.html
https://root.cern/root/html532/TMVA__GiniIndex.html:1562,Availability,down,down,1562,"Index: public TMVA::SeparationBase. Implementation of the GiniIndex as separation criterion. Function Members (Methods); public:. virtual~GiniIndex(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexGiniIndex(); TMVA::GiniIndexGiniIndex(const TMVA::GiniIndex& g); virtual TClass*IsA() const; TMVA::GiniIndex&operator=(const TMVA::GiniIndex&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; for just Signal and Background classes this boils down to:; Gini(Sample) = 2s*b/(s+b)^2 ( = 2 * purity * (1-purity) ). !! what we use here is 2*Gini.. as for the later use the factor; 2 is irrelevant and hence I'd like to save this calculation. GiniIndex(); construtor for the GiniIndex. { fName=""Gini""; }. GiniIndex(const TMVA::GiniIndex& g); copy constructor. {}. virtual ~GiniIndex(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndex.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GiniIndex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndex.html
https://root.cern/root/html532/TMVA__GiniIndex.html:1159,Modifiability,Inherit,Inheritance,1159,"tion members; data members; class charts. ROOT; » TMVA; » TMVA::GiniIndex. class TMVA::GiniIndex: public TMVA::SeparationBase. Implementation of the GiniIndex as separation criterion. Function Members (Methods); public:. virtual~GiniIndex(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexGiniIndex(); TMVA::GiniIndexGiniIndex(const TMVA::GiniIndex& g); virtual TClass*IsA() const; TMVA::GiniIndex&operator=(const TMVA::GiniIndex&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; for just Signal and Background classes this boils down to:; Gini(Sample) = 2s*b/(s+b)^2 ( = 2 * purity * (1-purity) ). !! what we use here is 2*Gini.. as for the later use the factor; 2 is irrelevant and hence I'd like to save this calculation. GiniIndex(); construtor for the GiniIndex. { fName=""Gini""; }. GiniIndex(const TMVA::GiniIndex& g); copy constructor. {}. virtual ~GiniIndex(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndex.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or sugge",MatchSource.WIKI,root/html532/TMVA__GiniIndex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndex.html
https://root.cern/root/html532/TMVA__GiniIndex.html:1172,Modifiability,Inherit,Inherited,1172,"tion members; data members; class charts. ROOT; » TMVA; » TMVA::GiniIndex. class TMVA::GiniIndex: public TMVA::SeparationBase. Implementation of the GiniIndex as separation criterion. Function Members (Methods); public:. virtual~GiniIndex(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexGiniIndex(); TMVA::GiniIndexGiniIndex(const TMVA::GiniIndex& g); virtual TClass*IsA() const; TMVA::GiniIndex&operator=(const TMVA::GiniIndex&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; for just Signal and Background classes this boils down to:; Gini(Sample) = 2s*b/(s+b)^2 ( = 2 * purity * (1-purity) ). !! what we use here is 2*Gini.. as for the later use the factor; 2 is irrelevant and hence I'd like to save this calculation. GiniIndex(); construtor for the GiniIndex. { fName=""Gini""; }. GiniIndex(const TMVA::GiniIndex& g); copy constructor. {}. virtual ~GiniIndex(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndex.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or sugge",MatchSource.WIKI,root/html532/TMVA__GiniIndex.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndex.html
https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html:1761,Availability,down,down,1761,"criterion. Function Members (Methods); public:. virtual~GiniIndexWithLaplace(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); virtual TClass*IsA() const; TMVA::GiniIndexWithLaplace&operator=(const TMVA::GiniIndexWithLaplace&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; Laplace's correction to the prob.density c/N --> (c+1)/(N+2); for just Signal and Background classes this then boils down to:; Gini(Sample) = 2(s*b+s+b+1)/(s+b+2)^2. GiniIndexWithLaplace(); construtor for the GiniIndexWithLaplace. { fName=""GiniLaplace""; }. GiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); copy constructor. {}. virtual ~GiniIndexWithLaplace(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndexWithLaplace.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__GiniIndexWithLaplace.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html
https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html:1291,Modifiability,Inherit,Inheritance,1291,"ublic TMVA::SeparationBase. Implementation of the GiniIndexWithLaplace as separation criterion. Function Members (Methods); public:. virtual~GiniIndexWithLaplace(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); virtual TClass*IsA() const; TMVA::GiniIndexWithLaplace&operator=(const TMVA::GiniIndexWithLaplace&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; Laplace's correction to the prob.density c/N --> (c+1)/(N+2); for just Signal and Background classes this then boils down to:; Gini(Sample) = 2(s*b+s+b+1)/(s+b+2)^2. GiniIndexWithLaplace(); construtor for the GiniIndexWithLaplace. { fName=""GiniLaplace""; }. GiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); copy constructor. {}. virtual ~GiniIndexWithLaplace(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndexWithLaplace.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions",MatchSource.WIKI,root/html532/TMVA__GiniIndexWithLaplace.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html
https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html:1304,Modifiability,Inherit,Inherited,1304,"ublic TMVA::SeparationBase. Implementation of the GiniIndexWithLaplace as separation criterion. Function Members (Methods); public:. virtual~GiniIndexWithLaplace(); static TClass*Class(); const TString&TMVA::SeparationBase::GetName(); Double_tTMVA::SeparationBase::GetSeparationGain(const Double_t& nSelS, const Double_t& nSelB, const Double_t& nTotS, const Double_t& nTotB); virtual Double_tGetSeparationIndex(const Double_t& s, const Double_t& b); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(); TMVA::GiniIndexWithLaplaceGiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); virtual TClass*IsA() const; TMVA::GiniIndexWithLaplace&operator=(const TMVA::GiniIndexWithLaplace&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Data Members; protected:. TStringTMVA::SeparationBase::fNamename of the concrete Separation Index impementation; Double_tTMVA::SeparationBase::fPrecisionCut. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Double_t GetSeparationIndex(const Double_t& s, const Double_t& b); Gini(Sample M) = 1 - (c(1)/N)^2 - (c(2)/N)^2 .... - (c(k)/N)^2; Where: M is a smaple of whatever N elements (events); that belong to K different classes; c(k) is the number of elements that belong to class k; Laplace's correction to the prob.density c/N --> (c+1)/(N+2); for just Signal and Background classes this then boils down to:; Gini(Sample) = 2(s*b+s+b+1)/(s+b+2)^2. GiniIndexWithLaplace(); construtor for the GiniIndexWithLaplace. { fName=""GiniLaplace""; }. GiniIndexWithLaplace(const TMVA::GiniIndexWithLaplace& g); copy constructor. {}. virtual ~GiniIndexWithLaplace(); destructor. {}. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: GiniIndexWithLaplace.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions",MatchSource.WIKI,root/html532/TMVA__GiniIndexWithLaplace.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__GiniIndexWithLaplace.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:522,Availability,avail,available,522,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:309,Integrability,Interface,Interface,309,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:350,Integrability,interface,interface,350,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:935,Modifiability,Inherit,Inheritance,935,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IFitterTarget.html:948,Modifiability,Inherit,Inherited,948,". TMVA::IFitterTarget. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IFitterTarget. class TMVA::IFitterTarget. IFitterTarget. Interface for a fitter 'target'. Defines interface to the estimator; function. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IFitterTarget(); static TClass*Class(); virtual Double_tEstimatorFunction(vector<Double_t>& parameters); virtual TClass*IsA() const; TMVA::IFitterTarget&operator=(const TMVA::IFitterTarget&); virtual voidProgressNotifier(TString, TString); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IFitterTarget(); {}. Double_t EstimatorFunction(vector<Double_t>& parameters). void ProgressNotifier(TString , TString ); function to notify the FitterTarget of the progress status of the fitter; sender : ""GA"", ""MC"", ...; progress : ""init"", ""iteration"", ""last"", ""stop"". {}. » Author: Andreas Hoecker, Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IFitterTarget.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IFitterTarget.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IFitterTarget.html
https://root.cern/root/html532/TMVA__IMethod.html:410,Availability,avail,available,410,". TMVA::IMethod. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::IMethod. class TMVA::IMethod. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~IMethod(); static TClass*Class(); virtual const TMVA::Ranking*CreateRanking(); virtual voidDeclareOptions(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*GetName() const; virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method spec",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:1797,Availability,error,error,1797,"es, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from cla",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2006,Energy Efficiency,monitor,monitoring,2006,"hod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automaticall",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2273,Energy Efficiency,Monitor,MonitorBoost,2273,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2257,Integrability,message,message,2257,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:2735,Integrability,message,message,2735,"ual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets). void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void GetHelpMessage() const; get specific help message from classifer. » Author: Andreas Hoecker, Joerg Stelzer, Helge Voss, Kai Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: IMethod.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:1424,Modifiability,Inherit,Inheritance,1424,"al~IMethod(); static TClass*Class(); virtual const TMVA::Ranking*CreateRanking(); virtual voidDeclareOptions(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*GetName() const; virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnaly",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__IMethod.html:1437,Modifiability,Inherit,Inherited,1437,"al~IMethod(); static TClass*Class(); virtual const TMVA::Ranking*CreateRanking(); virtual voidDeclareOptions(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*GetName() const; virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual voidInit(); virtual TClass*IsA() const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; virtual Bool_tMonitorBoost(TMVA::MethodBoost* boost); TMVA::IMethod&operator=(const TMVA::IMethod&); virtual voidPrintHelpMessage() const; virtual voidProcessOptions(); virtual voidReadWeightsFromStream(istream&); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTrain(); virtual voidWriteMonitoringHistosToFile() const. protected:. virtual voidGetHelpMessage() const; virtual voidMakeClassSpecific(ostream&, const TString&) const. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; virtual ~IMethod(); default destructur. {}. const char * GetName() const; ------- virtual member functions to be implemented by each MVA method; the name of the method. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); calculate the MVA value - some methods may return a per-event error estimate (unless: *err = -1). void Train( void ); training method. void ReadWeightsFromStream(istream& ); read weights from output stream. void WriteMonitoringHistosToFile( void ); write method specific monitoring histograms to target file. void MakeClass(const TString& classFileName = TString("""")) const; make ROOT-independent C++ class for classifier response. const Ranking* CreateRanking(); create ranking. void PrintHelpMessage() const; print help message. Bool_t MonitorBoost(TMVA::MethodBoost* boost); perfrom extra actions during the boosting at different stages. void Init(). void DeclareOptions(). void ProcessOptions(). Bool_t HasAnaly",MatchSource.WIKI,root/html532/TMVA__IMethod.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__IMethod.html
https://root.cern/root/html532/TMVA__Interval.html:310,Deployability,continuous,continuous,310,". TMVA::Interval. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Interval. class TMVA::Interval. Interval. Interval definition, continuous and discrete. Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step, min+n*step=max; e.g.: Interval(1,5,5)=1,2,3,4,5; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0. Note: **bin** counting starts from ZERO unlike in ROOT histograms. the TMVA::Interval Class. Interval definition, continuous and discrete; ; Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step=max ; e.g.: Interval(1,5,5)=1,2,3,4,5 ; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discret",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:717,Deployability,continuous,continuous,717,". TMVA::Interval. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::Interval. class TMVA::Interval. Interval. Interval definition, continuous and discrete. Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step, min+n*step=max; e.g.: Interval(1,5,5)=1,2,3,4,5; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0. Note: **bin** counting starts from ZERO unlike in ROOT histograms. the TMVA::Interval Class. Interval definition, continuous and discrete; ; Interval(min,max) : a continous interval [min,max]; Interval(min,max,n): a ""discrete interval"" [min,max], i.e the n numbers:; min, min+step, min+2*step,...., min+(n-1)*step=max ; e.g.: Interval(1,5,5)=1,2,3,4,5 ; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discret",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2023,Deployability,continuous,continuous,2023,".9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2105,Modifiability,Inherit,Inheritance,2105,".8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Interval.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page ",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2118,Modifiability,Inherit,Inherited,2118,".8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Interval.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page ",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2651,Security,access,accessors,2651,"n) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (c) 2005: *; » Last changed: root/tmva $Id: Interval.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:1861,Testability,Log,Log,1861,"n numbers:; min, min+step, min+2*step,...., min+(n-1)*step=max ; e.g.: Interval(1,5,5)=1,2,3,4,5 ; Interval(.5,1.,6)= .5, .6., .7, .8, .9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__Interval.html:2083,Testability,log,logger,2083,".9, 1.0 . Example: Interval(.5,1.,6) ; [ min max ] ; ------------------------------------------------------------; | | | | | |; .5 .6 .7 .8 .9 1.0 ; ; bin 0 1 2 3 4 5 . . Function Members (Methods); public:. virtual~Interval(); static TClass*Class(); Double_tGetElement(Int_t position) const; Double_tGetMax() const; Double_tGetMean() const; Double_tGetMin() const; Int_tGetNbins() const; Double_tGetRndm(TRandom3&) const; Double_tGetStepSize() const; Double_tGetWidth() const; TMVA::IntervalInterval(const TMVA::Interval& other); TMVA::IntervalInterval(Double_t min, Double_t max, Int_t nbins = 0); virtual TClass*IsA() const; TMVA::Interval&operator=(const TMVA::Interval&); voidSetMax(Double_t m); voidSetMin(Double_t m); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; private:. Double_tfMaxthe constraints of the Interval; Double_tfMin; Int_tfNbinswhen >0 : number of bins (discrete interval); when ==0 continuous interval; static TMVA::MsgLogger*fgLoggermessage logger. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Interval(Double_t min, Double_t max, Int_t nbins = 0). Interval(const TMVA::Interval& other). ~Interval(); destructor. Double_t GetElement(Int_t position) const; calculates the value of the ""number"" bin in a discrete interval.; Parameters:; Double_t position. Double_t GetStepSize() const; retuns the step size between the numbers of a ""discrete Interval"". Double_t GetRndm(TRandom3& ) const; get uniformely distributed number within interval. Double_t GetMin() const; accessors. { return fMin; }. Double_t GetMax() const; { return fMax; }. Double_t GetWidth() const; { return fMax - fMin; }. Int_t GetNbins() const; { return fNbins; }. Double_t GetMean() const; { return (fMax + fMin)/2; }. void SetMax(Double_t m); { fMax = m; }. void SetMin(Double_t m); { fMin = m; }. » Author: Peter Speckmayer » Copyright (",MatchSource.WIKI,root/html532/TMVA__Interval.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__Interval.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1292,Energy Efficiency,Adapt,Adaptive,1292,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1894,Energy Efficiency,adapt,adaptive,1894,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2427,Energy Efficiency,adapt,adaptive,2427,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1292,Modifiability,Adapt,Adaptive,1292,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1894,Modifiability,adapt,adaptive,1894,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1967,Modifiability,Inherit,Inheritance,1967,"amerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelze",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1980,Modifiability,Inherit,Inherited,1980,"amerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelze",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2427,Modifiability,adapt,adaptive,2427,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:2273,Safety,sanity check,sanity check,2273,"er { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.). const char* GetName() const; modified name (remove TMVA::). { return ""KDEKernel""; }. » Author: Asen Christov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: KDEKernel.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1044,Testability,Log,Log,1044,"epage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::KDEKernel. class TMVA::KDEKernel. Function Members (Methods); public:. virtual~KDEKernel(); static TClass*Class(); Float_tGetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); const char*GetName() const; virtual TClass*IsA() const; TMVA::KDEKernelKDEKernel(const TMVA::KDEKernel&); TMVA::KDEKernelKDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__KDEKernel.html:1753,Testability,log,logger,1753,"nelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); TMVA::KDEKernel&operator=(const TMVA::KDEKernel&); voidSetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b). private:. TMVA::MsgLogger&Log() const. Data Members; public:. enum EKernelType { kNone; kGauss; };; enum EKernelIter { kNonadaptiveKDE; kAdaptiveKDE; };; enum EKernelBorder { kNoTreatment; kKernelRenorm; kSampleMirror; };. private:. Float_tfFineFactorfine tuning factor for Adaptive KDE: factor to multiply the ""width"" of the Kernel function; TH1F*fFirstIterHisthistogram to be filled in the hidden iteration; Bool_tfHiddenIterationDefines if whats currently running is the ; TH1F*fHistcopy of input histogram; TMVA::KDEKernel::EKernelIterfIteriteration number; TMVA::KDEKernel::EKernelBorderfKDEborderThe method to take care about ""border"" effects; TF1*fKernel_integthe integral of the Kernel function; TMVA::MsgLogger*fLoggermessage logger; Float_tfLowerEdgethe lower edge of the PDF; Float_tfSigmaWidth of the Kernel function; TH1F*fSigmaHistcontains the Sigmas Widths for adaptive KDE ; Float_tfUpperEdgethe upper edge of the PDF. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; KDEKernel(TMVA::KDEKernel::EKernelIter kiter = kNonadaptiveKDE, const TH1* hist = 0, Float_t lower_edge = 0., Float_t upper_edge = 1., TMVA::KDEKernel::EKernelBorder kborder = kNoTreatment, Float_t FineFactor = 1.); constructor; sanity check. ~KDEKernel(); destructor. void SetKernelType(TMVA::KDEKernel::EKernelType ktype = kGauss); fIter == 1 ---> nonadaptive KDE; fIter == 2 ---> adaptive KDE. Float_t GetBinKernelIntegral(Float_t lowr, Float_t highr, Float_t mean, Int_t binnum); calculates the integral of the Kernel. KDEKernel(TMVA::KDEKernel::EKernel",MatchSource.WIKI,root/html532/TMVA__KDEKernel.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__KDEKernel.html
https://root.cern/root/html532/TMVA__kNN__Event.html:1633,Energy Efficiency,charge,charge,1633,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:2006,Energy Efficiency,Charge,Charge,2006,TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:1172,Modifiability,variab,variable,1172,; function members; data members; class charts. ROOT; » TEST; » TMVA::kNN::Event. class TMVA::kNN::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //N,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:2896,Modifiability,variab,variables,2896,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); TMVA::kNN::EventEvent(); TMVA::kNN::EventEvent(const TMVA::kNN::Event&); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4365,Modifiability,variab,variables,4365,"t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4435,Modifiability,Inherit,Inheritance,4435,"::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const. void Print(ostream& os) const. VarType GetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const. inlined functions for Event class. VarType G",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4448,Modifiability,Inherit,Inherited,4448,"::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const. void Print(ostream& os) const. VarType GetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const. inlined functions for Event class. VarType G",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:4616,Modifiability,variab,variable,4616,"onst TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA::kNN::VarTypeGetVar(const UInt_t i) const; const TMVA::kNN::VarVec&GetVars() const; Double_tGetWeight() const; TMVA::kNN::Event&operator=(const TMVA::kNN::Event&); voidPrint() const; voidPrint(ostream& os) const; voidSetTargets(const TMVA::kNN::VarVec& tvec). Data Members; private:. TMVA::kNN::VarVecfTgttargets for regression analysis; Short_tfTypeevent type ==0 or == 1, expand it to arbitrary class types? ; TMVA::kNN::VarVecfVarcoordinates (variables) for knn search; Double_tfWeightevent weight. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; Event(); Create an Event object.; When the constructor is invoked for the first time, the class static; variable fgTracks is 0 and the TClonesArray fgTracks is created. ~Event(). Event(). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type). Event(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec). Double_t GetWeight() const. VarType GetVar(UInt_t i) const. VarType GetTgt(UInt_t i) const. UInt_t GetNVar() const. UInt_t GetNTgt() const. Short_t GetType() const. VarType GetDist(TMVA::kNN::VarType var, UInt_t ivar) const; keep these two function separate. VarType GetDist(const TMVA::kNN::Event& other) const. void SetTargets(const TMVA::kNN::VarVec& tvec). const VarVec& GetTargets() const. const VarVec& GetVars() const. void Print() const. void Print(ostream& os) const. VarType GetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const. inlined functions for Event class. VarType GetVar(const UInt_t i) const. VarType GetTgt(const UInt_t i) const. » Author: Rustem Ospanov » Copyright (c) 2007: *; » Last changed: root/tmva $Id: Mod",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:2917,Performance,perform,performance,2917,"he first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharge; //Charge of this track; Double32_t fVertex[3]; //Track vertex position; Int_t fNpoint; //Number of points for this track; Short_t fValid; //Validity criterion; Int_t fNsp; //Number of points for this track with a special value; Double32_t *fPointValue; //[fNsp] a special quantity for some point.; TBits fTriggerBits; //Bits triggered by this track. An example of a batch program to use the Event/Track classes is given; in this directory: MainEvent.; Look also in the same directory at the following macros:; - eventa.C an example how to read the tree; - eventb.C how to read events conditionally. During the processing of the event (optionally) also a large number; of histograms can be filled. The creation and handling of the; histograms is taken care of by the HistogramManager class. Note: This version of the class Event (see EventMT.h and EventMT.cxx; for an alternative) uses static variables to improve performance (by; reducing the number of memory allocations). Consequently, only one; instance of the class Event should be in use at a time (a 2nd instance; would share the array of Tracks with the first instance). Function Members (Methods); public:. ~Event(); TMVA::kNN::EventEvent(); TMVA::kNN::EventEvent(const TMVA::kNN::Event&); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type); TMVA::kNN::EventEvent(const TMVA::kNN::VarVec& vec, Double_t weight, Short_t type, const TMVA::kNN::VarVec& tvec); TMVA::kNN::VarTypeGetDist(const TMVA::kNN::Event& other) const; TMVA::kNN::VarTypeGetDist(TMVA::kNN::VarType var, UInt_t ivar) const; TMVA::kNN::VarTypeGetDist(const TMVA::kNN::VarType var1, const UInt_t ivar) const; UInt_tGetNTgt() const; UInt_tGetNVar() const; const TMVA::kNN::VarVec&GetTargets() const; TMVA::kNN::VarTypeGetTgt(UInt_t i) const; TMVA::kNN::VarTypeGetTgt(const UInt_t i) const; Short_tGetType() const; TMVA::kNN::VarTypeGetVar(UInt_t i) const; TMVA",MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:235,Testability,TEST,TEST,235,. TMVA::kNN::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::kNN::Event. class TMVA::kNN::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharg,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__kNN__Event.html:337,Usability,simpl,simple,337,. TMVA::kNN::Event. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TEST; » TMVA::kNN::Event. class TMVA::kNN::Event. Event and Track classes. The Event class is a naive/simple example of an event structure.; public:; char fType[20];; char *fEventName; //run+event number in character format; Int_t fNtrack;; Int_t fNseg;; Int_t fNvertex;; UInt_t fFlag;; Double32_t fTemperature;; Int_t fMeasures[10];; Double32_t fMatrix[4][4];; Double32_t *fClosestDistance; //[fNvertex] indexed array!; EventHeader fEvtHdr;; TClonesArray *fTracks;; TRefArray *fHighPt; //array of High Pt tracks only; TRefArray *fMuons; //array of Muon tracks only; TRef fLastTrack; //pointer to last track; TRef fHistoWeb; //EXEC:GetHistoWeb reference to an histogram in a TWebFile; TH1F *fH;; TBits fTriggerBits; //Bits triggered by this event. The EventHeader class has 3 data members (integers):; public:; Int_t fEvtNum;; Int_t fRun;; Int_t fDate;. The Event data member fTracks is a pointer to a TClonesArray.; It is an array of a variable number of tracks per event.; Each element of the array is an object of class Track with the members:; private:; Float_t fPx; //X component of the momentum; Float_t fPy; //Y component of the momentum; Float_t fPz; //Z component of the momentum; Float_t fRandom; //A random track quantity; Float_t fMass2; //The mass square of this particle; Float_t fBx; //X intercept at the vertex; Float_t fBy; //Y intercept at the vertex; Float_t fMeanCharge; //Mean charge deposition of all hits of this track; Float_t fXfirst; //X coordinate of the first point; Float_t fXlast; //X coordinate of the last point; Float_t fYfirst; //Y coordinate of the first point; Float_t fYlast; //Y coordinate of the last point; Float_t fZfirst; //Z coordinate of the first point; Float_t fZlast; //Z coordinate of the last point; Double32_t fCharg,MatchSource.WIKI,root/html532/TMVA__kNN__Event.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__kNN__Event.html
https://root.cern/root/html532/TMVA__MCFitter.html:1402,Availability,Error,Error,1402,"al~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObje",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:1606,Availability,error,error,1606,"t::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetT",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:1690,Availability,error,error,1690,"c TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::Han",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7654,Deployability,configurat,configuration,7654," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:485,Modifiability,Config,Configurable,485," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:643,Modifiability,Config,Configurable,643," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:929,Modifiability,Config,ConfigurableTMVA,929," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:947,Modifiability,Config,Configurable,947," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:961,Modifiability,Config,Configurable,961," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:1985,Modifiability,Config,Configurable,1985,"eOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() const",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:2046,Modifiability,Config,Configurable,2046,"st; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA()",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:2543,Modifiability,Config,Configurable,2543,"::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidT",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:2852,Modifiability,Inherit,InheritsFrom,2852,"t*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp)",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:2918,Modifiability,Inherit,InheritsFrom,2918,"ject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator ne",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4158,Modifiability,Config,Configurable,4158,"_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4283,Modifiability,Config,Configurable,4283,":ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniq",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4375,Modifiability,Config,Configurable,4375,"FitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuf",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4437,Modifiability,Config,Configurable,4437,"e, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4860,Modifiability,Config,Configurable,4860,"TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:4921,Modifiability,Config,Configurable,4921,"size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ost",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:5083,Modifiability,Config,Configurable,5083,"erator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:5185,Modifiability,Config,Configurable,5185,"erator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:5890,Modifiability,Config,Configurable,5890,"erator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6087,Modifiability,Config,Configurable,6087,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6159,Modifiability,Config,Configurable,6159,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6258,Modifiability,Config,Configurable,6258,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6345,Modifiability,Config,Configurable,6345,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6385,Modifiability,Config,Configurable,6385,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7342,Modifiability,Inherit,Inheritance,7342," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7355,Modifiability,Inherit,Inherited,7355," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:7654,Modifiability,config,configuration,7654," b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:2742,Security,Hash,Hash,2742,"ent, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); TMVA::IFitterTarget&TMVA::FitterBase::GetFitterTarget() const; virtual const char*TObject::GetIconName() const; virtual const char*TMVA::FitterBase::GetName() const; Int_tTMVA::FitterBase::GetNpars() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual const char*TObject::GetTitle() const; virtual UInt_tTObject::GetUniqueID() const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual ULong_tTObject::Hash() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; voidTObject::MayNotUse(const char* method) const; TMVA::MCFitterMCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void*",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:5517,Testability,Test,TestBit,5517,"erator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:5556,Testability,Test,TestBits,5556,"erator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TObject&TObject::operator=(const TObject& rhs); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; voidTMVA::Configurable::PrintOptions() const; virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); virtual voidTObject::RecursiveRemove(TObject* obj); voidTObject::ResetBit(UInt_t f); virtual Double_tRun(vector<Double_t>& pars); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const.",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6233,Testability,Log,Log,6233,"ptions(const TString& s); voidSetParameters(Int_t cycles); virtual voidTObject::SetUniqueID(UInt_t uid); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seed",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:6966,Testability,log,logger,6966,"tream& o, const TString& prefix) const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::Configurable::GetReferenceFile() const; TMVA::MsgLogger&TMVA::FitterBase::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(). Data Members; public:. enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. protected:. TStringTMVA::FitterBase::fClassNameremove TMVA:: from TObject name; TMVA::IFitterTarget&TMVA::FitterBase::fFitterTargetpointer to target of fitting procedure; TMVA::MsgLogger*TMVA::FitterBase::fLoggermessage logger; Int_tTMVA::FitterBase::fNparsnumber of parameters; const vector<TMVA::Interval*>TMVA::FitterBase::fRangesallowed intervals. private:. Int_tfSamplesnumber of MC samples; UInt_tfSeedSeed for the random generator (0 takes random seeds); Double_tfSigmanew samples are generated randomly with a gaussian probability with fSigma around the current best value. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MCFitter(TMVA::IFitterTarget& target, const TString& name, const vector<TMVA::Interval*>& ranges, const TString& theOption); constructor. void DeclareOptions(); Declare MCFitter options. void SetParameters(Int_t cycles); set MC fitter configuration parameters. Double_t Run(vector<Double_t>& pars); Execute fitting. virtual ~MCFitter(); {}. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss » Copyright (c) 2005: *; » Last changed: root/tmva $Id: MCFitter.h 40005 2011-06-27 15:29:10Z st",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MCFitter.html:779,Usability,Clear,Clear,779," virtual~MCFitter(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual voidTObject::Delete(Option_t* option = """")MENU ; virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; Double_tTMVA::FitterBase::EstimatorFunction(vector<Double_t>& parameters); virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; const char*TMVA::Configurable::Ge",MatchSource.WIKI,root/html532/TMVA__MCFitter.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MCFitter.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:519,Availability,avail,available,519,". TMVA::MethodANNBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodANNBase. class TMVA::MethodANNBase: public TMVA::MethodBase. Base class for all TMVA methods using artificial neural networks. Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2204,Availability,Error,Error,2204,"al TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMV",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2333,Availability,error,error,2333,"rableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2417,Availability,error,error,2417,"bject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:8234,Energy Efficiency,Monitor,MonitorBoost,8234,"::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTMVA::MethodBase::Init(); voidInitANNBase(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual v",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16525,Energy Efficiency,monitor,monitoring,16525,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16594,Energy Efficiency,monitor,monitoring,16594,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16659,Energy Efficiency,monitor,monitoring,16659,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14610,Integrability,message,message,14610,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17612,Integrability,depend,depending,17612,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:20582,Integrability,message,message,20582," Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ra",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:20627,Integrability,message,messages,20627," Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ra",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:643,Modifiability,Config,Configurable,643," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:999,Modifiability,Config,Configurable,999," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:1329,Modifiability,Config,ConfigurableTMVA,1329," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:1347,Modifiability,Config,Configurable,1347," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:1361,Modifiability,Config,Configurable,1361," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2781,Modifiability,Config,Configurable,2781,"ase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TString&TMVA::MethodBase::GetJobName() const; virtual Double_tTMVA::MethodBase::GetMaximumSign",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:2842,Modifiability,Config,Configurable,2842,"tancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TString&TMVA::MethodBase::GetJobName() const; virtual Double_tTMVA::MethodBase::GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Do",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:4851,Modifiability,Config,Configurable,4851,"optimal_significance_value) const; Double_tTMVA::MethodBase::GetMean(Int_t ivar) const; const TString&TMVA::MethodBase::GetMethodName() const; TMVA::Types::EMVATMVA::MethodBase::GetMethodType() const; TStringTMVA::MethodBase::GetMethodTypeName() const; virtual vector<Float_t>TMVA::MethodBase::GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity); virtual vector<Float_t>TMVA::MethodBase::GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity); virtual const vector<Float_t>&GetMulticlassValues(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*TMVA::MethodBase::GetName() const; UInt_tTMVA::MethodBase::GetNEvents() const; UInt_tTMVA::MethodBase::GetNTargets() const; UInt_tTMVA::MethodBase::GetNvar() const; UInt_tTMVA::MethodBase::GetNVariables() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual Double_tTMVA::MethodBase::GetProba(Double_t mvaVal, Double_t ap_sig); const TStringTMVA::MethodBase::GetProbaName() const; virtual Double_tTMVA::MethodBase::GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; virtual voidTMVA::MethodBase::GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const; virtual const vector<Float_t>&GetRegressionValues(); Double_tTMVA::MethodBase::GetRMS(Int_t ivar) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TH1F* histS, TH1F* histB) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; virtual Double_tTMVA::MethodBase::GetSeparation(TH1*, TH1*) const; virtual Double_tTMVA::MethodBase::GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; Double_tTMVA::MethodBase::GetSignalReferenceCut() const; Double_tTMVA::MethodBase::GetSignalReferenceCutOrientation() const; ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:7370,Modifiability,Inherit,InheritsFrom,7370,"TrainingROOTVersionString() const; UInt_tTMVA::MethodBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTMVA::MethodBase::Init(); voidInitANNBase(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:7436,Modifiability,Inherit,InheritsFrom,7436,"ningTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTMVA::MethodBase::Init(); voidInitANNBase(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:9061,Modifiability,Config,Configurable,9061,"ssFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual voidPrintNetwork() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject:",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:9276,Modifiability,Config,Configurable,9276,"TObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual voidPrintNetwork() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActiva",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:9436,Modifiability,Config,Configurable,9436," ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual voidPrintNetwork() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); void",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:9498,Modifiability,Config,Configurable,9498,"); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual voidPrintNetwork() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:10523,Modifiability,Config,Configurable,10523,"L(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:10584,Modifiability,Config,Configurable,10584,"dTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid)",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:10936,Modifiability,Config,Configurable,10936,"TransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClass",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11105,Modifiability,Config,Configurable,11105,"aveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetActivation(TMVA::TActivation* activation); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT,",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:12730,Modifiability,Config,Configurable,12730,"* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:13170,Modifiability,Config,Configurable,13170,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:13655,Modifiability,Config,Configurable,13655,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14162,Modifiability,Config,Configurable,14162,"::Configurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14201,Modifiability,Config,Configurable,14201,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14573,Modifiability,layerS,layerSpec,14573,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14659,Modifiability,Config,Configurable,14659,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:15128,Modifiability,Config,Configurable,15128,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16296,Modifiability,layers,layers,16296,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16952,Modifiability,layers,layers,16952,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17089,Modifiability,variab,variables,17089,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17302,Modifiability,variab,variable,17302,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:17604,Modifiability,layers,layers,17604,"TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHessianzjh; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18604,Modifiability,Inherit,Inheritance,18604,"mator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18617,Modifiability,Inherit,Inherited,18617,"mator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18939,Modifiability,variab,variables,18939,"t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19021,Modifiability,layers,layers,19021,"t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19222,Modifiability,layerS,layerSpec,19222," fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19834,Modifiability,layers,layers,19834,"s valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for each input neuron. void ForceNetworkCalculations(); calculate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:21644,Modifiability,variab,variables,21644,"ges, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeurons.at(index); }. » Author: Andreas Hoecker, Peter Speckmayer, Matt Jachowski, Jan Therhaag » Copyright (c) 2",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:8906,Performance,Optimiz,OptimizeTuningParameters,8906,"st; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; virtual voidPrintNetwork() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* wghtnode); virtual voidTObject::RecursiveRemove(TObject* obj); voidTM",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11530,Performance,tune,tuneParameters,11530,"SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:7216,Security,Hash,Hash,7216," TMVA::Event*TMVA::MethodBase::GetTrainingEvent(Long64_t ievt) const; UInt_tTMVA::MethodBase::GetTrainingROOTVersionCode() const; TStringTMVA::MethodBase::GetTrainingROOTVersionString() const; UInt_tTMVA::MethodBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidTMVA::MethodBase::Init(); voidInitANNBase(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; virtual Bool_tTMV",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18278,Security,access,access,18278,"ase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:18544,Security,access,access,18544,"ase::fNbinsMVAoutputnumber of bins in MVA output histograms; TObjArray*fNetworkTObjArray of TObjArrays representing network; TMVA::TActivation*fOutputactivation function to be used for output layers, depending on estimator; Int_tfRandomSeedrandom seed for initial synapse weights; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; vector<Int_t>fRegulatorIdxindex to different priors from every synapses; vector<Double_t>fRegulatorsthe priors as regulator; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class; TObjArray*fSynapsesarray of pointers to synapses, no structural data; boolfUseRegulatorzjh; TRandom3*frgenrandom number generator for various uses. private:. TObjArray*fInputLayercache this for fast access; TStringfLayerSpeclayout specification option; Int_tfNcyclesnumber of epochs to train; TStringfNeuronInputTypename of neuron input calculator class; TStringfNeuronTypename of neuron activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:22344,Security,access,accessors,22344,"d PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeurons.at(index); }. » Author: Andreas Hoecker, Peter Speckmayer, Matt Jachowski, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodANNBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11332,Testability,test,testTime,11332,"nalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11839,Testability,Test,TestBit,11839,"TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFi",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11878,Testability,Test,TestBits,11878,"* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11934,Testability,Test,TestClassification,11934,"* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:11986,Testability,Test,TestMulticlass,11986,"* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:12034,Testability,Test,TestRegression,12034,"* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:14176,Testability,Log,Log,14176,"onfigurable::EnableLooseOptions(Bool_t b = kTRUE); voidForceNetworkCalculations(); voidForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); virtual voidTMVA::IMethod::GetHelpMessage() const; TMVA::TNeuron*GetInputNeuron(Int_t index); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; Double_tGetNetworkOutput(); const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; TMVA::TNeuron*GetOutputNeuron(Int_t index = 0); const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); Int_tNumCycles(); vector<Int_t>*ParseLayoutString(TString layerSpec); voidPrintMessage(TString message, Bool_t force = kFALSE) const; voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidWaitForKeyboard(); voidTMVA::Configurable::WriteOptionsReferenceToFile().",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16164,Testability,test,testing,16164,"A::Configurable::WriteOptionsReferenceToFile(). private:. voidAddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); voidBuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); voidBuildLayers(vector<Int_t>* layout, Bool_t from_file = false); voidDeleteNetwork(); voidDeleteNetworkLayer(TObjArray*& layer); voidForceWeights(vector<Double_t>* weights); voidInitWeights(); voidPrintLayer(TObjArray* layer) const; voidPrintNeuron(TMVA::TNeuron* neuron) const. Data Members; public:. enum EEstimator { kMSE; kCE; };; enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::TActivation*fActivationactivation function to be used for hidden layers; TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TH1*>fEpochMonHistBepoch monitoring hitograms for background; vector<TH1*>fEpochMonHistSepoch monitoring hitograms for signal; vector<TH1*>fEpochMonHistWepoch monitoring hitograms for weights; TMVA::MethodANNBase::EEstimatorfEstimator; TH1F*fEstimatorHistTestmonitors convergence of independent test sample; TH1F*fEstimatorHistTrainmonitors convergence of training sample; TStringfEstimatorS; TMVA::TActivation*fIdentityactivation for input and output layers; TMVA::TNeuronInput*fInputCalculatorinput calculator for all neurons; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; TMatrixDfInvHe",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:16795,Testability,test,test,16795,,MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:1179,Usability,Clear,Clear,1179," virtual~MethodANNBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; Bool_tDebug() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Dr",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:19472,Usability,clear,clear,19472,"on activation function class; vector<TNeuron*>fOutputNeuronscache this for fast access; static const Bool_tfgDEBUGdebug flag. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; void DeclareOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: NCycles=xx :the number of training cycles; Normalize=kTRUE,kFALSe :if normalised in put variables should be used; HiddenLayser=""N-1,N-2"" :the specification of the hidden layers; NeuronType=sigmoid,tanh,radial,linar : the type of activation function; used at the neuronn. void ProcessOptions(); do nothing specific at this moment. vector<Int_t>* ParseLayoutString(TString layerSpec); parse layout specification string and return a vector, each entry; containing the number of neurons to go in each successive layer. void InitANNBase(); initialize ANNBase object. ~MethodANNBase(); destructor. void DeleteNetwork(); delete/clear network. void DeleteNetworkLayer(TObjArray*& layer); delete a network layer. void BuildNetwork(vector<Int_t>* layout, vector<Double_t>* weights = NULL, Bool_t fromFile = kFALSE); build network given a layout (number of neurons in each layer); and optional weights array. void BuildLayers(vector<Int_t>* layout, Bool_t from_file = false); build the network layers. void BuildLayer(Int_t numNeurons, TObjArray* curLayer, TObjArray* prevLayer, Int_t layerIndex, Int_t numLayers, Bool_t from_file = false); build a single layer with neurons and synapses connecting this; layer to the previous layer. void AddPreLinks(TMVA::TNeuron* neuron, TObjArray* prevLayer); add synapses connecting a neuron to its preceding layer. void InitWeights(); initialize the synapse weights randomly. void ForceWeights(vector<Double_t>* weights); force the synapse weights. void ForceNetworkInputs(const TMVA::Event* ev, Int_t ignoreIndex = -1); force the input values of the input neurons; force the value for",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodANNBase.html:21519,Usability,clear,clear,21519,"ate input values to each neuron. void PrintMessage(TString message, Bool_t force = kFALSE) const; print messages, turn off printing by setting verbose and debug flag appropriately. void WaitForKeyboard(); wait for keyboard input, for debugging. void PrintNetwork() const; print network representation, for debugging. void PrintLayer(TObjArray* layer) const; print a single layer, for debugging. void PrintNeuron(TMVA::TNeuron* neuron) const; print a neuron, for debugging. Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); get the mva value generated by the NN. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the NN. const std::vector<Float_t> & GetMulticlassValues(); get the multiclass classification values generated by the NN. void AddWeightsXMLTo(void* parent) const; create XML description of ANN classifier. void ReadWeightsFromXML(void* wghtnode); read MLP from xml weight file. void ReadWeightsFromStream(istream& istr); destroy/clear the network then read it back in from the weights file. const TMVA::Ranking* CreateRanking(); compute ranking of input variables by summing function of weights. void CreateWeightMonitoringHists(const TString& bulkname, vector<TH1*>* hv = 0) const. void WriteMonitoringHistosToFile() const; write histograms to file. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. Bool_t Debug() const; who the hell makes such strange Debug flags that even use ""global pointers"".. void SetActivation(TMVA::TActivation* activation); setters for subclasses. void SetNeuronInputCalculator(TMVA::TNeuronInput* inputCalculator). void Train(); this will have to be overridden by every subclass. Double_t GetNetworkOutput(); { return GetOutputNeuron()->GetActivationValue(); }. Int_t NumCycles(); accessors. { return fNcycles; }. TNeuron* GetInputNeuron(Int_t index); { return (TNeuron*)fInputLayer->At(index); }. TNeuron* GetOutputNeuron(Int_t index = 0); { return fOutputNeur",MatchSource.WIKI,root/html532/TMVA__MethodANNBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodANNBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:1973,Availability,avail,available,1973,"of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual vo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3423,Availability,Error,Error,3423,"kSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long6",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3552,Availability,error,error,3552,"al TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3636,Availability,error,error,3636,"pare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*Data() const; TMVA::DataSetInfo&DataInfo() const; virtual voidDeclareCompatibilityOptions(); virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&GetInputLabel(Int_t i) const",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21603,Availability,avail,availabel,21603,"ing phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMul",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30768,Availability,error,error,30768,"t* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMe",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30784,Availability,error,error,30784,"t* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMe",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24399,Deployability,configurat,configuration,24399,"squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:34713,Deployability,update,update,34713," }. void SetBaseDir(TDirectory* methodDir); { fBaseDir = methodDir; }. void SetMethodBaseDir(TDirectory* methodDir); { fMethodBaseDir = methodDir; }. UInt_t GetTrainingTMVAVersionCode() const; the TMVA version can be obtained and checked using; if (GetTrainingTMVAVersionCode()>TMVA_VERSION(3,7,2)) {...}; or; if (GetTrainingROOTVersionCode()>ROOT_VERSION(5,15,5)) {...}. { return fTMVATrainingVersion; }. UInt_t GetTrainingROOTVersionCode() const; { return fROOTTrainingVersion; }. TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true). const TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { retur",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:26328,Energy Efficiency,monitor,monitoring,26328,"void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* buf); reads one line from the input stream; checks for certain keywords and interprets; the line if keywords are found. void CreateMVAPdfs(); Create PDFs of the MVA output variables. Double_t GetProba(Double_t mvaVal, Double_t ap_sig); compute likelihood ratio. Double_t GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; compute rarity:; R(x) = Integrate_[-oo..x] { PDF(x') dx' }; where PDF(x) is the PDF of the classifier's signal or background distribution. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& err); fill background efficiency (resp. rejection) versus signal efficiency plots; returns signal efficiency at background efficiency indicated in theString. Double_t GetTrainingEfficiency(const TString& ). std::vector<Float_t> GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity). std::vector<Float_t> GetMulticlassTr",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:31038,Energy Efficiency,Monitor,MonitorBoost,31038,". Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMeth",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:503,Integrability,depend,depends,503,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21533,Integrability,message,message,21533,"ethods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDevia",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:29056,Integrability,interface,interface,29056,"= 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for train",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:320,Modifiability,Config,Configurable,320,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:1785,Modifiability,variab,variables,1785," at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; public:. virtual~MethodBase(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidAddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidCheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& th",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2094,Modifiability,Config,Configurable,2094,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2365,Modifiability,Config,Configurable,2365,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2677,Modifiability,Config,ConfigurableTMVA,2677,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2695,Modifiability,Config,Configurable,2695,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2709,Modifiability,Config,Configurable,2709,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:3982,Modifiability,Config,Configurable,3982,"rtual voidTObject::Delete(Option_t* option = """")MENU ; voidDisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&GetInputLabel(Int_t i) const; const TString&GetInputTitle(Int_t i) const; const TString&GetInputVar(Int_t i) const; const TString&GetJobName() const; virtual Double_tGetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; Double_tGetMean(Int_t ivar) const; const TString&GetMethodName() const; TMVA::Types::EMVAGetMe",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:4043,Modifiability,Config,Configurable,4043,"sableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tDoMulticlass() const; Bool_tDoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeGetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tGetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*GetEvent() const; const TMVA::Event*GetEvent(const TMVA::Event* ev) const; const TMVA::Event*GetEvent(Long64_t ievt) const; const TMVA::Event*GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&GetInputLabel(Int_t i) const; const TString&GetInputTitle(Int_t i) const; const TString&GetInputVar(Int_t i) const; const TString&GetJobName() const; virtual Double_tGetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; Double_tGetMean(Int_t ivar) const; const TString&GetMethodName() const; TMVA::Types::EMVAGetMethodType() const; TStringGetMethodTypeName() const; virtual v",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:5754,Modifiability,Config,Configurable,5754," virtual Double_tGetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; Double_tGetMean(Int_t ivar) const; const TString&GetMethodName() const; TMVA::Types::EMVAGetMethodType() const; TStringGetMethodTypeName() const; virtual vector<Float_t>GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity); virtual vector<Float_t>GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity); virtual const vector<Float_t>&GetMulticlassValues(); virtual Double_tGetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); Double_tGetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0); virtual const char*GetName() const; UInt_tGetNEvents() const; UInt_tGetNTargets() const; UInt_tGetNvar() const; UInt_tGetNVariables() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual Double_tGetProba(Double_t mvaVal, Double_t ap_sig); const TStringGetProbaName() const; virtual Double_tGetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; virtual voidGetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const; virtual const vector<Float_t>&GetRegressionValues(); Double_tGetRMS(Int_t ivar) const; virtual Double_tGetROCIntegral(TH1F* histS, TH1F* histB) const; virtual Double_tGetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; virtual Double_tGetSeparation(TH1*, TH1*) const; virtual Double_tGetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; Double_tGetSignalReferenceCut() const; Double_tGetSignalReferenceCutOrientation() const; virtual Double_tGetSignificance() const; const TMVA::Event*GetTestingEvent(Long64_t ievt) const; Double_tGetTestTime() const; const TString&GetTestvarName() const; virtual const char*TObject::GetTit",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:7769,Modifiability,Inherit,InheritsFrom,7769,"rtual Double_tGetTrainingEfficiency(const TString&); const TMVA::Event*GetTrainingEvent(Long64_t ievt) const; UInt_tGetTrainingROOTVersionCode() const; TStringGetTrainingROOTVersionString() const; UInt_tGetTrainingTMVAVersionCode() const; TStringGetTrainingTMVAVersionString() const; Double_tGetTrainTime() const; TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringGetWeightFileName() const; Double_tGetXmax(Int_t ivar) const; Double_tGetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tHasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tIsSignalLike(); virtual Bool_tIsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*MethodBaseDir() const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:7835,Modifiability,Inherit,InheritsFrom,7835,"vent*GetTrainingEvent(Long64_t ievt) const; UInt_tGetTrainingROOTVersionCode() const; TStringGetTrainingROOTVersionString() const; UInt_tGetTrainingTMVAVersionCode() const; TStringGetTrainingTMVAVersionString() const; Double_tGetTrainTime() const; TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringGetWeightFileName() const; Double_tGetXmax(Int_t ivar) const; Double_tGetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tHasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tIsSignalLike(); virtual Bool_tIsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*MethodBaseDir() const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTO",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:9315,Modifiability,Config,Configurable,9315," = """") const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*MethodBaseDir() const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* met",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:9478,Modifiability,Config,Configurable,9478," const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configura",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:9620,Modifiability,Config,Configurable,9620," asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:9682,Modifiability,Config,Configurable,9682,"ect::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMeth",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:10415,Modifiability,Config,Configurable,10415,") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:10476,Modifiability,Config,Configurable,10476,"igurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject:",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:10774,Modifiability,Config,Configurable,10774,"ream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& cor",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:10876,Modifiability,Config,Configurable,10876," voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurre",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:12285,Modifiability,Config,Configurable,12285,", Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidWriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:12561,Modifiability,Config,Configurable,12561,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:12788,Modifiability,Config,Configurable,12788,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:13151,Modifiability,Config,Configurable,13151,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:13190,Modifiability,Config,Configurable,13190,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:13619,Modifiability,Config,Configurable,13619,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:13957,Modifiability,Config,Configurable,13957,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:16070,Modifiability,variab,variables,16070,"(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 if Sig>Bkg, -1 otherwise; TMVA::DataSetInfo&fDataSetInfo! the data set information (sometimes needed); TMVA::PDF*fDefaultPDFdefault PDF definitions; Bool_tfDisableWriting! set to true in order to suppress writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:16223,Modifiability,variab,variable,16223,"(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 if Sig>Bkg, -1 otherwise; TMVA::DataSetInfo&fDataSetInfo! the data set information (sometimes needed); TMVA::PDF*fDefaultPDFdefault PDF definitions; Bool_tfDisableWriting! set to true in order to suppress writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:17952,Modifiability,variab,variables,17952,"writing to XML; TH1*fEffSefficiency histogram for rootfinder; vector<const std::vector<TMVA::Event*>*>fEventCollectionsif the method needs the complete event-collection, the transformed event coll. ist stored here.; TStringfFileDirunix sub-directory for weight files (default: ""weights""); Bool_tfHasMVAPdfsMVA Pdfs are created for this classifier; Bool_tfHelphelp flag; Bool_tfIgnoreNegWeightsInTrainingIf true, events with negative weights are not used in training; TStringfJobNamename of job -> user defined, appears in weight files; TMVA::PDF*fMVAPdfBbackground MVA PDF; TMVA::PDF*fMVAPdfSsignal MVA PDF; Double_tfMeanBmean (background); Double_tfMeanSmean (signal); TDirectory*fMethodBaseDirbase directory for the method; TStringfMethodNamename of the method (set in derived class); TMVA::Types::EMVAfMethodTypetype of method (set in derived class); Int_tfNbinsMVAPdfnumber of bins used in histogram that creates PDF; Bool_tfNormalisenormalise input variables; Int_tfNsmoothMVAPdfnumber of times a histogram is smoothed before creating the PDF; TStringfParentDirmethod parent name, like booster name; UInt_tfROOTTrainingVersionROOT version used for training; Double_tfRmsBRMS (background); Double_tfRmsSRMS (signal); Double_tfSignalReferenceCutminimum requirement on the MVA output to declare an event signal-like; Double_tfSignalReferenceCutOrientationminimum requirement on the MVA output to declare an event signal-like; TMVA::PDF*fSplBPDFs of MVA distribution (background); TMVA::TSpline1*fSplRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplRefShelper splines for RootFinder (signal); TMVA::PDF*fSplSPDFs of MVA distribution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribu",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19594,Modifiability,variab,variable,19594,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19711,Modifiability,variab,variable,19711,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:19773,Modifiability,variab,variable,19773,"ibution (signal); TMVA::PDF*fSplTrainBPDFs of training MVA distribution (background); TSpline*fSplTrainEffBvsSsplines for training signal eff. versus background eff.; TMVA::TSpline1*fSplTrainRefBhelper splines for RootFinder (background); TMVA::TSpline1*fSplTrainRefShelper splines for RootFinder (signal); TMVA::PDF*fSplTrainSPDFs of training MVA distribution (signal); TSpline*fSpleffBvsSsplines for signal eff. versus background eff.; UInt_tfTMVATrainingVersionTMVA version used for training; Double_tfTestTimefor timing measurements; TStringfTestvarvariable used in evaluation, etc (mostly the MVA); Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overrid",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:20221,Modifiability,Inherit,Inheritance,20221,"Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:20234,Modifiability,Inherit,Inherited,20234,"Double_tfTrainTimefor timing measurements; TMVA::TransformationHandlerfTransformationthe list of transformations; TMVA::TransformationHandler*fTransformationPointerpointer to the rest of transformations; Bool_tfTxtWeightsOnlyif TRUE, write weights only to text files ; Bool_tfUseDecorrsynonymous for decorrelation; TStringfVarTransformStringlabels variable transform method; TMVA::Types::ESBTypefVariableTransformTypethis is the event type (sig or bgd) assumed for variable transform; TStringfVariableTransformTypeStringlabels variable transform type; Bool_tfVerboseverbose flag; TMVA::EMsgTypefVerbosityLevelverbosity level; TStringfVerbosityLevelStringverbosity level (user input string); TStringfWeightFileweight file name; Double_tfXmaxmaximum (signal and background); Double_tfXminminimum (signal and background); static TMVA::MethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:20993,Modifiability,Variab,VariableTransform,20993,"ethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21052,Modifiability,variab,variables,21052,"ethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21093,Modifiability,Variab,VariableTransformType,21093,"ethodBase*fgThisBasethis pointer; TH1F*fmvaBPDFs of MVA distribution (background); TH1F*fmvaSPDFs of MVA distribution (signal). Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; ~MethodBase( void ); destructor. void SetupMethod(); setup of methods. void ProcessSetup(); process all options; the ""CheckForUnusedOptions"" is done in an independent call, since it may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void CheckSetup(); check may be overridden by derived class; (sometimes, eg, fitters are used which can only be implemented during training phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21816,Modifiability,variab,variable,21816,"g phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Doubl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22571,Modifiability,variab,variable,22571," H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22689,Modifiability,variab,variable,22689,"s"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void Wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23027,Modifiability,variab,variable,23027,"e = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType anal",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23149,Modifiability,variab,variable,23149,"rs(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23753,Modifiability,variab,variables,23753,"lc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header f",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23764,Modifiability,variab,variable,23764,"lc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header f",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24108,Modifiability,variab,variables,24108,"A::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. I",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24119,Modifiability,variab,variable,24119,"A::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. I",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24399,Modifiability,config,configuration,24399,"squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; wri",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24854,Modifiability,variab,variables,24854,"ing& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:24985,Modifiability,variab,variables,24985,"teToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set direc",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:25174,Modifiability,variab,variable,25174,"fied. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:25452,Modifiability,variab,variable,25452,"file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading from memory. void ReadStateFromXML(void* parent). void ReadStateFromStream(istream& tf); read the header from the weight files of the different MVA methods. void WriteVarsToStream(ostream& tf, const TString& prefix = """") const; write the list of variables (name, min, max) for a given data; transformation method to the stream. void ReadVarsFromStream(istream& istr); Read the variables (name, min, max) for a given data; transformation method from the stream. In the stream we only; expect the limits which will be set. void AddVarsXMLTo(void* parent) const; write variable info to XML. void AddSpectatorsXMLTo(void* parent) const; write spectator info to XML. void AddClassesXMLTo(void* parent) const; write class info to XML. void AddTargetsXMLTo(void* parent) const; write target info to XML. void ReadVariablesFromXML(void* varnode); read variable info from XML. void ReadSpectatorsFromXML(void* specnode); read spectator info from XML. void ReadClassesFromXML(void* clsnode); read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* b",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:26611,Modifiability,variab,variables,26611," read number of classes from XML. void ReadTargetsFromXML(void* tarnode); read target info from XML. TDirectory* BaseDir() const; returns the ROOT directory where info/histograms etc of the; corresponding MVA method instance are stored. TDirectory* MethodBaseDir() const; returns the ROOT directory where all instances of the; corresponding MVA method are stored. void SetWeightFileDir(TString fileDir); set directory of weight file. void SetWeightFileName(TString ); set the weight file name (depreciated). TString GetWeightFileName() const; retrieve weight file name. void WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); writes all MVA evaluation histograms to file. void WriteMonitoringHistosToFile( void ); write special monitoring histograms to file; dummy implementation here -----------------. Bool_t GetLine(istream& fin, char* buf); reads one line from the input stream; checks for certain keywords and interprets; the line if keywords are found. void CreateMVAPdfs(); Create PDFs of the MVA output variables. Double_t GetProba(Double_t mvaVal, Double_t ap_sig); compute likelihood ratio. Double_t GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; compute rarity:; R(x) = Integrate_[-oo..x] { PDF(x') dx' }; where PDF(x) is the PDF of the classifier's signal or background distribution. Double_t GetEfficiency(const TString& , TMVA::Types::ETreeType , Double_t& err); fill background efficiency (resp. rejection) versus signal efficiency plots; returns signal efficiency at background efficiency indicated in theString. Double_t GetTrainingEfficiency(const TString& ). std::vector<Float_t> GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity). std::vector<Float_t> GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity). Double_t GetSignificance( void ); compute significance of mean difference; significance = |<S> - <B>|/Sqrt(RMS_S2 + RMS_B2). Double_t GetSeparation(TH1* , TH1* ) const; compute ""separation"" define",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28676,Modifiability,variab,variable,28676,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28718,Modifiability,variab,variables,28718,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:28759,Modifiability,variab,variables,28759,"(x)) dx }. Double_t GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; compute ""separation"" defined as; <s2> = (1/2) Int_-oo..+oo { (S(x)2 - B(x)2)/(S(x) + B(x)) dx }. Double_t GetROCIntegral(TH1F* histS, TH1F* histB) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; calculate the area (integral) under the ROC curve as a; overall quality measure of the classification. Double_t GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Double_t& optimal_significance_value) const; plot significance, S/Sqrt(S^2 + B^2), curve for given number; of signal and background events; returns cut for maximum significance; also returned via reference is the maximum significance. void Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t& , Double_t& , Double_t& , Double_t& , Double_t& , Double_t& ); calculates rms,mean, xmin, xmax of the event variable; this can be either done for the variables as they are or for; normalised variables (in the range of 0-1) if ""norm"" is set to kTRUE. void MakeClass(const TString& classFileName = TString("""")) const; create reader class for method (classification only at present). void PrintHelpMessage() const; prints out method-specific help method. Double_t IGetEffForRoot(Double_t ); interface for RootFinder. Double_t GetEffForRoot(Double_t ); returns efficiency as function of cut. const std::vector<TMVA::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(c",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32141,Modifiability,variab,variable,32141,". {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32429,Modifiability,variab,variables,32429,"accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets the minimum requirement on the MVA output to declare an event signal-like. { return fSignalReferenceCut; }. Double_t GetSignalReferenceCutOrientation() const; { return fSignalReferenceCutOrientation; }. void SetSignalReferenceCut(Double_t cut); sets the min",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35367,Modifiability,variab,variables,35367,"nst. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35516,Modifiability,variab,variables,35516,"rs ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35850,Modifiability,variab,variables,35850,"sisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Lo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:466,Performance,perform,performance,466,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:638,Performance,perform,performance,638,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:9160,Performance,Optimiz,OptimizeTuningParameters,9160,"_tIsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*MethodBaseDir() const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidPrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidReadStateFromFile(); voidReadStateFromStream(istream& tf); voidReadStateFromStream(TFile& rf); voidReadStateFromXMLString(const char* xmlstr); virtual voidTObject::RecursiveRemove(TObject* obj); voidRerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11193,Performance,tune,tuneParameters,11193," out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidWriteEvaluationHistosToFile(TMVA::Typ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21905,Performance,Optimiz,OptimizeTuningParameters,21905,".; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); pre",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22070,Performance,tune,tuned,22070,".; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); pre",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:22122,Performance,tune,tuneParameters,22122,"relation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminat",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:7633,Security,Hash,Hash,7633,"nt(Long64_t ievt) const; Double_tGetTestTime() const; const TString&GetTestvarName() const; virtual const char*TObject::GetTitle() const; virtual Double_tGetTrainingEfficiency(const TString&); const TMVA::Event*GetTrainingEvent(Long64_t ievt) const; UInt_tGetTrainingROOTVersionCode() const; TStringGetTrainingROOTVersionString() const; UInt_tGetTrainingTMVAVersionCode() const; TStringGetTrainingTMVAVersionString() const; Double_tGetTrainTime() const; TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringGetWeightFileName() const; Double_tGetXmax(Int_t ivar) const; Double_tGetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tTMVA::IMethod::HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tHasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tIsSignalLike(); virtual Bool_tIsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidMakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*MethodBaseDir() const; virtual Bool_tMonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers,",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:31392,Security,access,accessors,31392,"s if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expr",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32759,Security,access,accessors,32759,"odType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler().GetMin(ivar); }. Double_t GetXmax(Int_t ivar) const; { return GetTransformationHandler().GetMax(ivar); }. Double_t GetSignalReferenceCut() const; sets the minimum requirement on the MVA output to declare an event signal-like. { return fSignalReferenceCut; }. Double_t GetSignalReferenceCutOrientation() const; { return fSignalReferenceCutOrientation; }. void SetSignalReferenceCut(Double_t cut); sets the minimum requirement on the MVA output to declare an event signal-like. { fSignalReferenceCut = cut; }. void SetSignalReferenceCutOrientation(Double_t cutOrientation); { fSignalReferenceCutOrientation = cutOrientation; }. void SetMethodDir(TDirectory* methodDir); { fBaseDir = fMethodBaseDir = methodDir; }. void SetBaseDir(TDirectory* methodDir)",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:34549,Security,access,accessors,34549,"renceCutOrientation = cutOrientation; }. void SetMethodDir(TDirectory* methodDir); { fBaseDir = fMethodBaseDir = methodDir; }. void SetBaseDir(TDirectory* methodDir); { fBaseDir = methodDir; }. void SetMethodBaseDir(TDirectory* methodDir); { fMethodBaseDir = methodDir; }. UInt_t GetTrainingTMVAVersionCode() const; the TMVA version can be obtained and checked using; if (GetTrainingTMVAVersionCode()>TMVA_VERSION(3,7,2)) {...}; or; if (GetTrainingROOTVersionCode()>ROOT_VERSION(5,15,5)) {...}. { return fTMVATrainingVersion; }. UInt_t GetTrainingROOTVersionCode() const; { return fROOTTrainingVersion; }. TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true). const TransformationHandler& GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const. void RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); { fTransformationPointer=fTargetTransformation; }. DataSetInfo& DataInfo() const; ---------- event accessors ------------------------------------------------; returns reference to data set. { return fDataSetInfo; }. UInt_t GetNEvents() const; event reference and update. { return Data()->GetNEvents(); }. Bool_t HasMVAPdfs() const; { return fHasMVAPdfs; }. void SetAnalysisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be r",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:35794,Security,access,accessors,35794,"sisType(TMVA::Types::EAnalysisType type); { fAnalysisType = type; }. Types::EAnalysisType GetAnalysisType() const; { return fAnalysisType; }. Bool_t DoRegression() const; { return fAnalysisType == Types::kRegression; }. Bool_t DoMulticlass() const; { return fAnalysisType == Types::kMulticlass; }. void DisableWriting(Bool_t setter); setter method for suppressing writing to XML and writing of standalone classes. { fDisableWriting = setter; }. const TString& GetWeightFileDir() const; { return fFileDir; }. Bool_t IsNormalised() const; are input variables normalised ?. { return fNormalise; }. void SetNormalised(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Lo",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:36645,Security,access,access,36645,"ed(Bool_t norm); { fNormalise = norm; }. Bool_t Verbose() const; set number of input variables (only used by MethodCuts, could perhaps be removed); void SetNvar( Int_t n ) { fNvar = n; }; verbose and help flags. { return fVerbose; }. Bool_t Help() const; { return fHelp; }. const TString& GetInternalVarName(Int_t ivar) const; ---------- protected event and tree accessors -----------------------------; names of input variables (if the original names are expressions, they are; transformed into regexps). { return (*fInputVars)[ivar]; }. const TString& GetOriginalVarName(Int_t ivar) const; { return DataInfo().GetVariableInfo(ivar).GetExpression(); }. Bool_t HasTrainingTree() const; { return Data()->GetNTrainingEvents() != 0; }. void MakeClassSpecific(ostream& , const TString& = """") const; ---------- protected auxiliary methods ------------------------------------; make ROOT-independent C++ class for classifier response (classifier-specific implementation). {}. void MakeClassSpecificHeader(ostream& , const TString& = """") const; header and auxiliary classes. {}. Bool_t TxtWeightsOnly() const; if TRUE, write weights only to text files. { return kTRUE; }. Float_t GetTWeight(const TMVA::Event* ev) const; access to event information that needs method-specific information. Bool_t IsConstructedFromWeightFile() const; { return fConstructedFromWeightFile; }. void SetCurrentEvent(Long64_t ievt) const. Data(). ECutOrientation GetCutOrientation() const; { return fCutOrientation; }. Bool_t IgnoreEventsWithNegWeightsInTraining() const; { return fIgnoreNegWeightsInTraining; }. » Author: Andreas Hoecker, Peter Speckmayer, Joerg Stelzer, Helge Voss, Kai Voss, Eckhard von Toerne, Jan Therhaag » Copyright (c) 2005-2011: *; » Last changed: root/tmva $Id: MethodBase.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:597,Testability,benchmark,benchmark,597,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:690,Testability,test,test,690,". TMVA::MethodBase. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBase. class TMVA::MethodBase: public TMVA::IMethod, public TMVA::Configurable. Virtual base Class for all MVA method; MethodBase hosts several specific evaluation methods.; The kind of MVA that provides optimal performance in an analysis strongly; depends on the particular application. The evaluation factory provides a; number of numerical benchmark results to directly assess the performance; of the MVA training on the independent test sample. These are:; ; The signal efficiency at three representative background efficiencies; (which is 1 − rejection).; The significance of an MVA estimator, defined by the difference; between the MVA mean values for signal and background, divided by the; quadratic sum of their root mean squares.; The separation of an MVA x, defined by the integral; ½∫(S(x) − B(x))2/(S(x) + B(x))dx, where; S(x) and B(x) are the signal and background distributions, respectively.; The separation is zero for identical signal and background MVA shapes,; and it is one for disjunctive shapes.; ; The average, ∫x μ(S(x))dx, of the signal μ-transform.; The μ-transform of an MVA denotes the transformation that yields; a uniform background distribution. In this way, the signal distributions; S(x) can be directly compared among the various MVAs. The stronger S(x); peaks towards one, the better is the discrimination of the MVA. The; μ-transform is; documented here.; ; The MVA standard output also prints the linear correlation coefficients between; signal and background, which can be useful to eliminate variables that exhibit too; strong correlations.; ; . Function Members (Methods);      This is an abstract class, constructors will not be documented.;     Look at the header to check for available constructors.; pub",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11049,Testability,test,testTime,11049,"it(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidSetAnalysisType(TMVA::Types::EAnalysisType type); voidSetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = ",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11484,Testability,Test,TestBit,11484,", Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidWriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:11523,Testability,Test,TestBits,11523,", Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidSetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMethodBaseDir(TDirectory* methodDir); voidSetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidSetSignalReferenceCut(Double_t cut); voidSetSignalReferenceCutOrientation(Double_t cutOrientation); voidSetTestTime(Double_t testTime); voidSetTestvarName(const TString& v = """"); voidSetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidSetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTestClassification(); virtual voidTestMulticlass(); virtual voidTestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidWriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:13165,Testability,Log,Log,13165,"s::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidWriteStateToFile() const. protected:. virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidTMVA::IMethod::GetHelpMessage() const; const TString&GetInternalVarName(Int_t ivar) const; const TString&GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*GetThisBase(); Float_tGetTWeight(const TMVA::Event* ev) const; const TString&GetWeightFileDir() const; Bool_tHasTrainingTree() const; Bool_tHelp() const; Bool_tIgnoreEventsWithNegWeightsInTraining() const; Bool_tIsConstructedFromWeightFile() const; Bool_tIsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString& = """") const; virtual voidMakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidNoErrorCalc(Double_t *const err, Double_t *const errUpper); virtual voidReadWeightsFromStream(istream&); virtual voidReadWeightsFromStream(TFile&); virtual voidReadWeightsFromXML(void* wghtnode); voidTMVA::Configurable::ResetSetFlag(); voidSetNormalised(Bool_t norm); voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void*",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:14691,Testability,log,log,14691," voidSetWeightFileDir(TString fileDir); voidSetWeightFileName(TString); voidStatistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTxtWeightsOnly() const; Bool_tVerbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. voidAddClassesXMLTo(void* parent) const; virtual voidAddClassifierOutput(TMVA::Types::ETreeType type); virtual voidAddClassifierOutputProb(TMVA::Types::ETreeType type); voidAddInfoItem(void* gi, const TString& name, const TString& value) const; virtual voidAddMulticlassOutput(TMVA::Types::ETreeType type); virtual voidAddRegressionOutput(TMVA::Types::ETreeType type); voidAddSpectatorsXMLTo(void* parent) const; voidAddTargetsXMLTo(void* parent) const; voidAddVarsXMLTo(void* parent) const; voidCreateMVAPdfs(); static voidCreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); voidDeclareBaseOptions(); TMVA::MethodBase::ECutOrientationGetCutOrientation() const; Double_tGetEffForRoot(Double_t); Bool_tGetLine(istream& fin, char* buf); static Double_tIGetEffForRoot(Double_t); voidInitBase(); voidProcessBaseOptions(); voidReadClassesFromXML(void* clsnode); voidReadSpectatorsFromXML(void* specnode); voidReadStateFromXML(void* parent); voidReadTargetsFromXML(void* tarnode); voidReadVariablesFromXML(void* varnode); voidReadVarsFromStream(istream& istr); voidResetThisBase(); voidWriteStateToStream(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:15814,Testability,test,testing,15814,"tEffForRoot(Double_t); Bool_tGetLine(istream& fin, char* buf); static Double_tIGetEffForRoot(Double_t); voidInitBase(); voidProcessBaseOptions(); voidReadClassesFromXML(void* clsnode); voidReadSpectatorsFromXML(void* specnode); voidReadStateFromXML(void* parent); voidReadTargetsFromXML(void* tarnode); voidReadVariablesFromXML(void* varnode); voidReadVarsFromStream(istream& istr); voidResetThisBase(); voidWriteStateToStream(ostream& tf) const; voidWriteStateToXML(void* parent) const; voidWriteVarsToStream(ostream& tf, const TString& prefix = """") const. Data Members; public:. enum EWeightFileType { kROOT; kTEXT; };; enum ECutOrientation { kNegative; kPositive; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tfSetupCompletedis method setup; const TMVA::Event*fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypefAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tfBackgroundClassindex of the Background-class; vector<TString>*fInputVarsvector of input variables used in MVA; vector<Float_t>*fMulticlassReturnValholds the return-values for the multiclass classification; Int_tfNbinsnumber of bins in input variable histograms; Int_tfNbinsHnumber of bins in evaluation histograms; Int_tfNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*fRegressionReturnValholds the return-values for the regression; UInt_tfSignalClassindex of the Signal-class. private:. TDirectory*fBaseDirbase directory for the instance, needed to know where to jump back from localDir; Bool_tfConstructedFromWeightFileis it obtained from weight file?; TMVA::MethodBase::ECutOrientationfCutOrientation+1 i",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:21803,Testability,log,log,21803,"g phase). void InitBase(); default initialization called by all constructors. void DeclareBaseOptions(); define the options (their key words) that can be set in the option string; here the options valid for ALL MVA methods are declared.; know options: VariableTransform=None,Decorrelated,PCA to use transformed variables; instead of the original ones; VariableTransformType=Signal,Background which decorrelation matrix to use; in the method. Only the Likelihood; Method can make proper use of independent; transformations of signal and background; fNbinsMVAPdf = 50 Number of bins used to create a PDF of MVA; fNsmoothMVAPdf = 2 Number of times a histogram is smoothed before creating the PDF; fHasMVAPdfs create PDFs for the MVA outputs; V for Verbose output (!V) for non verbos; H for Help message. void ProcessBaseOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". void CreateVariableTransforms(const TString& trafoDefinition, TMVA::DataSetInfo& dataInfo, TMVA::TransformationHandler& transformationHandler, TMVA::MsgLogger& log); create variable transformations. void DeclareCompatibilityOptions(). std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument; This is just a dummy .. have a look at the MethodBDT how you could; perhaps implment the same thing for the other Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Doubl",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23164,Testability,Test,TestRegression,23164,"r Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteSt",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23436,Testability,test,test,23436,"r Classifiers.. void TrainMethod(). void GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const. void AddRegressionOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteSt",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23538,Testability,Test,TestMulticlass,23538,"criminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStat",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23556,Testability,test,test,23556,"criminating variable. void AddMulticlassOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStat",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:23593,Testability,Test,TestClassification,23593,"VA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void NoErrorCalc(Double_t *const err, Double_t *const errUpper). Double_t GetMvaValue(const TMVA::Event *const ev, Double_t* err = 0, Double_t* errUpper = 0). Bool_t IsSignalLike(). Bool_t IsSignalLike(Double_t mvaVal). void AddClassifierOutput(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void AddClassifierOutputProb(TMVA::Types::ETreeType type); prepare tree branch with the method's discriminating variable. void TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); calculate <sum-of-deviation-squared> of regression output versus ""true"" value from test sample. bias = average deviation; dev = average absolute deviation; rms = rms of deviation. void TestMulticlass(); test multiclass classification. void TestClassification(); initialization. void WriteStateToStream(ostream& tf) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void AddInfoItem(void* gi, const TString& name, const TString& value) const; xml writing. void AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType). void WriteStateToXML(void* parent) const; general method used in writing the header of the weight files where; the used variables, variable transformation type etc. is specified. void ReadStateFromStream(TFile& rf); write reference MVA distributions (and other information); to a ROOT type weight file. void WriteStateToFile() const; write options and weights to file; note that each one text file for the main configuration information; and one ROOT file for ROOT objects are created. void ReadStateFromFile(); Function to write options and weights to file. void ReadStateFromXMLString(const char* xmlstr); for reading f",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30165,Testability,test,testTime,30165,"A::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30209,Testability,test,testing,30209,"A::Event*>& GetEventCollection(TMVA::Types::ETreeType type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(voi",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:30232,Testability,test,testTime,30232," type). TString GetTrainingTMVAVersionString() const; calculates the TMVA version string from the training version code on the fly. TString GetTrainingROOTVersionString() const; calculates the ROOT version string from the training version code on the fly. TMVA::MethodBase* GetThisBase(); return a pointer the base class of this method. void ResetThisBase(); reset required for RootFinder. const TMVA::Event* GetEvent(const TMVA::Event* ev) const. const TMVA::Event* GetEvent() const. const TMVA::Event* GetEvent(Long64_t ievt) const. const TMVA::Event* GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const. const TMVA::Event* GetTrainingEvent(Long64_t ievt) const. const TMVA::Event* GetTestingEvent(Long64_t ievt) const. void Train(). void SetTrainTime(Double_t trainTime); store and retrieve time used for training. { fTrainTime = trainTime; }. Double_t GetTrainTime() const; { return fTrainTime; }. void SetTestTime(Double_t testTime); store and retrieve time used for testing. { fTestTime = testTime; }. Double_t GetTestTime() const; { return fTestTime; }. void Init(); options treatment. void DeclareOptions(). void ProcessOptions(). void Reset(); reset the Method --> As if it was not yet trained, just instantiated; virtual void Reset() = 0;; for the moment, I provide a dummy (that would not work) default, just to make; compilation/running w/o parameter optimisation still possible. {return;}. Double_t GetMvaValue(Double_t* errLower = 0, Double_t* errUpper = 0); classifier response:; some methods may return a per-event error estimate; error calculation is skipped if err==0. const std::vector<Float_t>& GetRegressionValues(); regression response. const std::vector<Float_t>& GetMulticlassValues(); multiclass classification response. const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeig",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:32004,Testability,Test,Test,32004,". const Ranking* CreateRanking(); create ranking. Bool_t MonitorBoost(TMVA::MethodBoost* ); perfrom extra actions during the boosting at different stages. {return kFALSE;}. void AddWeightsXMLTo(void* parent) const; the actual ""weights"". void ReadWeightsFromXML(void* wghtnode). void ReadWeightsFromStream(istream& ). void ReadWeightsFromStream(TFile& ); {}. const TString& GetJobName() const; ---------- public accessors -----------------------------------------------; classifier naming (a lot of names ... aren't they ;-). { return fJobName; }. const TString& GetMethodName() const; { return fMethodName; }. TString GetMethodTypeName() const; { return Types::Instance().GetMethodName(fMethodType); }. Types::EMVA GetMethodType() const; { return fMethodType; }. const char* GetName() const; { return fMethodName.Data(); }. const TString& GetTestvarName() const; { return fTestvar; }. const TString GetProbaName() const; { return fTestvar + ""_Proba""; }. void SetTestvarName(const TString& v = """"); build classifier name in Test tree; MVA prefix (e.g., ""TMVA_""). { fTestvar = (v=="""") ? (""MVA_"" + GetMethodName()) : v; }. UInt_t GetNvar() const; number of input variable used by classifier. { return DataInfo().GetNVariables(); }. UInt_t GetNVariables() const; { return DataInfo().GetNVariables(); }. UInt_t GetNTargets() const; { return DataInfo().GetNTargets(); }. const TString& GetInputVar(Int_t i) const; internal names and expressions of input variables. { return DataInfo().GetVariableInfo(i).GetInternalName(); }. const TString& GetInputLabel(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetLabel(); }. const TString& GetInputTitle(Int_t i) const; { return DataInfo().GetVariableInfo(i).GetTitle(); }. Double_t GetMean(Int_t ivar) const; normalisation and limit accessors. { return GetTransformationHandler().GetMean(ivar); }. Double_t GetRMS(Int_t ivar) const; { return GetTransformationHandler().GetRMS(ivar); }. Double_t GetXmin(Int_t ivar) const; { return GetTransformationHandler(",MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBase.html:2527,Usability,Clear,Clear,2527,,MatchSource.WIKI,root/html532/TMVA__MethodBase.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBase.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2032,Availability,Error,Error,2032,"; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMV",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2161,Availability,error,error,2161,"t::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2245,Availability,error,error,2245,"able(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollec",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:16796,Availability,avail,availabel,16796,"thodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the document",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:8378,Energy Efficiency,Monitor,MonitorBoost,8378,"; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBayesClassifierMethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBayesClassifierMethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA:",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:17285,Integrability,message,message,17285,"d classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:522,Modifiability,Config,Configurable,522," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:878,Modifiability,Config,Configurable,878," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:1208,Modifiability,Config,ConfigurableTMVA,1208," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:1226,Modifiability,Config,Configurable,1226," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:1240,Modifiability,Config,Configurable,1240," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2609,Modifiability,Config,Configurable,2609,"ase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TString&TMVA::MethodBase::GetJobName() const; virtual Double_tTMVA::MethodBase::GetMaximumSign",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:2670,Modifiability,Config,Configurable,2670,"tancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TString&TMVA::MethodBase::GetJobName() const; virtual Double_tTMVA::MethodBase::GetMaximumSignificance(Double_t SignalEvents, Double_t BackgroundEvents, Do",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:4697,Modifiability,Config,Configurable,4697,"ce_value) const; Double_tTMVA::MethodBase::GetMean(Int_t ivar) const; const TString&TMVA::MethodBase::GetMethodName() const; TMVA::Types::EMVATMVA::MethodBase::GetMethodType() const; TStringTMVA::MethodBase::GetMethodTypeName() const; virtual vector<Float_t>TMVA::MethodBase::GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity); virtual vector<Float_t>TMVA::MethodBase::GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity); virtual const vector<Float_t>&TMVA::MethodBase::GetMulticlassValues(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*TMVA::MethodBase::GetName() const; UInt_tTMVA::MethodBase::GetNEvents() const; UInt_tTMVA::MethodBase::GetNTargets() const; UInt_tTMVA::MethodBase::GetNvar() const; UInt_tTMVA::MethodBase::GetNVariables() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual Double_tTMVA::MethodBase::GetProba(Double_t mvaVal, Double_t ap_sig); const TStringTMVA::MethodBase::GetProbaName() const; virtual Double_tTMVA::MethodBase::GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; virtual voidTMVA::MethodBase::GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const; virtual const vector<Float_t>&TMVA::MethodBase::GetRegressionValues(); Double_tTMVA::MethodBase::GetRMS(Int_t ivar) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TH1F* histS, TH1F* histB) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; virtual Double_tTMVA::MethodBase::GetSeparation(TH1*, TH1*) const; virtual Double_tTMVA::MethodBase::GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; Double_tTMVA::MethodBase::GetSignalReferenceCut() const; Double_tTMVA::MethodBase::GetSignalReferenceCutOri",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:7219,Modifiability,Inherit,InheritsFrom,7219,"MethodBase::GetTrainingROOTVersionString() const; UInt_tTMVA::MethodBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBayesClassifierMethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBayesClassifierMethodBayesClassifier(const TString& jobName",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:7285,Modifiability,Inherit,InheritsFrom,7285,"odBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBayesClassifierMethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBayesClassifierMethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TS",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:9205,Modifiability,Config,Configurable,9205,"String& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """,MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:9386,Modifiability,Config,Configurable,9386,"MVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisTy",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:9516,Modifiability,Config,Configurable,9516,"emovedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bo",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:9578,Modifiability,Config,Configurable,9578,"d* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:10544,Modifiability,Config,Configurable,10544,"m(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); void",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:10605,Modifiability,Config,Configurable,10605,"void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMem",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:10957,Modifiability,Config,Configurable,10957,"emove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtua",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11059,Modifiability,Config,Configurable,11059,"TargetTransformation); virtual voidTMVA::MethodBase::Reset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT,",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:12702,Modifiability,Config,Configurable,12702,"voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:12947,Modifiability,Config,Configurable,12947,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:13195,Modifiability,Config,Configurable,13195,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:13702,Modifiability,Config,Configurable,13702,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:13741,Modifiability,Config,Configurable,13741,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:14065,Modifiability,Config,Configurable,14065,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:14511,Modifiability,Config,Configurable,14511,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15404,Modifiability,variab,variables,15404,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15593,Modifiability,variab,variable,15593,"ons(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:16039,Modifiability,Inherit,Inheritance,16039,"mpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t Get",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:16052,Modifiability,Inherit,Inherited,16052,"mpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t Get",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:16547,Modifiability,Variab,Variable,16547,"ss classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Ab",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:17483,Modifiability,variab,variables,17483,"d classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); standard constructor. MethodBayesClassifier(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); constructor from weight file. Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); Variable can handle classification with 2 classes. void Init( void ); default initialisation. void DeclareOptions(); define the options (their key words) that can be set in the option string. void ProcessOptions(); the option string is decoded, for availabel options see ""DeclareOptions"". ~MethodBayesClassifier( void ); destructor. void Train( void ); some training. void AddWeightsXMLTo(void* parent) const. void ReadWeightsFromStream(istream& istr); read back the training results from a file (stream). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); returns MVA value for given event. void MakeClassSpecific(ostream& , const TString& ) const; write specific classifier response. void GetHelpMessage() const; get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void ReadWeightsFromXML(void* ); {}. const Ranking* CreateRanking(); ranking of input variables. { return 0; }. » Author: Abhishek Narain » Copyright (c) 2005-2006: *; » Last changed: root/tmva $Id: MethodBayesClassifier.h 40005 2011-06-27 15:29:10Z stelzer $ » Last generated: 2011-11-03 20:19; This page has been automatically generated. For comments or suggestions regarding the documentation or ROOT in general please send a mail to ROOT support. ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:9050,Performance,Optimiz,OptimizeTuningParameters,9050,"(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBayesClassifierMethodBayesClassifier(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>TMVA::MethodBase::OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void*); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler*",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11484,Performance,tune,tuneParameters,11484,"voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:7065,Security,Hash,Hash,7065,"String&); const TMVA::Event*TMVA::MethodBase::GetTrainingEvent(Long64_t ievt) const; UInt_tTMVA::MethodBase::GetTrainingROOTVersionCode() const; TStringTMVA::MethodBase::GetTrainingROOTVersionString() const; UInt_tTMVA::MethodBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; virtual voidInit(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBayesClassifierMethodBayesClassifier(TMVA:",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11286,Testability,test,testTime,11286,"am& out, Option_t* option = """"); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObj",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11793,Testability,Test,TestBit,11793,"ct::SetDtorOnly(void* obj); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBa",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11832,Testability,Test,TestBits,11832,"voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11888,Testability,Test,TestClassification,11888,"voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11940,Testability,Test,TestMulticlass,11940,"voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:11988,Testability,Test,TestRegression,11988,"voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidTMVA::MethodBase::SetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidTMVA::MethodBase::WriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:13716,Testability,Log,Log,13716,"TMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); virtual voidGetHelpMessage() const; const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidTMVA::MethodBase::MakeClassSpecificHeader(ostream&, const TString& = """") const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; ",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:15094,Testability,test,testing,15094,"voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. virtual voidDeclareOptions(); virtual voidProcessOptions(). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. Class Charts. Inheritance; Inhe",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBayesClassifier.html:1058,Usability,Clear,Clear,1058," virtual~MethodBayesClassifier(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); virtual const char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidTMVA::MethodBase::DeclareCompatibilityOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() co",MatchSource.WIKI,root/html532/TMVA__MethodBayesClassifier.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBayesClassifier.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2759,Availability,error,error,2759,"ructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as sign",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:5736,Availability,Error,Error,5736,"char*TObject::ClassName() const; virtual voidTObject::Clear(Option_t* = """"); virtual TObject*TObject::Clone(const char* newname = """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::Ge",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:5865,Availability,error,error,5865," """") const; virtual Int_tTObject::Compare(const TObject* obj) const; TMVA::ConfigurableTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::M",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:5949,Availability,error,error,5949,"bleTMVA::Configurable::Configurable(const TString& theOption = """"); virtual voidTObject::Copy(TObject& object) const; virtual const TMVA::Ranking*CreateRanking(); TMVA::DataSet*TMVA::MethodBase::Data() const; TMVA::DataSetInfo&TMVA::MethodBase::DataInfo() const; virtual voidDeclareOptions(); virtual voidTObject::Delete(Option_t* option = """")MENU ; voidTMVA::MethodBase::DisableWriting(Bool_t setter); virtual Int_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:21807,Availability,error,error,21807,"values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTraini",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24150,Availability,down,down,24150,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27196,Availability,error,error,27196,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:28441,Availability,avail,available,28441,"runing completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with th",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29847,Deployability,Update,UpdateTargets,29847,"vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionT",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29941,Deployability,Update,UpdateTargetsRegression,29941,"ive event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:30059,Deployability,update,update,30059,"ive event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:402,Energy Efficiency,Energy,Energy,402,". TMVA::MethodBDT. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBDT. class TMVA::MethodBDT: public TMVA::MethodBase. Analysis of Boosted Decision Trees. Boosted decision trees have been successfully used in High Energy; Physics analysis for example by the MiniBooNE experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. Successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signa",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2131,Energy Efficiency,adapt,adaptive,2131,"g the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Fo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:12511,Energy Efficiency,Monitor,MonitorBoost,12511," const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidMakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidMakeClassSpecificHeader(ostream&, const TString&) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBDTMethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBDTMethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::Pri",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:31163,Energy Efficiency,monitor,monitoring,31163,"air<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::DecisionTree* dt); Implementation of M_TreeBoost using a Huber loss function as desribed by Friedman 1999. void InitGradBoost(vector<TMVA::Event*> ); initialize targets for first tree. Double_t TestTreeQuality(TMVA::DecisionTree* dt); test the tree quality.. in terms of Miscalssification. Double_t Boost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); apply the boosting alogrithim (the algorithm is selecte via the the ""option"" given; in the constructor. The return value is the boosting weight. void BoostMonitor(Int_t iTree); fills the ROCIntegral vs Itree from the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTr",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:32146,Energy Efficiency,adapt,adaption,32146," the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTree* dt); adaption of the AdaBoost to regression problems (see H.Drucker 1997). void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* parent); reads the BDT from the xml file. void ReadWeightsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3717,Integrability,depend,depending,3717,"termined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Double_tBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, Int_t iTree, UInt_t cls = 0); virtual voidTObject::Browse(TBrowser* b); voidTMVA::Configurable::CheckForUnusedOptions() const; virtual voidTMVA::MethodBase::CheckSetup(); static TClass*Class(); ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29038,Integrability,rout,routine,29038,"on't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > v",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33900,Integrability,message,message,33900,"ding to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. void SetMaxDepth(Int_t d); {fMaxDepth = d;}. void SetNodeMinEvents(Int_t d); {fNodeMinEvents = d;}. void SetNTrees(Int_t d); {fNTrees = d;}. void SetAdaBoostBeta(Double_t b); {fAdaBoostBeta = b;}. void SetNo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:896,Modifiability,variab,variable,896,". TMVA::MethodBDT. Quick Links:; ROOT Homepage; Class Index; Class Hierarchy. Search. Source:; header file; source file; viewVC header viewVC source. Sections:; class description; function members; data members; class charts. ROOT; » TMVA; » TMVA::MethodBDT. class TMVA::MethodBDT: public TMVA::MethodBase. Analysis of Boosted Decision Trees. Boosted decision trees have been successfully used in High Energy; Physics analysis for example by the MiniBooNE experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. Successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signa",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:1432,Modifiability,variab,variable,1432,"experiment; (Yang-Roe-Zhu, physics/0508045). In Boosted Decision Trees, the; selection is done on a majority vote on the result of several decision; trees, which are all derived from the same training sample by; supplying different event weights during the training. Decision trees:. Successive decision nodes are used to categorize the; events out of the sample as either signal or background. Each node; uses only a single discriminating variable to decide if the event is; signal-like (""goes right"") or background-like (""goes left""). This; forms a tree like structure with ""baskets"" at the end (leave nodes),; and an event is classified as either signal or background according to; whether the basket where it ends up has been classified signal or; background during the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2131,Modifiability,adapt,adaptive,2131,"g the training. Training of a decision tree is the; process to define the ""cut criteria"" for each node. The training; starts with the root node. Here one takes the full training event; sample and selects the variable and corresponding cut value that gives; the best separation between signal and background at this stage. Using; this cut criterion, the sample is then divided into two subsamples, a; signal-like (right) and a background-like (left) sample. Two new nodes; are then created for each of the two sub-samples and they are; constructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Fo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3401,Modifiability,variab,variables,3401,"t leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); vi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:4167,Modifiability,Config,Configurable,4167,,MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:4613,Modifiability,Config,Configurable,4613,,MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:4943,Modifiability,Config,ConfigurableTMVA,4943,,MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:4961,Modifiability,Config,Configurable,4961,,MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:4975,Modifiability,Config,Configurable,4975,,MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:6359,Modifiability,Config,Configurable,6359,"t_tTObject::DistancetoPrimitive(Int_t px, Int_t py); Bool_tTMVA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); const vector<TMVA::DecisionTree*>&GetForest() const; virtual voidGetHelpMessage() const; virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TStri",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:6420,Modifiability,Config,Configurable,6420,"VA::MethodBase::DoMulticlass() const; Bool_tTMVA::MethodBase::DoRegression() const; virtual voidTObject::Draw(Option_t* option = """"); virtual voidTObject::DrawClass() constMENU ; virtual TObject*TObject::DrawClone(Option_t* option = """") constMENU ; virtual voidTObject::Dump() constMENU ; virtual voidTObject::Error(const char* method, const char* msgfmt) const; virtual voidTObject::Execute(const char* method, const char* params, Int_t* error = 0); virtual voidTObject::Execute(TMethod* method, TObjArray* params, Int_t* error = 0); virtual voidTObject::ExecuteEvent(Int_t event, Int_t px, Int_t py); virtual voidTObject::Fatal(const char* method, const char* msgfmt) const; virtual TObject*TObject::FindObject(const char* name) const; virtual TObject*TObject::FindObject(const TObject* obj) const; TMVA::Types::EAnalysisTypeTMVA::MethodBase::GetAnalysisType() const; const vector<double>&GetBoostWeights() const; const char*TMVA::Configurable::GetConfigDescription() const; const char*TMVA::Configurable::GetConfigName() const; virtual Option_t*TObject::GetDrawOption() const; static Long_tTObject::GetDtorOnly(); virtual Double_tTMVA::MethodBase::GetEfficiency(const TString&, TMVA::Types::ETreeType, Double_t& err); const TMVA::Event*TMVA::MethodBase::GetEvent() const; const TMVA::Event*TMVA::MethodBase::GetEvent(const TMVA::Event* ev) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt) const; const TMVA::Event*TMVA::MethodBase::GetEvent(Long64_t ievt, TMVA::Types::ETreeType type) const; const vector<TMVA::Event*>&TMVA::MethodBase::GetEventCollection(TMVA::Types::ETreeType type); const vector<TMVA::DecisionTree*>&GetForest() const; virtual voidGetHelpMessage() const; virtual const char*TObject::GetIconName() const; const TString&TMVA::MethodBase::GetInputLabel(Int_t i) const; const TString&TMVA::MethodBase::GetInputTitle(Int_t i) const; const TString&TMVA::MethodBase::GetInputVar(Int_t i) const; const TString&TMVA::MethodBase::GetJobName() const; virtual Double_tTMVA",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:8518,Modifiability,Config,Configurable,8518,"optimal_significance_value) const; Double_tTMVA::MethodBase::GetMean(Int_t ivar) const; const TString&TMVA::MethodBase::GetMethodName() const; TMVA::Types::EMVATMVA::MethodBase::GetMethodType() const; TStringTMVA::MethodBase::GetMethodTypeName() const; virtual vector<Float_t>TMVA::MethodBase::GetMulticlassEfficiency(vector<std::vector<Float_t> >& purity); virtual vector<Float_t>TMVA::MethodBase::GetMulticlassTrainingEfficiency(vector<std::vector<Float_t> >& purity); virtual const vector<Float_t>&GetMulticlassValues(); virtual Double_tGetMvaValue(Double_t* err = 0, Double_t* errUpper = 0); virtual const char*TMVA::MethodBase::GetName() const; UInt_tTMVA::MethodBase::GetNEvents() const; UInt_tTMVA::MethodBase::GetNTargets() const; UInt_tTMVA::MethodBase::GetNvar() const; UInt_tTMVA::MethodBase::GetNVariables() const; virtual char*TObject::GetObjectInfo(Int_t px, Int_t py) const; static Bool_tTObject::GetObjectStat(); virtual Option_t*TObject::GetOption() const; const TString&TMVA::Configurable::GetOptions() const; virtual Double_tTMVA::MethodBase::GetProba(Double_t mvaVal, Double_t ap_sig); const TStringTMVA::MethodBase::GetProbaName() const; virtual Double_tTMVA::MethodBase::GetRarity(Double_t mvaVal, TMVA::Types::ESBType reftype = Types::kBackground) const; virtual voidTMVA::MethodBase::GetRegressionDeviation(UInt_t tgtNum, TMVA::Types::ETreeType type, Double_t& stddev, Double_t& stddev90Percent) const; virtual const vector<Float_t>&GetRegressionValues(); Double_tTMVA::MethodBase::GetRMS(Int_t ivar) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TH1F* histS, TH1F* histB) const; virtual Double_tTMVA::MethodBase::GetROCIntegral(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; virtual Double_tTMVA::MethodBase::GetSeparation(TH1*, TH1*) const; virtual Double_tTMVA::MethodBase::GetSeparation(TMVA::PDF* pdfS = 0, TMVA::PDF* pdfB = 0) const; Double_tTMVA::MethodBase::GetSignalReferenceCut() const; Double_tTMVA::MethodBase::GetSignalReferenceCutOrientation() const; ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:11161,Modifiability,Inherit,InheritsFrom,11161,"TMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; voidInitEventSample(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidMakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidMakeClassSpecificHeader(ostream&, const TString&) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBa",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:11227,Modifiability,Inherit,InheritsFrom,11227,"ersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; voidInitEventSample(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidMakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; virtual voidMakeClassSpecific(ostream&, const TString&) const; virtual voidMakeClassSpecificHeader(ostream&, const TString&) const; voidTObject::MayNotUse(const char* method) const; TDirectory*TMVA::MethodBase::MethodBaseDir() const; TMVA::MethodBDTMethodBDT(TMVA::DataSetI",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:13320,Modifiability,Config,Configurable,13320,"TMethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:13501,Modifiability,Config,Configurable,13501,"se::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:13661,Modifiability,Config,Configurable,13661,"rs) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObjec",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:13723,Modifiability,Config,Configurable,13723,"tic voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetCo",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:14711,Modifiability,Config,Configurable,14711,"TMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneP",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:14772,Modifiability,Config,Configurable,14772,":MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual void",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15150,Modifiability,Config,Configurable,15150,"::RerouteTransformationHandler(TMVA::TransformationHandler* fTargetTransformation); virtual voidReset(); voidTObject::ResetBit(UInt_t f); virtual voidTObject::SaveAs(const char* filename = """", Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::Tes",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15343,Modifiability,Config,Configurable,15343,"Option_t* option = """") constMENU ; virtual voidTObject::SavePrimitive(ostream& out, Option_t* option = """"); voidSetAdaBoostBeta(Double_t b); virtual voidTMVA::MethodBase::SetAnalysisType(TMVA::Types::EAnalysisType type); voidTMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Do",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16999,Modifiability,Config,Configurable,16999,"tory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:17287,Modifiability,Config,Configurable,17287,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:17499,Modifiability,Config,Configurable,17499,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:18006,Modifiability,Config,Configurable,18006,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:18045,Modifiability,Config,Configurable,18045,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:18214,Modifiability,Config,Configurable,18214,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:18660,Modifiability,Config,Configurable,18660,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20554,Modifiability,variab,variables,20554,"VA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20743,Modifiability,variab,variable,20743,"VA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:22272,Modifiability,variab,variables,22272,"nation with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTrainingignore negative event weights in the training; Int_tfNodeMinEventsmin number of events in node; Double_tfNodePurityLimitpurity limit for sig/bkg nodes; Bool_tfPairNegWeightsGlobalpair ev. with neg. and pos. weights in traning sample and ""annihilate"" them ; Bool_tfPairNegWeightsInNoderandomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<T",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:23335,Modifiability,variab,variables,23335,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24220,Modifiability,variab,variables,24220,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24525,Modifiability,variab,variables,24525,". with neg. and pos. weights in node and don't boost them; Bool_tfPruneBeforeBoostflag to prune before boosting; TMVA::DecisionTree::EPruneMethodfPruneMethodmethod used for prunig; TStringfPruneMethodSprune method option String; Double_tfPruneStrengtha parameter to set the ""amount"" of pruning..needs to be adjusted; Bool_tfRandomisedTreeschoose a random subset of possible cut variables at each node during training; Bool_tfRenormByClassindividually re-normalize each event class to the original size after boosting; map<TMVA::Event*,std::vector<double> >fResidualsindividual event residuals for gradient boost; Double_tfSampleFractionfraction of events used for bagged grad boost; Double_tfSampleSizeFractionrelative size of bagged event sample to original sample size; TMVA::SeparationBase*fSepTypethe separation used in node splitting; TStringfSepTypeSthe separation (option string) used in node splitting; Double_tfShrinkagelearning rate for gradient boost;; vector<TMVA::Event*>fSubSamplesubsample for bagged grad boost; Double_tfSumOfWeightssum of all event weights; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:25053,Modifiability,variab,variables,25053,"ts; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the b",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:25261,Modifiability,Inherit,Inheritance,25261,"d individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of va",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:25274,Modifiability,Inherit,Inherited,25274,"d individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of va",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:26285,Modifiability,variab,variables,26285,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:26318,Modifiability,variab,variables,26318,"Int_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the boosting type for the trees in the forest (AdaBoost e.t.c..); known: AdaBoost; AdaBoostR2 (Adaboost for regression); Bagging; GradBoost; AdaBoostBeta the boosting parameter, beta, for AdaBoost; UseRandomisedTrees choose at each node splitting a random set of variables; UseNvars use UseNvars variables in randomised trees; UsePoission Nvars use UseNvars not as fixed number but as mean of a possion distribution; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of even",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:32146,Modifiability,adapt,adaption,32146," the testSample for the monitoring plots; during the training .. but using the testing events. Double_t AdaBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); the AdaBoost implementation.; a new training sample is generated by weighting; events that are misclassified by the decision tree. The weight; applied is w = (1-err)/err or more general:; w = ((1-err)/err)^beta; where err is the fraction of misclassified events in the tree ( <0.5 assuming; demanding the that previous selection was better than random guessing); and ""beta"" being a free parameter (standard: beta = 1) that modifies the; boosting. Double_t Bagging(vector<TMVA::Event*> , Int_t iTree); call it boot-strapping, re-sampling or whatever you like, in the end it is nothing; else but applying ""random"" weights to each event. Double_t RegBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt); a special boosting only for Regression ...; maybe I'll implement it later... Double_t AdaBoostR2(vector<TMVA::Event*> , TMVA::DecisionTree* dt); adaption of the AdaBoost to regression problems (see H.Drucker 1997). void AddWeightsXMLTo(void* parent) const; write weights to XML. void ReadWeightsFromXML(void* parent); reads the BDT from the xml file. void ReadWeightsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33355,Modifiability,variab,variable,33355,"ghtsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursiv",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33395,Modifiability,variab,variables,33395,"ghtsFromStream(istream& istr); read the weights (BDT coefficients). Double_t GetMvaValue(Double_t* err = 0, Double_t* errUpper = 0). Double_t GetMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursiv",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33507,Modifiability,variab,variable,33507,"tMvaValue(Double_t* err, Double_t* errUpper, UInt_t useNTrees); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fFore",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33652,Modifiability,variab,variable,33652,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33675,Modifiability,variab,variable,33675,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33766,Modifiability,variab,variable,33766,"umber of; decision trees. Double_t PrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Return the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:33851,Modifiability,variab,variables,33851,"n the MVA value (range [-1;1]) that classifies the; event according to the majority vote from the total number of; decision trees. const std::vector<Float_t>& GetMulticlassValues(); get the multiclass MVA response for the BDT classifier. const std::vector<Float_t> & GetRegressionValues(); get the regression value generated by the BDTs. void WriteMonitoringHistosToFile( void ); Here we could write some histograms created during the processing; to the output file. vector< Double_t > GetVariableImportance(); Return the relative variable importance, normalized to all; variables together having the importance 1. The importance in; evaluated as the total separation-gain that this variable had in; the decision trees (weighted by the number of events). Double_t GetVariableImportance(UInt_t ivar); Returns the measure for the variable importance of variable ""ivar""; which is later used in GetVariableImportance() to calculate the; relative variable importances. const TMVA::Ranking* CreateRanking(); Compute ranking of input variables. void GetHelpMessage() const; Get help message text. typical length of text line:; ""|--------------------------------------------------------------|"". void MakeClassSpecific(ostream& , const TString& ) const; make ROOT-independent C++ class for classifier response (classifier-specific implementation). void MakeClassSpecificHeader(ostream& , const TString& ) const; specific class header. void MakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; recursively descends a tree and writes the node instance to the output streem. const std::vector<TMVA::DecisionTree*>& GetForest() const; { return fForest; }. const std::vector<TMVA::Event*>& GetTrainingEvents() const; { return fEventSample; }. const std::vector<double>& GetBoostWeights() const; { return fBoostWeights; }. void SetMaxDepth(Int_t d); {fMaxDepth = d;}. void SetNodeMinEvents(Int_t d); {fNodeMinEvents = d;}. void SetNTrees(Int_t d); {fNTrees = d;}. voi",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:13165,Performance,Optimiz,OptimizeTuningParameters,13165,"dBaseDir() const; TMVA::MethodBDTMethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL); TMVA::MethodBDTMethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); virtual Bool_tTMVA::MethodBase::MonitorBoost(TMVA::MethodBoost*); virtual Bool_tTObject::Notify(); voidTObject::Obsolete(const char* method, const char* asOfVers, const char* removedFromVers) const; static voidTObject::operator delete(void* ptr); static voidTObject::operator delete(void* ptr, void* vp); static voidTObject::operator delete[](void* ptr); static voidTObject::operator delete[](void* ptr, void* vp); void*TObject::operator new(size_t sz); void*TObject::operator new(size_t sz, void* vp); void*TObject::operator new[](size_t sz); void*TObject::operator new[](size_t sz, void* vp); TMVA::IMethod&TMVA::IMethod::operator=(const TMVA::IMethod&); virtual map<TString,Double_t>OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); virtual voidTObject::Paint(Option_t* option = """"); virtual voidTMVA::Configurable::ParseOptions(); virtual voidTObject::Pop(); virtual voidTObject::Print(Option_t* option = """") const; virtual voidTMVA::MethodBase::PrintHelpMessage() const; voidTMVA::Configurable::PrintOptions() const; virtual voidProcessOptions(); voidTMVA::MethodBase::ProcessSetup(); virtual Int_tTObject::Read(const char* name); voidTMVA::Configurable::ReadOptionsFromStream(istream& istr); voidTMVA::Configurable::ReadOptionsFromXML(void* node); voidTMVA::MethodBase::ReadStateFromFile(); voidTMVA::MethodBase::ReadStateFromStream(istream& tf); voidTMVA::MethodBase::ReadStateFromStream(TFile& rf); voidTMVA::MethodBase::ReadStateFromXMLString(const char* xmlstr); virtual voidReadWeightsFromStream(istream& istr); virtual voidReadWeightsFromXML(void* parent); virtual voidTObject::RecursiveRemove(TObject* obj); voidTMVA::MethodBase::RerouteTransformatio",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15750,Performance,tune,tuneParameters,15750," d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virt",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27722,Performance,optimiz,optimizing,27722,"um number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destru",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29320,Performance,Optimiz,OptimizeTuningParameters,29320,"ocessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29485,Performance,tune,tuned,29485,"ocessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:29537,Performance,tune,tuneParameters,29537,"Method. void Reset( void ); reset the method, as if it had just been instantiated (forget all training etc.). ~MethodBDT( void ); destructor. void InitEventSample( void ); Write all Events from the Tree into a vector of Events, that are; more easily manipulated. This method should never be called without; existing trainingTree, as it the vector of events from the ROOT training tree. void PreProcessNegativeEventWeights(); o.k. you know there are events with negative event weights. This routine will remove; them by pairing them with the closest event(s) of the same event class with positive; weights; A first attempt is ""brute force"", I dont' try to be clever using search trees etc,; just quick and dirty to see if the result is any good. std::map<TString,Double_t> OptimizeTuningParameters(TString fomType = ""ROCIntegral"", TString fitType = ""FitGA""); call the Optimzier with the set of paremeters and ranges that; are meant to be tuned. void SetTuneParameters(map<TString,Double_t> tuneParameters); set the tuning parameters accoding to the argument. void Train(); BDT training. void GetRandomSubSample(); fills fEventSample with fSampleFraction*NEvents random training events. Double_t GetGradBoostMVA(TMVA::Event& e, UInt_t nTrees); returns MVA value: -1 for background, 1 for signal. void UpdateTargets(vector<TMVA::Event*> , UInt_t cls = 0); Calculate residua for all events;. void UpdateTargetsRegression(vector<TMVA::Event*> , Bool_t first = kFALSE); Calculate current residuals for all events and update targets for next iteration. Double_t GetWeightedQuantile(vector<std::pair<Double_t,Double_t> > vec, const Double_t quantile, const Double_t SumOfWeights = 0.0); calculates the quantile of the distribution of the first pair entries weighted with the values in the second pair entries. Double_t GradBoost(vector<TMVA::Event*> , TMVA::DecisionTree* dt, UInt_t cls = 0); Calculate the desired response value for each region. Double_t GradBoostRegression(vector<TMVA::Event*> , TMVA::Dec",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27589,Safety,avoid,avoided,27589,"in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded, for available options see ""DeclareOptions"". void Init( void ); common initialisation with defaults for the BDT-Method. void Reset( ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:11007,Security,Hash,Hash,11007,"UInt_tTMVA::MethodBase::GetTrainingROOTVersionCode() const; TStringTMVA::MethodBase::GetTrainingROOTVersionString() const; UInt_tTMVA::MethodBase::GetTrainingTMVAVersionCode() const; TStringTMVA::MethodBase::GetTrainingTMVAVersionString() const; Double_tTMVA::MethodBase::GetTrainTime() const; TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true); const TMVA::TransformationHandler&TMVA::MethodBase::GetTransformationHandler(Bool_t takeReroutedIfAvailable = true) const; virtual UInt_tTObject::GetUniqueID() const; vector<Double_t>GetVariableImportance(); Double_tGetVariableImportance(UInt_t ivar); TStringTMVA::MethodBase::GetWeightFileName() const; Double_tTMVA::MethodBase::GetXmax(Int_t ivar) const; Double_tTMVA::MethodBase::GetXmin(Int_t ivar) const; virtual Bool_tTObject::HandleTimer(TTimer* timer); virtual Bool_tHasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); virtual ULong_tTObject::Hash() const; Bool_tTMVA::MethodBase::HasMVAPdfs() const; virtual voidTObject::Info(const char* method, const char* msgfmt) const; virtual Bool_tTObject::InheritsFrom(const char* classname) const; virtual Bool_tTObject::InheritsFrom(const TClass* cl) const; voidInitEventSample(); virtual voidTObject::Inspect() constMENU ; voidTObject::InvertBit(UInt_t f); virtual TClass*IsA() const; virtual Bool_tTObject::IsEqual(const TObject* obj) const; virtual Bool_tTObject::IsFolder() const; Bool_tTObject::IsOnHeap() const; virtual Bool_tTMVA::MethodBase::IsSignalLike(); virtual Bool_tTMVA::MethodBase::IsSignalLike(Double_t mvaVal); virtual Bool_tTObject::IsSortable() const; Bool_tTObject::IsZombie() const; virtual voidTObject::ls(Option_t* option = """") const; virtual voidTMVA::MethodBase::MakeClass(const TString& classFileName = TString("""")) const; voidMakeClassInstantiateNode(TMVA::DecisionTreeNode* n, ostream& fout, const TString& className) const; virtual voidMakeClassSpecific(ostream&, const TSt",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:21417,Security,validat,validation,21417,"values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBetabeta parameter for AdaBoost algorithm; TStringfAdaBoostR2Lossloss type used in AdaBoostR2 (Linear,Quadratic or Exponential); Bool_tfAutomaticuse user given prune strength or automatically determined one using a validation sample; Bool_tfBaggedGradBoostturn bagging in combination with grad boost on/off; TStringfBoostTypestring specifying the boost type; Double_tfBoostWeightntuple var: boost weight; vector<double>fBoostWeightsthe weights applied in the individual boosts; Bool_tfDoBoostMonitorcreate control plot with ROC integral vs tree number; Double_tfErrorFractionntuple var: misclassification error fraction; vector<TMVA::Event*>fEventSamplethe training events; Double_tfFValidationEventsfraction of events to use for pruning; vector<TMVA::DecisionTree*,allocator<TMVA::DecisionTree*> >fForestthe collection of decision trees; Int_tfITreentuple var: ith tree; Bool_tfInverseBoostNegWeightsboost ev. with neg. weights with 1/boostweight rathre than boostweight; UInt_tfMaxDepthmax depth; Double_tfMinLinCorrForFisherthe minimum linear correlation between two variables demanded for use in fisher criterium in node splitting; TTree*fMonitorNtuplemonitoring ntuple; Int_tfNCutsgrid used in cut applied in node splitting; UInt_tfNNodesMaxmax # of nodes; Int_tfNTreesnumber of decision trees requested; TStringfNegWeightTreatmentvariable that holds the option of how to treat negative event weights in training; Bool_tfNoNegWeightsInTraini",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24958,Security,Validat,Validation,24958,"ts; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the b",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:2784,Testability,log,log,2784,"ructed using the same mechanism as described for the root; node. The devision is stopped once a certain node has reached either a; minimum number of events, or a minimum or maximum signal purity. These; leave nodes are then called ""signal"" or ""background"" if they contain; more signal respective background events from the training sample. Boosting:. The idea behind adaptive boosting (AdaBoost) is, that signal events; from the training sample, that end up in a background node; (and vice versa) are given a larger weight than events that are in; the correct leave node. This results in a re-weighed training event; sample, with which then a new decision tree can be developed.; The boosting can be applied several times (typically 100-500 times); and one ends up with a set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as sign",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:3515,Testability,test,test,3515," set of decision trees (a forest).; Gradient boosting works more like a function expansion approach, where; each tree corresponds to a summand. The parameters for each summand (tree); are determined by the minimization of a error function (binomial log-; likelihood for classification and Huber loss for regression).; A greedy algorithm is used, which means, that only one tree is modified; at a time, while the other trees stay fixed. Bagging:. In this particular variant of the Boosted Decision Trees the boosting; is not done on the basis of previous training results, but by a simple; stochastic re-sampling of the initial training event sample. Random Trees:; Similar to the ""Random Forests"" from Leo Breiman and Adele Cutler, it; uses the bagging algorithm together and bases the determination of the; best node-split during the training on a random subset of variables only; which is individually chosen for each split. Analysis:. Applying an individual decision tree to a test event results in a; classification of the event as either signal or background. For the; boosted decision tree selection, an event is successively subjected to; the whole set of decision trees and depending on how often it is; classified as signal, a ""likelihood"" estimator is constructed for the; event being signal or background. The value of this estimator is the; one which is then used to select the events from an event sample, and; the cut value on this estimator defines the efficiency and purity of; the selection. Function Members (Methods); public:. virtual~MethodBDT(); voidTObject::AbstractMethod(const char* method) const; voidTMVA::Configurable::AddOptionsXMLTo(void* parent) const; voidTMVA::MethodBase::AddOutput(TMVA::Types::ETreeType type, TMVA::Types::EAnalysisType analysisType); virtual voidAddWeightsXMLTo(void* parent) const; virtual voidTObject::AppendPad(Option_t* option = """"); TDirectory*TMVA::MethodBase::BaseDir() const; Double_tBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, Int_t",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:15570,Testability,test,testTime,15570,"TMVA::MethodBase::SetBaseDir(TDirectory* methodDir); voidTObject::SetBit(UInt_t f); voidTObject::SetBit(UInt_t f, Bool_t set); voidTMVA::Configurable::SetConfigDescription(const char* d); voidTMVA::Configurable::SetConfigName(const char* n); virtual voidTMVA::MethodBase::SetCurrentEvent(Long64_t ievt) const; virtual voidTObject::SetDrawOption(Option_t* option = """")MENU ; static voidTObject::SetDtorOnly(void* obj); voidSetMaxDepth(Int_t d); voidTMVA::MethodBase::SetMethodBaseDir(TDirectory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseC",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16059,Testability,Test,TestBit,16059,"tory* methodDir); voidTMVA::MethodBase::SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& pr",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16098,Testability,Test,TestBits,16098,":SetMethodDir(TDirectory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::Write",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16154,Testability,Test,TestClassification,16154,"tory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16206,Testability,Test,TestMulticlass,16206,"tory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:16254,Testability,Test,TestRegression,16254,"tory* methodDir); voidTMVA::Configurable::SetMsgType(TMVA::EMsgType t); voidSetNodeMinEvents(Int_t d); voidSetNodePurityLimit(Double_t l); voidSetNTrees(Int_t d); static voidTObject::SetObjectStat(Bool_t stat); voidTMVA::Configurable::SetOptions(const TString& s); voidTMVA::MethodBase::SetSignalReferenceCut(Double_t cut); voidTMVA::MethodBase::SetSignalReferenceCutOrientation(Double_t cutOrientation); voidTMVA::MethodBase::SetTestTime(Double_t testTime); voidTMVA::MethodBase::SetTestvarName(const TString& v = """"); voidTMVA::MethodBase::SetTrainTime(Double_t trainTime); virtual voidSetTuneParameters(map<TString,Double_t> tuneParameters); virtual voidTObject::SetUniqueID(UInt_t uid); voidTMVA::MethodBase::SetupMethod(); virtual voidShowMembers(TMemberInspector& insp); virtual voidStreamer(TBuffer& b); voidStreamerNVirtual(TBuffer& b); virtual voidTObject::SysError(const char* method, const char* msgfmt) const; Bool_tTObject::TestBit(UInt_t f) const; Int_tTObject::TestBits(UInt_t f) const; virtual voidTMVA::MethodBase::TestClassification(); virtual voidTMVA::MethodBase::TestMulticlass(); virtual voidTMVA::MethodBase::TestRegression(Double_t& bias, Double_t& biasT, Double_t& dev, Double_t& devT, Double_t& rms, Double_t& rmsT, Double_t& mInf, Double_t& mInfT, Double_t& corr, TMVA::Types::ETreeType type); Double_tTestTreeQuality(TMVA::DecisionTree* dt); virtual voidTrain(); voidTMVA::MethodBase::TrainMethod(); virtual voidTObject::UseCurrentStyle(); virtual voidTObject::Warning(const char* method, const char* msgfmt) const; virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0); virtual Int_tTObject::Write(const char* name = 0, Int_t option = 0, Int_t bufsize = 0) const; virtual voidTMVA::MethodBase::WriteEvaluationHistosToFile(TMVA::Types::ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const.",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:18020,Testability,Log,Log,18020,"ETreeType treetype); virtual voidWriteMonitoringHistosToFile() const; voidTMVA::Configurable::WriteOptionsToStream(ostream& o, const TString& prefix) const; voidTMVA::MethodBase::WriteStateToFile() const. protected:. virtual voidDeclareCompatibilityOptions(); virtual voidTObject::DoError(int level, const char* location, const char* fmt, va_list va) const; voidTMVA::Configurable::EnableLooseOptions(Bool_t b = kTRUE); const TString&TMVA::MethodBase::GetInternalVarName(Int_t ivar) const; const TString&TMVA::MethodBase::GetOriginalVarName(Int_t ivar) const; const TString&TMVA::Configurable::GetReferenceFile() const; static TMVA::MethodBase*TMVA::MethodBase::GetThisBase(); Float_tTMVA::MethodBase::GetTWeight(const TMVA::Event* ev) const; const TString&TMVA::MethodBase::GetWeightFileDir() const; Bool_tTMVA::MethodBase::HasTrainingTree() const; Bool_tTMVA::MethodBase::Help() const; Bool_tTMVA::MethodBase::IgnoreEventsWithNegWeightsInTraining() const; Bool_tTMVA::MethodBase::IsConstructedFromWeightFile() const; Bool_tTMVA::MethodBase::IsNormalised() const; TMVA::MsgLogger&TMVA::Configurable::Log() const; Bool_tTMVA::Configurable::LooseOptionCheckingEnabled() const; voidTObject::MakeZombie(); voidTMVA::MethodBase::NoErrorCalc(Double_t *const err, Double_t *const errUpper); voidTMVA::Configurable::ResetSetFlag(); voidTMVA::MethodBase::SetNormalised(Bool_t norm); voidTMVA::MethodBase::SetWeightFileDir(TString fileDir); voidTMVA::MethodBase::SetWeightFileName(TString); voidTMVA::MethodBase::Statistics(TMVA::Types::ETreeType treeType, const TString& theVarName, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&, Double_t&); Bool_tTMVA::MethodBase::TxtWeightsOnly() const; Bool_tTMVA::MethodBase::Verbose() const; voidTMVA::Configurable::WriteOptionsReferenceToFile(). private:. Double_tAdaBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tAdaBoostR2(vector<TMVA::Event*>, TMVA::DecisionTree* dt); Double_tBagging(vector<TMVA::Event*>, Int_t iTree); voidBoostMonitor(Int_t ",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:20244,Testability,test,testing,20244,"ts = 0.0); Double_tGradBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt, UInt_t cls = 0); Double_tGradBoostRegression(vector<TMVA::Event*>, TMVA::DecisionTree* dt); virtual voidInit(); voidInitGradBoost(vector<TMVA::Event*>); voidPreProcessNegativeEventWeights(); Double_tPrivateGetMvaValue(TMVA::Event& ev, Double_t* err = 0, Double_t* errUpper = 0, UInt_t useNTrees = 0); Double_tRegBoost(vector<TMVA::Event*>, TMVA::DecisionTree* dt); voidUpdateTargets(vector<TMVA::Event*>, UInt_t cls = 0); voidUpdateTargetsRegression(vector<TMVA::Event*>, Bool_t first = kFALSE). Data Members; public:. enum TMVA::MethodBase::EWeightFileType { kROOT; kTEXT; };; enum TObject::EStatusBits { kCanDelete; kMustCleanup; kObjInCanvas; kIsReferenced; kHasUUID; kCannotPick; kNoContextMenu; kInvalidObject; };; enum TObject::[unnamed] { kIsOnHeap; kNotDeleted; kZombie; kBitMask; kSingleKey; kOverwrite; kWriteDelete; };. public:. Bool_tTMVA::MethodBase::fSetupCompletedis method setup; const TMVA::Event*TMVA::MethodBase::fTmpEvent! temporary event when testing on a different DataSet than the own one. protected:. TMVA::Types::EAnalysisTypeTMVA::MethodBase::fAnalysisTypemethod-mode : true --> regression, false --> classification; UInt_tTMVA::MethodBase::fBackgroundClassindex of the Background-class; vector<TString>*TMVA::MethodBase::fInputVarsvector of input variables used in MVA; vector<Float_t>*TMVA::MethodBase::fMulticlassReturnValholds the return-values for the multiclass classification; Int_tTMVA::MethodBase::fNbinsnumber of bins in input variable histograms; Int_tTMVA::MethodBase::fNbinsHnumber of bins in evaluation histograms; Int_tTMVA::MethodBase::fNbinsMVAoutputnumber of bins in MVA output histograms; TMVA::Ranking*TMVA::MethodBase::fRankingpointer to ranking object (created by derived classifiers); vector<Float_t>*TMVA::MethodBase::fRegressionReturnValholds the return-values for the regression; UInt_tTMVA::MethodBase::fSignalClassindex of the Signal-class. private:. Double_tfAdaBoostBeta",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:24809,Testability,log,log,24809,"ts; Bool_tfTrainWithNegWeightsyes there are negative event weights and we don't ignore them; Double_tfTransitionPointbreak-down point for gradient regression; Bool_tfUseExclusiveVarsindividual variables already used in fisher criterium are not anymore analysed individually for node splitting; Bool_tfUseFisherCutsuse multivariate splits using the Fisher criterium; UInt_tfUseNTrainEventsnumber of randomly picked training events used in randomised (and bagged) trees; UInt_tfUseNvarsthe number of variables used in the randomised tree splitting; Bool_tfUsePoissonNvarsuse ""fUseNvars"" not as fixed number but as mean of a possion distr. in each split; Bool_tfUseWeightedTreesuse average classification from the trees, or have the individual trees trees in the forest weighted (e.g. log(boostweight) from AdaBoost; Bool_tfUseYesNoLeafuse sig or bkg classification in leave nodes or sig/bkg; vector<TMVA::Event*>fValidationSamplethe Validation events; vector<Double_t>fVariableImportancethe relative importance of the different variables; map<TMVA::Event*,std::pair<Double_t,Double_t> >fWeightedResidualsweighted regression residuals; static const Int_tfgDebugLeveldebug level determining some printout/control plots etc. Class Charts. Inheritance; Inherited Members; Includes; Libraries. Function documentation; MethodBDT(const TString& jobName, const TString& methodTitle, TMVA::DataSetInfo& theData, const TString& theOption = """", TDirectory* theTargetDir = 0); the standard constructor for the ""boosted decision trees"". MethodBDT(TMVA::DataSetInfo& theData, const TString& theWeightFile, TDirectory* theTargetDir = NULL). Bool_t HasAnalysisType(TMVA::Types::EAnalysisType type, UInt_t numberClasses, UInt_t numberTargets); BDT can handle classification with multiple classes and regression with one regression-target. void DeclareOptions(); define the options (their key words) that can be set in the option string; know options:; nTrees number of trees in the forest to be created; BoostType the b",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
https://root.cern/root/html532/TMVA__MethodBDT.html:27334,Testability,log,log,27334,"n; UseNTrainEvents number of training events used in randomised (and bagged) trees; SeparationType the separation criterion applied in the node splitting; known: GiniIndex; MisClassificationError; CrossEntropy; SDivSqrtSPlusB; nEventsMin: the minimum number of events in a node (leaf criteria, stop splitting); nCuts: the number of steps in the optimisation of the cut for a node (if < 0, then; step size is determined by the events); UseFisherCuts: use multivariate splits using the Fisher criterion; UseYesNoLeaf decide if the classification is done simply by the node type, or the S/B; (from the training) in the leaf node; NodePurityLimit the minimum purity to classify a node as a signal node (used in pruning and boosting to determine; misclassification error rate); UseWeightedTrees use average classification from the trees, or have the individual trees; trees in the forest weighted (e.g. log(boostweight) from AdaBoost; PruneMethod The Pruning method:; known: NoPruning // switch off pruning completely; ExpectedError; CostComplexity; PruneStrength a parameter to adjust the amount of pruning. Should be large enough such that overtraining is avoided.; PruneBeforeBoost flag to prune the tree before applying boosting algorithm; PruningValFraction number of events to use for optimizing pruning (only if PruneStrength < 0, i.e. automatic pruning); NegWeightTreatment IgnoreNegWeightsInTraining Ignore negative weight events in the training.; DecreaseBoostWeight Boost ev. with neg. weight with 1/boostweight instead of boostweight; PairNegWeightsGlobal Pair ev. with neg. and pos. weights in traning sample and ""annihilate"" them; PairNegWeightsInNode Randomly pair miscl. ev. with neg. and pos. weights in node and don't boost them; NNodesMax maximum number of nodes allwed in the tree splitting, then it stops.; MaxDepth maximum depth of the decision tree allowed before further splitting is stopped. void DeclareCompatibilityOptions(). void ProcessOptions(); the option string is decoded,",MatchSource.WIKI,root/html532/TMVA__MethodBDT.html,root-project,root,v6-32-06,https://root.cern,https://root.cern/root/html532/TMVA__MethodBDT.html
