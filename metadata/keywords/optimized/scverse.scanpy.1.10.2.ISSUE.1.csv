quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:729,down,down,729,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922,1,['down'],['down']
Availability,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482,1,['error'],['error']
Availability,"I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis (like UMAP or Louvain) on this kNN graph. Is that right? I suppose this is currently not implemented for t-SNE? With openTSNE it'd be easy to use the pre-built kNN graph and run t-SNE directly on that. Also, the default parameters of t-SNE in scanpy could IMHO be improved, see https://www.nature.com/articles/s41467-019-13056-x. Some of these recommendations (learning rate, initialization) are now default in openTSNE. There are some open issues at scanpy related to t-SNE such as https://github.com/theislab/scanpy/issues/1150 and https://github.com/theislab/scanpy/issues/996 but I think this suggestion would supersede them. We had a brief discussion of this at openTSNE here https://github.com/pavlin-policar/openTSNE/issues/102. I can see four somewhat separate suggestions:. 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph; 2. add tSNE support for `ingest` using openTSNE functionality.; 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults.; 4. add some tSNE ""recipes"" based on https://www.nature.com/articles/s41467-019-13056-x. What of this, if any, makes sense from the scanpy point of view?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233:167,avail,available,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233,2,"['avail', 'down']","['available', 'downstream']"
Availability,I'm pretty sure it's the pandas 0.23 issue... same error message as the one encountered here: https://github.com/theislab/scanpy/issues/158,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/162#issuecomment-391991529:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162#issuecomment-391991529,1,['error'],['error']
Availability,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,2,['error'],['error']
Availability,"I'm pushing this from 1.9, but am also considering how well posed the issue is. There's a fairly complicated relationship between this kind of ""normalization"" and the `norm`, `vmin`, `vmax`, etc. arguments. I think this would need a tutorial (at least) to go with it. Some thoughts:. * Basically, what this feature is is an additional transformation applied to the summarized values before they are mapped to colors. This could (and probably should) also be available for sizes of the dots.; * This is kinda covered by matplotlib's `norm` values, but those can only be applied to all the data at once – not per group.; * If we make it easier to split out getting summarized dataframe then plotting the values, this could largely be handled in user code.; * If you are doing a `z-score` normalization, surely you'd want a centered colorbar and diverging palette?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-1084726453:458,avail,available,458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-1084726453,1,['avail'],['available']
Availability,"I'm thinking `n_comps` should default to `None`, and we'd define behaviour like:. ```python; if n_comps is None:; min_dim = min(adata.n_vars, adata.n_obs); if 50 >= min_dim:; n_comps = min_dim - 1; else:; n_comps = 50; ```. and we let sklearn throw an error if the user specified a number of components that doesn't work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586662503:252,error,error,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586662503,1,['error'],['error']
Availability,"I'm trying to import some data I downloaded from GEO using the read_10x_mtx() function. Since this data was generated with an older version of Cellranger, there is no features.tsv.gz file. I renamed the genes.tsv.gz file to features.tsv.gz but that still doesn't fix my problem. I am pasting the error message below: . ```pytb; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /Applications/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3077 try:; -> 3078 return self._engine.get_loc(key); 3079 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-13-884b80f3079d> in <module>; ----> 1 adata = sc.read_10x_mtx('/Users/kulkarnia2/Box/scRNASeq/HNSCC/Combined_TC_CK_scRNAseq/all_samples/HD_1_PBL'). ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 302 make_unique=make_unique,; 303 cache=cache,; --> 304 cache_compression=cache_compression,; 305 ); 306 if genefile_exists or not gex_only:. ~/.local/lib/python3.7/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression); 371 else:; 372 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 373 adata.var['feature_types'] = genes[2].values; 374 adata.obs_names = pd.read_csv(path / 'barcodes.tsv.gz', header=Non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1408:33,down,downloaded,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1408,3,"['down', 'error', 'toler']","['downloaded', 'error', 'tolerance']"
Availability,"I'm trying to install scanpy through `pip install scanpy` but I'm getting this weird error; ```; $ pip install scanpy; Collecting scanpy; Downloading scanpy-0.2.9.1.tar.gz (208kB); Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-lbk_t73k/scanpy/setup.py"", line 39, in <module>; readme = readme_f.read(); File ""/opt/conda/lib/python3.6/encodings/ascii.py"", line 26, in decode; return codecs.ascii_decode(input, self.errors)[0]; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); ```. That's with pip version `9.0.1` and python 3.6. I'm getting similar errors for older versions of scanpy, including 0.2.1. Perhaps this is a bug in pip but I'm not sure, I installed a bunch of other unrelated packages without any issues.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43,4,"['Down', 'error']","['Downloading', 'error', 'errors']"
Availability,"I'm trying to plot on a view of an on-disk AnnData object, and it throws an error. Not sure if this is meant to be a supported feature, but I gave it a go. Here's a little example to reproduce:. ```python; adata = sc.AnnData(X=np.random.binomial(100, .01, (100, 100))); adata.obs_names = adata.obs_names.astype(str); # Both these work; sc.pp.pca(adata); sc.pl.pca(adata[:, :5], color=""0""); adata.write(""tmp.h5ad""); adata_backed = sc.read(""tmp.h5ad"", backed=""r""); sc.pl.pca(adata_backed, color=""0"") # this works; sc.pl.pca(adata_backed[:, :5], color=""0"") # this throws an error; ```. <details>; <summary> traceback (pretty long) </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); h5py/_objects.pyx in h5py._objects.ObjectID.__dealloc__(). KeyError: 0. Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'; Traceback (most recent call last):; File ""h5py/_objects.pyx"", line 200, in h5py._objects.ObjectID.__dealloc__; KeyError: 0; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-255f06b48663> in <module>(); 1 adata_backed = sc.read(""tmp.h5ad"", backed=""r""); 2 sc.pl.pca(adata_backed, color=""0""); ----> 3 sc.pl.pca(adata_backed[:, :5], color=""0""). /usr/local/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py in pca(adata, color, use_raw, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save, ax); 114 title=title,; 115 show=False,; --> 116 save=False, ax=ax); 117 utils.savefig_or_show('pca_scatter', show=show, save=save); 118 if show == False: return axs. /usr/local/lib/python3.6/site-packages/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263,2,['error'],['error']
Availability,"I'm trying to run BBKNN on a AnnData object built with `scanpy==1.4.6` but it's failing when getting the graph. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; sc.external.pp.bbknn(; adata,; batch_key=""batch"",; n_pcs=21,; neighbors_within_batch=5,; trim=0); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Command error:; Traceback (most recent call last):; File ""~/sc_batch_effect_correction.py"", line 160, in <module>; trim=args.trim); File ""/opt/venv/lib/python3.7/site-packages/scanpy/external/pp/_bbknn.py"", line 120, in bbknn; **kwargs,; File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 281, in bbknn; approx=approx, metric=metric, **kwargs); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 325, in bbknn_pca_matrix; neighbors_within_batch=neighbors_within_batch); File ""/opt/venv/lib/python3.7/site-packages/bbknn/__init__.py"", line 168, in get_graph; knn_indices[ind_from[:,None],col_range[None,:]] = ckdout[1]; ValueError: shape mismatch: value array of shape (240,4) could not be broadcast to indexing result of shape (240,5); ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.2 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1222:334,Error,Error,334,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1222,2,"['Error', 'error']","['Error', 'error']"
Availability,"I'm trying to take subgroups from the AnnData object as such:; `adata_1 = adata[adata.obs['louvain'] == '0']`; which works but if I want to get the inverse; `adata_1 = adata[adata.obs['louvain'] != '0']`; it sometimes throws this error only on the second line.; 'IndexError: index 8 is out of bounds for axis 0 with size 8'; After some debugging, it seems like this occurs when you try run louvain clustering at different resolutions (ie doing it more than once). . Is there something real elementary that I am missing here? Or is there a better way of doing what I need? Thanks, Kevin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833,1,['error'],['error']
Availability,"I'm using Scanpy with the following software versions:. python==3.7; scanpy==1.4.4; numpy==1.17.2; anndata==0.6.22.post1. on Ubuntu 18.04. I am able to save my AnnData object just fine with . ```py; sc.write(results_file, adata); ```; and to load it again with . ```py; adata = sc.read(results_file); ```. however if I save it after I run the command . ```py; sc.tl.rank_genes_groups(adata, 'louvain12_lab', method='wilcoxon'); ```. the AnnData object will save but when I try to reload it, I get an error message:. ```pytb; ValueError Traceback (most recent call last); <ipython-input-141-159082f1696f> in <module>; 1 results_file = os.path.join(adir, '{project}.count_{count}.gene_{gene}.mito_{mito}.HVGs_{nhvgs}.TPT.{log}.scale.TEST.h5ad'.format(project=project_name, count=count_thresh, gene=gene_thresh, mito=mitothresh, nhvgs=nhvgs, log=logstatus)); 2 print(results_file); ----> 3 adata = sc.read(results_file). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /opt/min",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832:500,error,error,500,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832,1,['error'],['error']
Availability,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297,2,['error'],['error']
Availability,"I'm using scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 on Mac 10.12.6 with python 3.7.1; I'm trying to do a pca on a annData object; `sc.tl.pca(adata, svd_solver='arpack')`; and get the following error even after restarting the jupyter notebook:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-26-eb775d53dbfd> in <module>; ----> 1 sc.tl.pca(adata, svd_solver='arpack'). ~/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 504 ; 505 if data_is_AnnData:; --> 506 adata.obsm['X_pca'] = X_pca; 507 if use_highly_variable:; 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). ValueError: no field of name X_pca; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/504:297,error,error,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504,1,['error'],['error']
Availability,"I've been able to pin down the culprit.; Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226:22,down,down,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226,1,['down'],['down']
Availability,"I've been having some issues recently when trying to subset an anndata object after I save it to disk. Everything works perfectly, but after I save it to disk using `adata.write(filename, compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's relate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/884:503,error,error,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884,1,['error'],['error']
Availability,"I've been thinking it would be good to add a `mask` argument to a number of functions. I think `mask_vars=~(adata.var[""mito""] | adata.var[""ribo""])` could work here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744#issuecomment-800775264:46,mask,mask,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744#issuecomment-800775264,1,['mask'],['mask']
Availability,"I've been trying to export my data to SPRING using the external export feature. I do all my processing in Seurat and then export a loom file to be read in scanpy and export to SPRING. I've been however getting the below error. The notebook with the code and the loom file can be found here: https://github.com/tejas-j/seurat2spring. Is there a better way to achieve what I'm trying to do (data -> Seurat -> scanpy -> SPRING) . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-3b0044b18ade> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sce.exporting.spring_project(data, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); 4 print(time.time() - t0). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, overwrite); 157 # Write continuous colors; 158 continuous_extras['Uniform'] = np.zeros(E.shape[0]); --> 159 write_color_tracks(continuous_extras, subplot_dir / 'color_data_gene_sets.csv'); 160 ; 161 # Create and write a dictionary of color profiles to be used by the visualizer. ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in write_color_tracks(ctracks, fname); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). ~/miniconda2/envs/py36/lib/python3.6/site-packages/scanpy/_exporting.py in <listcomp>(.0); 301 out = []; 302 for name,score in ctracks.items():; --> 303 line = name + ',' + ','.join(['%.3f' %x for x in score]); 304 out += [line]; 305 out = sorted(out,key=lambda x: x.split(',')[0]). TypeError: must be real number, not numpy.str_; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889:220,error,error,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889,1,['error'],['error']
Availability,"I've encountered similar issue last week and it was because `adata.obs` contained a column which was `n_obs x 1` `scipy.sparse.spmatrix`. The below code reproduces the formatter issue (`pandas==1.3.3`):. ```python; import scanpy as sc; from scipy.sparse import csr_matrix. adata = sc.datasets.pbmc3k(); adata.X = csr_matrix(adata.X); adata.obs['total_counts'] = adata.X.sum(1) # is sparse, pandas doesn't complain; adata.obs # raises the formatter error; ```. <details>. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(obj, self, cycle); 395 ; 396 return _default_pprint(obj, self, cycle). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 698 """"""A pprint that just redirects to the normal repr function.""""""; 699 # Find newlines and replace them with p.break_(); --> 700 output = repr(obj); 701 lines = output.splitlines(); 702 with p.group():. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in __repr__(self); 993 else:; 994 width = None; --> 995 self.to_string(; 996 buf=buf,; 997 max_rows=max_rows,. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in to_string(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width, max_colwidth, encoding); 1129 decimal=decimal,; 1130 ); -> 1131 return fmt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:448,error,error,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['error'],['error']
Availability,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-797806911:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-797806911,1,['error'],['error']
Availability,"I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']`; Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file.; The file I was reading in was from HTO data and only had one column:. > Hashtag1-GTCAACTCTTTAGCG; > Hashtag2-TTCCGCCTCTCTTTG; > Hashtag3-AAGTATCGTTTCGCA; > unmapped. So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):. >RP11-34P13.7	RP11-34P13.7	Gene Expression; >FO538757.3	FO538757.3	Gene Expression; >FO538757.2	FO538757.2	Gene Expression; >AP006222.2	AP006222.2	Gene Expression; >RP4-669L17.10	RP4-669L17.10	Gene Expression. It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697,4,['error'],['error']
Availability,"I've fixed the error I was getting, which was posted on another issue and referenced here.; Here's the solution that worked for me:; https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-1286416876:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-1286416876,1,['error'],['error']
Availability,"I've found a workaround, when I downgrade to `anndata=0.6.22.post1` (still with `scanpy==1.4.5.post2`), it generates an output with `paga_path` but also this warning:. ```; FutureWarning: In anndata v0.7+, arrays contained within an AnnData object will maintain their dimensionality. For example, prior to v0.7 `adata[0, 0].X` returned a scalar and `adata[0, :]` returned a 1d array, post v0.7 they will return two dimensional arrays. If you would like to get a one dimensional array from your AnnData object, consider using the `adata.obs_vector`, `adata.var_vector` methods or accessing the array directly.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609:32,down,downgrade,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609,1,['down'],['downgrade']
Availability,"I've got one minor comment left (one last redundant print statement), but otherwise I'm good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170:42,redundant,redundant,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170,1,['redundant'],['redundant']
Availability,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:109,avail,available,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101,3,['avail'],['available']
Availability,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421:47,mask,masked,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421,1,['mask'],['masked']
Availability,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:59,down,downloader,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932,1,['down'],['downloader']
Availability,"I've tried running `sc.pp.neighbors` with only 1 feature, got the following error:. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-6-e652dbfa9fae> in <module>; 3 ; 4 adata = sc.datasets.paul15(); ----> 5 sc.pp.neighbors(adata[:, 0]). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 653 use_dense_distances = (metric == 'euclidean' and X.shape[0] < 8192) or knn == False; 654 if use_dense_distances:; --> 655 _distances = pairwise_distances(X, metric=metric, **metric_kwds); 656 knn_indices, knn_distances = get_indices_distances_from_dense_matrix(; 657 _distances, n_neighbors). ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds); 1586 func = partial(distance.cdist, metric=metric, **kwds); 1587 ; -> 1588 return _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1589 ; 1590 . ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in _parallel_pairwise(X, Y, func, n_jobs, **kwds); 1204 ; 1205 if effective_n_jobs(n_jobs) == 1:; -> 1206 return func(X, Y, **kwds); 1207 ; 1208 # enforce a threading backend to prevent data communication overhead. ~/.local/miniconda3/envs/reprog/lib/python3.6/site-packages/sklearn/metrics/pairwise.py in euclidean_distances(X, Y, Y_norm_squared, squared, X_norm_squared); 230 paired_dista",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/837:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837,1,['error'],['error']
Availability,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>; <summary> Example usage </summary>. ```python; from adjustText import adjust_text. def gen_mpl_labels(; adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None; ):; if adjust_kwargs is None:; adjust_kwargs = {""text_from_points"": False}; if text_kwargs is None:; text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():; if g in exclude:; continue; medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:; texts = [; plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(); ]; else:; texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):; ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False); gen_mpl_labels(; pbmc,; ""Low-level celltypes"",; exclude=(""None"",), # This was before we had the `nan` behaviour; ax=ax,; adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),; text_kwargs=dict(fontsize=14),; ); fig = ax.get_figure(); fig.tight_layout(); plt.show(); ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1513#issuecomment-735051689:1710,mainten,maintenance,1710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513#issuecomment-735051689,1,['mainten'],['maintenance']
Availability,"IIRC, it's discussed in more detail in Malte's paper:. > ; In the same way that cellular count data can be normalized to make them comparable between cells, gene counts can be scaled to improve comparisons between genes. Gene normalization constitutes scaling gene counts to have zero mean and unit variance (z scores). This scaling has the effect that all genes are weighted equally for downstream analysis. There is currently no consensus on whether or not to perform normalization over genes. While the popular Seurat tutorials (Butler et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0020)) generally apply gene scaling, the authors of the Slingshot method opt against scaling over genes in their tutorial (Street et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0125)). The preference between the two choices revolves around whether all genes should be weighted equally for downstream analysis, or whether the magnitude of expression of a gene is an informative proxy for the importance of the gene. In order to retain as much biological information as possible from the data, we opt to refrain from scaling over genes in this tutorial. https://www.embopress.org/doi/full/10.15252/msb.20188746. Since there has been no new development on this topic, we cited Malte and also opted not to scale. This is also discussed by Malte himself in the issue that was cited above. I cannot comment on spatial data itself and make confident statements here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034415456:388,down,downstream,388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034415456,2,['down'],['downstream']
Availability,"If I read a file with read_h5ad() and then process with . `sc.pp.filter_genes(adata, min_cells=int(foo)); `; Things work as intended. But if I change that read line to be read_h5ad(h5_path, backed='r') then when I attempt to filter I get this error instead:. ```; File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 228, in filter_genes:; else X > 0, axis=0):; TypeError: '>' not supported between instances of 'SparseDataset' and 'int'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/650:243,error,error,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/650,1,['error'],['error']
Availability,"If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2351:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351,1,['error'],['error']
Availability,"If it is caused by the same score, how to ensure the uniquenss? Thanks. I did not receive the var.unique.name error thus I think it was not caused by duplicate gene names. It is neurips 2021 single cell competition dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906382163:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906382163,1,['error'],['error']
Availability,"If we pinned `umap-learn>=0.5.1`.1 it would be impossible to install scvelo, since [it pins umap<0.5](https://github.com/theislab/scvelo/blob/1659cc8e00a45fcf87cd80a7013aae5531744613/requirements.txt#L9). We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206:354,down,downstream,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206,1,['down'],['downstream']
Availability,"If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1886:154,error,errors,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886,1,['error'],['errors']
Availability,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107534834:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107534834,2,['error'],['error']
Availability,"If you try to color a scatter plot by gene expression in a layer, but the layer is sparse, an error is thrown. This occurs on both current release and master. Code to reproduce:. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(); pbmc.layers[""sparse""] = pbmc.raw.X; sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse"") ; ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-89244dc07987> in <module>; 3 pbmc = sc.datasets.pbmc68k_reduced(); 4 pbmc.layers[""sparse""] = pbmc.raw.X; ----> 5 sc.pl.pca(pbmc, color=[""HES4""], layer=""sparse""). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 410 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 411 """"""; --> 412 return plot_scatter(adata, 'pca', **kwargs); 413 ; 414 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 199 _data_points[:, 0], _data_points[:, 1],; 200 marker=""."", c=color_vector, rasterized=settings._vector_friendly,; --> 201 **kwargs,; 202 ); 203 . ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs); 1587 def inner(ax, *args, data=None, **kwargs):; 1588 if data is None:; -> 1589 return func(ax, *map(sanitize_sequence, args), **kwargs); 1590 ; 1591 bound = new_sig.bind(ax, *args, **kwargs). ~/miniconda3/envs/scanpy-conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/700:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700,1,['error'],['error']
Availability,"If you use `knn=False` to calculate neighbors, any choice of metric is ignored. [Here's the offending line of code.](https://github.com/theislab/scanpy/blob/6c1daba7448be72de84dec16a038fcaeda1636ad/scanpy/neighbors/__init__.py#L706). A quick example:. ```python; import scanpy.api as sc; import numpy as np. adata = sc.datasets.krumsiek11(); adata.obs_names_make_unique(); sc.pp.pca(adata) # To get rid of warnings; adata_eucl = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True); adata_spear = sc.pp.neighbors(adata, knn=False, method=""gauss"", copy=True, metric=""correlation""). assert np.all(adata_eucl.uns[""neighbors""][""connectivities""] == adata_spear.uns[""neighbors""][""connectivities""]); ```. Additionally, I suspect this should throw an error:. ```python; sc.pp.neighbors(adata, method=""gauss"", knn=False, metric=""not a real metric""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/241:751,error,error,751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/241,1,['error'],['error']
Availability,Import error when old version of tqdm is installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1244:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1244,1,['error'],['error']
Availability,Import error when running cyclone,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/655:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/655,1,['error'],['error']
Availability,ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_nor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20375,ERROR,ERROR,20375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5973,ERROR,ERROR,5973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"In #706 @LuckyMD gives a minimal working example in [this comment](https://github.com/theislab/scanpy/issues/706#issuecomment-505335006) that may give you a useful starting point. Their advice to create/post a way to reproduce the error is good too, as it may help you identify the source of the problem in the process (and make it easier for others to help troubleshoot)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/952#issuecomment-567617566:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/952#issuecomment-567617566,1,['error'],['error']
Availability,"In a recent paper, we found the brute force KNN computation to become very expensive as the data sizes increase. I’ve noticed the kNN graph computed during the “neighbors” computation can be cached and reused when Umap-learn is called downstream but when Cuml UMAP is used, the kNN graph is recomputed each time. . In cuml 0.13 we added an optional `knn_graph` argument to umap’s training and inference methods to allow it to accept pre-computed kNN graph. This will allow the kNN graph to be computed once and reused when `n_neighbors` has not been changed. I think this would further accelerate the exploratory data analysis and visualization process with scanpy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1279:235,down,downstream,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1279,1,['down'],['downstream']
Availability,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442,4,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-748548060:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-748548060,1,['error'],['error']
Availability,"In some edge cases, the control gene selection retrieves the same gene(s) that are also in the gene_list used for scoring.; As a result, when the following line is called, we end up with an empty control gene set, causing the downstream error in #2153; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L173. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [x] Closes #2153 ; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875:226,down,downstream,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875,2,"['down', 'error']","['downstream', 'error']"
Availability,"In supplementary figure 9 of our paper, I did a light comparison of tools using the demuxlet data as ground truth: https://www.cell.com/cms/10.1016/j.cels.2020.05.010/attachment/040c239d-1e70-42a4-8974-9fbd75c65551/mmc1.pdf; Which I think is a fine first stab at getting at this comparison, but it could be better. Hashsolo performance was comparable with other methods but is able to recover cell types with lower CMO counts. . I think that sounds great. That's an issue we had as well, but I noticed it occurring for NK cells in kidney; ![Screen Shot 2021-01-13 at 9 18 30 AM](https://user-images.githubusercontent.com/6864886/104486266-5d095680-5580-11eb-971e-c882063f2a45.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008:385,recover,recover,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008,1,['recover'],['recover']
Availability,"In that case, I don't fully understand this typing and will just continue reading quietly ;). I assumed it would throw errors as for example in C++.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441254115:119,error,errors,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441254115,1,['error'],['errors']
Availability,"In the current release, we check for the counts being integer valued. kallisto can assign partial counts, (e.g a gene can have 1.5 counts) which triggers the check, triggering an error. For the next bugfix release we've softened consequences of this check failing to a warning, and the check can be skipped. See discussion in #1642 and #1679 for details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832:179,error,error,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832,1,['error'],['error']
Availability,"In the documentation (https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html) the figure given as an example for pl.violin does not match the actual output of pl.violin (rather, it's showing a stacked violin). If there's a more appropriate place for me to record errors in the documentation, please let me know. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1294:273,error,errors,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1294,1,['error'],['errors']
Availability,"In the error it looks like numba requires numpy < 1.20, so you could try installing the `numpy‑1.19.5+mkl` whl from https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy before installing the scikit-misc one from https://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-misc? . When you get the `Requirement already satisfied` error from `pip install`, you might need to first do `pip uninstall <pkg>` before installing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644,2,['error'],['error']
Availability,"In theory I think we can do most of that. In practice, I got some errors. I think it would be worth formalizing what the supported interface for doing multimodal analysis is. I'd really like it to be uniform. I could see it being based on keys in `.var`:. ```python; adata.var[""gex""] = adata.var[""expression_type""] == ""Gene Expression""; sc.pl.pca(adata, var_key=""gex""); sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); # This also has the nice feature that it could abstract out the current `use_highly_variable` argument; ```. View based:. ```python; gex_view = adata[:, adata.var[""expression_type""] == ""Gene Expression""]; sc.pp.pca(gex_view) # Calculate pca on gene expression; sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); ```. Different expression types could be put under `.obsm` (probably the closest ""analogy"" to `SingleCellExperiment`'s `assays()`). But this raises questions of what counts as a variable, and I think would take more work to implement. Of course, there are many other ways this could be done as well. As it could impact APIs throughout `scanpy`, I think input from @falexwolf and @flying-sheep is important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618,1,['error'],['errors']
Availability,"Indeed it was enlightening and useful...However, still gives me an error... ```pytb; type(adata); anndata.base.AnnData. adata.write_loom('./filtered_gene_bc_matrices_h5.loom'); ... writing to '.loom' file densifies sparse matrix; Converting to csc format; Creating; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-8-333dccc1e180> in <module>(); ----> 1 adata.write_loom('./filtered_gene_bc_matrices_h5.loom'). /anaconda3/lib/python3.6/site-packages/anndata/base.py in write_loom(self, filename); 1736 """"""; 1737 from .readwrite.write import write_loom; -> 1738 write_loom(filename, self); 1739 ; 1740 @staticmethod. /anaconda3/lib/python3.6/site-packages/anndata/readwrite/write.py in write_loom(filename, adata); 71 if os.path.exists(filename):; 72 os.remove(filename); ---> 73 create(filename, X, row_attrs=row_attrs, col_attrs=col_attrs); 74 ; 75 . /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in create(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1019 ; 1020 if scipy.sparse.issparse(matrix):; -> 1021 return _create_sparse(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1022 ; 1023 # Create the file (empty). /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in _create_sparse(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 982 if ds is None:; 983 logging.info(""Creating""); --> 984 ds = create(filename, matrix[:, ix:ix + window].toarray(), row_attrs, ca, file_attrs, chunks, chunk_cache, dtype, compression_opts); 985 else:; 986 logging.info(""Adding columns""). /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in create(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1033 ; 1034 for key, vals in row_attrs.items():; -> 1035 ds.set_attr(key, vals, axis=0); 1036 ; 1037",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/154#issuecomment-389486091:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154#issuecomment-389486091,1,['error'],['error']
Availability,Ingest error when neighbors from bbknn,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1201:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201,1,['error'],['error']
Availability,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780:457,down,downstream,457,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780,1,['down'],['downstream']
Availability,"Interesting! I was coming across this error in #2816 (where there is a fix), but only with older versions of dependencies. Probably worth back porting that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830#issuecomment-1910515749:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830#issuecomment-1910515749,1,['error'],['error']
Availability,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:984,Down,Downloading,984,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,Internal Server Error for queries.biomart_annotations,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1660:16,Error,Error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660,1,['Error'],['Error']
Availability,"Introduces a function to calculate marker gene overlaps between a reference set of marker genes provided as a dictionary, and data-derived marker genes as calculated by `sc.tl.rank_genes_groups()`. Currently implemented overlap functions are: overlap counts (with row or column normalization), overlap coefficient, and jaccard index. Still to do:; - write a test; - finish documentation; - allow p-value thresholding when available; - allow using top X marker genes rather than all calculated markers; - test that it works properly...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549:422,avail,available,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549,1,['avail'],['available']
Availability,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs × n_vars = 1493240 × 4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361,3,"['error', 'fault']","['error', 'fault']"
Availability,Is sctransform available ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068:15,avail,available,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068,1,['avail'],['available']
Availability,"Is there a way to filter for a set of genes, where if any one of the genes in a list are expressed, those cells will be plotted? I've tried switching Xparx's solution to a list, but receive the error ""ValueError: Buffer has wrong number of dimensions (expected 1, got 0)"". I've also tired chansigit's method, but find that flatten returns as not found?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/599#issuecomment-873451217:194,error,error,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-873451217,1,['error'],['error']
Availability,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```; scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:; No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration.; One possibility is to increase the size of NCV relative to NEV.; ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/25#issuecomment-313218328:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25#issuecomment-313218328,2,['error'],['error']
Availability,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1874:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874,3,['error'],['error']
Availability,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698851156:209,mainten,maintenance,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698851156,1,['mainten'],['maintenance']
Availability,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. ; I use pip install --user for scanpy because otherwise I receive an error message: ; Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; My workaround has been to use --user as a directory and add a path to import scanpy.; I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302:227,error,error,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302,1,['error'],['error']
Availability,It causes exactly the same issue when I run:. ```; import numpy as np; import umap; ```; There is no segfault message. The jupyter kernel failure message is: . _Kernel restarting. The kernel appears to have died. It will restart automatically._,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-754566053:138,failure,failure,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-754566053,1,['failure'],['failure']
Availability,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or; 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501:105,error,error,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501,1,['error'],['error']
Availability,"It is an enrichment analysis but foot-print based: we don't just look at the elements of a pathway/TF but also the biological downstream effects that occur when said biological process is active. ; ""Annotation/ Enrichment Analysis"" fits but it would be good to also mention somewhere that they are foot-print based. Would this be okay?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1767#issuecomment-810829669:126,down,downstream,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767#issuecomment-810829669,1,['down'],['downstream']
Availability,"It is said that ""Be reminded that it is not advised to use the corrected data matrices for differential expression testing."" in scanpy document (http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.mnn_correct.html) when execute MNN correction. However, Haghverdi Laleh (the one who presents MNN correction strategy, https://www.nature.com/articles/nbt.4091) says ""MNN correction improves differential expression analyses, After batch correction is performed, the corrected expression values can be used in routine downstream analyses such as clustering prior to differential gene expression identification"" in his Nature Biotech paper. So, I am a little confused. We have compared some corrections methods, such as regress_out, combat, MNN and MultiCCA (used by seurat), the results show that MNN and CCA have a better effect than regress_out and combat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173:519,down,downstream,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173,1,['down'],['downstream']
Availability,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703829011:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703829011,1,['error'],['error']
Availability,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>; <summary> Example error </summary>. ```pytb; n_epochs = 0 if maxiter is None else maxiter; > X_umap = simplicial_set_embedding(; X,; neighbors['connectivities'].tocoo(),; n_components,; alpha,; a,; b,; gamma,; negative_sample_rate,; n_epochs,; init_coords,; random_state,; neigh_params.get('metric', 'euclidean'),; neigh_params.get('metric_kwds', {}),; verbose=settings.verbosity > 3,; E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308:124,ping,ping,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308,2,"['error', 'ping']","['error', 'ping']"
Availability,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:40,Error,Error,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018,2,"['Error', 'error']","['Error', 'error']"
Availability,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:; sc.pp.highly_variable_genes(pbmc, batch_key=""phase""); sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error; sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False); ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/758#issuecomment-517145132:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758#issuecomment-517145132,3,['error'],['error']
Availability,It looks like this may have stalled a bit. Is anyone currently working on making some form of doublet detection available from scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117:112,avail,available,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117,1,['avail'],['available']
Availability,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:824,Mask,Mask,824,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170,1,['Mask'],['Mask']
Availability,"It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1910:300,error,error,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910,1,['error'],['error']
Availability,"It looks like your adata object is corrupted. You should be able to type; `adata.X` to get the matrix. How are you generating the adata object?. On Thu, Dec 6, 2018 at 5:56 PM ltosti <notifications@github.com> wrote:. > Hi there,; >; > When running sc.pp.highly_variable_genes(adata.X) I get the following; > error:; >; > AttributeError: X not found; >; > I then ran sc.pp.highly_variable_genes(adata) and got the following:; >; > ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf,; > inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]).; > You can drop duplicate edges by setting the duplicates kwarg; >; > The older sc.pp.filter_genes_dispersion(adata.X) works fine.; >; > Do you know how to fix this?; >; > Thank you!; >; > *Info*: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0; > pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > louvain==0.6.1; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/391>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RPErIznAoUd0DwpbdlEjkOUyjTdks5u2Uw4gaJpZM4ZG6Jw>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693:309,error,error,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693,1,['error'],['error']
Availability,"It looks to me like the sklearn dependency was update more due to bugs in earlier 0.21.* releases series, see 7716bfdec3cb9bd19923a91180dabc35ffd7709a. We don't promise compatibility with older versions of sklearn, so downgrading is not a good long-term solution. @Koncopd might also be able to give some advice on this, as I believe he has been using pytorch with scanpy, though I'm not sure if this is via conda environments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158:218,down,downgrading,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158,1,['down'],['downgrading']
Availability,"It seems like the dendrogram feature has been merged into the master branch according to this thread #308 and it is documented in the API. However, after updating my scanpy to 1.3.2, I still cannot access the dendrogram feature and get the following error when I set `dendrogram=True` when using `sc.pl.heatmap`:; `AttributeError: Unknown property dendrogram`. Here are the versions that I am using:; scanpy==1.3.2 anndata==0.6.10 numpy==1.14.3 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. Do you plan on releasing the dendrogram feature? Which package version currently has it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/344:250,error,error,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/344,1,['error'],['error']
Availability,It seems that something wrong happened for the Seurat meta slot. The code told that this error happened when AnnData tried to construct obs attribute. ; I am afraid this beyond my scope since I cannot access your data for further debugging,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761:89,error,error,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761,1,['error'],['error']
Availability,"It seems that upgrading from 1.8.1 to 1.8.2 introduce an error on umap version checking, mentioned by #1978 (and a potential solution); > Why are we using umap.__version__ instead of importlib.metadata.version('umap-learn')?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-963422681:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-963422681,1,['error'],['error']
Availability,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146,1,['error'],['error']
Availability,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):; ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts; 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20; 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15; 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1; 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0; ```. and later. ```; 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=; set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```; ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0; pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0; subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro; gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-661285497:920,ERROR,ERROR,920,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-661285497,1,['ERROR'],['ERROR']
Availability,It seems to be something about the `genes.tsv`. I replaced it with another genes.tsv and it didn't produce errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-973500395:107,error,errors,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-973500395,1,['error'],['errors']
Availability,"It seems you do not always end up with n-1 neighbors, because for n=3, you suddenly get differing number of neighbors:; ```python; import scanpy as sc; adata = sc.datasets.blobs(n_observations=5). for n_neighbors in [1, 2, 3]:; sc.pp.neighbors(adata, n_neighbors=n_neighbors); print(f'n_neighbors = {n_neighbors}:\n', adata.uns['neighbors']['connectivities'].A); ```; Output:; ```; n_neighbors = 1:; [[0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]]; n_neighbors = 2:; [[0. 0. 0. 1. 0.]; [0. 0. 1. 0. 0.]; [0. 1. 0. 0. 0.]; [1. 0. 0. 0. 1.]; [0. 0. 0. 1. 0.]]; n_neighbors = 3:; [[0. 0.5849553 0. 1. 0.5849636 ]; [0.5849553 0. 1. 0.5849678 0. ]; [0. 1. 0. 0.58496827 0. ]; [1. 0.5849678 0.58496827 0. 1. ]; [0.5849636 0. 0. 1. 0. ]]; ```; It is been while that I read about UMAP and can't get my head around why this happens right now. Relying on UMAP seems a good idea to me, maybe the corner case `n_neighbors=1` should just be catched with a more meaningful error message?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1706#issuecomment-788885174:1002,error,error,1002,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706#issuecomment-788885174,1,['error'],['error']
Availability,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:137,down,down,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193,1,['down'],['down']
Availability,"It still does not work for me, even in a virtualenv. I always get:; ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed.; #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs; rm -rf ~/.cache/pip #make download clearer; python3 -m venv scanpy_scripts; source scanpy_scripts/bin/activate; python -m pip install -U pip; python -m pip install scanpy_scripts; #same error; python -m pip install -U setuptools #39.2 -> 47.3.1; python -m pip install scanpy_scripts; #same error; python -m pip install -U wheel; python -m pip install scanpy_scripts; #same error; echo $PYTHONPATH; #is blank. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039:162,ERROR,ERROR,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039,6,"['ERROR', 'down', 'echo', 'error']","['ERROR', 'download', 'echo', 'error']"
Availability,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-342897102:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-342897102,1,['error'],['error']
Availability,"It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1497:223,error,error,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497,2,"['Error', 'error']","['Error', 'error']"
Availability,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401:125,failure,failures,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401,1,['failure'],['failures']
Availability,"It would help to tell *where* in the code the error is thrown. Please provide a traceback. > Does using adata.var_names_make_unique() also makes the variable names of adata.X unique?. If X is a DataFrame, yes. Otherwise X doesn’t have any names stored inside (`var_names` are stored as `.var.index`.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778,1,['error'],['error']
Availability,"It's **a** thing, not yet **the** thing. For directed PAGA follow [this](https://github.com/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/792#issuecomment-523843131:206,robust,robust,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792#issuecomment-523843131,1,['robust'],['robust']
Availability,"It's a bug that there is no error output. I haven't thought about drawing the PAGA graph in higher dimensions yet, hence no possibility to initialize from that. One could think about adding this functionality... but I don't know how meaningful that is at this stage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/306#issuecomment-430363010:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306#issuecomment-430363010,1,['error'],['error']
Availability,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look.; ________________________________; From: MalteDLuecken <notifications@github.com>; Sent: Monday, April 20, 2020 2:42:07 PM; To: theislab/scanpy <scanpy@noreply.github.com>; Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>; Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172#issuecomment-616528291:467,error,error,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172#issuecomment-616528291,1,['error'],['error']
Availability,"It's only on master, but I don't think that would change anything here. The fix was for cases where `sc.pp.highly_variable_genes()` outputs an error due to bin boundaries being duplicated as genes were unexpressed. . I reckon this is not actually a bug. It's a possible scenario that no genes are highly variable in all batches, no? Is `highly_variable_intersection` `False` everywhere, or is `highly_variable_nbatches` somehow false? The former can be `False` if your batches are heterogeneous.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559392108:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559392108,1,['error'],['error']
Availability,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,3,"['Down', 'error', 'fault']","['Downgrading', 'error', 'fault']"
Availability,It’s less error prone and a nicer API. Fixes #563,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/564:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/564,1,['error'],['error']
Availability,"I’ll take a look if you update your issue with a code block that I can copy, that will download the dataset and then reproduce the error without me having to go to any website and download anything manually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640:87,down,download,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640,3,"['down', 'error']","['download', 'error']"
Availability,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384,1,['error'],['error']
Availability,"I’ve only found this problem in the wild when people tried to create a figure with a dimension of size 0. It implies that either matplotlib passes some faulty instructions to libpng or that your libpng installation is broken. It’s very unlikely that it’s a problem with scanpy. Does something simple with matplotlib work? Just `pyplot.scatter([0,1], [0,1])` or so?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026:152,fault,faulty,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026,1,['fault'],['faulty']
Availability,"Just a heads up, it looks like Pandas 1.3.3 might break things again, was experiencing errors that I was able to resolve by downgrading. I can create a new issue if you'd like. Error below so you can determine if this is the same issue or not:; ```; adata.obs['log_counts'] = np.log(adata.obs['n_counts']); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (38978); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453:87,error,errors,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453,3,"['Error', 'down', 'error']","['Error', 'downgrading', 'errors']"
Availability,Just a minor improvement. Now you can specify the total counts to downsample to on a per-cell basis by passing an array for `counts_per_cell`. This is so I don't have to split and merge an AnnData object when I want multiple distributions of counts per cell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/602:66,down,downsample,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/602,1,['down'],['downsample']
Availability,"Just added a test and changed the behaviour of scale a little more.; The case of zero variance was until now replace with an arbitrary tiny variance, which arbitrarily blew up the scaled value and made it completely meaningless `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/cus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:449,error,errors,449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['error'],['errors']
Availability,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1429#issuecomment-1759763329:91,avail,available,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429#issuecomment-1759763329,1,['avail'],['available']
Availability,"Just checked using this dockerfile, works flawlessly:. ```dockerfile; FROM continuumio/miniconda. RUN conda install python=3.8; RUN pip install flit>=3.1; RUN git clone https://github.com/theislab/scanpy.git; WORKDIR /scanpy; # Go to the mainline-pip branch if it hasn’t been merged into master yet; RUN git checkout mainline-pip || true; RUN FLIT_ROOT_INSTALL=1 flit install -s --dep=develop # Make development install of scanpy; # Make sure the dist-info folder has a plus in its name; RUN SCANPY_VERSION=$(python -c 'from importlib.metadata import version; print(version(""scanpy""))') && \; echo $SCANPY_VERSION | grep '+' &&; test -d /opt/conda/lib/python3.8/site-packages/scanpy-$SCANPY_VERSION.dist-info; # Install project that depends on scanpy; RUN pip install scvelo; # Make sure it’s still a dev install; RUN test -L /opt/conda/lib/python3.8/site-packages/scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617:593,echo,echo,593,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617,1,['echo'],['echo']
Availability,Just checked.. same thing applies for windows. It returns an error until you `conda install pytables`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641,1,['error'],['error']
Availability,"Just checking to make sure we're working with the same data, since there could be different errors coming from that. The PR should do the right thing on `pbmc3k`. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421#issuecomment-453899907:92,error,errors,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453899907,1,['error'],['errors']
Availability,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:; > ; > I get the following error when I tun dotplot:; > ; > `ValueError Traceback (most recent call last); > in (); > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'); > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds); > 409; > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,; > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds); > 412; > 413; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > ValueError: no field of name MYL2; > `; > ; > Do we need to store marker genes within the adata object?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/502#issuecomment-467172649:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502#issuecomment-467172649,1,['error'],['error']
Availability,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-871319496:58,ping,ping,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-871319496,1,['ping'],['ping']
Availability,"Just saw that I forgot to comment on these two issues that @ivirshup mentioned above:. > ## Feature selection on an already transformed matrix; > ; > Would it be reasonable to include a way to compute the deviant genes from pearson normalized matrix? Ideally, we should not have to compute it twice to get all the results in one object. The easiest would probably be to add an `return_hvgs` option to `normalize_pearson_residuals()`, which would allow to skip our RAM-optimized HVG selection function for cases where speed / efficiency is needed and RAM usage is not a concern. ; This would give the same HVGs as our current function, but won't offer the batch correction currently implemented -- unless we implement the same batch correction option for `normalize_pearson_residuals()`, i.e. to compute residuals for each batch separately and then simply concatenate across cells... I would have to think a bit if this makes sense (maybe it does) and what properties these batch-corrected residuals will have. (@dkobak, do you want to comment?). If we can live without the batch correction for this ""fast lane case"", I can also just implement it without. Let me know!. > ## Docs consistency; > ; > A number of parameters are available in multiple functions. Would it make sense to use some of our tooling so there's only one place to edit these?. Sounds good - I think @giovp was suggesting something similar earlier, but recommended to wait for the next PR with this. > We really need another way to handle this (e.g. the way we do it in Squidpy with package constants) but this is for another PR. I have no experience with package constant yet but just let me know if I should do something here :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698:1225,avail,available,1225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698,1,['avail'],['available']
Availability,KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297,1,['error'],['error']
Availability,LED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2374,ERROR,ERROR,2374,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"LGTM! . Don't worry about the test failures, those are due to a networkx update changing how plots look, which we'll deal with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018:35,failure,failures,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018,1,['failure'],['failures']
Availability,LLVM ERROR: Symbol not found: __svml_sqrtf8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696:5,ERROR,ERROR,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696,1,['ERROR'],['ERROR']
Availability,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353:309,avail,available,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353,1,['avail'],['available']
Availability,"Look at the documentation before you ask questions. The object returned from the function you called doesn’t return a matplotlib object, it returns a dictionary, assuming that the ‘show’ parameter is off. You can’t loop through a dictionary like an array, you need to retrieve the keys access individual values and then use the ‘ylim’ property. Get Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; From: ZxyChopcat ***@***.***>; Sent: Thursday, September 16, 2021 1:24:05 PM; To: theislab/scanpy ***@***.***>; Cc: Vekeria, Jai Patel ***@***.***>; Comment ***@***.***>; Subject: Re: [theislab/scanpy] How to use stacked_violin with variable y-axis limits between rows? (#386). Hi,; I tried to set the y-axis limit, but failed with the error:; `>>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False). for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File """", line 2, in; AttributeError: 'str' object has no attribute 'set_ylim'; `; I use scanpy 1.8.1.; Do you have any idea? Thanks!. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWF",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:759,error,error,759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,1,['error'],['error']
Availability,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734:122,down,downloads,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734,1,['down'],['downloads']
Availability,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:523,error,errors,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166,3,"['down', 'error']","['downgrade', 'errors']"
Availability,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2107583455:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2107583455,1,['error'],['error']
Availability,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (“Kor**s**unsky19” is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-661049767:354,error,errors,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-661049767,1,['error'],['errors']
Availability,"Looks like the issue goes deeper, to `get_version` being called on RTD. Seems like some interaction of that package and the environment. Ping @flying-sheep",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1900#issuecomment-869127933:137,Ping,Ping,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900#issuecomment-869127933,1,['Ping'],['Ping']
Availability,"Looks like the same error hit in #585, as well as https://github.com/theislab/scanpy/pull/493#issuecomment-477674448. @flying-sheep I haven't been able to reproduce, but maybe we should just throw an `__init__.py` in there, since it fixes this for @fbrundu, before the `v1.4.1` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731,1,['error'],['error']
Availability,Looks like there was a typo at the bottom of `scanpy/preprocessing/_dca.py` that was causing a parse error. This should fix it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/527:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/527,1,['error'],['error']
Availability,"Looks like this is not available for python yet ([docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/test/codecoverage-for-pullrequests?view=azure-devops#prerequisites)). > While you can collect and publish code coverage results for many different languages using Azure Pipelines, the code coverage for pull requests feature discussed in this document is currently available only for .NET and .NET core projects using the Visual Studio code coverage results format (file extension .coverage). Support for other languages and coverage formats will be added in future milestones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276:23,avail,available,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276,2,['avail'],['available']
Availability,MAGIC in external causes test failures if its not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1001:30,failure,failures,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001,1,['failure'],['failures']
Availability,Make partition modularity available in adata.uns,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819:26,avail,available,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819,1,['avail'],['available']
Availability,Make plot_scatter() available to user,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617:20,avail,available,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617,1,['avail'],['available']
Availability,"Many thanks for everyone's input. The bug is indeed due to an issue with Pandas ≥1.3. I am running Scanpy 1.8.1 and I can confirm that the indexing problem remains with Pandas 1.3.0, 1.3.2, and the latest 1.3.4, but resolves when downgrading to 1.2.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-948031374:230,down,downgrading,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-948031374,1,['down'],['downgrading']
Availability,"Mask for pca, normalize_pearson_residuals_pca, scatterplot, scale",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272:0,Mask,Mask,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272,1,['Mask'],['Mask']
Availability,Math domain error in rank_genes_groups function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530,1,['error'],['error']
Availability,Math domain error when using the Wilcoxon rank-sum,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566,1,['error'],['error']
Availability,"Matplotlib 3 came and went without https://github.com/matplotlib/matplotlib/issues/9460 being fixed. @ftheis still can’t properly distinguish clusters made by scanpy. The two designated colorblind-friendly colormaps in matplotlib look [like this](https://gist.github.com/flying-sheep/5172a1f1f9757d4ece239e742ba41b08). An alternative would be to push red or green to the end of the current color cycle, so it only appears for 10+ clusters. @mpetroff created a [neat tool](https://colorcyclepicker.mpetroff.net/) that could help to design a custom one if we decide the available ones are too ugly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/387:568,avail,available,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387,1,['avail'],['available']
Availability,"Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1090:842,down,down,842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090,1,['down'],['down']
Availability,"Matplotlib 3.4 has dropped 3.6 support. Since matplotlib is our most painful dependency (reliably causes test failures when it updates), it's a great time to drop 3.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473:89,reliab,reliably,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473,2,"['failure', 'reliab']","['failures', 'reliably']"
Availability,"Maybe I am doing something wrong. I try to recover the observation from annData as a dataframe, and I am playing with some of the commands. This is an example. ```; import scanpy.api as sc; data = sc.read_text('/media/SETH_DATA/SETH_Alex/Fibroblasts.txt').T. print(data.data); ```. Then this error happens:. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-14-1f44700b9ea5> in <module>(); ----> 1 print(data.data). ~/anaconda3_6/lib/python3.6/site-packages/anndata/utils.py in new_func(*args, **kwargs); 104 def new_func(*args, **kwargs):; 105 warnings.simplefilter('always', DeprecationWarning) # turn off filter; --> 106 warnings.warning(; 107 'Use {0} instead of {1}, {1} will be removed in the future.'; 108 .format(new_name, func.__name__),. AttributeError: module 'warnings' has no attribute 'warning'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/394:43,recover,recover,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/394,2,"['error', 'recover']","['error', 'recover']"
Availability,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681:6,down,downgrade,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681,1,['down'],['downgrade']
Availability,Memory error and Anndata error raised while using sc.read_h5ad,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,2,['error'],['error']
Availability,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-759329104:80,down,down,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-759329104,1,['down'],['down']
Availability,"Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32631,error,errors,32631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,Minor Bug: scanpy.logging.print_versions() throws Key Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:54,Error,Error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,1,['Error'],['Error']
Availability,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python; ValueError: could not convert string to float: 'q99'; ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-524526783:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-524526783,2,['error'],['error']
Availability,"Minor bug I assume. Using fewer than 50 cells raises the following error when trying to run `sc.tl.pca`. The code handles this when the `n_vars < 50` but not when `n_obs` is. ```pytb; ValueErrorTraceback (most recent call last); <ipython-input-823-4c11b9b62e6d> in <module>; ----> 1 sc.tl.pca(bla). ~/.virtualenvs/default/lib/python3.6/site-packages/scanpy/preprocessing/simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 504 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state); 505 X = adata_comp.X; --> 506 X_pca = pca_.fit_transform(X); 507 ; 508 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y); 357 ; 358 """"""; --> 359 U, S, V = self._fit(X); 360 U = U[:, :self.n_components_]; 361 . ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 404 # Call different fits for either full or truncated SVD; 405 if self._fit_svd_solver == 'full':; --> 406 return self._fit_full(X, n_components); 407 elif self._fit_svd_solver in ['arpack', 'randomized']:; 408 return self._fit_truncated(X, n_components, self._fit_svd_solver). ~/.virtualenvs/default/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit_full(self, X, n_components); 423 ""min(n_samples, n_features)=%r with ""; 424 ""svd_solver='full'""; --> 425 % (n_components, min(n_samples, n_features))); 426 elif n_components >= 1:; 427 if not isinstance(n_components, (numbers.Integral, np.integer)):. ValueError: n_components=50 must be between 0 and min(n_samples, n_features)=38 with svd_solver='full'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432,1,['error'],['error']
Availability,"Mmh no, it does work as you expect, just need to turn the dendrogram off.; ```python; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {; ""1"": [""GNLY"", ""NKG7""],; ""0"": [""CD3D""],; ""2"": [""CD79A"", ""MS4A1""],; ""4"": [""CD79A"", ""MS4A1""],; ""3"": [""FCER1A""],; }. sc.pl.heatmap(; pbmc,; marker_genes_dict,; groupby=""clusters"",; vmin=-2,; vmax=2,; cmap=""RdBu_r"",; dendrogram=False,; swap_axes=True,; ); ```. or just pass the list of markers (list, not mapping); ```python; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(; pbmc,; marker_genes_list,; groupby=""clusters"",; vmin=-2,; vmax=2,; cmap=""RdBu_r"",; dendrogram=True,; swap_axes=True,; ); ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:; ```; WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.; categories: 0, 1, 2, etc.; var_group_labels: 1, 0, 2, etc.; ```; and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723051024:1700,error,error,1700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723051024,1,['error'],['error']
Availability,"My code also has the same bug problem, may I ask, how to solve it?. `adata.raw = adata # keep full dimension safe; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",#; n_top_genes=2000,; layer=""counts"",; batch_key=""orig.ident"",; subset=True,; span=1; ); `. Error output. `ValueError Traceback (most recent call last); Cell In[13], line 3; 1 #高变基因选取; 2 adata.raw = adata # keep full dimension safe; ----> 3 sc.pp.highly_variable_genes(; 4 adata,; 5 flavor=""seurat_v3"",#; 6 n_top_genes=2000,; 7 layer=""counts"",; 8 batch_key=""orig.ident"",; 9 subset=True,; 10 span=1; 11 ); 13 filename = 'melanoma_sw_high_var.h5ad'; 14 adata.write(filename). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:441, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 439 sig = signature(_highly_variable_genes_seurat_v3); 440 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 441 return _highly_variable_genes_seurat_v3(; 442 adata,; 443 layer=layer,; 444 n_top_genes=n_top_genes,; 445 batch_key=batch_key,; 446 check_values=check_values,; 447 span=span,; 448 subset=subset,; 449 inplace=inplace,; 450 ); 452 if batch_key is None:; 453 df = _highly_variable_genes_single_batch(; 454 adata,; 455 layer=layer,; (...); 462 flavor=flavor,; 463 ). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:87, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 85 x = np.log10(mean[not_const]); 86 model = loess(x, y, span=span, degree=2); ---> 87 model.fit(); 88 estimat_var[not_const] = model.outputs.fitted_values; 89 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:927, in _loess.loess.fit(). ValueError: b'Extrapolation not allowed with blending'`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837:264,Error,Error,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837,1,['Error'],['Error']
Availability,"My main point is that having an implicit mapping between colors and the categories is not that user or developer friendly. It seems to me like it'd be simpler to just have the mapping be explicit. This wouldn't change much from right now, except for cutting down on some boiler plate in a bunch of plotting functions. That example was just to demonstrate that it could even be simpler to have an explicit mapping, since we don't have to do:. ```python; dict(zip(adata.obs[key].cat.categories, adata.uns[key + ""_colors""])); # and instead could just do:; adata.uns[key + ""_colors""]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679:258,down,down,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679,1,['down'],['down']
Availability,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-725881193:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-725881193,2,"['down', 'error']","['downstream', 'error']"
Availability,"My suspicion is that this is more likely to do with the plotting functions, than the calculation. I think the issue is that previously the axis limits weren't being set (though they were calculated). Now they are set, but it turns out they were calculated on the full range of scores – not just the plotted ones. Here's what a potential fix looks like:. <details>; <summary> Big images </summary>. Without fix:. ![tmp](https://user-images.githubusercontent.com/8238804/88772041-7cbfe480-d1c3-11ea-80e9-9ea26c3d4cea.png). With fix:. ![tmp_new](https://user-images.githubusercontent.com/8238804/88772070-88aba680-d1c3-11ea-8872-16a26103b892.png). </details>. What do you think? (ping @fidelram)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-665499836:677,ping,ping,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-665499836,1,['ping'],['ping']
Availability,"My thinking on this right now is that:. * The code for masking logic (pre this PR) is kind of a mess; * This PR doesn't make the code nicer. But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices. I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.com/scipy/scipy/issues/20169#issuecomment-1973335172) to accept a `row_mask` argument:. ```python; from scipy import sparse; import numpy as np; from operator import mul, truediv. def broadcast_csr_by_vec(X, vec, op, axis):; if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Which *I think* would be something like:. ```python; def broadcast_csr_by_vec(X, vec, op, axis, row_mask: None | np.ndarray):; if row_mask is not None:; vec = np.where(row_mask, vec, 1); if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra). I think either of these solutions would be simpler since we do the masking all in one place, and don't have to have a second update step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345:55,mask,masking,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345,3,['mask'],"['masked', 'masking']"
Availability,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1987:340,error,error,340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987,1,['error'],['error']
Availability,Neighbors.compute_transitions() with error 'AnnData' object has no attribute '_connectivities',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2109:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109,1,['error'],['error']
Availability,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366284420:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366284420,1,['error'],['error']
Availability,"New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:; * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path; * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value).; * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter.; * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105:361,Recover,Recover,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105,1,['Recover'],['Recover']
Availability,"Nice! But may I ask why you’re still importing everything from umap instead of from pynndescent?. I’d assume if we’d do that we’d be more robust to further umap updates, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583:138,robust,robust,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583,1,['robust'],['robust']
Availability,No idea about the error in the performance test. @flying-sheep ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626,1,['error'],['error']
Availability,No longer getting errors on plotting tests. Was this being actively worked on? I think it's ready to close otherwise.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572,1,['error'],['errors']
Availability,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:288,down,downsampling,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['down'],['downsampling']
Availability,"No problem!. > The idea for uns concatenation is exactly that one yes. Basically, if the keys are unique, then concatenate, if they are the same, override and throw a warning. I was thinking that this should have multiple modes, chosen by an argument like `merge_uns`. I'm thinking options would be:. * `None`: the default. Maintain current behaviour of just not merging.; * `""unique""`: Only keep values which are uniquely specified; * `""identical""`: Only keep values which are the same in all objects; * `""override""`: Just take the first value from each. You wouldn't have to implement all of these, just one that makes spatial concatenation work for now. > With respect to mixed anndata objects (e.g. one visium adata concatenated with one scRNA-seq), I will just concatenate the obsm and add empty entries to the one missing (like zeros) or something along the lines of masked arrays (although I don't think it's particularly useful in this case). Could there be a `fill_value ` argument here? A way for people to specify what the fill value should be?. I'm mainly against masked arrays since I don't think they're going to work with sparse matrices, and I'm not sure about other array subtypes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-599924513:873,mask,masked,873,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-599924513,2,['mask'],['masked']
Availability,"No problem, gave a chance to optimize the code a bit (peak memory was about 3x AnnData size, now down to about 2x).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-437745410:97,down,down,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-437745410,1,['down'],['down']
Availability,No problem. I think increasing the test coverage should be prioritised to make scanpy more robust.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576:91,robust,robust,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576,1,['robust'],['robust']
Availability,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:24,failure,failures,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061,1,['failure'],['failures']
Availability,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366300686:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366300686,2,['error'],['error']
Availability,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766:138,reliab,reliable,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766,1,['reliab'],['reliable']
Availability,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924:165,down,downstream,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924,1,['down'],['downstream']
Availability,"No, those “invalid instruction” errors pop up sometimes. I think they’re caused by some dependency being compiled for an instruction set that not all GitHub runners support. Ways to deal with it:. 1. just restart until it works (annoying, but not much work); 2. figure out broken dependency, then; 1. if the wheel on PyPI is broken, raise an issue upstream; 2. if we compile it in the runner ourselves, set a compile flag to make it only use instructions that are compatible with all runners (i.e. not `-m arch=native` but select [an older architecture](https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794:32,error,errors,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794,1,['error'],['errors']
Availability,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716,1,['error'],['error']
Availability,"Not a bug, _per se_, as the code runs fine, but you currently cannot install scanpy directly with the rapids extras. Running `pip install scanpy[rapids]` fails with the following error:. ```python; ERROR: Could not find a version that satisfies the requirement cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]) (from versions: 0.5.0, 0.6.1, 0.6.1.post1); ERROR: No matching distribution found for cudf>=0.9; extra == ""rapids"" (from scanpy[rapids]); ```; ; A quick check shows that `PyPi` has the most recent version of rapids suite (cuML, cuDF, cuGRAPH) at 0.6.1 - hence the fail. The only place I can see to get versions of the cu suite that meets the requirements in `setup.py`is from the rapidsAI conda channel, where the most recent version is 0.140. However, if I try to `pip install scanpy` followed by the necessary conda command to install the rapids packages, I get a broken environment that won't let me `import scanpy as sc`, frequently - though not always - because of issues with pandas. How should I install the rapids extras?. Anyways, I recognise these features are experimental, but would love to see them become standard as they are a huge boon when working on big datasets, particularly as I have access to some really good GPUs remotely.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1280:179,error,error,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1280,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"Not sure if still required (the code in the anndata repo is close to this), but here is a minimal example:; ```py; import scanpy as sc; adata = sc.datasets.pbmc3k(); h5adfile = 'pbmc3k.h5ad'; adata.write(h5adfile); a1 = sc.read_h5ad(h5adfile); a2 = sc.read_h5ad(h5adfile, backed='r+'); sc.tl.score_genes(a1, ['KIR3DL2-1', 'AL590523.1', 'CT476828.1']); # OK; sc.tl.score_genes(a2, ['KIR3DL2-1', 'AL590523.1', 'CT476828.1']); # ERROR ; ```. thanks..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/883#issuecomment-545478497:426,ERROR,ERROR,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883#issuecomment-545478497,1,['ERROR'],['ERROR']
Availability,"Not sure we can do a lot with just a traceback. Could you create a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to reproduce this error, and describe what you were trying to do?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-477832283:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-477832283,1,['error'],['error']
Availability,NotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacke,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2338,Error,Error,2338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"Now if I intend to run ingest, I will get this error:; running ingest; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); 13 frames; <ipython-input-22-9176945aef7f> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 131 ; 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951,1,['error'],['error']
Availability,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526495713:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526495713,1,['error'],['error']
Availability,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931:57,avail,available,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931,5,"['avail', 'error']","['available', 'errors']"
Availability,Numba error in calculate_qc_metrics on a windows machine,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843,1,['error'],['error']
Availability,OK I computed the neighbors using umap-learn 0.5.1 and then downgraded to 0.4.6 for UMAP. Not elegant but so far so good.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-909198091:60,down,downgraded,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-909198091,1,['down'],['downgraded']
Availability,"OK I install umap 0.4 . ```; pip install git+git://github.com/lmcinnes/umap@0.4dev; ```. However, it doesn't seem to run any faster and actually throws an error now. ```; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```; gives; ```; AttributeError Traceback (most recent call last); <timed eval> in <module>. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553019440:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-553019440,1,['error'],['error']
Availability,"OK great. The same errors as on master happen, so this didn’t introduce any failures. Thank you very much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721:19,error,errors,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721,2,"['error', 'failure']","['errors', 'failures']"
Availability,"OK! Thanks! @fidelram Should we simply regenerate all images using `matplotlib.testing.setup()`, which seems to be the most stable way to go and in the future restrict ourselves to that? I guess this is closer to a reliable test setup for all the images than the current solution via `mpl.use(""agg"")`. Also the name suggests that matplotlib does it this way. But you did some research at the time when introducing the first tests, right?. Thanks for the comment on the PAGA notebook, too, @ivirshup. I'll make sure that I didn't hard-code anything into the plotting functions that might collide with anything else happening on travis... but it's astonishing... In the meanwhile I work-around with a data-base test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565:215,reliab,reliable,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565,1,['reliab'],['reliable']
Availability,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172#issuecomment-616468922:249,error,error,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172#issuecomment-616468922,2,"['avail', 'error']","['available', 'error']"
Availability,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment; 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183:566,error,error,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183,2,"['down', 'error']","['download', 'error']"
Availability,"OK, so you’re using Python < 3.8 and `importlib_metadata`. The line `umap_version = version(""umap-learn"")` throws an error. It works for me with the same setup:. ```console; $ python -c 'from importlib_metadata import version; print(version(""umap-learn""))'; 0.3.0; ```. You said in #704 that it works “with a commit a few before” that one. You could use `git bisect` to figure out which commit exactly make a difference, but I think the issue might be either. 1. the way umap-learn 0.3.9 is installed on your system. maybe it doesn’t have proper metadata or so. you should have a directory called `umap_learn-0.3.9-py3.7.egg-info` right next to the `umap` package.; 2. You have an older version of `importlib_metadata` with a bug or so. The code basically does this:. ```py; from importlib_metadata import Distribution; def version(name):; for resolver in Distribution._discover_resolvers():; for d in resolver(name):; return d.metadata['Version']; raise PackageNotFoundError(name); ```. I don’t see how importing or not importing umap should change this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739#issuecomment-511980962:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739#issuecomment-511980962,1,['error'],['error']
Availability,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:77,failure,failures,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573,1,['failure'],['failures']
Availability,"OK; now I have more time. The error thrown at ; ```; 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs; --> 208 - disp_mean_bin[df['mean_bin']].values) \; 209 / disp_std_bin[df['mean_bin']].values; ```; astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324469115:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324469115,1,['error'],['error']
Availability,OR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60732,ERROR,ERROR,60732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,OR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62535,ERROR,ERROR,62535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,OR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62211,ERROR,ERROR,62211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py; >>> list(iter(np.array([[1,2],[3,5]]))) ; [array([1, 2]), array([3, 5])]; ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-533874937:227,error,errors,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-533874937,1,['error'],['errors']
Availability,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:27,failure,failures,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130,1,['failure'],['failures']
Availability,"Oh, and I just realized it's meant to be `backed=False` and `backed=True`. I'd assumed the documentation was wrong, as `backed=True` and `backed=""True""` both throw the error:. ```python; ValueError: Invalid mode; must be one of r, r+, w, w-, x, a; ```. And I'd never checked `backed=False`. That's probably more for another issue though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-421873798:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-421873798,1,['error'],['error']
Availability,"Oh, huh, I thought allowing modifications was on by default. My bad. . > Yes, now that you made everything a property, I would have expected it to take much longer than 10 minutes. It's great that you did!. I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through `?sc.settings.{setting}`!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479744957:310,avail,available,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479744957,1,['avail'],['available']
Availability,"Oh, sorry, I had completely missed your comment here!. > It looks great!. Thanks! Can I ask why you used leiden clustering on this?. > One first improvement could be to expose a parameters that explicitly ask for the number of rings in the neighbors. This should be easy enough. I'm curious as to whether this it's better to leave this up to whatever algorithm is being used however, since the one step graph has some nice properties. It'd probably be important to include distance in the multistep graph. > Btw, how do I push to this specific PR from my local repo?. This should be fairly straight forward. If you're using the github cli, I think it should just be:. ```sh; gh pr checkout 1383; # whatever changes; git push; ```. Let me know if that gives you errors, since it might be a repository permissions issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681:761,error,errors,761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681,1,['error'],['errors']
Availability,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:31,downtime,downtime,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039,1,['downtime'],['downtime']
Availability,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section ; ### Using a preprocessing recipe. adata = paul15_raw(); sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324336195:70,error,error,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324336195,1,['error'],['error']
Availability,"Ok so it doesnt work, again, even with pip... @ivirshup I tried the code you wrote, and it gives me the same error:. `` AttributeError: module 'cairo' has no attribute 'version_info'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166#issuecomment-614798701:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166#issuecomment-614798701,1,['error'],['error']
Availability,"Ok, I identified the root cause of the neighbor error and reported it as a bug: . https://github.com/scverse/scanpy/issues/2244. This probably happens because you have duplicated rows or cells with almost identical gene counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854,1,['error'],['error']
Availability,"Ok, so I downgraded to numba version 0.52.0 and that seems to be working well as of 5 minutes ago. . Thanks for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-813536425:9,down,downgraded,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-813536425,1,['down'],['downgraded']
Availability,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users.; - plot function moved to scanpy/external/pl.py as scrublet_score_distribution().; - functions linked via 'See also' sections.; - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553:304,avail,available,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553,1,['avail'],['available']
Availability,"Okay, when I run this:; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""); sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); I get no error. ; Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-726806853:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-726806853,2,['error'],['error']
Availability,"On current master:. ```python; import scanpy as sc. a = sc.datasets.krumsiek11(); assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]; # True; ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1895:262,down,downstream,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895,1,['down'],['downstream']
Availability,"Once again, I got this error, even if I didn't import `seaborn`. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-10-a5c62c51242c> in <module>; 1 # plt.figure(figsize=(10, 10)); 2 rcParams['figure.figsize'] = 8, 8; ----> 3 sc.pl.umap(all_dataset['pdac_pengj_02'], color='cluster', legend_loc='on data', legend_fontsize='small', title='', frameon=False). f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _color_vector(adata, values_key, values, palette, na_color); 1128 return values, False; 1129 else: # is_categorical_dtype(values); -> 1130 color_map = _get_palette(adata, values_key, palette=palette); 1131 color_vector = values.map(color_map).map(to_hex); 1132 . f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_palette(adata, values_key, palette); 1103 _utils._set_default_colors_for_categorical_obs(adata, values_key); 1104 else:; -> 1105 _utils._validate_palette(adata, values_key); 1106 return dict",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-865741927:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-865741927,1,['error'],['error']
Availability,"One more point for the mask argument, would be useful in plotting to allow things like plotting expression with some clusters masked out (#759).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-824590137:23,mask,mask,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-824590137,2,['mask'],"['mask', 'masked']"
Availability,"Oops, didn't mean to close this initially. The datasets still don't download right on master. I've opened #1102 to fix it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082#issuecomment-599176533:68,down,download,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082#issuecomment-599176533,1,['down'],['download']
Availability,Option for downloading tissue image for spatial visium dataset,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506:11,down,downloading,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506,1,['down'],['downloading']
Availability,"Option to ignore ""nan"" with sc.pl.rank_genes_groups() and error while writing data to .h5ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1651:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1651,1,['error'],['error']
Availability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 bf5f27aa9e968de6e73fc7abb46a89084ddf6880; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2831: Prepare 1.9.8, stop ignoring citation errors'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2831-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2831 on branch 1.9.x (Prepare 1.9.8, stop ignoring citation errors)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423:528,error,errors,528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423,2,['error'],['errors']
Availability,PAGA plotting error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/487:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/487,1,['error'],['error']
Availability,"PPS: I see that I'm getting test failures with some github automatic tests, with none of the failures clearly coming from the code I edited -- do you know what is going on here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463:33,failure,failures,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463,2,['failure'],['failures']
Availability,"PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata = sc.datasets.pbmc3k(); sc.pp.scale(adata); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-d1141fe2ca57> in <module>; ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy); 910 if isinstance(data, AnnData):; 911 adata = data.copy() if copy else data; --> 912 view_to_actual(adata); 913 # need to add the following here to make inplace logic work; 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata); 377 ; 378 def view_to_actual(adata):; --> 379 if adata.is_view:; 380 warnings.warn(; 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > Current scanpy master branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151:307,Error,Error,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151,1,['Error'],['Error']
Availability,PR problem: docstring error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484,1,['error'],['error']
Availability,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204:205,down,download,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204,1,['down'],['download']
Availability,"PYTHON_VERSION variable is empty, so we actually pass `python=` in `conda create` so Travis always tests scanpy with latest Python in Conda distribution. Therefore Python 3.5 is actually never tested. Furthermore, conda switched to python 3.7, so now all test are run on Python 3.7. This is also the reason of weird HDF error message we get in tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/201:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/201,1,['error'],['error']
Availability,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we don’t internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2702:1113,error,error,1113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702,1,['error'],['error']
Availability,Passing a RandomState instance can cause failures to save,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:41,failure,failures,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,1,['failure'],['failures']
Availability,"Passing string or function to `vmax`, `vmin` when categorical in `color` throws error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800,1,['error'],['error']
Availability,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:617,fault,faults,617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,1,['fault'],['faults']
Availability,"Personally, I don't like it because; * Explicit is better than implicit; * there could be cases where I would like to plot Ensembl/Entrez or whatever identifier I have in `var_names` directly, even if I have a `gene_symbols` column available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/385#issuecomment-443412025:232,avail,available,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385#issuecomment-443412025,1,['avail'],['available']
Availability,Phneograph was recently updated and also new wrappers are available in external thanks to @awnimo @Koncopd .; Does this work for you @asmariyaz23 ? I will close this but feel free to reopen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-706139788:58,avail,available,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-706139788,1,['avail'],['available']
Availability,"Ping @WeilerP @adamgayoso, since you've both raised this idea today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-1028414654:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-1028414654,1,['Ping'],['Ping']
Availability,Ping @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-761747050:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-761747050,1,['Ping'],['Ping']
Availability,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1546:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546,3,"['Ping', 'error']","['Ping', 'error']"
Availability,Ping @flying-sheep,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1241#issuecomment-631952736:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241#issuecomment-631952736,1,['Ping'],['Ping']
Availability,"Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456; * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`.; * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088,1,['Ping'],['Ping']
Availability,"Ping @ivirshup. I wanna merge this if possible, it'd be great if you can have a look at the reply above. Together with this PR and https://github.com/theislab/scanpy/pull/1488, it would be great to do gene-set enrichment of all cell types at once without loops \o/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1388#issuecomment-724859143:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1388#issuecomment-724859143,1,['Ping'],['Ping']
Availability,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1474#issuecomment-722610470:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474#issuecomment-722610470,1,['Ping'],['Ping']
Availability,"Pinging this, as I've encountered it as well. I ran into non-reproducible UMAPs when rerunning code/notebooks and systematically went through my pipeline to find the source(s) of error, one of which was `sc.tl.score_genes_cell_cycle`. Setting the random seed externally did not help, but @Iwo-K's comment got me on the right track. I am now using the following simple hack, which fixes the issue for me:. ```python; adata.X = adata.X.astype('<f8') # Make float64 to ensure stability; sc.tl.score_genes_cell_cycle(adata, use_raw=False,; s_genes=cc_s_genes, g2m_genes=cc_g2m_genes,; random_state=0); adata.X = adata.X.astype('<f4') # Return to float32 for consistency; ```. Would be great if this would be fixed internally, perhaps using @Iwo-K's solution?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-849730924:0,Ping,Pinging,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-849730924,2,"['Ping', 'error']","['Pinging', 'error']"
Availability,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:677,error,errors,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267,1,['error'],['errors']
Availability,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467#issuecomment-715475234:308,error,error,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467#issuecomment-715475234,1,['error'],['error']
Availability,"Please provide more details. What is `folder` in your case and what is the error message? Follow the issue template, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817677727:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817677727,1,['error'],['error']
Availability,"Please re-open this; currently receiving this error with Python 3.9.7 and scanpy 1.8.2. Just in case it's useful, CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937,1,['error'],['error']
Availability,Plotting UMAP in backed mode leads to error when setting color palettes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2401:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401,1,['error'],['error']
Availability,Plotting categorical data throws an error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850,1,['error'],['error']
Availability,Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1975:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975,1,['error'],['error']
Availability,Plotting error when NaN in the categorical column and there are repetitive colours,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2133:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2133,1,['error'],['error']
Availability,Plotting on view of backed anndata throws error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263,1,['error'],['error']
Availability,Plotting with using scanpy.pl gives attribute error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['error'],['error']
Availability,"Possibly related to #275. The provided `sc.datasets.pbmc3k` does not have values for `""gene_ids""`. It'd be useful to have a standard dataset with ensembl ids and gene symbols for testing visualization functions with the `gene_symbols` argument. ```python; In [1]: import scanpy.api as sc ; ...: sc.datasets.pbmc3k().var.head() ; Out[1]: ; gene_ids; index ; MIR1302-10 NaN; FAM138A NaN; OR4F5 NaN; RP11-34P13.7 NaN; RP11-34P13.8 NaN. In [2]: import h5py ; ...: with h5py.File(""./data/pbmc3k_raw.h5ad"") as f: ; ...: print(repr(f[""var""][:])) ; ...: ; array([(b'MIR1302-10', -1), (b'FAM138A', -1), (b'OR4F5', -1), ...,; (b'CU459201.1', -1), (b'AC002321.2', -1), (b'AC002321.1', -1)],; dtype=[('index', 'S19'), ('gene_ids', 'i1')]); ```. However, if I download the source files, everything works out fine:. ```python. In [3]: !wget http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz ; ...; In [4]: !tar xzf pbmc3k_filtered_gene_bc_matrices.tar.gz; ...; In [5]: sc.read_10x_mtx(""./filtered_gene_bc_matrices/hg19"").var.head() ; Out[5]: ; gene_ids; MIR1302-10 ENSG00000243485; FAM138A ENSG00000237613; OR4F5 ENSG00000186092; RP11-34P13.7 ENSG00000238009; RP11-34P13.8 ENSG00000239945; ```. Which makes me think the file hosted at `http://falexwolf.de/data/pbmc3k_raw.h5ad` was created when there was a bug in the `read_10x_mtx` code.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/428:747,down,download,747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/428,1,['down'],['download']
Availability,Potential error in scanpy.tl.rank_genes_groups?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2634:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634,1,['error'],['error']
Availability,"Potentially fixes #1355. * Would still need tests/ further consideration.; * Need to fix missing values not being plotted below present ones. Using this branch:. ```python; import scanpy as sc; import numpy as np; import matplotlib as mpl. pbmc = sc.datasets.pbmc3k_processed(); pbmc.obs[""louvain""].iloc[::2] = np.nan; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain""); ```. ![image](https://user-images.githubusercontent.com/8238804/89258138-e54b0d80-d66a-11ea-8d13-e7bf975c3203.png). ```python; with mpl.rc_context({""figure.dpi"": 150}):; sc.pl.umap(pbmc, color=""louvain"", groups=list(pbmc.obs[""louvain""].cat.categories[:3])); ```. ![image](https://user-images.githubusercontent.com/8238804/89258165-f6941a00-d66a-11ea-9eaf-3a51a5a49a38.png). ## Update:. This PR expanded in scope quite a bit, so I'd like to wrap it up. Most things are implemented and seem to work. Regression tests need to be added, for these cases. - [x] Tests for all fixed cases (probably write these down as well); - [x] Decide on adding arguments, and default values; - [x] Decide on whether continuous legend update happens in this PR",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356:1001,down,down,1001,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356,1,['down'],['down']
Availability,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. it’s not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2595:102,avail,available,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595,1,['avail'],['available']
Availability,"Prepare 1.9.8, stop ignoring citation errors",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831,1,['error'],['errors']
Availability,Prevent error when no third point is found,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/266:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/266,1,['error'],['error']
Availability,"Previously discussed in #240. A few things left to discuss:. ## Tests. These are pretty simple, ""this doesn't intrinsically throw an error"" type tests. Should the tests cover more than that? Should they be more thorough is checking arguments won't throw errors? I'm open to suggestions on other things that could be checked. Also, is there a place they'd be more appropriate?. ## Allowing storage of multiple network representations . I think this would also be a pretty simple addition, but wanted to check again before implementing it. I'm thinking of adding a `use_network` argument which would allow key access to network stored in the AnnData object – similar to the `use_rep` argument. @LuckyMD mentioned there might be some storage concerns here, though I think the user is ultimately responsible for size in this case. The value added here is different representations are useful for different analysis, and it'd be useful to not have to have two objects when the rest of the data would be shared. ## Allow more choice of partition method for `louvain-igraph` package. I'm not too fussed on this one. It's just that `""RBConfiguration""` is hard coded when other methods are available, and I'm not aware of a reason it would be the best choice.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248:133,error,error,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248,3,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"Probably is, I think the `nan`s are for all zero genes. But I think there's a better solution than a procedural warning and data that causes errors downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294:141,error,errors,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294,2,"['down', 'error']","['downstream', 'errors']"
Availability,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957:259,fault,fault,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957,2,['fault'],['fault']
Availability,"PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt';",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:17206,error,error,17206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,['error'],['error']
Availability,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytest’s test files (`test_*.py` and `conftest.py`) aren’t Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225:566,error,error,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225,1,['error'],['error']
Availability,R scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65491,ERROR,ERROR,65491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,R scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69572,ERROR,ERROR,69572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60893,ERROR,ERROR,60893,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68757,ERROR,ERROR,68757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64835,ERROR,ERROR,64835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3703,ERROR,ERROR,3703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61879,ERROR,ERROR,61879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69085,ERROR,ERROR,69085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_grou,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72198,ERROR,ERROR,72198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64340,ERROR,ERROR,64340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,Random test failure of `test_plotting.py::test_paga`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:12,failure,failure,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['failure'],['failure']
Availability,Rank gene groups math error in windows,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061,1,['error'],['error']
Availability,"Re: #1649. Does this still need a max fold change argument?. More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-781059091:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-781059091,1,['avail'],['available']
Availability,"Re: quotes: Yes, the difference is that escape sequences work in double quoted strings. So for me a double quoted string in otherwise single quoted TOML means “pay attention, this one has special stuff in it”. Re: Build: The problem is that. 1. we’re installing louvain and it; 2. [doesn’t have a Python 3.9 wheel](https://pypi.org/project/louvain/#files), which causes us to download the sdist,; 3. [Sets `2to3=True` in setup.py](https://github.com/vtraag/louvain-igraph/blob/0.7.0/setup.py#L827-L828), for which [setuptools has removed support](https://setuptools.pypa.io/en/latest/history.html#v58-0-0). I think the best course of action would be to just port louvain to Python 3 only, and until then make sure our build environment as setuptools 57 installed. See https://github.com/vtraag/louvain-igraph/issues/57. Or we can deactivate louvain tests, skip installing it in the tests, and let people who need it deal with that. Or we ask @vtraag to upload Python 3.9 and 3.10 wheels, then we kicked the problem back two releases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897:376,down,download,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897,1,['down'],['download']
Availability,"Re: testing externals, I've tried my best to just test the way it interfaces with scanpy. i.e., if MAGIC silently fails to return the correct output, scanpy tests would pass so long as the output is the right type / shape. If MAGIC throws an error when run from scanpy, this might be something you would like to address (i.e. by contacting the relevant external developer) regardless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189,1,['error'],['error']
Availability,"Realised this functionality is already available via `pip install "".[dev]""`. May be good to mention somewhere, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-694244682:39,avail,available,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-694244682,1,['avail'],['available']
Availability,Recipes with plotting option throw import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/153:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153,1,['error'],['error']
Availability,Reduce error potential from networkx (e.g. #1227),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1323:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1323,1,['error'],['error']
Availability,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1806:79,down,down,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806,3,"['down', 'error']","['down', 'error', 'errors']"
Availability,"Regarding the other packages: of course, we will also interface those as optional dependencies... But I'd do it from the original Scanpy repo. To me, the whole problem is simply about keeping a clean structure and throwing clear error messages if optional dependencies are not installed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382344862:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382344862,1,['error'],['error']
Availability,Remove python 3.8 only code from download code,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1087:33,down,download,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087,1,['down'],['download']
Availability,"Removes the need to specify a genome string in 10x h5 files by default. This removes a personal annoyance of mine, where I had to figure out what the reference was called when there's often only one reference used per file. For cellranger `v3.0.0+` files, specifying a genome acts as a filter on input, as it did already. However, it doesn't only act if `gex_only` is `True`. Additionally, the behavior of `gex_only` has been changed to fit the documentation, i.e. it just filters for gene expression variables. For legacy files:. * If the file only has one genome group, that one is used by default; * If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. As the behavior of the function has meaningfully changed, this is a breaking change (though I'd be surprised if it affected many people). Personally, I haven't seen many 10x files which contain multiple genomes, so I'd appreciate feedback or examples from people who have.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442:670,error,error,670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442,1,['error'],['error']
Availability,Rename mask parameters,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2857:7,mask,mask,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2857,1,['mask'],['mask']
Availability,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224:23,avail,available,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224,1,['avail'],['available']
Availability,"Reorder operations to avoid overflows. Behavior Fixed:; ```py; import scanpy as sc; import numpy as np; X = np.random.randint(0,1000, size= (3000,2000)); ann = sc.AnnData(np.log(X+1)); gsize = X.shape [0] / 2; ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); ```; ```pytb; ... storing 'group' as categorical; C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars; (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-7-bccdb587a644> in <module>; 5 gsize = X.shape [0] / 2; 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize); ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000); 8; 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds); 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); --> 372; 373 scores[np.isnan(scores)] = 0; 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. After the fix, the same code no longer raises an error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1062:1443,error,error,1443,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062,2,['error'],['error']
Availability,Require a minimum groupsize for marker detection to prevent division by zero errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490:77,error,errors,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490,1,['error'],['errors']
Availability,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037957505:306,error,errors,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037957505,1,['error'],['errors']
Availability,"Right now I do not get the error if I do these steps:. ```py; sc.pp.normalize_per_cell(adata, counts_per_cell_after=norm_counts_per_cell); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=n_top_genes); sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-520178937:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520178937,1,['error'],['error']
Availability,"Right now, when we do `sc.pl.pca_loadings(adata, components=range(5))` to plot first 5 components or even weirder things like `sc.pl.pca_loadings(adata, components=[-10, 0, 5])` the plotting function silently subtracts 1 and uses these as indices for `adata.varm['PCs']`. We can see in the plot title things like `PC-11`. It's confusing and error prone. This change throws an error if a PC index is invalid.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/803:341,error,error,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/803,2,['error'],['error']
Availability,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279,2,['error'],['error']
Availability,"Running `sc.pl.paga(adata)` in v1.4 returns an error:; ```; Traceback (most recent call last):. File ""<ipython-input-412-3baa85828ec9>"", line 1, in <module>; sc.pl.paga(adata). File ""/path/to/scanpy/scanpy/plotting/_tools/paga.py"", line 445, in paga; adjacency_solid, layout=layout, random_state=random_state, init_pos=init_pos, layout_kwds=layout_kwds, adj_tree=adj_tree, root=root). UnboundLocalError: local variable 'adj_tree' referenced before assignment; ```. There is a conditional before the referenced line, which assigns value to `adj_tree`, and indeed, running these works fine:; ```; sc.pl.paga(adata, layout='rt'); sc.pl.paga(adata, layout='rt_circular'); sc.pl.paga(adata, layout='eq_tree'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/487:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/487,1,['error'],['error']
Availability,Running example with magics gives error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/208:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/208,1,['error'],['error']
Availability,"Running https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/cluster.py on the latest released Scanpy (1.4.4.post1) gives a memory error:. ```; reading 1M_neurons_filtered_gene_bc_matrices_h5.h5; Variable names are not unique. To make them unique, call `.var_names_make_unique`.; (0:01:39); running recipe zheng17; filtered out 3983 genes that are detectedin less than 1 counts; Killed; ```. This is running with 60GB of memory (n1-standard-16), but also occurs with 104GB (n1-highmem-16). It looks like there has been a regression somewhere since this used to run OK. I think the error may be happening in anndata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/811:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/811,2,['error'],['error']
Availability,"Running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3') produces scikit-misc error; package not installable with either pip or conda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,Running scanpy on M1 apple silicon clashes with Numba errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:54,error,errors,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). ; for adata in adata_control:; adata.var[""mt""] = adata.var_names.str.startswith(""mt-""); sc.pp.calculate_qc_metrics(; adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True; ); I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2304:98,error,error,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304,1,['error'],['error']
Availability,"Runs static analysis concurrently with tests, while currently static analysis is run first. This cuts down on total test time, and will always test both correctness and style.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/846:102,down,down,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/846,1,['down'],['down']
Availability,RuntimeError: libpng signaled error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852,1,['error'],['error']
Availability,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164,1,['error'],['error']
Availability,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300,1,['error'],['error']
Availability,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue.; leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5); adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575,2,"['down', 'error']","['downgrading', 'error']"
Availability,"Same here, downgrading made everything work",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-691088607:11,down,downgrading,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-691088607,1,['down'],['downgrading']
Availability,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. ; I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276,1,['error'],['error']
Availability,Same issue here. Downgrading scipy from 1.5.4 to 1.2.1 helps.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-720711607:17,Down,Downgrading,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-720711607,1,['Down'],['Downgrading']
Availability,"Same problem here. So glad that I found this ticket. From flying-sheep's commit, it looks like either upgrading scanpy to the newest version or downgrading pandas would work. There is also some anndata version requirement going up, no idea why.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-458954075:144,down,downgrading,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-458954075,1,['down'],['downgrading']
Availability,"Scanorama's `nn_approx` uses annoy, which is a package that has caused many a headache due to its instability. From my experience, these segfaults started showing up since 1.17.x got released, and tend to begin happening more consistently if anything is installed into the environment after annoy itself somehow. Downgrading to 1.16.3 via pip tends to make them go away. It would be neat if there was some sort of more reliable workaround, keeping annoy stable and not bothering the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866#issuecomment-1976231395:313,Down,Downgrading,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866#issuecomment-1976231395,2,"['Down', 'reliab']","['Downgrading', 'reliable']"
Availability,Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (n_active + m_active + 1) / 12)); ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`; _rank_gene_groups.py:313; ```; scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(; (n_active * m_active * (1/12.0) * (n_active + m_active + 1))); ```; Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1061:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061,1,['error'],['error']
Availability,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698886893:12,mainten,maintenance,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698886893,2,['mainten'],['maintenance']
Availability,Scanpy docs are down?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1746:16,down,down,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1746,1,['down'],['down']
Availability,Scanpy import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2138:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138,1,['error'],['error']
Availability,"Scanpy vs. 1.3.6; installed using pip3; OSX 10.10.5; Jupyter lab. code:; `list_of_list_of_marker_genes = [mg1, mg2, mg3]; for mg in list_of_list_of_marker_genes:; sc.pl.stacked_violin(adata, mg, groupby = 'louvain’, rotation=90); print(mg)`. This works for some mg's but not for all; sc.pl.matrixplot works for all of them; the same for sc.pl.violin; it works also if I would combine all marker genes into one list and then run; sc.pl.stacked_violin. When I say it does not work: it typically generates one stacked plot and then; 'hangs up' with an error message for subsequent plots:. Error message:. IndexError: list index out of range. When I run sc.pl.stacked_violin for the individual mg’s, some work others don’t. It is a reproducible results. I explicitly tested whether the genes in the respective marker gene lists are present in ’n_cells’. If not, I update the lists. What am I missing here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405:549,error,error,549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405,2,"['Error', 'error']","['Error', 'error']"
Availability,Scanpy.pl.embedding throws error when projection='3d' and all values are the same for coloring,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability,Scatterplot with color for categorical value outputs attribute error about legend,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102,1,['error'],['error']
Availability,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:53,error,error,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810,3,"['Error', 'error']","['Error', 'error']"
Availability,Seems this has been fixed in https://github.com/bioconda/bioconda-recipes/pull/21423. ; `1.4.6` is available again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1146#issuecomment-613471671:99,avail,available,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146#issuecomment-613471671,1,['avail'],['available']
Availability,"Setting one root works well:; `sc.pl.paga(adata, layout='eq_tree', root=[9])`; Setting multiple roots returns an error: ; `TypeError: unhashable type: 'list'`; Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/128:113,error,error,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128,1,['error'],['error']
Availability,Several HTTP errors,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604:13,error,errors,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604,1,['error'],['errors']
Availability,"Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1102:20,down,downloading,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102,2,['down'],"['downloaded', 'downloading']"
Availability,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141#issuecomment-2210675845:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141#issuecomment-2210675845,1,['error'],['error']
Availability,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on?. If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1501#issuecomment-730233047:232,mask,mask,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501#issuecomment-730233047,1,['mask'],['mask']
Availability,"Simple test case; ```; data = sc.read(""pbmc3k.h5ad""); logical_ar = data.var[""name""] == ""RER1""; df = data[:, logical_ar]; df.uns = data.uns # this causes an error ; ```. Causes this error; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-8b2cadedfe9b> in <module>(); 1 l = data.var[""name""] == ""RER1""; 2 df = data[:, l]; ----> 3 df.uns = data.uns. /usr/local/lib/python3.6/site-packages/anndata/base.py in uns(self, value); 987 # here, we directly generate the copy; 988 adata = self._adata_ref._getitem_copy((self._oidx, self._vidx)); --> 989 self._init_as_actual(adata); 990 self._uns = value; 991 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, dtype, shape, filename, filemode); 816 self._varm = BoundRecArr(varm, self, 'varm'); 817 ; --> 818 self._check_dimensions(); 819 self._check_uniqueness(); 820 . /usr/local/lib/python3.6/site-packages/anndata/base.py in _check_dimensions(self, key); 1692 raise ValueError('Observations annot. `obs` must have number of '; 1693 'rows of `X` ({}), but has {} rows.'; -> 1694 .format(self._n_obs, self._obs.shape[0])); 1695 if 'var' in key and len(self._var) != self._n_vars:; 1696 raise ValueError('Variables annot. `var` must have number of '. ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/323:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323,2,['error'],['error']
Availability,Simplification of _ranks in rang_genes_groups. Passing pandas index to scipy dendrogram now causes an error. This fixes the problem.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1290:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1290,1,['error'],['error']
Availability,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3; """"""; One of the scanpy versions introduced a bug that was recently fixed, ; where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. ; I believe it is because adata.var.index is being stored as the ; adata.uns ""gene_symbol"" output for tl.rank_genes_groups, ; and pl.rank_genes_groups correctly looks for the adata.var.index, ; but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2; """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],; gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:; # Try 1.7.2 way first; ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""); except:; # Use gene names if that doesn't work; gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(); ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706:1802,down,downstream,1802,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706,1,['down'],['downstream']
Availability,"Since we don't know when a release of `pynndescent` will go out, I think it's fine to keep this a little hacky for now. I think it can be less hacky than now doing something like this:. ```python; from_init = pynndescent.NNDescent(train, n_neighbors=15, init_graph=indices); from_init._rp_forest = rp_forest; query_indices_init, query_distances_init = from_scratch.query(test); ```. Once a release of pynndescent comes out we can support doing it the proper way. . I'd say it's up to you whether you want to have the kinda hacky solution or not. I definitely don't want UMAP to be pinned to below 0.5 when we release 1.7 proper, and it would be good for ingest to work with UMAP 0.5. The only downside I see to the kinda hacky solution as an intermediate is that you're fixing it twice. I don't think it'll be hard to go from this to the clean version however. -------------------------. I haven't looked into what needs to happen for the UMAP embedding transfer stuff to work. Is that pretty straight forward?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133:693,down,downside,693,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133,1,['down'],['downside']
Availability,"So I guess basic difference is that this one can convert starfish to anndata ""online"" without having to read from disk the anndata object. Also, my understanding with `save_anndata` method is that it doesn't export all the features we might want (e.g. area of segmentation masks or others, to be stored in obs). However, this could also be fixed by sending a PR there and modifying what is saved in anndata of the expression matrix.; What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362#issuecomment-671884211:273,mask,masks,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362#issuecomment-671884211,1,['mask'],['masks']
Availability,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600,2,"['down', 'error']","['downsampling', 'error']"
Availability,"So I just tried to install the package from the master branch by running. ```; pip install git+https://github.com/theislab/scanpy.git; ```; (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build; Complete output from command python setup.py egg_info:; running egg_info; creating pip-egg-info/scanpy.egg-info; writing pip-egg-info/scanpy.egg-info/PKG-INFO; writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt; writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt; writing requirements to pip-egg-info/scanpy.egg-info/requires.txt; writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt; writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'; warning: manifest_maker: standard file '-c' not found; ; error: package directory 'scanpy/exs' does not exist; ; ----------------------------------------; Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/; The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-284343715:1043,error,error,1043,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-284343715,2,['error'],['error']
Availability,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579,1,['error'],['error']
Availability,"So assuming that we are only interested in downsampling, then I'd say `NearMiss` and related are straightforward and scalable (just need to compute a kmeans whcih is really fast)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1043141030:43,down,downsampling,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1043141030,1,['down'],['downsampling']
Availability,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:34,down,downstream,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668,1,['down'],['downstream']
Availability,"So it appears to me that the difference between the discrete and continuous colours is purely an internal `scanpy` decision. Plotting with `matplotlib` and a `pd.Categorical` returns the same error as before. ![image](https://user-images.githubusercontent.com/8499679/73891118-81719480-4841-11ea-8752-b7490d89f4bd.png). An alternative would be to explicitly return a categorical from the clustering function, i.e. rather than ensuring that the clustering returns an array of `str`, ensure that it returns a categorical where the categories are ints. Categorical (string) output: scanpy works, matplotlib errors:. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891608-a1ee1e80-4842-11ea-97b8-16c4618a894f.png). </details>. Integer output: matplotlib works, scanpy mistakenly uses continuous colormap:. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891676-bd592980-4842-11ea-8043-5ed74693ee28.png). </details>. Cateogrical (integer) output: both work. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891704-ccd87280-4842-11ea-91c1-445b1574d812.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582657247:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582657247,2,['error'],"['error', 'errors']"
Availability,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713:39,down,downloading,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713,3,['down'],['downloading']
Availability,"So it will only work on non-negative expression values without any pre-process?; I guess that make sense, thank you for the reply. The version of the package:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. The AnnData objects were all read through same commands without any modification. sc.read_10x_h5(filepath, gex_only=False). the dataset I used to test them are:. https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_protein_v3; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/malt_10k_protein_v3. It appears to me that it only works on the v2 nsclc h5 data. I was trying to merge the three data sets and run through SAM to compare with the result of BBKNN, didn't work. So I tried to run each of them individually in the loop. I guess it won't work on CITESeq data without other processing?. I tried removed all the antibody read counts from adata.X and ran it once, still got same error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989:1135,error,error,1135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989,1,['error'],['error']
Availability,So my X actually contained negative values. I removed my _scanpy.pp.scale_ step and tried this downsampling step earlier in my pipeline and its working. Thanks for taking time to help with this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282:95,down,downsampling,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282,1,['down'],['downsampling']
Availability,"So my idea was the following:; If you have a full dataset and some genes are 0 everywhere, except in the cells in cluster A, then you filter out cluster A in your new dataset, and recompute everything... those genes now have 0 variance in your filtered dataset. That would give you an error that didn't appear before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494330011:285,error,error,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494330011,1,['error'],['error']
Availability,"So the format seems to be correct. Do you have the genes that are apparently missing in your object? You can check this for all the values that are mentioned in the `KeyError` output at the bottom of your error report. For example, is this statement `True`?; `'USP1' in [str(i) for i in adata.var_names]`. If not, your `adata` object might just be missing the cell cycle genes you are looking for. How many genes are in your object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-762881039:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-762881039,1,['error'],['error']
Availability,"So the issue is incompatibilities between versions of sphinx and their `objects.inv`? Is there an open issue in sphinx for this?. > > Do you expect this to be compatible with older sphinx versions?; >; > Of course! Why would it not be?. Mostly because the inner workings of Sphinx are a mystery to me, so I have no idea what features your changes rely on 😆. This was mainly me asking if we should bump the minimum version of sphinx allowed. Maybe we should if there are issues with the `objects.inv`s?. > Maybe we can link to the dev docs?. Or we could add the classes to nitpick ignore? Then once the docs are rebuilt it will do the right thing without any intervention, and we don't have to be keeping an eye out for this. My main concern here is that the `scipy.github.io` address may not be permanent, similar to how numpy temporarily used a github.io address while they revamped their docs. Basically, it may just break or go down without notice. I thought we could even just trigger a new build of the anndata stable docs, but there's an issue there, probably to do with sphinx not being pinned on release. I do want to make a new anndata release soon-ish though. -----------. I'm happy for you to pick one of the approaches and merge it. AnnData could also use a fix for this, I've temporarily just pinned sphinx below 4.1 there too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1948#issuecomment-880405295:931,down,down,931,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1948#issuecomment-880405295,1,['down'],['down']
Availability,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:104,down,download,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702,4,"['down', 'error']","['download', 'downloading', 'error']"
Availability,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154498462:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154498462,1,['error'],['error']
Availability,"So this is possibly related to #1136 (pure speculation 😅 ). Basically, on a Vm with ubuntu 18:; ```; conda create -n temp_env_scanpy; conda activate temp_env_scanpy; (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: -; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1; ```; Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:; ```; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError:; ```; Another student working with me had the same issue in windows. His error was:; ```; UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2; ```; But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed.; In all cases, conda was `4.8.3`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142:960,error,error,960,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142,1,['error'],['error']
Availability,"So this would be a reproducible example:. ```py; import gzip; import shutil; from urllib.request import urlopen; from pathlib import Path. from tqdm.notebook import tqdm; import scanpy as sc. url = ""https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE194122&format=file&file=GSE194122%5Fopenproblems%5Fneurips2021%5Fmultiome%5FBMMC%5Fprocessed%2Eh5ad%2Egz"". path = Path(""data/GSE194122_openproblems_neurips2021_multiome_BMMC_processed.h5ad""); if not path.is_file():; with (; urlopen(url) as raw,; tqdm.wrapattr(raw, ""read"", total=int(raw.headers[""Content-Length""])) as wrapped,; gzip.open(wrapped, 'rb') as f_in,; path.open('wb') as f_out,; ):; shutil.copyfileobj(f_in, f_out). adata_atac = sc.read(path); adata_atac.X = (adata_atac.X > 0)*1; sc.pp.highly_variable_genes(adata_atac, n_top_genes=13634); adata_atac = adata_atac[:,adata_atac.var['highly_variable']]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1910369113:232,down,download,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1910369113,1,['down'],['download']
Availability,"So you want to e.g., downweight the likelihood of sampling cells with a particular feature (like a common cell type), and upweight others. What do you want to use this weighting for now in the `sc.tl.rank_genes_groups` function? Or in the visualization functions you changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494111085:21,down,downweight,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494111085,1,['down'],['downweight']
Availability,"So, without any evidence, I think it should be fine. The reason I had put an error in the first place is that the typical behavior is to pass log normalized data to this HVG function, and I didn't want people to run this incorrectly. I think another solution would be to just throw a UserWarning, though in a way I like the idea of having an argument that disables the `check_nonnegative_integer()`. I think I would call it `enforce_counts_seurat_v3` though. You might also consider bypassing the check if the flag is set, because it can be slowish for large datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793,1,['error'],['error']
Availability,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:847,recover,recovers,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336,1,['recover'],['recovers']
Availability,"Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python; if plot:; from .. import plotting as pl # should not import at the top of the file; pl.filter_genes_dispersion(filter_result, log=True); ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python; In [1]: import numpy as np; ...: import pandas as pd; ...: import scanpy.api as sc; ...: ; ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures; ...: sc.logging.print_versions(); /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file.; In [3]: sc.pp.recipe_zheng17(adata, plot=True); running recipe zheng17; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-3-c19f237f1c6e> in <module>(); ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy); 106 if plot:; 107 from .. import plotting as pl # should not import at the top of the file; --> 108 pl.filter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/153:106,error,error,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153,3,['error'],"['error', 'errors']"
Availability,"Some tests are still failing, but not because of `uns/spatial`. They all throw errors along these lines:; ```; assert 'Error: Image files did not match.\n RMS Value: 15.114361035293829\n; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432:79,error,errors,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432,2,"['Error', 'error']","['Error', 'errors']"
Availability,"Some ways I like to work with the code:. * Left side of screen is text editor, right side is terminal/ docs/ something else; * 86 characters available if I have a side bar open, 95 without; * Split code browser; * 84 columns with a side bar open, 95 without. 120 is too long for this. Also this is a pretty wide laptop screen (16-inch). I believe Alex uses a MacBook Air with even more limited screen real estate.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1694#issuecomment-787409697:141,avail,available,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694#issuecomment-787409697,1,['avail'],['available']
Availability,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:149,failure,failure,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,1,['failure'],['failure']
Availability,"Sometimes, it can happen when downloading 10x files from e.g. GEO that they are not organized in; folders but instead, they have a sample-specific prefix. E.g. . ```console; sturm@zeus [SSH] processed % ll; total 156M; -rw-r--r-- 1 dbadmin dbadmin 29K May 21 2018 GSM3148575_BC09_TUMOR1_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148575_BC09_TUMOR1_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 34M May 21 2018 GSM3148575_BC09_TUMOR1_matrix.mtx.gz; -rw-r--r-- 1 dbadmin dbadmin 28K May 21 2018 GSM3148576_BC09_TUMOR2_barcodes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 259K May 21 2018 GSM3148576_BC09_TUMOR2_genes.tsv.gz; -rw-r--r-- 1 dbadmin dbadmin 33M May 21 2018 GSM3148576_BC09_TUMOR2_matrix.mtx.gz; ```. This PR adds a keyword argument `prefix` to `read_10x_mtx` which enables to load these files ; without manual renaming and moving, e.g. ; ```python; adata = sc.read_10x_mtx(""path/to/files"", prefix=""GSM3148575_BC09_TUMOR1_""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1250:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250,1,['down'],['downloading']
Availability,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features!. > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default; * Consolidate implementation to a single well maintained library; * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points?. * `tsne` should allow weights to be passed through (whether perplexity based, or not); * There should be a warn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636:569,error,error,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636,1,['error'],['error']
Availability,Sorry for all the trouble. I just wanted to download from your dropbox link but the file wasn't there anymore...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-457869163:44,down,download,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-457869163,1,['down'],['download']
Availability,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage.; Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324638985:345,mainten,maintenance,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324638985,1,['mainten'],['maintenance']
Availability,"Sorry for opening this thread again, but I think I've run into the same problem. Here's my code and error:; ```; mat_all = sc.read_loom(filename=""RSV.loom""); sc.pp.pca(mat_all); sc.pp.neighbors(mat_all); sc.tl.umap(mat_all); ```; The error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/31048.tmpdir/ipykernel_3245/2128514342.py in <module>; 3 sc.pp.pca(mat_all); 4 sc.pp.neighbors(mat_all); ----> 5 sc.tl.umap(mat_all); 6 sc.pl.tsne(mat_all, color=""cluster"",legend_loc=""on data"",; 7 size=20, save=True). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 192 default_epochs = 500 if neighbors['connectivities'].shape[0] <= 10000 else 200; 193 n_epochs = default_epochs if maxiter is None else maxiter; --> 194 X_umap = simplicial_set_embedding(; 195 X,; 196 neighbors['connectivities'].tocoo(),. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. And the versions I've been running:; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062410460:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062410460,2,['error'],['error']
Availability,"Sorry for the late reply, the notifications for this thread got sent to my spam folder. @giovp . - I think so! It’s not difficult to extend it to more latent variables. We could allow them to specify any column(s) in the `obs` DataFrame.; - Hmm, I think `statsmodels` can do regression on lots of different models, but from the source paper it sounds like using Poisson was simplest/fastest and did not affect the results too much when compared to negative binomial regression. I think parameter estimation for other models might be a bit more involved.; - I think that would be pretty straightforward. What outputs are you referring to, specifically?; - I’ve been testing by computing correlations between the genes from the python and R implementations. You could also compare rank-ordering of cells by variance. Another approach might be to compare the output of downstream analysis methods (like clustering) to see if the results are similar, and compare to the output of unprocessed data as a negative control.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077:866,down,downstream,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077,1,['down'],['downstream']
Availability,Sorry for the late reply. The issue seems to only occur in Win10 but not Linux. No error on linux using the exact same codes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-814555908:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-814555908,1,['error'],['error']
Availability,"Sorry for the super-late response! I just worked through almost 60 issues starting with the most recent, this is the last one... Sorry about that. `paga_path` requires computing a pseudotime before-hand as one needs to order cells at single-cell resolution along the path. I added a more meaningful error message stating that. PS: Now, there is also a test for PAGA [here](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py), making sure that the canonical use ([here](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb)) remains unchanged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335:299,error,error,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335,1,['error'],['error']
Availability,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842:70,error,errors,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842,1,['error'],['errors']
Availability,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311:72,fault,fault,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311,1,['fault'],['fault']
Availability,"Sorry, this seems to be a UMAP issue. To really dig down to this, you'd probably run this using the UMAP package and submit a bug report there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/257#issuecomment-418822885:52,down,down,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/257#issuecomment-418822885,1,['down'],['down']
Availability,"Sort of separate but also, an error writing such data with `adata.write(""results.h5ad"")`. Traceback:; ```; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'uns/rank_genes_groups_filtered/names' of <class 'h5py._hl.files.File'> from /.; ```. `del adata.uns[""rank_genes_groups_filtered""]` and the .write() call succeeds",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1651#issuecomment-779382361:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1651#issuecomment-779382361,2,['error'],['error']
Availability,"Sorta!. ![image](https://user-images.githubusercontent.com/8238804/108616034-ce7cd480-745d-11eb-93e4-996a912c5041.png). Not sure if it's not working because something is wrong with the configuration, because it doesn't work with PRs, or that it takes a bit for search results to be available. One downside of using this over algolia's search is that we get search analytics through algolia, while we'd have to upgrade our readthedocs subscription to have access to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773:282,avail,available,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773,2,"['avail', 'down']","['available', 'downside']"
Availability,"Sounds good, we are currently hosting the whole scanpy-scripts as a bioconda package, but we could look into having it as pip installable as well. Does this means that scanpy administrators are happy to have the scanpy-scripts code poured here to make them pip installable, or that you want to contribute the pip packaging to the repo where we currently have scanpy-scripts? We have travis testing for our scripts layer, that would make maintenance easier on your side, as it would detect any changes on scanpy that break the scripts layers (taking you to only break API if extremely necessary - in turn making your tool more stable for external users).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478:437,mainten,maintenance,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478,1,['mainten'],['maintenance']
Availability,"Sounds great, @falexwolf! I did notice the slow-down and agree it's not great. That's a great suggestion, I'll take a look. Thanks, glad it helped!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427484003:48,down,down,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427484003,1,['down'],['down']
Availability,"Sounds like a great idea. generally the order should be the same as in the signature, but I don’t see a problem in reshuffling the lovain args to match the leiden ones. We have to be careful with details though: e.g. `partition_type` needs to be slightly different for both:. ```rst; Type of partition to use. Defaults to :class:`~louvain.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~louvain.find_partition`.; ```; ```rst; Type of partition to use. Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~leidenalg.find_partition`.; ```. @falexwolf do you think we should go ahead with https://pypi.org/project/legacy-api-wrap (and introduce `*` in `louvain`’s signature` or do you think we can slightly reshuffle the last few arguments of `louvain` without considering it a backwards compat break?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741:381,avail,available,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741,2,['avail'],['available']
Availability,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2470:501,down,downstream,501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470,2,['down'],['downstream']
Availability,"Spatial tutorial gets 'HTTPError: HTTP Error 403: Forbidden' error by running; `adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node"")`. The error raised by calling `urllib.request.urlretrieve` method for downloading data from 10xgenomics. Sergei suggested to change the User-Agent. . The `_download.py` tries to get the data via `urllib.request.urlretrieve` as before. If it is not possible the User-agent is changed to 'scanpy-user'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334:39,Error,Error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334,4,"['Error', 'down', 'error']","['Error', 'downloading', 'error']"
Availability,"Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master); --------|--------------------------|--------------; `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs; 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1022:475,Ping,Ping,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022,1,['Ping'],['Ping']
Availability,"Starting from the end: I think if you could upload the clustering results from the Scanpy paper / PAGA preprint to the scanpy github repo, it would be great. I still have the dropbox link of course, but I guess in the long run it's better if that file was located here and linked from the https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells page. The issue with 1 cell missing was because I did not specify `header=None` when loading it with Pandas :) So my error, not yours. The file is correct as is. That said, I am worried about the influence the random seed in randomized PCA seems to give in this case. Let me show you how it looks:. ![mln-tsne-clustering-comparison](https://user-images.githubusercontent.com/8970231/47555195-71af9480-d90b-11e8-85fb-a3e8dcb7a66f.png). I would be fine with some cells getting into other clusters depending on the random seed, and it would even be okay if small clusters changed their identities, but what we see here is a very drastic change of the cluster structure. Are you sure that the only difference is the randomized PCA outcome? Can it be that some of the default parameters in `sc.pp.recipe_zheng17`, `sc.pp.neighbors`, or `sc.tl.louvain` changed since when you ran the clustering? The scanpy code I posted above is the full code I used, and I ran it yesterday after updating scanpy via pip. BTW, the visualization above is taken from https://www.biorxiv.org/content/early/2018/10/25/453449 which we posted yesterday. Any comments very welcome! I hope you don't mind being thanked in the acknowledgements!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-433334926:496,error,error,496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-433334926,1,['error'],['error']
Availability,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1626976895:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1626976895,1,['error'],['error']
Availability,Still have to use scipy 1.4.1 or 1.4.2. There's now 1.6.1 but this also results in the same error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-795204132:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-795204132,1,['error'],['error']
Availability,"Still occurring, though it's a really weird case. Here's some code to reproduce:. ```python; a = sc.AnnData(np.ones((100, 100))); sc.pp.pca(a); # RuntimeWarning: invalid value encountered in true_divide; # self.explained_variance_ / total_var.sum(); sc.pl.pca(a) # Throws the same error as above; a.uns[""pca""]; ```. ```; {'params': {'zero_center': True, 'use_highly_variable': False},; 'variance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,; 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,; 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],; dtype=float32),; 'variance_ratio': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],; dtype=float32)}; ```. Though I do get the same behaviour with `svd_solver=""randomized""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264#issuecomment-766319589:281,error,error,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264#issuecomment-766319589,1,['error'],['error']
Availability,"Still the error message could be a lot better. I’ve made the same mistake,; it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>; wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825,1,['error'],['error']
Availability,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-701591572:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-701591572,1,['error'],['error']
Availability,"Sure, I’ll happily elaborate!. As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py; def test_score_genes():; adata = TODO # create test data here; gene_list = TODO; gene_pool = TODO; gene_list, gene_pool, get_subset = _check_score_genes_args(; adata, gene_list, gene_pool, use_raw=use_raw, layer=layer; ). bins = list(_score_genes_bins(; gene_list,; gene_pool,; ctrl_as_ref=False, # needs to be renamed; ctrl_size=50,; n_bins=25,; get_subset=get_subset,; )). assert 0 not in map(len, bins); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331:882,degraded,degraded,882,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331,1,['degraded'],['degraded']
Availability,"Sure, this works as a workaround. Thing is, if I call doublets like described in the scrublet README, I do not get an error:; This works:; ```python; import scrublet as scr; import scanpy as sc; adata = sc.datasets.paul15(). scrub = scr.Scrublet(X); doublet_scores, predicted_doublets = scrub.scrub_doublets(); ```; So is this upstream?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-778326318:118,error,error,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-778326318,1,['error'],['error']
Availability,"Sure:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-161-7b672fc51046> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973:1649,error,error,1649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973,1,['error'],['error']
Availability,"TCTCATN', 'AATCTATCACAN', 'CTCCCTTTTGCN', 'TTTGACACCGCC',; 'CGCGCCTTGTCA', 'AACCTTTGATGG',; ...; 'TATCTGTAATCA', 'ATGGGTGAACAG', 'TCCGATAGTGGA', 'TTGTCAATCTCT',; 'CGGTGGCTGAGT', 'TCCATATCAGGG', 'TGGCGTTAGTAT', 'TTCTTCTGGTTT',; 'ACTATGGCTGGT', 'CGTGAACCCTGT'],; dtype='object', length=1500); >>> print(all((adata00a.var_names == day_x.var_names).all() for day_x in adata_list)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<stdin>"", line 1, in <genexpr>; NameError: name 'adata00a' is not defined; >>> print(adata.var_names, adata); Index(['GTGCCATATTCN', 'TCGCAGCCTGCT', 'CTGTAGCCCCCA', 'TGTATGTTGCTT',; 'CAGTATCTCATN', 'AATCTATCACAN', 'CTCCCTTTTGCN', 'TTTGACACCGCC',; 'CGCGCCTTGTCA', 'AACCTTTGATGG',; ...; 'GCCCAGGTGCCA', 'GACGAAACCATG', 'CCCGCCCAAGTT', 'GTGCGTTAAGTG',; 'TCCTACCTGTAC', 'CACACTGATGAT', 'CAGCATACTCCN', 'AGAAACCTTGGG',; 'GACATAAATCAG', 'AGGGGTGACGAC'],; dtype='object', length=3971) AnnData object with n_obs × n_vars = 119446 × 3971 ; obs: 'batch', 'tech'; ```; The `adata00a` threw some errors as it hadn't been defined yet, and I wan't totally sure what you were trying to reference there, but I tried with both just `adata` and `day00a` and it still threw errors (not defined and ValueError respectively). Assuming that you just wanted the var_names for each day I just ran them separately and also got the cell barcodes:. ```; >>> print(day01.var_names); Index(['CCGTCATCTTCT', 'GATTCGATTTCC', 'TTTTGGCCGTTA', 'TGAGTTTTTATN',; 'CCGTCTCTACTN', 'ATAAGTTGCTTG', 'CCGTCGCAAGGT', 'ACACCTTGGAAA',; 'AGCCCGCCCAGN', 'GAAAATCGATCN',; ...; 'AACCCGCCCAGN', 'CCCATCGACTGA', 'GCGGAAGGCGCT', 'TACTTGGTTTGC',; 'GTCTTGGTTACC', 'CTCGCGGCCGTT', 'CCCAAATTTCGT', 'CCGGAGGTTTAG',; 'CTAAACGGCTGT', 'GAAATGAGGATG'],; dtype='object', length=500); >>> print(day02.var_names); Index(['AACCATCAGCGG', 'GTCCCACTACAT', 'CCCTTTCCGAGN', 'AGGGCACTTTGG',; 'CCTGAGAAGCGT', 'GGGGCTGTTGGG', 'ACTGACTTACCC', 'CAAGACTACTAT',; 'GCATTATGTCCC', 'TTCGGTGTCATG',; ...; 'AGCAGCGTTATA', 'A",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/914#issuecomment-553986902:1254,error,errors,1254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/914#issuecomment-553986902,2,['error'],['errors']
Availability,"Tbh, I found out about `groups` after writing the function and looking for a way to put the dots in front. Maybe there is a simpler way to do this... But then the command you suggest gives an error on my own data if I don't also specify `color='bulk_labels'` (works for the pbmc68k, but doesn't colour anything in), and then it just puts all the labels on the same plot and doesn't create small multiples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-566487331:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-566487331,1,['error'],['error']
Availability,Test case failure with test_visium_default not having any visible data points,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048:10,failure,failure,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048,1,['failure'],['failure']
Availability,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572:5,failure,failures,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572,1,['failure'],['failures']
Availability,Test rtd failures,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1900:9,failure,failures,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900,1,['failure'],['failures']
Availability,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:637,avail,available,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886,2,['avail'],['available']
Availability,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-668005293:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-668005293,1,['error'],['error']
Availability,"Thank you for all your thoughts! That's very interesting and helpful!. > although it would also make sense for log1p to be a class method, given that it only needs to exist for AnnData objects. Yes! I also think so. But then the question is which function makes into AnnData and which doesn't. Right now we only put functionality that is related to bookkeeping of the data into AnnData. Everything else remains out of it, even it's something as simple as `log1p`... but that's just a safeguard towards cluttering the object... I agree that it would be more convenient to have some of this in `AnnData`. I guess numpy went a similar way: not all of numpy's functions are available as `np.ndarray`'s class methods. > In such a library it's easy to switch between an in-place or copying workflow, to inspect intermediate output if desired. Interesting! I never thought of this. > This behavior is what numpy.log1p itself is doing here, for that matter–with an out argument it still returns the array. Yes! I think that's a good solution. The `out` argument is very verbose and allows setting a second name for the reference to the modified object, which is returned in addition. I thought about making `inplace` the default for Scanpy's function or not for a long time and finally decided for the unorthodox choice of making it the default - having in mind that AnnData's will become pretty large and at some point backed on disk (which hugely limits the possibilities of how you can write pipelines). Then the `out` rationale doesn't work anymore, as, by default, there simply is no second reference around... Again, thank you for your perspective. And, I'll merge this as soon as having figured out the `chunked` issue. Should be tomorrow or so...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076:670,avail,available,670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076,1,['avail'],['available']
Availability,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2425:197,avail,available,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425,1,['avail'],['available']
Availability,"Thank you for the detailed response @mrocklin!. > It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. I will try to produce a test case and post it there. > Another option would be to see if you can swap out Anndata for Xarray. This has been discussed before (https://github.com/theislab/anndata/issues/32) but the sticking point was sparse support.; Perhaps with some of the techniques being discussed in this issue it might become an option again, with all the benefits you outlined. > I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. Thanks - I've opened issues for these features on the CuPy issue tracker.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310:85,down,down,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310,1,['down'],['down']
Availability,"Thank you for these thoughts!. I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-364055498:756,down,download,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-364055498,1,['down'],['download']
Availability,"Thank you for your thoughts!. 1. `normalize_per_cell` needs to remove zero-expression cells as these can't be normalized, the alternative would be to require it as a preprocessing step; but you're right, wflynny, I'll frame it as a fall-back for `normalize_per_cell` in the next version and output a warning... which will make things backwards compatible...; 2. Any filtering operation on the cells/observations should also affect `.raw`. I'll look into this today. ; 3. Any filtering operation on the variables should **not** affect `.raw`. I didn't know that this gives problems in `rank_genes_groups`? Of course, you don't find everything in `.X` that you find in `.raw.X` and you'll get a key error if you try to; but is there a fundamental problem, @LuckyMD?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-407038976:697,error,error,697,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-407038976,1,['error'],['error']
Availability,"Thank you so much for the feedback!; I'll definitely talk to the admin, but I am not sure he would update. Considering conda, I've tried using ; conda create -n scanpy python=3.6 scanpy; conda activate scanpy. It creates the environment, but then apparently I need to run a jupyter notebook from the terminal for the environment to be activated. When trying to do it, I am getting a ""Jupyter Notebook requires JavaScript"" error, and I can't figure out how to solve it while connecting through ssh, because running ""jupyter notebook --no-browser"" generates a token I can use only on the local machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341:422,error,error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341,1,['error'],['error']
Availability,"Thank you so much for the reply.; Error posted above is happening in two independent datasets possibly due to confounding factors as you mentioned. Though I don't quite comprehend what is a confounding factor in my specific case. . Here is the output of the batches and covariates as requested. ```python; pd.crosstab(adata.obs[""384plate""], adata.obs[""age_group""]); ```. ```pytb; age_group Old YoungAdult Pediatric Fetal NewBorn; 384plate ; 27YOMP1 0 368 0 0 0; 27YOMP2 0 383 0 0 0; 27YOMP3 0 184 0 0 0; BM01152P1 0 384 0 0 0; BM01152P2 0 384 0 0 0; BM01158P1 0 0 382 0 0; BM01158P2 0 0 384 0 0; BM8182P1 0 55 0 0 0; FBFLP5L2 0 0 0 382 0; FBML1 0 0 0 378 0; FBML2 0 0 0 322 0; FBP5L1 0 0 0 377 0; FLP5L1 0 0 0 381 0; FLP5L3 0 0 0 338 0; FLP6L1 0 0 0 376 0; FLP6L2 0 0 0 383 0; FLP6L3 0 0 0 53 0; UCB250P1 0 0 0 0 382; UCB250P2 0 0 0 0 384; UCB250P3 0 0 0 0 150; UCB259P1 0 0 0 0 373; UCB259P2 0 0 0 0 376; UCB270P1 0 0 0 0 382; UCB270P2 0 0 0 0 128; UCBBMP4 0 41 272 0 63; UCBBMP5 0 0 0 0 325; hHSCP1B1 379 0 0 0 0; hHSCP1B2 359 0 0 0 0; hHSCP1B3 377 0 0 0 0; hHSCP2B1 376 0 0 0 0; hHSCP2B2 350 0 0 0 0; hHSCP3B1 371 0 0 0 0; hHSCP3B2 340 0 0 0 0; hHSCP4B1 290 0 0 0 0; ```. ```python; pd.crosstab(adata.obs[""384plate""], adata.obs[""sex""]); ```. ```pytb; sex F M U; 384plate ; 27YOMP1 0 368 0; 27YOMP2 0 383 0; 27YOMP3 0 184 0; BM01152P1 0 384 0; BM01152P2 0 384 0; BM01158P1 0 382 0; BM01158P2 0 384 0; BM8182P1 0 55 0; FBFLP5L2 0 55 327; FBML1 0 0 378; FBML2 0 0 322; FBP5L1 0 0 377; FLP5L1 0 0 381; FLP5L3 0 338 0; FLP6L1 0 376 0; FLP6L2 0 71 312; FLP6L3 0 0 53; UCB250P1 0 382 0; UCB250P2 0 384 0; UCB250P3 0 150 0; UCB259P1 0 373 0; UCB259P2 0 376 0; UCB270P1 0 382 0; UCB270P2 0 128 0; UCBBMP4 0 376 0; UCBBMP5 0 325 0; hHSCP1B1 0 379 0; hHSCP1B2 173 186 0; hHSCP1B3 216 161 0; hHSCP2B1 0 376 0; hHSCP2B2 350 0 0; hHSCP3B1 0 371 0; hHSCP3B2 158 182 0; hHSCP4B1 0 290 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766498505:34,Error,Error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766498505,1,['Error'],['Error']
Availability,"Thank you so much for your explanation, I've tried your code, it's not working yet, I think I should go through my previous code, I'm sure something is wrong. But I understand what you said, I'll try to figure out the errors. ; Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-584256959:218,error,errors,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-584256959,1,['error'],['errors']
Availability,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044414191:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044414191,1,['error'],['error']
Availability,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885,2,['error'],['error']
Availability,Thank you! IDK how I missed that it’s used further down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/789#issuecomment-522966587:51,down,down,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/789#issuecomment-522966587,1,['down'],['down']
Availability,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md; ```python; sc.tl.something(adata); ```. ```pytb; XError Traceback (most recent call last); ....; XError: some message.; ```; ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833#issuecomment-531482480:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833#issuecomment-531482480,1,['error'],['error']
Availability,"Thank you! I’d prefer a nicer, more explicit error that describes the problem. You could use sth like:. ```py; if not is_categorical_dtype(adata.obs[groupby].dtype):; raise ValueError(; f""The column `adata.obs[groupby]` needs to be categorical, ""; f""but the {groupby!r} column is of dtype {adata.obs[groupby].dtype}.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1029#issuecomment-584665061:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029#issuecomment-584665061,1,['error'],['error']
Availability,"Thank you! So you say it doesn’t work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382,1,['error'],['error']
Availability,"Thank you~ Firstly, it's an AssertionError in sc.pp.normalize_per_cell step ; secondly , toy example csv data is presented as below:. ```; Group,Group1,Group1,Group3,Group6,Group5; Gene1,11,0,0,14,0; Gene2,12,17,9,34,11; Gene3,0,0,0,0,2; ```. so, u can test this error locally by:. ```python; df = pd.read_csv('data/dropout/dropout1/counts.csv', index_col=0); genes = df.index.values; barcodes = df.columns; adata = sc.AnnData(np.transpose(df.values), var=pd.DataFrame(genes), obs=pd.DataFrame(barcodes)); adata.var_names_make_unique(); sc.pp.filter_genes(adata, min_cells=1); adata.raw = adata; sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); ```; lastly, the version is 1.4.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001:263,error,error,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001,1,['error'],['error']
Availability,"Thanks @flying-sheep for the thorough feedback! I made the changes. There is still a Travis CI error about slow_to_import modules. Since trimap is now in external, I am now sure how this test is being affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094,1,['error'],['error']
Availability,"Thanks @giovp for your quick reply! I upgraded pandas and ran your code with the pbmc dataset. This ran fine. On my own dataset it is still giving the same error. So maybe something is wrong with the way I created adata. Because my code ran fine before upgrading scanpy and I found this issue: https://github.com/theislab/single-cell-tutorial/issues/28#issue-576248363 I thought it might be a real bug. ; After running your example I will just look into how I created adata to see if I can find the error. ; This is what it looks like now: ; ```; AnnData object with n_obs × n_vars = 2773 × 3783 ; obs: 'n_genes', 'plate', 'platebatch', 'stage', 'well_no', 'ERCC_genes', 'n_total_counts', 'percent_mito', 'n_counts', 'percent_ribo', 'percent_protein_coding', 'percent_lincRNA', 'sum_lincRNA', 'percent_antisense', 'sum_antisense', 'percent_miRNA', 'sum_miRNA', 'percent_bidirectional_promoter_lncRNA', 'sum_bidirectional_promoter_lncRNA', 'percent_snoRNA', 'n_counts_norm', 'Chat_norm_expr', 'cellnr', 'louvain', 'velocity_self_transition', 'lineages', 'root_cells', 'end_points', 'velocity_pseudotime'; var: 'ENS_names', 'geneid', 'feature', 'chr', 'fullname', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'velocity_gamma', 'velocity_r2', 'velocity_genes'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'plate_colors', 'stage_colors', 'umap', 'velocity_graph', 'velocity_graph_neg', 'velocity_settings', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'velocity_tsne', 'velocity_umap'; varm: 'PCs'; layers: 'Ms', 'Mu', 'spliced', 'unspliced', 'variance_velocity', 'velocity'; ```. The adata.X of the pbmc data is `scipy.sparse.csr.csr_matrix`; My adata.X is `numpy.ndarray`. This probably results in the problem of the difference in dimensions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-601076097:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-601076097,2,['error'],['error']
Availability,"Thanks @ivirshup ! In addition to changing the documentation, it would probably make sense to throw an error if these two arguments are passed together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372,1,['error'],['error']
Availability,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726165481:113,avail,available,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726165481,1,['avail'],['available']
Availability,"Thanks Alex! That's great, thanks also for adding me to the authors list. I haven't seen that patsy error on my Ubuntu machine either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-451888324:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451888324,1,['error'],['error']
Availability,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm; adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: ; #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:; sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976:845,error,error,845,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976,1,['error'],['error']
Availability,"Thanks a lot. ---Original---; From: ""James ***@***.***&gt;; Date: Thu, Sep 29, 2022 00:06 AM; To: ***@***.***&gt;;; Cc: ""Sijian ***@***.******@***.***&gt;;; Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). ; I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964:290,Down,Downgrading,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964,1,['Down'],['Downgrading']
Availability,"Thanks both, just to clarify, I am using the `min_in_group_fraction` and `max_out_group_fraction` args for `sc.tl.rank_genes_groups_filtered()`, which are not available as custom cutoff args for `sc.queries.enrich()` (otherwise I agree entirely)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1043#issuecomment-586153305:159,avail,available,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043#issuecomment-586153305,1,['avail'],['available']
Availability,Thanks but the error persists even after using `adata.obs_names_make_unique()`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212,1,['error'],['error']
Availability,"Thanks everyone! I wonder how this affects one-pipeline-for-everything; portals, like the EBI single cell expression atlas... and standarized; pipelines like cellranger. On Mon, Jul 1, 2019 at 3:29 PM MalteDLuecken <notifications@github.com>; wrote:. > Based on my experience setting a single cutoff for all datasets will not; > work, as I've used a lot of different cutoffs depending on the; > distributions. I would echo @ivirshup <https://github.com/ivirshup>'s; > suggestion of looking at distributions. Joint distributions being a lot; > more important than individual histograms. There's a small discussion about; > it in our best practices paper; > <https://www.embopress.org/lookup/doi/10.15252/msb.20188746>; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/718?email_source=notifications&email_token=AACL4TMTNHMCCFM7MGMIZ73P5IBDPA5CNFSM4H4DUZEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY6D6LQ#issuecomment-507264814>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACL4TKKTTZ4IHBJJDFAPKLP5IBDPANCNFSM4H4DUZEA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/718#issuecomment-507267593:418,echo,echo,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718#issuecomment-507267593,1,['echo'],['echo']
Availability,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right?. It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:; ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png); and after:; ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:; https://docs.python.org/3/library/exceptions.html#exception-hierarchy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507#issuecomment-733582404:507,error,errors,507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507#issuecomment-733582404,1,['error'],['errors']
Availability,"Thanks for all the work in developing this package, it's truly fantastic. . I ran into what seems like a bug in the new plotting function sc.pl.rank_genes_groups_stacked_violin. It seems that when the ranked genes between 2 groups are similar (e.g. 'Tnf' is a highly ranked gene between two groups), then 'Tnf' is only plotted once on the first group, and any following groups with the same gene are truncated. You can see this in the toy example image I attached - when comparing groups M1 and M1+M2, 'Tnf' should be plotted for each group, but it is only plotted on group M1, therefore truncating group M2. When I plot the same data using rank_genes_groups_dotplot, this error doesn't happen and 'Tnf' is correctly plotted twice. I know this is a small bug that most people will probably not run across, but just in case you're comparing expression across similar groups this might be a useful fix. Thanks!. ![stacked_violin_global](https://user-images.githubusercontent.com/37122760/44924265-bd353000-ad18-11e8-84d0-a0136083dbdd.png). ![dotplot_global](https://user-images.githubusercontent.com/37122760/44924244-aa226000-ad18-11e8-9351-4b28d11a7ee5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252:673,error,error,673,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252,1,['error'],['error']
Availability,"Thanks for getting back to me. I fixed the formatting errors and moved trimap to scanpy external. ; trimap is no longer imported by default, so the overall import time is unaffected. ; I also added an example to the docstring. Please let me know if further fixes are required.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-541174606:54,error,errors,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-541174606,1,['error'],['errors']
Availability,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:196,down,download,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615,1,['down'],['download']
Availability,"Thanks for letting me know!. If it's working in the newest version, there's not much for us to fix. Please let us know if you run into the error on the latest release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963465126:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963465126,1,['error'],['error']
Availability,"Thanks for opening a new issue for this, and the info. Could you let me know a bit more about how you've installed scanpy? E.g. what OS, did you use conda or pip, etc. My guess would be that this is numba related (which, from reporting the cpu flags, I'm guessing you suspect too). Are you able to import `numba`? If so, what about `pynndescent` and `umap`? I'm trying to figure out if some code in scanpy is triggering the error, or if it's one of our dependencies. ---------------. Initially mentioned in https://github.com/theislab/scanpy/issues/1823#issuecomment-983551937",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2062#issuecomment-983814860:424,error,error,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062#issuecomment-983814860,1,['error'],['error']
Availability,"Thanks for opening an issue!. Many of the function in scanpy do not support being applied on a backed anndata. `highly_variable_genes` hasn't had support for out of core computation implemented, so it errors. Better out of core support is something we're working for. Is it possible to load `X` into memory here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583:201,error,errors,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583,1,['error'],['errors']
Availability,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209,2,"['Down', 'error']","['Downloads', 'error']"
Availability,"Thanks for pointing out the error in the documentation. This only affects the scatter plots. I observed that most people I interact with prefer the scatter plots without the frames. But we can change this back if it worries you. No problem. You have become the plotting expert for Scanpy, I'd say; so your opinion obviously counts a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/229#issuecomment-411656016:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/229#issuecomment-411656016,1,['error'],['error']
Availability,"Thanks for reporting @dawe and thanks for updating @WeilerP .; I ran into the same problem with the pip version.; When using **python 3.9** in a fresh virtual enviroment, there's an error related to llvmlite:; <details>; <summary>; error message; </summary>. ```; Building wheel for llvmlite (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: /home/mischko/test/python_virtual/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""'; __file__='""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-rb92hbao; cwd: /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,5,"['ERROR', 'error']","['ERROR', 'error', 'errored']"
Availability,"Thanks for the H/T @ivirshup ! I was able to find the library ids and I also added the metadata as suggested. This should do for now. I have also changed the plotting function to make it work with the new `uns` structure. The idea for uns concatenation is exactly that one yes. Basically, if the keys are unique, then concatenate, if they are the same, override and throw a warning. With respect to mixed anndata objects (e.g. one visium adata concatenated with one scRNA-seq), I will just concatenate the obsm and add empty entries to the one missing (like zeros) or something along the lines of masked arrays (although I don't think it's particularly useful in this case).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-599627259:597,mask,masked,597,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-599627259,1,['mask'],['masked']
Availability,"Thanks for the PR. . One concern that I have is that similar solutions do not exists for other plotting functions. For coherence, ideally the `annot_col` argument should be available for other cases. Thus, I think that a better and more generic approach would be to simply modify your genes names in the `AnnData` object and let all plotting functions use those names. For this, you simply do:. ```PYTHON; adata.var = adata.var.reset_index().set_index(annot_col); # adata.var_names is automatically updated; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441017256:173,avail,available,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441017256,1,['avail'],['available']
Availability,"Thanks for the bug report! I think we've just fixed the first and third issue in #729, but I'm not to sure about the second. Could you try updating to the newest release of AnnData and letting us know if the error still occurs?. Would you mind also letting us know if this error occurs when you use one of the built in datasets, like `sc.datasets.pbmc3k()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731#issuecomment-509464033:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731#issuecomment-509464033,2,['error'],['error']
Availability,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845:99,mainten,maintenance,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845,1,['mainten'],['maintenance']
Availability,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906,2,['error'],['error']
Availability,"Thanks for the explanation. But what do you mean by ""discrete"" here?. And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I guess that's just local optima that are found. It feels strange to generally say that ICA is better as higher dimensions still separate out clusters, while at lower dimensions there is redundant information compared to PCA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063:338,redundant,redundant,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063,1,['redundant'],['redundant']
Availability,"Thanks for the explanations @ivirshup! This makes quite a bit more sense to me now (the block sparse matrix stuff). If I understand the `.raw` removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with `.layers`? I assume that e.g., MT or ribo genes are mainly removed for cellular representation analysis. Some people will also want to remove them from DE analysis to have a set of results that are easy to interpret and have less multiple testing burden. It seems to me that adding masking like this would be quite a large endeavour, no?. > What if a highly variable gene in one dataset just isn't present in another? Is it because it wasn't found in that dataset at all, or because it was only present in a few cells? If it was only present in a few cells, how can I be sure a particular cell type wasn't just poorly represented in that dataset?. I don't see this as such a big issue. If you assume anything filtered out was removed because it was predominantly 0, then it would not have been included in the HVG set of that dataset anyway. So you can assume it would not be in the HVG intersection for that dataset and if you add it, then a 0 for each cell would probably not be that problematic. And whether this was due to a particular cell type being poorly represented can be answered by the gene set that you do have for these cells. Typically there is sufficient gene-gene covariance that you still keep this signal somehow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661:201,mask,masks,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661,2,['mask'],"['masking', 'masks']"
Availability,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-540457004:169,down,downstream,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-540457004,1,['down'],['downstream']
Availability,"Thanks for the fix!. For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526476496:128,error,error,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526476496,1,['error'],['error']
Availability,"Thanks for the help. I have traced the randomness to sc.tl.score_genes_cell_cycle. Even if I explicitly state the random state to be 0, two repeats of score_genes_cell_cycle from the same data would give different downstream clustering. On the other hand, if I use one score_genes_cell_cycle output and repeat the downstream clustering methods, the clusters are the same. ; I am currently using scanpy==1.3.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-432462799:214,down,downstream,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-432462799,2,['down'],['downstream']
Availability,"Thanks for the long response @ivirshup!. For 1. I think a ufunc should always act on adata.X and I want it to return the adata object with the sqrt applied to adata.X. Adding support for the sklearn operators would be great. For the second part, my intention is for the result to be `adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X`, and it's fine with me in the varnames are lost so long as the obsnames are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:495,error,error,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,1,['error'],['error']
Availability,Thanks for the nice report submission. The code error is caused by the categories being integers when the code expect an 'str'. This is an easy fix. . The mapping of labels to color being different when colors are not in `adata.uns` is because the mapping is not saved (Fig 2 and 3). It is also an easy fix but requires the modification of `adata.uns` to save the colors. This is already done in `sc.pl.embedding` so should be OK to do but I would like to know @ivirshup opinion. For Fig 1. when there are more cells the problem is not there or maybe is simply not visible But I have some idea on how to address it. For Fig 6 I really don't know.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-762778317:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-762778317,1,['error'],['error']
Availability,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257,1,['error'],['error']
Availability,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468005012:78,error,error,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468005012,1,['error'],['error']
Availability,"Thanks for the report!. `scanpy.read_10x_h5` is expecting the files for the count matrices, not the UMI info. So it's throwing a non-sensical error. `read_10x_h5` is expecting files like `filtered_feature_bc_matrix.h5` or `raw_feature_bc_matrix_h5.h5`. For example:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_feature_bc_matrix.h5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162,1,['error'],['error']
Availability,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,4,"['ERROR', 'Error', 'error']","['ERROR', 'Errors', 'error']"
Availability,"Thanks for the report. I'm having trouble reproducing this behaviour locally. Two thoughts:. 1. It looks like there's a newer version of leidenalg available, could you upgrade that?; 2. Maybe there is something about the neighborhood graph. Could you either: reproduce this with some dummy data (e.g. `sc.datasets.blobs`) or share the `test` object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178,1,['avail'],['available']
Availability,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/4#issuecomment-278581479:461,error,errors,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4#issuecomment-278581479,2,['error'],"['error', 'errors']"
Availability,"Thanks for the suggestion. Actually, I am using cellxgene which takes the; h5ad file as an input. when using anndata.write() function, it only output; the anndata.X as the expression matrix. And also there is no option of; useRaw here.; Also, I tried to re-assign anndata.X = anndata.raw.X, but it returns an; error saying its wrong shape.; Do you have any suggestions?. Thanks a lot!. On Mon, Jun 3, 2019 at 6:03 AM Maximilian Haeussler <; notifications@github.com> wrote:. > The scanpyToCellbrowser function has an option useRaw that will use the; > .raw matrix, if present, for the .tsv export.; >; > Otherwise, the raw matrix of all genes is stored as ad.raw.X and the; > variable names are in ad.raw.var. You can use scanpyToCellbrowser to write; > the matrix and all annotations, or anndataToTsv to write just the matrix.; > Or use code from there to write your own.; >; > On Fri, May 31, 2019 at 5:14 PM Jing He <notifications@github.com> wrote:; >; > > Hi, the expression matrix I exported from adata.write only have the top; > > variable genes. Is there a way to output the raw matrix including all; > genes?; > >; > > —; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub; > > <; > https://github.com/theislab/scanpy/issues/262?email_source=notifications&email_token=AACL4TNOFS6MLIH44P6J5HDPYE6ENA5CNFSM4FU553M2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVQBGI#issuecomment-497746073; > >,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AACL4TORHPOQ2GTWTUGTAI3PYE6ENANCNFSM4FU553MQ; > >; > > .; > >; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/262?email_source=notifications&email_token=AAUAIIIOXG5HSDCKTFYS7KLPYTT6BA5CNFSM4FU553M2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWY5RAA#issuecomment-498194560>,; > or mute the thread; > <https://github.com/n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-499091368:310,error,error,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-499091368,1,['error'],['error']
Availability,"Thanks for this contribution! Can you look at the travis errors? See https://github.com/theislab/scanpy/pull/797#issuecomment-536861482 for background. To fix formatting errors you can use https://github.com/psf/black. Furthermore, can you add a small example to the docstring? (see for example: https://github.com/theislab/scanpy/blob/master/scanpy/external/tl/_palantir.py)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-540005836:57,error,errors,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-540005836,2,['error'],['errors']
Availability,"Thanks for your comments, I understand the struggle of implementing CI for GPU code!. @Zethson here are my answers to your questions:; 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice.; 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. ; `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-816665412:170,avail,available,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-816665412,1,['avail'],['available']
Availability,"Thanks for your great package, it is really powerful, but I am encountered with some mistakes in installing.; My platform is Linux login-0-1.local 2.6.32-504.16.2.el6.x86_64 #1 SMP Wed Apr 22 06:48:29 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux, and Python 2.7.10。; I also try to install in win10 , neither Python 2.7.10 or Python 3.6 makes errors again. firstly, it says versioneer.py has errors, so I reinstall the package,; but when I try to install scanpy again, errors comes out again. Following picture clearly show my errors.; Thanks a lot, if you have time to see my question. ![image](https://user-images.githubusercontent.com/25199946/46243375-34d4a880-c406-11e8-9bb5-4392664fb3cc.png). ![image](https://user-images.githubusercontent.com/25199946/46243461-13c08780-c407-11e8-96c9-bfbb0d863b2f.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/276:337,error,errors,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/276,4,['error'],['errors']
Availability,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036:94,failure,failure,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036,1,['failure'],['failure']
Availability,Thanks for your interest! It would be cool if `Marsilea` could be part of `Scanpy`. . The `Marsilea` is shipped with a wide range of plot options which already include the [dot plot](https://marsilea.readthedocs.io/en/latest/tutorial/heatmap.html#matrix-heatmap-with-sized-elements) (We call it Sized Heatmap). Here is a [list](https://marsilea.readthedocs.io/en/latest/api/plots.html) of all available plot options for your reference. . Any further suggestions or requests to expand the plot options are welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226:393,avail,available,393,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226,1,['avail'],['available']
Availability,"Thanks for your reply! (And no worries - mine is even later). . I see your point about ecosystem vs. external. My main qualm about ecosystem (at least in its current form) is that it's just links to external projects that happen to use scanpy, and the burden of downloading these projects, learning their unique syntax, and seeing how they apply to the scanpy project at hand is off-loaded to the user. The main reason I have pushed for inclusion in external is the convenience of being able to call the function with a single scanpy command, in a format the user is already very familiar with. On the other hand, I do see your point about code maintenance and syncing between my project and scanpy. Changes in my shannonca project might necessitate changes in the wrapper function. That said, since my wrapper is very agnostic to the underlying methods used, I would hope this wouldn't have to happen very often (basically, it just controls where the inputs are found and where the outputs are deposited. This wouldn't change unless scanpy's architecture did). However, as currently written, the documentation may have to change more frequently since it refers to specific function arguments used in my package. For now, I am willing to open a new pull request into ecosystem (if that is the correct workflow) and you can feel free to close this issue. For future releases, if you want to combine the convenience of external with the low maintenance burden of ecosystem, you might consider allowing external modules to ""outsource"" their documentation. So in scanpy's documentation, a function F under external would simply have the format sc.external.tl.F(adata, **kwargs), where **kwargs is passed directly to a method maintained by the tool developer, with a link to a docstring in the external repository. I would happily make this for shannonca as a proof of concept, if you think it's worth trying.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780#issuecomment-911791808:262,down,downloading,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780#issuecomment-911791808,3,"['down', 'mainten']","['downloading', 'maintenance']"
Availability,"Thanks for your reply, @falexwolf. I was looking through the same error and I can't really understand why the results are different - it might be a difference in accuracy levels between the manual wilcoxon method that was used before, and the built-in scipy.stats function I used. I looked at the differences and they indeed look marginal. **Edit:** I actually just went back through the check results, and the comparison between the results before and after are pretty much identical - it could just be a difference in bit-depth. For example, it's tagging (2.292195 , 5.7448500e-01) as different from (2.292195 , 0.574485). . I also compared a before-after with my dataset and I get very similar marker genes, albeit in slightly different order (see attached images). I don't really know what would be the best way to address these differences - I am simply using the built in spicy.stats function and not changing the output it gives me. Could this marginal difference be caused by the estimation in the ""chunk"" approach used in the previous version? Even with this marginal difference, I would assume that using the scipy function is more ""accurate"". Please let me know what you would prefer and what would be the best way to proceed.; ![figure_1_newwilcox](https://user-images.githubusercontent.com/37122760/46375973-c93b4700-c662-11e8-8581-b85a28e36dbc.png); ![figure_1_originalwilcox](https://user-images.githubusercontent.com/37122760/46375974-c93b4700-c662-11e8-810b-48238394be1e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-426424354:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-426424354,1,['error'],['error']
Availability,"Thanks for your response. As of today that's correct: AWS, GCP and DO. Azure support is a work in progress at the moment. It should be available by the end of this month most likely. Do you have a hard deadline on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-881369655:135,avail,available,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-881369655,1,['avail'],['available']
Availability,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:819,down,downstream,819,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,1,['down'],['downstream']
Availability,"Thanks on that method @ivirshup - our version was written before I was maintainer, and maybe that function wasn't available. . Happy to adopt whatever general approach you recommend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886548222:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886548222,1,['avail'],['available']
Availability,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730:201,robust,robust,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730,1,['robust'],['robust']
Availability,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. ; Cheers, ; Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363800572:222,error,errors,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363800572,1,['error'],['errors']
Availability,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:; > `sc.pp.neighbors_tsne(adata)`; > `sc.tl.tsne(adata)`; > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right?. I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,; ```; sc.pp.neighbors_tsne(adata); sc.tl.tsne(adata); ```. would also be fine with me. I think it's important that the following works:. ```; sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759329085:1290,down,downstream,1290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759329085,1,['down'],['downstream']
Availability,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:126,checkpoint,checkpoint,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698,4,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Thanks- that doesn't seem to be as easy as I was thinking.. ; 1. I think for most applications that I have in mind I would be interested in the relative differences. Are cells distributed differently in two conditions, regardless of whether there are more cells overall in one of the conditions?; 2. My bad, I thought the were already calculated over a grid layout.. would that also require to down sample the larger cell population to match the smaller one?; 3. That would be very cool, but having this for qualitative assessment would be already useful. Ok, thanks - will do if I come up with a satisfying solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-478274180:394,down,down,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478274180,1,['down'],['down']
Availability,Thanks. Can you share the code that produces the error? Maybe also the image as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1405#issuecomment-686782513:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1405#issuecomment-686782513,1,['error'],['error']
Availability,"Thanks. I tried this as well. The problem that I had was that going back to a Boolean for subsetting was not easy:; ```python; adata.obs['boolean'] = adata.obs['boolean'].astype(str).astype('category'); adata[adata.obs['boolean'].astype(bool)]; ```; This throws a key error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-26-3fef793fe5bd> in <module>; ----> 1 adata[adata.obs['boolean'].astype(bool)]. /opt/conda/lib/python3.7/site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /opt/conda/lib/python3.7/site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /opt/conda/lib/python3.7/site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 32 index = index[0].values, index[1]; 33 ax0, ax1 = unpack_index(index); ---> 34 ax0 = _normalize_index(ax0, names0); 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1. /opt/conda/lib/python3.7/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 99 not_found = indexer[positions < 0]; 100 raise KeyError(; --> 101 f""Values {list(not_found)}, from {list(indexer)}, ""; 102 ""are not valid obs/ var names or indices.""; 103 ). KeyError: 'Values [True, True, True, (.... I shorten this part....) True, True, True, True, True, True, True, True, True, True, True, True, True, True], are not valid obs/ var names or indices.'; ```; while this works:; ```python; adata[adata.obs['boolean'].astype(bool) == True]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-778331854:268,error,error,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-778331854,1,['error'],['error']
Availability,"Thanks. The dataset is here:. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE194122. Sicne it is from GSE, I think it is easy to download and it is formed into h5ad format (the multiome part).; GSE194122_openproblems_neurips2021_multiome_BMMC_processed.h5ad.gz. Code:. ```; adata_atac.X = (adata_atac.X > 0)*1; sc.pp.highly_variable_genes(adata_atac, n_top_genes=13634); adata_atac = adata_atac[:,adata_atac.var['highly_variable']]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906521560:136,down,download,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906521560,1,['down'],['download']
Availability,"That error is not specific to scanpy. It would be good to know which; library is causing the problem such that it can be updated but most likely; is either numpy, scipy, matplotlib or sklearn. Maybe try to update those; packages and see if the error goes away or try to google the error to find; some solution. On Fri, Oct 5, 2018 at 2:59 PM Dilawar Singh <notifications@github.com>; wrote:. > Same issue here. Using pip +pyhton3.7 and not conda to install from pypi.; > Is there a way to resolve it without installing using conda?; >; > Logs:; >; > [dilawars@chamcham scanpy_exp]$ python planaria.py; > /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; > import imp; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > ... storing 'clusters' as categorical; > computing tSNE; > using data matrix X directly; > using the 'MulticoreTSNE' package by Ulyanov (2017); > finished (0:02:53.98); > saving figure to file ./figures/tsne_full.pdf; > computing neighbors; > using data matrix X directly; > Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280#issuecomment-427357518>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1WzuXR5Mhpb3jNte9UkVDqzQjb1pks5uh1eZgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171,3,['error'],['error']
Availability,"That is a wonderful solution! I will give it a shot shortly. Thank you so much for your help!. Here's some example code of how Seurat handles cluster scoring and merging with random forests and OOBE:. ```; pbmc <- ValidateClusters(pbmc, pc.use = 1:30, top.genes = 30). pbmc <- BuildClusterTree(pbmc, ; do.reorder = T, ; reorder.numeric = T). node.scores <- AssessNodes(pbmc). node.scores[order(node.scores$oobe,decreasing = T),] -> node.scores. nodes.merge <- node.scores[which(node.scores[,2] > 0.1),]; nodes.to.merge <- sort(nodes.merge$node) ; pbmc.merged <- pbmc. for (n in nodes.to.merge); {; pbmc.merged <- MergeNode(pbmc.merged, n); }. ```. Here's an explanation, as this code was derived from this recent (and awesome) publication:; ; From page 6 of the Supplementary Methods of Plass et al 2018: http://science.sciencemag.org/content/early/2018/04/18/science.aaq1723. To prevent obtaining spurious clusters result of overclustering, the robustness of the clusters was calculated using the function AssessNodes from Seurat. For each cluster, the average expression of all variable genes (4910) is computed and a phylogenetic tree based on the distance matrix in gene expression space is computed. Next, it computes an Out of Bag Error for a random forest classifier trained on each internal node split of the tree. We recursively build a tree and assessed all its nodes, merging all clusters with an out of bag error bigger than 0.1 until no such nodes were found.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410:946,robust,robustness,946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410,3,"['Error', 'error', 'robust']","['Error', 'error', 'robustness']"
Availability,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747:291,error,error,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747,1,['error'],['error']
Availability,"That looks great Isaac, thanks a lot!. > * Restructure how elements are added to `uns`, as mentioned in [theislab/anndata#295 (comment)](https://github.com/theislab/anndata/issues/295#issuecomment-596164456). . agree, I also think that it could be best in the case of different data types (not visium). It's also best if the tree structure does not change in case of concatenation. > * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. . what about `X_coords` ?. > * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name. . This was also in the plans but further down the line (support for multiple slices should be first). I could have a look at this soon. What about re-open the `theislab/spatial` branch and merge this PR there? I could then work on how to handle the new `uns` structure in the plotting functions and have a definitive version of multiple slices support in anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596448147:770,down,down,770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596448147,1,['down'],['down']
Availability,"That problem occurs within h5py (we just wrap the underlying OSError) and isn’t a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb; OSError: Can't read data (file read failed:; time = Sat Aug 1 13:27:54 2020,; filename = '/path.../filtered_gene_bc_matrices.h5ad',; file descriptor = 47,; errno = 5,; error message = 'Input/output error',; buf = 0x55ec782e9031,; total read size = 7011,; bytes this sub-read = 7011,; bytes actually read = 18446744073709551615,; offset = 0); ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because that’d explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too!. I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that there’s 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559; - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196:336,error,error,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196,3,['error'],"['error', 'errors-accessing-']"
Availability,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-362374369:54,avail,available,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-362374369,1,['avail'],['available']
Availability,"That's a good point! I just added the Benjamini-Hochberg correction to the Wilcoxon code (as well as to the t-tests) and left that as the default. I left the Bonferroni code in there and marked the place with comments. If and when the pull request is complete, they can choose what to keep and remove the extra comments. Either way, since the uncorrected p-values are also outputted, the user can choose whichever correction they want downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103:435,down,downstream,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103,1,['down'],['downstream']
Availability,"That's a good point, and it is not:; ```python; reducer = umap.UMAP(min_dist=0.5); embedding = reducer.fit_transform(adata.obsm[""X_scVI""]); adata.obsm[""X_umap""] = embedding; ```; again produces stable results on only 3/4 CPUs. . Ok, let's forget about UMAP. It's only a nice figure to get an overview of the data and I don't use it for downstream stuff. Irreproducible clustering, on the other hand, is quite a deal-breaker, as for instance cell-type annotations depend on it. I mean, why would I even bother releasing the source code of an analysis alongside the paper if it is not reproducible anyway? . I found out a few more things: ; - the leiden algorithm itself seems deterministic on all 4 nodes, when started from a pre-computed `adata.obsp[""connectivities""]`. ; - when running `pp.neighbors` with `NUMBA_DISABLE_JIT=1`, the clustering is stable on all four nodes (but terribly slow, ofc); - when rounding the connectivities to 3-4 digits, the clustering is also stable (plus the total runtime is reduced from 2:30 to 1:50min). ```python; adata.obsp[""connectivities""] = np.round(adata.obsp[""connectivities""], decimals=3); adata.obsp[""distances""] = np.round(adata.obsp[""distances""], decimals=3); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946539365:336,down,downstream,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-946539365,1,['down'],['downstream']
Availability,That's an HTTP error. You need to report this to the data hoster aka EBI,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834,1,['error'],['error']
Availability,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526890943:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526890943,1,['error'],['error']
Availability,"That's not a bug, that's a feature ;). You can only compute as many PCs as the minimum number of dimensions in n_samples and n_features. Do you feel as though the error message is unclear on this? I feel as though changing the default to match the setting can be dangerous as may not recall how many PCs were used then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586474464:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586474464,1,['error'],['error']
Availability,"That's odd. sklearn calculates the explained variance and variance ratio as follows:; ```python; # Calculate explained variance & explained variance ratio; X_transformed = U * Sigma; self.explained_variance_ = exp_var = np.var(X_transformed, axis=0); if sp.issparse(X):; _, full_var = mean_variance_axis(X, axis=0); full_var = full_var.sum(); else:; full_var = np.var(X, axis=0).sum(); self.explained_variance_ratio_ = exp_var / full_var; ```. I do it in the same way:; ```python; X_pca = (u * s)[:, idx] # sort PCs in decreasing order; ev = X_pca.var(0). total_var = _get_mean_var(X)[1].sum(); ev_ratio = ev / total_var; ```; I'll investigate... EDIT: Strange, your assertion error is not reproducible on my end. The code runs fine for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930:677,error,error,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930,1,['error'],['error']
Availability,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>; wrote:. > I have a dataset for which I have an observation that is only available; > for some cells. When I make a scatter plot that I color code for this; > observation not all cells are plotted:; >; > import randomimport scanpy as sc; >; > adata = sc.datasets.blobs(); > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]; >; > sc.tl.pca(adata); > sc.pl.pca(adata, color='property', size=50); >; > While this should plot 10 cells it only shows one cell:; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>; > I can get the plot I want by filtering cells first:; >; > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50); >; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>; > Would you agree that scanpy should plot all cells that have a valid; > observation?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/536>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536#issuecomment-474007740:185,avail,available,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474007740,1,['avail'],['available']
Availability,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:13,redundant,redundant,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242,1,['redundant'],['redundant']
Availability,"That’s weird, but that might be another issue, please check out #1378. /edit: seems to be a conda bug that only occurs on windows due to flit ([legally](https://www.python.org/dev/peps/pep-0376/#record)) writing windows newlines into the RECORD file, and conda reading them as two newlines each and then crashing. ---. This PR adds instructions on how to integrate with conda, which I screenshotted. It fails for me with this error:. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound: ; - loompy[version='>=3.0.5']; ```. But since loompy 3.x isn’t on conda-forge, that’s correct. Seems that resolving anndata’s dependencies on conda is currently not possible and you need to wait until loompy gets upgraded on conda-forge. Or until Quansight-Labs/beni#3 is resolved and you can specify that you don’t want all deps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1377#issuecomment-675423209:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377#issuecomment-675423209,1,['error'],['error']
Availability,"The Jaccard metric, taken from umap, I believe, returns for a pair of vectors x and y the Jaccard distance between their sets of nonzeros. ([Code](https://github.com/theislab/scanpy/blob/7975f0774c0737bccfc312be0f2a81a3922c2185/scanpy/neighbors/umap/distances.py#L156).). In the case that you feed the raw or logged gene expression matrix, this is reasonable: it's the fraction of genes with nonzero expression shared by the two cells. If you compute this on PCA vectors, however, which are essentially all nonzero, you are getting some version of the complete graph, downsampled to k in some random way. This would explain why clustering and embedding based on that graph is garbage. While investigating this, we (me and @sidneymbell) came across some behavior that may or may not be the desired default. If you call `tools._utils.choose_representation` with `use_rep=None, n_pcs=None`, then it will return `X_pca` (all columns) because `X_pca[:,:None] = X_pca`, which will be the top 50 PCs if one is running with defaults. I might have expected this to instead return `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207:568,down,downsampled,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207,1,['down'],['downsampled']
Availability,"The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053:577,avail,available,577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053,1,['avail'],['available']
Availability,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-528179543:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-528179543,1,['error'],['error']
Availability,"The PCA test `test_mask_defaults` only passed because of `float32` being to loose in some situation. When the mask randomly was `[True, True, True, True, True]` the test should have failed. Now the test works as intended.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2914:110,mask,mask,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2914,1,['mask'],['mask']
Availability,"The checks shouldn't take any time. But you're right; you're also slicing the `.var` and the `.varm` annotations if you make this call and we could check whether this perceivably slows down things (only for very large data, I guess). If it does, it would be very simple to add an accessor `.slice_X` that enables convenient slicing of the data matrix. That's a bit ugly but would vanish in the plotting function. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480:185,down,down,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480,1,['down'],['down']
Availability,"The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1768:213,down,down,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768,2,"['down', 'error']","['down', 'error']"
Availability,"The current model is stable and has been successfully used in many instances. It will also be available in Scanpy 1.2. In addition, there will be another model. General improvements only regard the ease of use of PAGA and are model-independent anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/96#issuecomment-393972623:94,avail,available,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96#issuecomment-393972623,1,['avail'],['available']
Availability,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py; import scanpy as as; adata = sc.datasets.pbmc3k(); # sc.pp.normalize_total(adata, target_sum=10000); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000); adata.var[""highly_variable""].sum(); ```; ```; 10367; ```; Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)); Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R; library(dplyr); library(Seurat); library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)); ```; ```; 2292; ```; However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888:816,down,downloaded,816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888,1,['down'],['downloaded']
Availability,"The docs for `sc.pl.scatter` say . > The palette can be a valid ListedColormap name ('Set2', 'tab20', …). but setting `palette` to a string throws an error. ```python; adata = sc.datasets.paul15(); sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""); ```. ```pytb; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-698-58a5366a0f70> in <module>; 1 adata = sc.datasets.paul15(); ----> 2 sc.pl.scatter(adata, ""Cma1"", ""Irf8"", color='paul15_clusters', palette=""Set2""). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,"The documentation says:. > percent_top : Container[int], optional (default: (50, 100, 200, 500)); > Which proportions of top genes to cover. If empty or None don’t calculate. However, supplying `percent_top=None` or `percent_top=[]` leads to index-out-of-bounds error, due to `proportions = top_segment_proportions(X, percent_top)` being always executed and `top_segment_proportions()` not handling a None or empty second argument.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421,1,['error'],['error']
Availability,"The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1471:4,down,download,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471,2,['down'],"['download', 'downloaded']"
Availability,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865,1,['error'],['error']
Availability,The error seems to be that [`rdist`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L663) is called from [`umap.umap_.optimize_layout`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L776) with float64 arrays while it can only handle float32 arrays. There seem to have been a few changes in umap [between 0.3.8 and 0.3.9](https://github.com/lmcinnes/umap/compare/0.3.8...0.3.9) maybe you should try 0.3.9.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071,1,['error'],['error']
Availability,"The function of ""sc.pp.filter"" report an error ""index out of range"", why?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2759:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2759,1,['error'],['error']
Availability,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-639309900:193,error,error,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-639309900,2,['error'],['error']
Availability,"The idea of having ""smart subsample"" functionality available in scanpy has been a topic of discussion for a while. I would like to see a benchmark of these methods on single cell data before choosing one to include here. Are you aware of anything in this space?. Update:. It looks like the lab it's from have put out some writing on this: https://dl.acm.org/doi/pdf/10.1145/3388440.3412409",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055:51,avail,available,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055,1,['avail'],['available']
Availability,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:294,error,error,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304,1,['error'],['error']
Availability,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623:91,error,error,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623,4,"['error', 'failure']","['error', 'failure']"
Availability,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:87,down,downgrade,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076,2,"['down', 'error']","['downgrade', 'error']"
Availability,"The main change here is passing `None` instead of `0` to `total`, right?. Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507#issuecomment-733508444:96,error,errors,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507#issuecomment-733508444,1,['error'],['errors']
Availability,The max categorical error was one that I thought was addressed by anndata 0.6.18. I assume this is still on 0.6.22rc1? There was previously a switch from defaulting to ordered categoricals to unordered instead. There are quite a few unit tests... but clearly not perfect coverage. Others will be able to say more about the coverage than me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744,1,['error'],['error']
Availability,The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472,2,"['down', 'error']","['download', 'error']"
Availability,"The nans (with a proper warning) would be the right way but having data that causes downstream is not an option. As an intermediate solution, I added a note to the docs and made them zeros:; https://github.com/theislab/scanpy/commit/dce2be194a6ff865ecaeb939f3c990f6c3b0e244",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479412666:84,down,downstream,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479412666,1,['down'],['downstream']
Availability,"The only issue I can think of was when I was creating the object. Before I used to transfer the `adata.obs` dataframe to a new one by doing `adata_new.obs = adata_old.obs`. When I did this in `scanpy==1.7.1` the transfer didnÄt show any errors, but it didn't copy. This was fixed when I added the `.copy()` to that command. . When I ran the same thing on a macbook pro, the labels somehow disappeared after calculating highly variable genes. . I have been using this notebook since `scanpy==1.6` and it didn't give me any problems until I upgraded to `scanpy==1.7.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787874441:237,error,errors,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787874441,1,['error'],['errors']
Availability,The only solution so far is to increase the tolerance threshold of the tests! I don't know where those differences come from. Is always a problem. I will be very glad if you find a better solution.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136:44,toler,tolerance,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136,1,['toler'],['tolerance']
Availability,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:428,fault,fault,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971,1,['fault'],['fault']
Availability,The package is now available on [pypi](https://pypi.org/project/glmpca/0.1.0/) and there is an [automated test suite](https://github.com/willtownes/glmpca-py/blob/master/tests/glmpca_tests.py).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929:19,avail,available,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929,1,['avail'],['available']
Availability,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822059389:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822059389,2,['error'],"['error', 'errors']"
Availability,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,4,"['Avail', 'error']","['Available', 'error']"
Availability,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015,1,['error'],['error']
Availability,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-705222557:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-705222557,1,['error'],['error']
Availability,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331,2,['error'],['error']
Availability,The same exact error also happens using the docker image suggested on the web site; fastgenomics/scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-390604622:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-390604622,1,['error'],['error']
Availability,The solution do downgrade to pandas=0.22 worked for me. Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-391277887:16,down,downgrade,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-391277887,1,['down'],['downgrade']
Availability,"The test `test_marker_overlap` keeps failing on the travis build for python 3.5. This seems to happen on the first build from a PR, but if the build is restarted it passes. Given that my `n=3` for this, it could also be random. Grabbed the error log from #579 (build [1735.1](https://travis-ci.org/theislab/scanpy/jobs/514097606)):. ```; _____________________________ test_marker_overlap ______________________________; def test_marker_overlap():; # Test all overlap calculations on artificial data; test_data = sc.AnnData(X = np.ones((9,10))); test_data.uns['rank_genes_groups'] = dict(); test_data.uns['rank_genes_groups']['names'] = np.rec.fromarrays(; [['a', 'b','c','d','e'], ['a','f','g','h','i']]); test_data.uns['rank_genes_groups']['pvals_adj'] = np.rec.fromarrays(; [[0.001, 0.01, 0.02, 0.05, 0.6], [0.001, 0.01, 0.02, 0.05, 0.6]]); ; marker_genes = {'type 1':{'a','b','c'}, 'type 2':{'a','f','g'}}; ; t1 = sc.tl.marker_gene_overlap(test_data, marker_genes); t2 = sc.tl.marker_gene_overlap(test_data, marker_genes, normalize='reference'); t3 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='overlap_coef'); t4 = sc.tl.marker_gene_overlap(test_data, marker_genes, method='jaccard'); t5 = sc.tl.marker_gene_overlap(test_data, marker_genes, top_n_markers=2); t6 = sc.tl.marker_gene_overlap(test_data, marker_genes, adj_pval_threshold=0.01); ; > assert t1.iloc[1,1] == 3.0; E assert 1.0 == 3.0; scanpy/tests/test_marker_gene_overlap.py:22: AssertionError; ```. Here's a [gist](https://gist.github.com/ivirshup/6965ebe2530c4eac67aebf41c3961959) of the full output. Any idea what's up @LuckyMD?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580,1,['error'],['error']
Availability,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1892:269,ping,ping,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892,1,['ping'],['ping']
Availability,"The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694859994:17,toler,tolerance,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694859994,1,['toler'],['tolerance']
Availability,"The tests use `group` but the code handles `obs`. TODO: should `heatmap` be changed too? Its docs actually speak of “variables or observations” and not “variables or groups”. About the test changes:. Some time ago, matplotlib made a change to font rendering. Since we have such high tolerance when comparing plots, that didn’t affect our tests. But that also means that our tests are almost useless, since the actual qualitative difference in the test that _did_ change behavior due to my PR wasn’t caught. Therefore I lowered the tolerance, which meant I had to regenerate everything with the new font rendering. | Before | After |; |--------|--------|; | ![](https://raw.githubusercontent.com/scverse/scanpy/bd758395a669c31a6c9eaa9239750fde368d3ca7/tests/_images/stacked_violin_std_scale_group/expected.png) | ![](https://raw.githubusercontent.com/scverse/scanpy/c06bbc83218ee426fa54e681ab39c8006e1668c0/tests/_images/stacked_violin_std_scale_group/expected.png) |",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243:283,toler,tolerance,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243,2,['toler'],['tolerance']
Availability,The tolerances need to be tight enough that the tests do anything though …. I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1898157315:4,toler,tolerances,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1898157315,2,['toler'],['tolerances']
Availability,The travis CI failure looks unrelated to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-840023795:14,failure,failure,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-840023795,1,['failure'],['failure']
Availability,"The variable folder has one file in .h5ad format as input or raw data. No, I execute the code correctly because every time I run this command or move forward with other commands, the number on the kernel increases without any error message. But in a folder, no object is generated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817693943:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817693943,1,['error'],['error']
Availability,There is an issue with the new Scipy. `statsmodels` is conflicting with it. Either downgrade scipy or upgrade statsmodels as soon as they fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236:83,down,downgrade,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236,1,['down'],['downgrade']
Availability,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522#issuecomment-470900854:39,avail,available,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-470900854,1,['avail'],['available']
Availability,There was an issue where values were being set as rgb values unintentionally which should be fixed by #1886. Can you give an example of how this was causing problems? What would cause you to hit errors here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-864681671:195,error,errors,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-864681671,1,['error'],['errors']
Availability,"There's a possibility of negative values depending on how careful you are with compensation and whether or not you clip values, but at least in my case the counts matrix was always non-negative. **Edit:** But that shouldn't matter because NNDescent is routinely called on PCA-embedded data which is zero centered, right? . If I can find a small subset of the matrix that produces this error reliably, I will share that with the `pynndescent` repo and link back here. Currently that's challenging given the original size of the matrix (a few million observations).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802982688:385,error,error,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802982688,2,"['error', 'reliab']","['error', 'reliably']"
Availability,"There’s a few uses:. 1. Humans. Once you understand the syntax ([very easy](https://docs.python.org/3/library/typing.html), i just get `Generator` wrong all the time) it improves your understanding what a function really accepts and returns; 2. IDEs. They’ll get better when inferring the types of variables and will show you more actual problems in the code and less false positives; 3. Testing. Some projects use mypy to check if all code in your repo typechecks properly, which can be integrated into a test suite; 4. Runtime type checking. Has a performance hit (as said) but given proper type hints, it makes your code safer and the error messages better (“Function blah excepted a parameter foo of type Bar, but you passed a foo of type Baz”). i’m not planning to do 3 and 4 (yet, and probably never)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142:638,error,error,638,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142,1,['error'],['error']
Availability,"There’s two differences:; 1. `np.unique(...)` returns the values sorted, `pd.Series(...).unique()` returns them in original order (this already makes the scores not match). This probably changes the sampling, but I wonder why the score difference is so large here! With only that change, I get:. > Arrays are not equal; >; > Mismatched elements: 2730 / 2730 (100%); > Max absolute difference: 0.22674037; > Max relative difference: 1581.75673912. 2. what you said: The original approach samples from the full list of genes in each bin, then restricts the sample to valid ones. Your approach samples from the valid genes in each bin. So if a bin e.g. contains mostly invalid genes, the original code adds only a few genes for that bin, while yours adds the maximum possible number. So the questions is: is the sampling bias introduced in the original code wanted? If not, you not only made the code more resilient, but also more objective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-1963784907:903,resilien,resilient,903,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-1963784907,1,['resilien'],['resilient']
Availability,"This PR adds a module `sc.metrics` for functions which wouldn't modify an anndata object, but are useful calculations. I'm basing this on `sklearn.metrics`, namely, how `sklearn` has separated transformers (`sc.tl`) from measurements. I've started it with two functions, `confusion_matrix` and `gearys_c` but think there are more use cases (e.g. `modularity`). I'm open to this not being a module, but I think these methods should be available and I'm not sure where they'd fit within the current api. My vision for this module is to make it easier to calculate values based on values you'd get using the scanpy ecosystem. Methods that would be included would be either *a)* not available in other libraries (`gearys_c`) or *b)* are available, but have difficult interfaces (`confusion_matrix`). ## `sc.metrics.confusion_matrix`. Creates a confusion matrix for comparing categorical labels. This is based on `sklearn.metrics.confusion_matrix` but is easier to use, and returns a object with labels. I think this is mostly done, though I'm considering changing the calling convention. Here's an example of usage:. ```python; import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc); sns.heatmap(sc.metrics.confusion_matrix(""bulk_labels"", ""leiden"", pbmc.obs)); ```. ![image](https://user-images.githubusercontent.com/8238804/68737959-1a28b780-0639-11ea-8576-4cf1907066d9.png). I've copied `seaborn`s calling convention here, but I think that could change. Right now the above call is equivalent to:. ```python; sc.metrics.confusion_matrix(pbmc.obs[""bulk_labels""], pbmc.obs[""louvain""]); ```. But I wonder if it would make more sense to have the DataFrame go first if it's provided. I've also based the API around my usage of confusion matrices, so I'm very open to more general feedback on this. My reason for including it here was the amount of code it took wrapping `sklearn.metrics.confusion_matrix` to get useful output. ## `sc.metrics.gearys_c` ([Wiki pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915:434,avail,available,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915,3,['avail'],['available']
Availability,This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me); - closes #1434 clarify qc metric and normalize total @havardtl; - closes #827 clarify diff component indexing @veghp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1680:63,Ping,Pinging,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680,1,['Ping'],['Pinging']
Availability,"This PR computes a hierarchical clustering and draws a dendrogram to some of the plots. This is particularly useful when looking at marker genes from `scanpy.tl.rank_genes_groups` because the categories and marker genes are reordered according to the dendrogram. Eg:. ```PYTHON; pbmc = sc.datasets.pbmc68k_reduced(); ```; ![image](https://user-images.githubusercontent.com/4964309/47084320-71304300-d213-11e8-9a02-4cb2558f4cd7.png). ![image](https://user-images.githubusercontent.com/4964309/47084465-d97f2480-d213-11e8-838e-4407e4b854c7.png). Currently, for all rank_genes_groups_* plots, the dendrogram is set to `True` by default as I think this results in more meaningful images. For `heatmap`, `dotplot`, `matrixplot` and `stacked_violin` plots, I added a new parameter to activate the dendrogram:. ```PYTHON; sc.pl.dotplot(pbmc, marker_genes, groupby='bulk_labels', dendrogram=True); ```; ![image](https://user-images.githubusercontent.com/4964309/47084622-50b4b880-d214-11e8-9179-6a9d5ecff306.png). More example are available at https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/308:1023,avail,available,1023,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/308,1,['avail'],['available']
Availability,"This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions hav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1753:442,error,error-case-sensitive-drives-supported,442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753,1,['error'],['error-case-sensitive-drives-supported']
Availability,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2512:200,avail,available,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512,2,"['avail', 'down']","['available', 'download']"
Availability,"This PR is meant to get doc builds working again. I've added `setuptools_scm` and fixed a typo in the shared plotting docs. Read the docs seems to be working again, but I'm still getting this error locally:. ```; Warning, treated as error:; /Users/isaac/github/scanpy/docs/external/scanpy.external.exporting.cellbrowser.rst:2:duplicate object description of scanpy.external.exporting.cellbrowser, other instance in api/scanpy.external.exporting.cellbrowser, use :noindex: for one of them; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/802:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/802,2,['error'],['error']
Availability,This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655:115,down,downstream,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655,1,['down'],['downstream']
Availability,This PR resolves the issues with:. * error when the type of a category is not `str`; * inconsistent color assigned to categories; * white space ; * horizontal lines not well aligned. Missing. - [x] Tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1603:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1603,1,['error'],['error']
Availability,"This adds RAPIDS as an (experimental) option for running some of the graph algorithms on a GPU. Example usage is demonstrated here: https://github.com/tomwhite/scanpy_usage/tree/rapids-gpu/1909_rapids_gpu. In summary:. ```python; sc.pp.neighbors(adata, method='rapids'); sc.tl.louvain(adata, flavor='rapids'); sc.tl.umap(adata, method='rapids'); ```. Timings (on 130K samples):. | Step | CPU time (s) | GPU time (s) | Speedup |; | --------- | ------------ | ------------ | ------- |; | Neighbors | 47 | 15 | 3x |; | Louvain | 70 | 1 | 70x |; | UMAP | 186 | 15 | 12x |. Comments:; * In general the output figures are quite different for each of the algorithms compared to regular Scanpy. (See the figures in the link above.); * RAPIDS uses exact nearest neighbors (using https://github.com/facebookresearch/faiss I think), whereas the default NNDescent algorithm in Scanpy is approximate.; * Louvain community detection results in a different number of communities (28 vs 45). I'm not sure if it is possible to change the termination criteria or other parameters that would make the two outputs the same, or at least more similar.; * UMAP is different too, and in particular it is bunched in one corner. There are a few very small clusters in the opposite corner, which looks like it might be a bug.; * UMAP computes the nearest neighbors again from scratch - it can’t reuse the ones computed earlier since RAPIDS only exposes the fit/transform methods, and not `simplicial_set_embedding` that regular UMAP exposes.; * In general it would be useful to understand what random number generators each of the alternatives use, how they can be controlled, and what prospects there are for achieving identical output (if any).; * This is using RAPIDS version 0.7 since it is the version available on the Google Cloud image I used (https://cloud.google.com/deep-learning-vm/docs/images).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830:1780,avail,available,1780,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830,1,['avail'],['available']
Availability,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487:286,error,error,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487,1,['error'],['error']
Availability,"This can’t be it, `__init__.py` is [optional since Python 3.3](https://www.python.org/dev/peps/pep-0420/). I also don’t see that import error, `import scanpy` works perfectly. Can you specify how you got that?. ```py; >>> import scanpy, anndata; >>> scanpy.external.tl.palantir(anndata.AnnData()); ImportError: ; please install palantir: . git clone git://github.com/dpeerlab/Palantir.git; cd Palantir; sudo -H pip3 install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185:136,error,error,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185,1,['error'],['error']
Availability,This error appears when using DESC autoencoder (github: eleozzr/desc) under scanpy 1.4.4. This was not an issue with earlier versions of scanpy. Is there a work-around available?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/895:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/895,2,"['avail', 'error']","['available', 'error']"
Availability,"This error happened to me too when working on a small dataset and scoring a single gene with ctrl_size=1. This happens at random in the following line: https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L168. I was working on a small test dataset with limited features and calling the `score_genes_cell_cycle` function, where only 1 cell cycle gene is left and ctrl_size is set as follows:; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L258",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660,1,['error'],['error']
Availability,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729,1,['error'],['error']
Availability,"This error message was hard to debug! Indeed it is due to the behavior of `sc.pp.neighbors`. Cells are sometimes given different numbers of neighbors. Sometimes that the errant cells have a number of neighbors greater than zero (unlike as seen in #2244, where the # of neighbors of some cells was 0). My fix builds on the one above and was:; ```; b = np.array(list(map(len, adata_ref.obsp['distances'].tolil().rows))) # number of neighbors of each cell; adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]] # select only those with the right number; sc.pp.neighbors(adata_ref_subset, DEFINED_NEIGHB_NUM) # rebuild the neighbor graph; ```; ___; @ViriatoII Your comment helped me fix things – but your fix itself didn't work for me. First, when I use `adata_ref = adata_ref[b]`, with `b` defined as above, it interprets `b` not as a boolean mask but as an index, returning a single cell duplicated over and over. I'm not sure what the intended behavior is here. My solution is to use `adata_ref[np.where(b == n_neigh-1)[0]]`. However, this subselection changes the number of neighbors that other cells have. For example, for my data,. ```; b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))); print(""Before subselecting"", np.unique(b, return_counts = True)). adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]]; c = np.array(list(map(len,adata_ref_subset.obsp['distances'].tolil().rows))); print(""After subselecting"", np.unique(c, return_counts = True)); ```; yields; ```; Before subselecting, (array([13, 14]), array([ 28, 1161359])); After subselecting, (array([10, 11, 12, 13, 14]),; array([ 15, 1, 633, 46, 1160664]))); ```. To solve both problems I needed to rebuild the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586,2,"['error', 'mask']","['error', 'mask']"
Availability,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw.; Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-701367442:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-701367442,1,['error'],['error']
Availability,"This feature is still in the development version of scanpy, therefore not available in the released scanpy version yet. See https://github.com/theislab/scanpy/issues/560 for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445:74,avail,available,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445,1,['avail'],['available']
Availability,"This fixes #415, by allowing one to find variable genes using the `equal_frequency` option. It also adds and option to change the number of bins for cell ranger flavor. I originally tried to copy the implementation in Seurat, which would allow a test similar to what's already present for the `equal_width` implementation. However the Seurat code has an error:; ```R; else if (binning.method==""equal_frequency"") {; data_x_bin <- cut(x = gene.mean, breaks = c(-1,quantile(gene.mean[gene.mean>0],probs=seq(0,1,length.out=num.bin)))); }; ```; The `-1` in the code makes it such that there is always only one value in the first bin, which goes from -1 to the minimum value. Not sure why they have this, but then we get different answers since the Scanpy code in `highly_variable_genes` always makes bins that have only one gene significant (to correct the other error from Seurat that normally excludes these bins/genes, which often contain some highly-expressed genes). Additionally, the `cut` function in R sometimes returns bin edges with different rounding than the Seurat implementation since Seurat does not modify the default `dig.lab = 3`. In contrast, I believe pandas uses the actual cutoffs in the data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/572:354,error,error,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/572,2,['error'],['error']
Availability,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507:35,down,downloading,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507,3,['down'],"['download', 'downloaded', 'downloading']"
Availability,"This functionality is available through `muon`: https://muon.readthedocs.io/en/latest/api/generated/muon.tl.leiden.html. Sorry for the confusion, but that tutorial is based on a development branch which is out of date and should be taken down. I'm also going to close this issue, since multimodal analysis in general is handled through `muon`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-2061253111:22,avail,available,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-2061253111,2,"['avail', 'down']","['available', 'down']"
Availability,"This has been discussed previously: https://github.com/theislab/scanpy/issues/1451, https://github.com/mwaskom/seaborn/issues/1423. I don't think that this sort of normalization is necessarily invalid or wrong, just situational. I also think it makes sense to mimic prior art, and this is how the argument works in seaborn. I do agree that just `x / max(abs(x))` is useful, and more often what people want to use here (if scaling at all). I like suggestion 2. more for this. I would suggest the following api:. ```python; normalization: Optional[Union[str, Callable[np.ndarray, np.ndarray]] (default: None); Normalization to apply to values. Can be selected from ""z-score"", ""minxmax_scale"", etc. or a Callable.; normalization_axis: Literal[""var"", ""group""] (default: ""var""); If a `normalization` is passed, which dimension of the data to normalize along.; ```. It would be nice if the normalization method was mentioned by default in the legend, but that can be difficult with how matplotlib doesn't really do text wrapping with it's notebook backend. Arguably, for `dotplot` `normalization` should be available for both size and color. What to you think @gokceneraslan @fidelram?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-804509620:1101,avail,available,1101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-804509620,1,['avail'],['available']
Availability,"This includes fixes for both #469 and #470 . #469 was a small indexing error. To fix #470, a `rankby_abs` check is included in the `logreg` section of the method that mirrors the `rankby_abs` checks in the other two methods. This PR additionally updates `select_groups` function in `scanpy/utils.py.` I was having some issues when the clusters that I was using were labelled by integers (i.e. when `adata.obs[key].cat.catagories.values.dtype` was some form of integer) AND when I was looking at a subset of the clusters (e.g. `groups=[0,1]`, not when `groups='all'`). At the start of the `rank_genes_groups` function, these cluster labels are converted into strings in the `groups_order` variable. In the `select_groups` function (line 667 of the original utils.py file), however, we call ; ``` ; np.where(adata.obs[key].cat.categories.values == name)[0][0]; ```; which fails with an error (since `name` is a string from `select_groups` and the elements of `adata.obs[key].cat.categories.values` are integers). Thus, this PR includes a check for the `dtype` of `adata.obs[key].cat.categories.values` - if it is numeric, we instead look at ; ``` ; np.where(adata.obs[key].cat.categories.values == float(name))[0][0]; ```. This error should only appear if the cluster labels are integers (since this is the only time that the cluster labels are converted to strings for `groups_order` in `rank_genes_groups`) but the above fix should also work if the cluster labels are any floating point numbers (just in case the `rank_genes_groups` is ever generalized in this way). ([Here](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.scalars.html) is a link to the numpy type hierarchy). Edit: added a line number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/471:71,error,error,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/471,3,['error'],['error']
Availability,"This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required.; - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. ; - I've moved what was sensible to use Scanpy functions. ; - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476:1236,mainten,maintenance,1236,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476,1,['mainten'],['maintenance']
Availability,"This is a bit of a grab bag, but is mostly `io` related. This started out as me trying to learn some vscode git integration, but turns out it's not great at figuring out what lines changed. Apologies for any weird stuff in the commits. Main changes:. * I've made the tests for `sc.datasets` more thorough. Now they actually check the data looks kinda okay, rather than whether they throw an error.; * I've removed cache-ing in a few places; * The `read_10x_*` tests, where that definitely shouldn't have been happening; * In a couple of the `sc.datasets`. I'd be willing to go back on this, but we shouldn't let them use the cache during testing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/592:391,error,error,391,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/592,1,['error'],['error']
Availability,This is all looks fine and should work perfectly. I'd need an example with some data and the lines of code that produce the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440391801:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440391801,1,['error'],['error']
Availability,"This is great, thanks! Now just for the neighbours `use_hvgs=` parameter and then we're sorted for using HVGs for downstream analysis without filtering the whole dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-427676209:114,down,downstream,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/284#issuecomment-427676209,1,['down'],['downstream']
Availability,This is helpful for downloading datasets from the 10x website and generally fixes #1264.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1296:20,down,downloading,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1296,1,['down'],['downloading']
Availability,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881:53,down,downgrade,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881,1,['down'],['downgrade']
Availability,"This is in an Ubuntu 16..04 Docker container:; ```; docker run --rm -it ubuntu:16.04; ```; Then I ran:; ```; apt-get update && apt-get install -y \; python3-pip \; python3-setuptools; python3-wheel. pip3 install scanpy; ```. I get the following output (after all of the dependencies are downloaded):. ```; warning: manifest_maker: standard file '-c' not found; ; reading manifest file 'scanpy.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'scanpy.egg-info/SOURCES.txt'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/pip-build-33o4crd7/scanpy/setup.py"", line 51, in <module>; 'Topic :: Scientific/Engineering :: Visualization',; File ""/usr/lib/python3.5/distutils/core.py"", line 148, in setup; dist.run_commands(); File ""/usr/lib/python3.5/distutils/dist.py"", line 955, in run_commands; self.run_command(cmd); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 179, in run; self.run_command('build'); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run; _build_py.run(self); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/usr/lib/python3/dist-packages/setuptools/command/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:287,down,downloaded,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,1,['down'],['downloaded']
Availability,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:; ```; ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,; 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,; 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,; 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,; 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529840088:200,error,error,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529840088,2,['error'],['error']
Availability,"This is not related, and most certainly separate issue. <can start a new thread > ; I am getting memory error with sc.tl.pca; What is your recommendation? . Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 111, in <module>; sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca; X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray; out = self._process_toarray_args(order, out); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args; return np.zeros(self.shape, dtype=self.dtype, order=order); MemoryError",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622663649:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622663649,1,['error'],['error']
Availability,"This is not the case study code. I think this comes from the PAGA tutorial. So I can't really say whether this is normal. I typically don't have PAGA errors or warnings. . Most of the errors seem to be deprecation warnings, so that should be fine... but the ""finite values"" on posx and posy error I haven't come across. It looks like this is on Windows. Is there a matplotlib issue with windows?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534975285:150,error,errors,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534975285,3,['error'],"['error', 'errors']"
Availability,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667898329:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667898329,1,['error'],['error']
Availability,"This is the error with the development version:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-36-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 733 """"""; --> 734 return embedding(adata, 'pca', **kwargs); 735 ; 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 243 itertools.product(color, idx_components); 244 ):; --> 245 color_source_vector = _get_color_source_vector(; 246 adata,; 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1016 ):; 1017 # We should probably just make an index for this, and share it over runs; -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1019 0; 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344,3,"['Down', 'error']","['Downloads', 'error']"
Availability,"This is the origin of the error:. Some of the cells don't have neighbours at the variable adata_ref.obsp['distances'].tolil().rows:. ```; array([list([223, 280, 316, 5791]), list([3877, 5899, 7766, 7807]),; list([165, 304, 423, 713]), ..., list([]),; list([94, 865, 7077, 7666]), list([])], dtype=object); ## (the maximum 4 elements of each list comes from having run sc.pp.neighbors(adata_ref, n_neighbors = 5)) ##; ```. The above array is impossible to stack with np.stack due to the sublists having different lengths. A potential solution might be filtering out those cells without neighbours, though this is suboptimal. I have tried it and new rows remain empty. Only after repeating it a second time, it works:. ```; DEFINED_NEIGHB_NUM =5; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref, n_neighbors = DEFINED_NEIGHB_NUM ); sc.tl.umap(adata_ref). b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))) == DEFINED_NEIGHB_NUM -1; adata_ref = adata_ref[b]; ```. A better solution would be correcting the Nearest Neighbour assignment so that it doesn't create empty distance lists. Did I understand this correctly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780,1,['error'],['error']
Availability,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:235,down,downgrading,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520,1,['down'],['downgrading']
Availability,"This is updated in the newest version of the module, where it looks for either `tissue_positions.csv` or `tissue_positions_list.csv`. The code on the github project works, but unfortunately the most recent version on PyPi was from Mar 2, 2023. . An easy fix is to download the github project directly, using something like ; `pip install git+https://github.com/scverse/scanpy.git#egg=scanpy`. I did it recently in a Google Colaboratory Notebook with a file with `tissue_positions.csv`, and it worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912:264,down,download,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912,1,['down'],['download']
Availability,"This is what I'm running; ```; bcType = 'NobatchCorr'; sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'); sc.pp.log1p(adata); adata.raw = adata; sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'); #adata = adata[:, adata.var.highly_variable]; sc.pp.scale(adata, max_value=10); sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10); sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10); sc.tl.umap(adata, random_state=10); sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10); ```; The code never fails, but Leiden parameters are not present in the adata as it should. Running; ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836:815,error,error,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836,1,['error'],['error']
Availability,"This issue just came up recently when I tried re-running an older notebook of mine. Whenever I try and run my code in Jupyter notebook and execute any cell that uses scanpy.tl.tsne my kernel crashes. When I try and execute the same code from the terminal I get ; `Segmentation fault: 11`. . This is the code I used to reproducibly get the error:; ```; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.pca(adata); sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. <img width=""629"" alt=""Screenshot 2019-10-16 at 14 39 09"" src=""https://user-images.githubusercontent.com/15019107/66920007-c2d7fd00-f022-11e9-93d6-560305d1cc50.png"">. Any ideas what the issue could be and how I can fix this? The function used to work fine for me. I am running scanpy in the following version:; `scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.9 numpy==1.16.4 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.10.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/874:277,fault,fault,277,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/874,2,"['error', 'fault']","['error', 'fault']"
Availability,"This looks great!. A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap?; * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose.; * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python; if basis in adata.obsm:; basis_key = basis; elif f""X_{basis}"" in adata.obsm:; basis_key = f""X_{basis}""; else:; raise KeyError(; f""Could not find entry in `obsm` for '{basis}'.\n""; f""Available keys are: {list(adata.obsm.keys())}.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523732596:1245,Avail,Available,1245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523732596,1,['Avail'],['Available']
Availability,This looks like an bug in the most recent release of `louvain`. Try downgrading?. I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-622229246:68,down,downgrading,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-622229246,1,['down'],['downgrading']
Availability,"This looks like an issue with `mnn_correct` , and is probably more appropriate for that repo (https://github.com/chriscainx/mnnpy). I would note that on my end I'm able to replicate the warnings but not the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167#issuecomment-615006407:207,error,error,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167#issuecomment-615006407,1,['error'],['error']
Availability,"This looks really cool. I don't see how this is a solution to the many groups issue though. Especially as you'd likely have the densities of many groups overlapping in the same area. Otherwise, I don't really know of a heuristic to assess whether the kde is reliable. I am okay with removing the 10 groups threshold and just letting the user deal with the mess... but maybe that's not the kindest thing to do. This is essentially a discussion of flexibility vs ease-of-use. Might merit a more principled discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/719#issuecomment-560101154:258,reliab,reliable,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/719#issuecomment-560101154,1,['reliab'],['reliable']
Availability,"This may be related to this issue:; https://github.com/theislab/scanpy/issues/918#issue-522668041. I was running:. `sc.tl.umap(bdata, init_pos='paga')`. But it gave me this error:. ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fca8d70fc80>)); [2] During: typing of call at /usr/local/lib/python3.6/dist-packages/umap/umap_.py (795). File ""../../usr/local/lib/python3.6/dist-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/936:173,error,error,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936,1,['error'],['error']
Availability,"This pull request is same as https://github.com/scverse/scanpy/pull/3110 with allowed edits to maintainers. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec) |; | -- | -- |; | Original | 297 |; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284:758,Down,Downloading,758,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"This seems to have something to do with not being able to estimate the variance within a group. If you add thes lines:; ```; adata.X[0,:] = np.array([1.,1.,1.]); adata.X[11,:] = np.array([1.,1.,1.]); ```; to your data, then it works as expected. I assume this is due to `NaN` being set to 1 in the p-value calculation. The t-test isn't defined in this case. Not sure what the error for `""logreg""` is though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258:376,error,error,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258,1,['error'],['error']
Availability,"This simplifies `top_segment_proportions_sparse_csr` by using improvements in numba which allow cacheing parallel code. A downside of this is it takes a really long time to compile on first run, which might be off-putting. Side note: I accidentally ran formatting before committing, so some other lines got changed too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844:122,down,downside,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844,1,['down'],['downside']
Availability,"This solves the problem with PYTHONPATH approach (without flit). The problem with flit is:; I didn't want to create a new environment or get my conda packages accidentally replaced by installations from pip, so i tried; `flit install --deps none -s` and `flit install --pth-file --deps none` and received the same error after running `conda list`.; It has been reported [here](https://github.com/conda/conda/issues/9074) already. Yes, it has dist-info there. Importing works fine with the flit installed packages, but i also want to be able to use `conda list`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1378#issuecomment-675477069:314,error,error,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378#issuecomment-675477069,1,['error'],['error']
Availability,"This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2374:30,error,errors,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374,1,['error'],['errors']
Availability,"This works with a non-backed adata, this works:. ```python; sc.pl.pca(adata[:, :5], color=""0""); ```. I'm not totally sure what exactly the other backed modes are supposed to do (especially when called instantiated by `read`, but none of them work either. `r`, `r+`, and `a` return similar errors, while `x`, `w`, and `w+` don't work, but that's because the file exists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-421872224:289,error,errors,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-421872224,1,['error'],['errors']
Availability,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/492#issuecomment-766321134:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-766321134,1,['error'],['errors']
Availability,"Three things:. 1. If that is a feature, then this is a bug (runs without error):. ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 10))); sc.pp.pca(adata); ```. 2. Defaults should work without tuning.; 3. > I feel as though changing the default to match the setting can be dangerous as may not recall how many PCs were used then. Given that I'm running `sc.pp.pca` without setting `n_comps`, I contend that the average user does not remember what the default value is. It would make more sense in both cases (`n_features <= n_comps` and `n_samples <= n_comps`) to throw a warning and set n_comps to the maximum allowable value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586479275:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586479275,1,['error'],['error']
Availability,"To answer the following question:. > 2. what you said: The original approach samples from the full list of genes in each bin, then restricts the sample to valid ones. Your approach samples from the valid genes in each bin.; >; > So if a bin e.g. contains mostly invalid genes, the original code adds only a few genes for that bin, while yours adds the maximum possible number.; >; > So the questions is: is the sampling bias introduced in the original code wanted? If not, you not only made the code more resilient, but also more objective. After going through the original [code from Seurat](https://github.com/satijalab/seurat/blob/c54e57d3423b3f711ccd463e14965cc8de86c31b/R/utilities.R#L280C3-L303), it seems to me that there's not equivalent to removing genes to be scored from the control gene set.; From what I can tell, if one of the genes to be scored happens to be chosen as the background, it will be included in the calculation.; But please correct me if that's not the case. So if the original implementation does not remove score genes from the control gene set, we would simply need to remove the following line: https://github.com/scverse/scanpy/blob/ec4457470618efd85da3c7b29f951cab01a49e3a/scanpy/tools/_score_genes.py#L169. (Note: if we want to keep the current behaviour, we should still remove the line above, since it would be redundant)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358:505,resilien,resilient,505,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358,2,"['redundant', 'resilien']","['redundant', 'resilient']"
Availability,"To make you reproduce my error, here is what I did with a Docker image:. 1. `singularity -d build sc_velocyto0.17.17_scannpy1.6.0_scvelo0.2.2.img docker://xie186/scrna_tutorial:0.1.0`. 2. sudo ufw allow 8689. 3. `singularity run --nv sc_velocyto0.17.17_scannpy1.6.0_scvelo0.2.2.img jupyter-lab --ip=<your_ip> --port=8689 --no-browser `. Then in browser, open '<your_ip>:8689' and run the code below in jupyterlab. . The data and code I ran is shown as below:. * Go to: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE132188. * Search ""GSE132188_RAW.tar"". * Download the file.; Uncompress the files:. ```; tar xvf GSE132188_RAW.tar; ```; You will get the following files.; ```; GSM3852752_E12_5_counts.tar.gz; GSM3852753_E13_5_counts.tar.gz; GSM3852754_E14_5_counts.tar.gz; GSM3852755_E15_5_counts.tar.gz; ```; Uncompress: ; ```; mkdir -p E12_5_counts/; tar zxvf GSM3852752_E12_5_counts.tar.gz --directory E12_5_counts/; mkdir -p E13_5_counts/; tar zxvf GSM3852753_E13_5_counts.tar.gz --directory E13_5_counts/; mkdir -p E14_5_counts/; tar zxvf GSM3852754_E14_5_counts.tar.gz --directory E14_5_counts/; mkdir -p E15_5_counts/; tar zxvf GSM3852755_E15_5_counts.tar.gz --directory E15_5_counts/; ```. Code:. ```; import numpy as np; import matplotlib.pyplot as pl; import numpy as np; import scanpy as sc; import scanpy.external as sce; import pandas as pd; from anndata import AnnData; import seaborn as sns; from scipy.sparse import csr_matrix; import networkx as nx; import xlsxwriter; from matplotlib import rcParams; import seaborn as sns; import scipy as sci; #GSEApy: Gene Set Enrichment Analysis in Python.; #import gseapy as gp; sc.settings.verbosity = 3; sc.logging.print_versions(). # Read cellranger files for all four samples; filename = './E12_5_counts/mm10/matrix.mtx'; filename_genes = './E12_5_counts/mm10/genes.tsv'; filename_barcodes = './E12_5_counts/mm10/barcodes.tsv'. e125 = sc.read(filename).transpose(); e125.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; e125",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315,2,"['Down', 'error']","['Download', 'error']"
Availability,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:296,error,error,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453,2,"['error', 'reliab']","['error', 'reliably']"
Availability,"Tried to install via `$ pip3 install -e .` but returned this error:; ```; Obtaining file://path/to/scanpy_1.4/scanpy; Complete output from command python setup.py egg_info:; /path/to/miniconda3/envs/bio/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.; from ._conv import register_converters as _register_converters; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""path/to/scanpy/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""path/to/scanpy/scanpy/__init__.py"", line 26, in <module>; check_versions(); File ""path/to/scanpy/scanpy/utils.py"", line 38, in check_versions; .format(__version__, anndata.__version__)); NameError: name '__version__' is not defined. ----------------------------------------; Command ""python setup.py egg_info"" failed with error code 1 in path/to/scanpy/; ```; The variable `__version__` in line 38 in utils.py is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/482:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482,2,['error'],['error']
Availability,Tried with the group option but got an `Value error: The truth value of a Index is ambiguous.` As I didn't know how to deal with it I just applied the function @LuckyMD posted above and it worked perfectly alright.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-897602161:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-897602161,1,['error'],['error']
Availability,Try continuing on black error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1536:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536,1,['error'],['error']
Availability,Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1927:69,error,erroring,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927,1,['error'],['erroring']
Availability,Tutorial error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1742:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742,1,['error'],['error']
Availability,"Two ideas: ; 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`.; 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1470#issuecomment-724573518:286,avail,available,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470#issuecomment-724573518,1,['avail'],['available']
Availability,"Two major, and two minor, updates to qc metric calculation:. ## Tests run much faster now. `test_qc_metrics.py` used to take ~30 seconds, now takes ~2. These tests have been kinda slow for a while. This was mostly due to numba compilation. I was using `numba.njit(parallel=True)`, which cannot be cached so compilation occurred every time the tests ran. However, I expect most use cases only calculate QC metrics once in a session, and only for large datasets (at least 300,000 cells) is parallelization + compilation faster than performing the calculation in a single thread. Now a cached single threaded version is used unless the dataset is large. ## Can now calculate observation and variable metrics separately. Split the calculation of qc metrics into two functions for obs and var. These separate calls are now available as: `describe_obs` and `describe_var` after `pd.DataFrame.describe`. This is mostly to go along with my split-apply-combine experiments. In particular a use case like:. ```python; (adata; .groupby(obs=""leiden""); .apply(sc.pp.describe_var); .combine(...); ); ```. Where metrics like number of fraction of cells, mean expression, etc. are calculated within each group (useful for things like #562). ## Minor updates. * User can now choose to use expression from `layers` or `raw` instead of `adata.X`; * Doc updates 🤞 (am I polluting `sc.pp._docs.py` too much?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615:818,avail,available,818,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615,1,['avail'],['available']
Availability,"UMAP is a scatterplot, thus the X and Y dimension both carry information, jitter would distort the data (beyond what UMAP already does) ; ; If you're concerned about overplotting, you can try changing the size and alpha or downsampling: ; `sc.pl.umap(adata, size = 5, alpha = 0.5)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573:223,down,downsampling,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573,1,['down'],['downsampling']
Availability,UMAP: no available 'use_rep' parameter for tool.umap(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/689:9,avail,available,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/689,1,['avail'],['available']
Availability,"Um, it wasn't me. ```; CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/linux-64/xorg-libxdmcp-1.1.2-h470a237_7.tar.bz2>; ```. Also, downsampling from 3785143 finished after an hour, but definitely had the wrong answer (all counts in one gene). I'm not sure what to make of this, since it's given reasonable results for smaller tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/340#issuecomment-435273679:175,down,downsampling,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340#issuecomment-435273679,1,['down'],['downsampling']
Availability,"Update to `downsample_counts` to allow downsampling total counts, similar to normalization by `cellranger aggr` (I'm pretty sure on this, there's a lot going on in their code). Additionally, enabled caching for the `numba`'d function, which cuts down on test time. As adding this feature meant renaming `target_counts` to `counts_per_cell`, this becomes a breaking change. Since it's breaking, I've also gone ahead and set `replace=False` by default as mentioned before (#340). Definitely willing to make changes. I've implemented this since I'm doing some integration work and figured it'd be nice to be able to try the basic `cellranger` strategy. Edit: The failing PAGA test occurs locally on master as well, but I don't think I broke that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/474:39,down,downsampling,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/474,2,['down'],"['down', 'downsampling']"
Availability,Update: I was able to get rid of the error by pip installing `dask` manually in my conda environment.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941,1,['error'],['error']
Availability,"Update: Nvm, I figured this out. Tt had to do with `qualname_overrides`, which I've updated. <details>; <summary> Old problem </summary>. @flying-sheep, weird sphinx bug I'm running into:. * The readthedocs builds are failing after commit fc83ec3; * The error is:. ```pytb; scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp.bbknn:24: WARNING: py:class reference target not found: sklearn.neighbors._dist_metrics.DistanceMetric; ```. * The error will still occur as long as this has been added:. ```rst; .. plot::; :context: close-figs. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.umap(adata); ```. * If I remove the `sc.tl.umap` line, the builds work fine, as `sklearn.neighbors.DistanceMetric` resolves and no warning is thrown. For now, I'm going to remove the type annotation from `sc.external.pp.bbknn`, since it's causing the error. Any ideas why calling `sc.tl.umap` means `sklearn.neighbors._dist_metrics.DistanceMetric` can no longer resolve? I assume it has something to do with packages being imported in an unexpected order, but also this is real weird. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775780103:254,error,error,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775780103,3,['error'],['error']
Availability,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946:53,error,error,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946,2,"['error', 'fault']","['error', 'fault']"
Availability,Updating scanpy discourse links to point at scverse. Ping @adamgayoso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2177:53,Ping,Ping,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177,1,['Ping'],['Ping']
Availability,Upload scrublet scores on test failure,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3069:31,failure,failure,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069,1,['failure'],['failure']
Availability,Use tqdm instead of tqdm.auto when downloading datasets,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:35,down,downloading,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['downloading']
Availability,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1107449372:166,error,error,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1107449372,1,['error'],['error']
Availability,"Using `adata.T.write_csvs(skip_data=False)` gives you this. If you only want the data matrix, you can also do `adata.to_df().to_csv()` using pandas. The last call will soon be available in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/314#issuecomment-431635269:176,avail,available,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/314#issuecomment-431635269,1,['avail'],['available']
Availability,"ValueError: h5 contains more than one genome, Available genomes are columns in the h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:46,Avail,Available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,1,['Avail'],['Available']
Availability,"We can compute any kind of residual in principle (NB right now, Poisson + log normal soon) in batchglm, this is also not restricted to categorical covariates and automatically selects whether closed form is available. The implmentation is numerically very stable. I think it could be a potential backend for this, @willtownes?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593266979:207,avail,available,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593266979,1,['avail'],['available']
Availability,"We could possibly add another parameter, (`handle_duplicates`, `duplicates_action`?), which could specify how to do this. I think the best default behavior for this is to throw an error. @fidelram, @VolkerBergen what do you think? I know we've been trying to reduce complexity in these methods, so is this worth it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/926#issuecomment-555323780:180,error,error,180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/926#issuecomment-555323780,1,['error'],['error']
Availability,"We currently distribute `scanpy` through `conda-forge`, so I would recommend using that for up to date versions. Will this still error if you've done that?. Also, it's a little unclear if your session info came from the conda environment you're running into issues with. Is this definitely the case? There shouldn't be that new of releases of scanpy or anndata available through bioconda as far as I know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234:129,error,error,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234,2,"['avail', 'error']","['available', 'error']"
Availability,"We didn't use the weights in Louvain (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_louvain.py#L31)?. Why did you decide to change the default in Leiden; (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_leiden.py#L31)? I'm fine with it, but a brief discussion would have been appropriate. :wink:. @LuckyMD; > how different is that to clustering on the UMAP embedding directly?; It's very different. The choice of weights will likely not have a dramatic effect, you're always clustering a graph that proxies neighborhoods in high-dimensional space. If you embed this structure in 2 or 3 d, even if you use the fantastic UMAP for it, you'll make errors (https://twitter.com/falexwolf/status/1108284982001315840). Also, the most computationally intense part is the embedding optimization, not the graph construction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732:740,error,errors,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732,1,['error'],['errors']
Availability,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:327,down,downstream,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918,1,['down'],['downstream']
Availability,"We had created this PR before https://github.com/scverse/scanpy/pull/3099. This one is the same PR with editing enabled for maintainers.; Hi,; We are submitting PR for speed up of the _get_mean_var function.; | | Time(sec) |; | -- | -- |; | Original | 18.49 |; | Updated | 3.97 |; | Speedup | 4.65743073 |. experiment setup : AWS r7i.24xlarge; ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; USE_FIRST_N_CELLS = 1300000; adata = adata[0:USE_FIRST_N_CELLS]; adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3280:680,Down,Downloading,680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3280,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"We have a backwards compatibility wrapper, I have no idea how this error can be possible:. https://github.com/theislab/anndata/blob/41eadb2a76d91ae455faf01afd2382143b9af4b2/anndata/_core/anndata.py#L2137-L2140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1027#issuecomment-587178083:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027#issuecomment-587178083,1,['error'],['error']
Availability,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK there’s no scRNA-Seq ones that aren’t dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesn’t end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364159311:159,down,downloaded,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364159311,1,['down'],['downloaded']
Availability,"We have a weird temporary global variable called `sc.pl._utils._tmp_cluster_pos`. We use it for storing the positions of cluster centroids (actually the centroids of any categorical variable for any sort of embedding). The weird part is that it's set in scatterplot functions (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_anndata.py#L468 and https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L809) and used only by `sc.pl.paga_compare` (https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/paga.py#L119). First, it's not obvious where paga_compare finds centroids (it was a mystery to me until recently). Second, the current design is error-prone (see a corner case https://github.com/theislab/scanpy/issues/686). Therefore, there should be a better place to store cluster centroids :). I'm not following the discussion about the future of AnnData, but maybe having something like `adata.uns['obs_category_leiden']` and storing colors and centroids in it e.g. `adata.uns['obs_category_leiden']['colors']` and `adata.uns['obs_category_leiden']['centroids']['X_umap']` would be more structured.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/938:711,error,error-prone,711,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/938,1,['error'],['error-prone']
Availability,"We have created this PR earlier https://github.com/scverse/scanpy/pull/3061. This one is the same PR with editing enabled for maintainers.; This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge.; ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=time.time(); adata = sc.read(input_file); adata.var_names_make_unique(); adata.shape; print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(); # To reduce the number of cells:; USE_FIRST_N_CELLS = 1300000; adata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3279:723,Down,Downloading,723,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279,2,"['Down', 'down']","['Downloading', 'download']"
Availability,"We just merged an update on the `downsample_counts` function by @ivirshup; evidently, the data type shouldn't be changed by downsampling, should it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293:124,down,downsampling,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293,1,['down'],['downsampling']
Availability,"We probably have two problems:. 1. CI doesn’t run; 2. Scanpy got harder to use for people. I think the first [is easy to fix](https://github.com/numba/numba/blob/c13c840a8f1f038c1e78472db472a8f19a0bd564/numba/core/config.py#L309): We just `export NUMBA_THREADING_LAYER=workqueue` in our tests. The second is harder, but first I want to note something:. > This was fine in the past, since pynndescent/ umap were forcing a workqueue backend which is always available. I wouldn’t call that situation *fine*, doing things at import time or even just requiring a certain value as configurable global state is bad behavior. This means our solution for the second shouldn’t be that we hardcode a threading layer to use here. We could make it configurable on our end or something, but no import time global state change. #1933 only fixes CI … also bad issue number, yikes!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874649964:455,avail,available,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874649964,1,['avail'],['available']
Availability,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251:495,robust,robust,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251,1,['robust'],['robust']
Availability,"We require matplotlib 3.x for other parts of scanpy, so that’s not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227#issuecomment-661039650:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227#issuecomment-661039650,2,"['down', 'error']","['downgrading', 'error']"
Availability,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-743207565:94,down,download,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-743207565,1,['down'],['download']
Availability,"We should definitely maintain the type in layers, and that means maintaining the type in .X makes sense too. We should also take care not to downcast more incompatible types: int32 can be expressed as float64, but not in float32. int64 has to stay int64.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-558138634:141,down,downcast,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-558138634,1,['down'],['downcast']
Availability,We should make the `random_state` of `make_blobs` available through our `blobs` function. This would make it easier to generate random data for testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1429:50,avail,available,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429,1,['avail'],['available']
Availability,"We typically have some marker information in the form of an Excel sheet, pandas DataFrame, and eventually a Python dictionary. Using these as gene annotations in various plotting functions (not pl.rank_genes_groups_* family but the others) is a very common task and it looks awesome thanks to @fidelram's `var_group_*` parameters. It would be even more fantastic to be able to pass simple dict (e.g. the ones we already use in [Malte's marker_gene_overlap](https://scanpy.readthedocs.io/en/latest/api/scanpy.tl.marker_gene_overlap.html#scanpy.tl.marker_gene_overlap)) to plotting functions where `var_group_positions` and `var_group_labels` are populated automatically. . One caveat is that there might be genes covered by multiple keys, but this is similar to supplying overlapping `var_group_position`s in current api, which can exit with an error. I already have a function for that but it's absolutely super ugly. I can send a PR after tidying it up, but if anyone else wants to do it, it's perfectly fine.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/646:844,error,error,844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646,1,['error'],['error']
Availability,"We were getting a lot of errors from dask tests because they were relying on test helpers from anndata 0.10. It's a small number of functions, but it depends on the types in the compat module so is difficult to copy out. To work around this I've temporarily bumped the minimum required version of anndata up to 0.10, but we definitely shouldn't actually do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895765916:25,error,errors,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895765916,1,['error'],['errors']
Availability,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3004#issuecomment-2063950003:32,error,errors,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004#issuecomment-2063950003,1,['error'],['errors']
Availability,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2063:760,error,error,760,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063,1,['error'],['error']
Availability,"Well, I know nothing, maybe you already have everything, but I could; look at an example? The advantage of the expression atlas is that they; have really good meta data. That's provided through their downloadable; files, as far as I remember. So if you got everything that is in their; downloadable meta data files, then you certainly have everything of; interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129:200,down,downloadable,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129,2,['down'],['downloadable']
Availability,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/27#issuecomment-314766836:81,robust,robustly,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27#issuecomment-314766836,1,['robust'],['robustly']
Availability,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:416,error,error,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756,1,['error'],['error']
Availability,What is the best way to recover raw count to adata.X,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1817:24,recover,recover,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817,1,['recover'],['recover']
Availability,What is the content of the variable `folder`? There must be an error message or else you are not executing the code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817683273:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817683273,1,['error'],['error']
Availability,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:372,mainten,maintenance,372,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285,1,['mainten'],['maintenance']
Availability,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python; import scanpy as sc; import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(); sce.pp.bbknn(pbmc, batch_key='bulk_labels'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/770#issuecomment-519007245:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770#issuecomment-519007245,1,['error'],['error']
Availability,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```; git clone https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703887451:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703887451,1,['error'],['error']
Availability,"What we're really after is the more general ability to execute different d/e tools without too much extra work, and have the results stored consistently in the annData for whatever downstream applications (plotting or otherwise), or just so that they're available for consumers of our annData objects. But maybe if it's something you guys aren't keen on we can just code it up in our own software layer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886464475:181,down,downstream,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886464475,2,"['avail', 'down']","['available', 'downstream']"
Availability,What would be a useful default?. I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/55#issuecomment-354442003:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55#issuecomment-354442003,1,['error'],['error']
Availability,Whats the timeline here? When will there be a release that includes this fix? Or should I downgrade pandas in the meantime?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015#issuecomment-585115015:90,down,downgrade,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015#issuecomment-585115015,1,['down'],['downgrade']
Availability,"When I call `sc.pp.normalize_total(adata)` on a system that does not have Dask installed, I get the following error:. ```; AnnData object with n_obs × n_vars = 710 × 33538; obs: 'filter_with_counts', 'scrublet_doublet_score', 'filter_with_scrublet'; var: 'gene_ids', 'feature_types', 'genome', 'filter_with_counts'. File ""/viash_automount/home/rcannood/workspace/viash_temp//viash-run-normalize_total-ppLnd4"", line 32, in <module>; sc.pp.normalize_total(; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 200, in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 25, in _normalize_data; if isinstance(counts, DaskArray):; TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. The error was introduced in [9cb915](https://github.com/scverse/scanpy/commit/9cb915bee5bfe11f62ffb37c0405656aae4574f2#diff-34d549afa2b23d0b2066964a51f698d918398edffd38379a73d02390e31ae5e8R24). . This PR solves the issue by checking that DaskArray is not None, though I'm sure alternative solutions are also possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2209:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209,2,['error'],['error']
Availability,"When I did `pip install --user scikit-misc` in my shell and then in python tried the line that errored for you `from skmisc.loess import loess`, everything worked fine for me. Also, depending on how conda is setup `pip install --user` might install it in your home directory, rather than the conda env. So you could also try activating the conda env and then running `pip install scikit-misc --force`. . Can you print out the full traceback of what happens when you run `from skmisc.loess import loess`? If that was causing the `ImportError` it might be easier to see outside of the try/except block. You can also try `import skmisc; print(skmisc.__file__)` to see what that returns. I also see some related issues (https://github.com/has2k1/scikit-misc/issues/12), which could indicate that it did not install correctly because it did not install the cython scripts properly on windows. The solution (install the numpy+mkl .whl first) in https://github.com/has2k1/scikit-misc/issues/4 might work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340:95,error,errored,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340,1,['error'],['errored']
Availability,"When I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct vers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:474,avail,available,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,1,['avail'],['available']
Availability,"When I read. > like Union[OrderedDict, pd.Series], this is a fine substitute for Intersect[Mapping, Sequence]. in the context of. > An example I could think of is needing key value lookup which is also ordered could be thought of as the intersection of Mapping and Sequence types. then `Intersect[Mapping, Sequence]` expects a new ""intersection object"" (here just an `OrderedDict`), which is to me an ""intersection way"" of subclassing - and the first is `OneOf`. So these are different things. My point is (repeating what Philipp said): in practice (in all the numerical stuff that I've done so far, including Scanpy), I have never encountered the need for defining such an intersection object on the typing level. I just overload functions using `OneOf` and account for differences in the passed objects attributes via `if isinstance(...):`... If I need a function that only eats a ""weird intersection type object"", I'll go and define the corresponding class and throw an error if the function gets fed something different. Fortunately, that happens quite rarely; but yeah, I had cases where I only wanted an `OrderedDict` but neither a `dict` or a `list`. But I'd never call this an ""intersection type"". @ivirshup You didn't explain the ""type lattice"": but according to what I learned about `Union` and `Intersection` in this thread, the sets involved in the mentioned ""set operations on the type lattice"" should have elements that are ""properties"" of types (as they are not restricted to actual class attributes, this, unfortunately, doesn't tell you right away which ""property"" you are intersecting: ""being ordered"", ""having a key accesor"", ""having a certain numerical range""). Right? Union and Intersection then refer to the maximal set of properties of the objects you pass. As each passed object can be characterized by a set of properties, all that naming makes sense. But for someone reading the docs, who isn't expected to know about all the properties of all each object that comes along th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443966884:973,error,error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443966884,1,['error'],['error']
Availability,"When I run `sc.tl.rank_genes_groups` and I set the `reference` argument to one of my groups I am testing, I get the error. ```pytb; 91 groups_order = [str(n) for n in groups_order]; 92 if reference != 'rest' and reference not in set(groups_order):; ---> 93 groups_order += [reference]; 94 if (reference != 'rest'; 95 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list; ```. That's because 'groups_order' is not a list at this point of the code when the argument `groups` is at its default `all`. When I change this and I pass a list, e.g. ['0', '1'], then the error vanished, because `groups order` will then be a list that we can add to. This should be changed, because the setting 'all' is the default value.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/346:116,error,error,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346,2,['error'],['error']
Availability,"When I run sc.pp.normalize_total(adata, target_sum=1e4),I got the error:ValueError: could not convert integer scalar,and How can I fixed this issue?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183,1,['error'],['error']
Availability,"When I run sc.rank_genes_groups() on my gene expression data, I do get separate matrices for names, scores, pvals, and pvals_adj. However, the scores don't match the pvals. In other words, with decreasing pvals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What'e the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12242378/ClusterOneVsRest.csv)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/701#issuecomment-1662515521:1024,down,down,1024,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701#issuecomment-1662515521,1,['down'],['down']
Availability,"When I run:; ```; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; #batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. It finished in about 10 seconds. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.10.0.dev57+g08be4e9; -----; PIL 9.4.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; adjustText 0.8; anyio NA; arrow 1.2.3; arviz 0.15.0; asciitree NA; asttokens NA; astunparse 1.6.3; attr 22.2.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bokeh 2.4.3; brotli NA; captum 0.6.0; cellrank 1.5.1; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 2.1.1; chex 0.1.6; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.3.0; dask_image 2022.09.0; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; decoupler 1.4.0; defusedxml 0.7.1; dill 0.3.6; docrep 0.3.2; dot_parser NA; entrypoints 0.4; executing 1.2.0; fasteners 0.17.3; fastjsonschema NA; flatbuffers 23.1.21; flax 0.5.0; fqdn NA; fsspec 2023.1.0; gast NA; google NA; gseapy 1.0.4; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; imagecodecs 2023.1.23; imageio 2.26.0; invgauss_ufunc NA; ipykernel 6.21.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; isoduration NA; jax 0.4.10; jaxlib 0.4.10; jedi 0.18.2; jinja2 3.0.3; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.3.0; jupyterlab_server 2.19.0; keras 2.11.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.3; lightning_utilities 0.7.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.7.1; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; ml_collections NA; ml_dtypes 0.1.0; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.1; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2493:190,avail,available,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493,1,['avail'],['available']
Availability,"When I tried to import scanpy into python 3.5.2, I got the following error message,. ```; >>> import scanpy as sc; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.5/dist-packages/scanpy/__init__.py"", line 3, in <module>; from .utils import check_versions, annotate_doc_types; File ""/usr/local/lib/python3.5/dist-packages/scanpy/utils.py"", line 18, in <module>; from ._settings import settings; File ""/usr/local/lib/python3.5/dist-packages/scanpy/_settings.py"", line 351; f'{k} = {v!r}'; ^; SyntaxError: invalid syntax; ```; My OS platform is `Ubuntu 16.04` and I installed `scanpy` by `pip install scanpy`. How could I resolve this issue? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/855:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855,1,['error'],['error']
Availability,"When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,1,['error'],['error']
Availability,"When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:; TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2370:216,error,error,216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370,1,['error'],['error']
Availability,"When exporting a SPRING project I get the following error (NameError: name 'NeighborsView' is not defined ). 16 days ago a bug issue was closed related to this ( #1260 ), however I still encounter the bug when using both Scanpy 1.5.1 or 1.5.0; . **Input**:; ```import time; t0 = time.time(); sc.external.exporting.spring_project(adata, './SPRING',; 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; custom_color_tracks=['total_counts']); print(time.time() - t0); ```. **Output**: ; ```Writing subplot to SPRING\all; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-59-9c683583ff59> in <module>; 1 import time; 2 t0 = time.time(); ----> 3 sc.external.exporting.spring_project(adata, './SPRING',; 4 'umap', subplot_name='all', overwrite=True, cell_groupings=['leiden'],; 5 custom_color_tracks=['total_counts']). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~\Anaconda3\envs\sfn-workshop\lib\site-packages\scanpy\external\exporting.py in _get_edges(adata, neighbors_key); 217 ; 218 def _get_edges(adata, neighbors_key=None):; --> 219 neighbors = NeighborsView(adata, neighbors_key); 220 if 'distances' in neighbors: # these are sparse matrices; 221 matrix = neighbors['distances']. NameError: name 'NeighborsView' is not defined; ```. #### AnnData: ; ```AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden'; var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1285:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1285,1,['error'],['error']
Availability,"When giving a plotting function the `gene_symbols` argument to specify that it should look in a column of `var` for `var_names` rather than look for them in the index, the underlying `_prepare_dataframe` function tries to find the `var_names` in `adata.var` rather than `adata.raw.var`, even when looking for the data itself in raw. For example, this code:. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; adata.var['varnames'] = list(adata.var.index); adata.raw.var['varnames'] = list(adata.raw.var.index); 'ENSGALG00000048305' in adata.raw.var['varnames'] # returns true; sc.pl.heatmap(; adata,; var_names=marker_genes_table.iloc[:, :5].values.flatten(),; groupby='cluster_anno',; show_gene_labels=True,; swap_axes=True,; gene_symbols='varnames',; save=True,; use_raw=True,; ); ```; produces this error:; <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ERROR: Gene symbol 'ENSGALG00000048305' not found in given gene_symbols column: 'varnames'. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-40-80ce653c9d2e> in <module>; ----> 1 sc.pl.heatmap(; 2 adata,; 3 var_names=marker_genes_table.iloc[:, :5].values.flatten(),; 4 groupby='cluster_anno',; 5 show_gene_labels=True,. ~/anaconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1413 ); 1414 ; -> 1415 categories, obs_tidy = _prepare_dataframe(; 1416 adata,; 1417 var_names,. TypeError: cannot unpack non-iterable NoneType object; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; ```; scanpy==1.4.6 anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277:856,error,error,856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277,3,"['ERROR', 'Error', 'error']","['ERROR', 'Error', 'error']"
Availability,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029,1,['error'],['error']
Availability,"When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python; adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))); sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):; File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>; sc.preprocessing._qc.describe_obs(adata); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions; raise IndexError(""Positions outside range of features.""); IndexError: Positions outside range of features.; ```; (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:; - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section?; - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2346:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346,1,['error'],['error']
Availability,"When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: ; ```; ValueError: Data must be 1-dimensional; ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1888:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888,1,['error'],['error']
Availability,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. ; I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you!. **Versions:**; > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-690431766:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-690431766,1,['error'],['error']
Availability,"When using long gene names the rank_genes_groups function does not work properly anymore as long gene names are trimmed down to 50 characters, which makes it difficult to look them up again in the adata object. I think the problem is caused on this line:; https://github.com/theislab/scanpy/blob/c5c32f2277ad3f9c5388fc5d0a602151f3bab42b/scanpy/tools/_rank_genes_groups.py#L401 where the gene names are casted to an unicode array with 50 elements. ```; np.array(['LOOONG','SHORT'],dtype='U5'); > array(['LOOON', 'SHORT'], dtype='<U5'); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753:120,down,down,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753,1,['down'],['down']
Availability,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667921094:121,error,errors,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667921094,1,['error'],['errors']
Availability,"While I run 'sc.tl.louvain', this error raised and told me I should call 'jgraph'.; Is it necessary for me to change the package name of 'igraph'to 'jgraph' manually?. ```pytb; ---------------------------------------------------------------------------; DeprecationWarning Traceback (most recent call last); <ipython-input-191-71b705e00011> in <module>; ----> 1 sc.tl.louvain(ad_2). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy); 112 directed = False; 113 if not directed: logg.debug(' using the undirected graph'); --> 114 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 115 if use_weights:; 116 weights = np.array(g.es[""weight""]).astype(np.float64). /usr/local/lib/python3.6/dist-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 379 def get_igraph_from_adjacency(adjacency, directed=None):; 380 """"""Get igraph graph from adjacency matrix.""""""; --> 381 import igraph as ig; 382 sources, targets = adjacency.nonzero(); 383 weights = adjacency[sources, targets]. /usr/local/lib/python3.6/dist-packages/igraph/__init__.py in <module>; 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807,1,['error'],['error']
Availability,"While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575; But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1663:493,avail,available,493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663,1,['avail'],['available']
Availability,"While testing my changes to dataset code, I saw that `sc.datasets.burczynski06()` raised the error:. ```python; ValueError: `X` needs to be of one of ndarray, MaskedArray, spmatrix, ZarrArray, ZappyArray, not <class 'dict'>.; ```. But it had a pretty easy fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/574:93,error,error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/574,2,"['Mask', 'error']","['MaskedArray', 'error']"
Availability,"While the single command works `adata = adata[adata[: , 'A'].X > 1, :]`. The compound command gives me the following error: ; TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1870#issuecomment-1058394641:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870#issuecomment-1058394641,1,['error'],['error']
Availability,"While trying to cluster using phenograph I get the error below. Could you help me understand why this happens?; ```; >>adata1; AnnData object with n_obs × n_vars = 77969 × 18417; obs: 'Id', 'Donor', 'Sample', 'Method', 'Position', 'UMI.Count', 'Expressed.Genes', 'Percent.Mitochond.', 'Percent.Ribo', 'CellType', 'Sex', 'Age'; var: 'name'; uns: 'pca'; obsm: 'X_pca'; varm: 'PCs'. >>import scanpy.external as sce; >>result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). PhenoGraph clustering; Finding 100 nearest neighbors using minkowski metric and 'auto' algorithm; Neighbors computed in 67.26673102378845 seconds; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-22-2cf1719c59ce> in <module>; 1 import scanpy.external as sce; ----> 2 result=sce.tl.phenograph(adata1.obsm['X_pca'],k=100). /usr/local/lib/python3.8/site-packages/scanpy/external/tl/_phenograph.py in phenograph(data, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method); 143 ); 144 ; --> 145 communities, graph, Q = phenograph.cluster(; 146 data=data,; 147 k=k,. /usr/local/lib/python3.8/site-packages/phenograph/cluster.py in cluster(data, clustering_algo, k, directed, prune, min_cluster_size, jaccard, primary_metric, n_jobs, q_tol, louvain_time_limit, nn_method, partition_type, resolution_parameter, n_iterations, use_weights, seed, **kargs); 243 ""Leiden completed in {} seconds"".format(time.time() - tic_), flush=True,; 244 ); --> 245 communities = np.asarray(communities.membership); 246 ; 247 print(""Sorting communities by size, please wait ..."", flush=True). /usr/local/lib/python3.8/site-packages/phenograph/core.py in neighbor_graph(kernel, kernelargs); 82 :return graph: n-by-n COO sparse matrix; 83 """"""; ---> 84 i, j, s = kernel(**kernelargs); 85 n, k = kernelargs[""idx""].shape; 86 graph = sp.coo_matrix((s, (i, j)), shape=(n, n)). /usr/local/lib/python3.8/site-packages/phenogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407,1,['error'],['error']
Availability,Wilcoxon rank_genes_groups math domain error (Scanpy 1.4.3),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"With pandas 1.3.4 and 1.3.3. * I can't replicate the initial issue; * I can replicate @michalk8's example. This looks very upstream in pandas. I will try and submit an issue/ check that this hasn't been reported to pandas already tomorrow. This may be a kinda easy fix (e.g. check value shape better during column assignment in pandas), but it can take a bit to figure out how to fix things there. AFAIK, we removed calls in scanpy which assigned (n x 1) matrices to pandas because of related, non-formatting error. Is the current scanpy release assigning these matrices anywhere?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-948025046:509,error,error,509,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-948025046,1,['error'],['error']
Availability,"With respect to the heatmap, indeed it is possible to transpose the matrix.; Currently, this option is only available for `stacked_violin`. I thought; about adding this option to other plots like heatmap, matrixplot and; dotplot but I have not find the time and it is always possible to save the; figure and rotate it so it has low priority for me. The changes are not as; trivial as simply rotating the matrix as all other elements need to be; adjusted. On Wed, Nov 7, 2018 at 3:03 AM Alex Wolf <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> should be the expert for this...; > 😄; >; > —; > You are receiving this because you were mentioned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/349#issuecomment-436477272>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1b_dlMN1mihuJIbXg2lPmMJvgqGgks5usj-FgaJpZM4YRQ7g>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/349#issuecomment-436548839:108,avail,available,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349#issuecomment-436548839,1,['avail'],['available']
Availability,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:251,Error,Error,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895:33,ping,ping,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895,1,['ping'],['ping']
Availability,"Would you mind reading through the link I sent and cutting this back?. This doesn't fit the ""reproducible"" criteria (I don't have that data file), and I'm not sure which line actually causes the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-478795943:195,error,error,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478795943,1,['error'],['error']
Availability,"X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I do umap analysis, I got a warning. I try to change the maxiter parameter, but it doesn't work. . ### Minimal code sample. ```python; sc.tl.umap(adata, maxiter=50); ```. ### Error output. ```pytb; computing UMAP; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited at iteration 20 with accuracies ; [0.01180801 0.01616286 0.01491355]; not reaching the requested tolerance 1e-08.; Use iteration 19 instead with accuracy ; 0.013873452618210833. eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; /data/home/ruanlab/huangxingyu/miniconda3/lib/python3.10/site-packages/umap/spectral.py:342: UserWarning: Exited postprocessing with accuracies ; [0.0114102 0.01466 0.01555016]; not reaching the requested tolerance 1e-08.; eigenvalues, eigenvectors = scipy.sparse.linalg.lobpcg(; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (1:07:21); ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.10.1; -----; Cython 0.29.33; IPython 8.13.2; PIL 9.4.0; annoy NA; asttokens NA; backcall 0.2.0; bbknn 1.6.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cycler 0.10.0; cython 0.29.33; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; executing 1.2.0; fontTools 4.39.0; h5py 3.8.0; idna 3.4; igraph 0.10.5; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.40.1; matplotlib 3.9.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.23.0; packaging 23.0; pandas 2.0.1; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; plotly 5.13.1; pooch v1.7.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3139:1061,toler,tolerance,1061,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139,1,['toler'],['tolerance']
Availability,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think?. In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example?; ```python; VALID_LEGENDLOCS = {; 'none',; 'right margin',; 'on data',; 'on data export',; 'best',; 'upper right',; 'upper left',; 'lower left',; 'lower right',; 'right',; 'center left',; 'center right',; 'lower center',; 'upper center',; 'center',; }; ```; Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255,1,['error'],['error']
Availability,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348,2,"['error', 'failure']","['error', 'failure']"
Availability,"Yeah, it's not working . Here https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.violin.html they say; > Wraps [seaborn.violinplot()](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot) for [AnnData](https://anndata.readthedocs.io/en/stable/generated/anndata.AnnData.html#anndata.AnnData). but when you add `orient='h'` or `orient='v'` to the `sc.pl.violin` run, it fails wit this error:; ```; TypeError: seaborn.categorical.violinplot() got multiple values for keyword argument 'orient'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164,1,['error'],['error']
Availability,"Yeah, so this is not a bug. It's just that there is no HVG that is shared between all of your batches. I would suggest selecting the number of HVGs that are shared by all batches but 1, and then go down to all batch but 2 if you want more HVGs. For example:; `adata.var['highly_variable'] = adata.var['highly_variable_nbatches'] == adata.obs.batch.nunique()-1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559552890:198,down,down,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559552890,1,['down'],['down']
Availability,"Yeah, two out of three of the HPCs I have access to don't make using a jupyter server particularly easy (one corporate firewall, one government). I use that with the other one, but it's down this week 😢",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703:186,down,down,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703,1,['down'],['down']
Availability,"Yes I am still getting this error, my version of anndata==0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-615097979:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-615097979,1,['error'],['error']
Availability,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:36,recover,recovered,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956,1,['recover'],['recovered']
Availability,"Yes, agreed. I was only talking about consistency between the raised error and docs. And yes, will open a PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930,1,['error'],['error']
Availability,"Yes, it should work without downgrading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656362456:28,down,downgrading,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656362456,1,['down'],['downgrading']
Availability,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-364063478:99,down,download,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-364063478,2,['down'],['download']
Availability,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/791#issuecomment-523152544:24,fault,fault,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791#issuecomment-523152544,1,['fault'],['fault']
Availability,"Yes, the 'leiden_colors' field in `.uns` will only be updated if needed, i.e., if the number of categories in the `leiden` field in `.obs` exceeds the number of available colors. As Fidel mentions, passing `palette` will automatically trigger resetting the colors according to the chosen palette.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295:161,avail,available,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295,1,['avail'],['available']
Availability,"Yes, this is related to the fact that `sanitize_anndata` cannot be meaningfully applied to a view of `AnnData`. You're right that one should also account for this case... I'll give it a thought. At least there should be a proper error hinting people to call `sc.utils.sanitize_anndata` when trying the call you mention. Thank you very much for pointing this out. :smile: It should have happened also before version 1.1, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-393834418:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-393834418,1,['error'],['error']
Availability,"Yes, this was my impression too. However there is a documented option; ""Switch to Windows containers"" which is available if you right click on the; Docker icon in the taskbar and this allows one to run vms using a Windows; kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the; > error with a Docker container for Windows in the cross-referenced issue; >; > Yes please. I’m confused how Windows comes into play though since I thougt; > that Docker always runs on a Linux kernel – natively on Linux and in a VM; > on macOS and Windows.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2334006260:111,avail,available,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2334006260,2,"['avail', 'error']","['available', 'error']"
Availability,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:28,mask,mask,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711,2,['mask'],"['mask', 'masks']"
Availability,"Yes, you have the choice of either having 'gene_symbols' as your index or 'gene_ids', what is not in the index is available as a column in `.var`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/382#issuecomment-443398154:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382#issuecomment-443398154,1,['avail'],['available']
Availability,"Yes. I'm interested in many of the things here. Thank you for pinging me. I'm happy to engage going forward in a variety of ways. Let's start with a few responses. > I tried looking at pydata sparse with Dask, but it ran a lot slower than regular scipy.sparse (which is what Scanpy uses). It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. @hameerabbasi is usually pretty responsive, and I know that he appreciates learning about new use cases of pydata/sparse. > So I wrote a wrapper around scipy.sparse to implement NumPy's __array_function__ protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular scipy.sparse. Thoughts on adding this to scipy.sparse itself so that we can avoid the wrapper? cc @rgommers. > It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:62,ping,pinging,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,2,"['down', 'ping']","['down', 'pinging']"
Availability,"You can check if the mirror is working by using the url:. http://<ensembl_biomart_mirror>/biomart/martview. This is the url used internally by bioservices. The available mirrors are listed [here](http://www.ensembl.org/info/about/mirrors.html). For example, at the moment the mirror useast is not available. > Service Temporarily Unavailable; > The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later. I think we can close this issue since it's not related to the scanpy's code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-456889768:160,avail,available,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-456889768,4,"['avail', 'downtime', 'mainten']","['available', 'downtime', 'maintenance']"
Availability,"You can interchange the cluster order (reference with the cluster your intersted in) and get only-upregulated ones for the inverted comparison (hence down-regulated genes) or set `rankby_abs` to `True`, which will then give you down-regulated genes in addition to up-regulated ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852:150,down,down-regulated,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852,2,['down'],['down-regulated']
Availability,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909#issuecomment-551772902:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909#issuecomment-551772902,1,['error'],['error']
Availability,You could just output `NaN` for all genes that were masked? That would be accurate as the test would fail in that case anyway. That should solve `n_genes == adata.n_vars`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176:52,mask,masked,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176,1,['mask'],['masked']
Availability,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396,1,['error'],['error']
Availability,"You don't have to use HVGs for downstream analysis, but it is typically done for two reasons (at least):; 1. Using fewer genes is computationally less expensive for downstream analysis.; 2. The signal-to-noise ratio is better with highly variable genes than in the full gene set. The second point is usually particularly important, as even if one single gene doesn't contribute as much to the PCA if it has lower variance, if you have 15000 low-variance genes this does affect the embedding. If you'd like a rationale for why HVGs are used, please see our [best-practices review](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578#issuecomment-759366430:31,down,downstream,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578#issuecomment-759366430,2,['down'],['downstream']
Availability,"You just saw in your output line [7], that you get back a tuple from `mnn_correct()`. This is also what it says in the error you get. Thus, `adata[0]` is your anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-544365236:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/873#issuecomment-544365236,1,['error'],['error']
Availability,"Your approach won’t work, since `test_pca_warnings` discards all our testing filters. What we had does work. PS: the comment “We explicitly handle these errors in tests” applies to the whole block of filters below, so please don’t insert `ignore` filters into that block.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2905#issuecomment-1997139220:153,error,errors,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2905#issuecomment-1997139220,1,['error'],['errors']
Availability,"You’re right! I wasn’t aware of PEP 508. The build appears to fail [here](https://travis-ci.org/theislab/scanpy/jobs/550248884#L285), but actually fails much later, due to numpy/numpy#13790. I filed pypa/pip#6651 to deal with the error being unclear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-505780384:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-505780384,1,['error'],['error']
Availability,"ZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16914,ERROR,ERROR,16914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['ERROR'],['ERROR']
Availability,[ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1809,ERROR,ERROR,1809,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1956,ERROR,ERROR,1956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2688,ERROR,ERROR,2688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2397,ERROR,ERROR,2397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2250,ERROR,ERROR,2250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3567,ERROR,ERROR,3567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2835,ERROR,ERROR,2835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3276,ERROR,ERROR,3276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-Fals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3129,ERROR,ERROR,3129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"[ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2188:1111,down,downgrade,1111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188,1,['down'],['downgrade']
Availability,"[ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1412:1081,error,error,1081,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412,1,['error'],['error']
Availability,"[Here are the specific lines for their cluster ordering](https://github.com/GreenleafLab/ArchR/blob/6765ad962d4d8dcb292a326071c9b5c30c25918e/R/Clustering.R#L368-L383). They do a hierarchical clustering on the mean position of each cluster in the reduced dimensional space. We don't necessarily have access to that space (which may not even exist, e.g. BBKNN graph) at clustering time so we can't use this exact method. ### Current thoughts. My preferences in APIs lean towards modularity and shallowness. I like that the `leiden` function pretty much only computes `leiden` clusters, nothing else. I don't love the idea of adding complexity or computation on top of that. I also think ""gives better label orderings"" is a vague target which is hard to have meaningful tests for, so can be difficult to support. I think this would be a little convenient, but I don't see it being very convenient. I would like to hear if other people would really like this feature. At the moment, I don't think it's utility outweighs it's downsides to me. What I would be more for is some sort of `relabel_clusterings` utility function, which just does the relabelling and could have multiple ways of doing so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348:1021,down,downsides,1021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348,1,['down'],['downsides']
Availability,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-635762909:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-635762909,1,['error'],['error']
Availability,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:154,recover,recover,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340,1,['recover'],['recover']
Availability,[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47371,Error,Error,47371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4021,ERROR,ERROR,4021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Command errored out with exit status 1: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2' Check the logs for full command output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:4860,error,error,4860,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,4,"['ERROR', 'down', 'error']","['ERROR', 'downloads', 'error', 'errored']"
Availability,"\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 370 res = None; 371 try:; --> 372 pm.run(self.state); 373 if self.state.cr is not None:; 374 break. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:9304,avail,available,9304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['avail'],['available']
Availability,"\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,. ImportError: DLL load failed while importing _loess: The specified module could not be found. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/1877627730.py in <module>; ----> 1 sc.pp.highly_variable_genes(adata, n_top_genes=50",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:1398,error,errors,1398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['error'],['errors']
Availability,"_3', 'ClusterMarkers_0_sub_30', 'ClusterMarkers_0_sub_31', 'ClusterMarkers_0_sub_32', 'ClusterMarkers_0_sub_33', 'ClusterMarkers_0_sub_34', 'ClusterMarkers_0_sub_35', 'ClusterMarkers_0_sub_36', 'ClusterMarkers_0_sub_37', 'ClusterMarkers_0_sub_38', 'ClusterMarkers_0_sub_39', 'ClusterMarkers_0_sub_4', 'ClusterMarkers_0_sub_40', 'ClusterMarkers_0_sub_41', 'ClusterMarkers_0_sub_42', 'ClusterMarkers_0_sub_43', 'ClusterMarkers_0_sub_44', 'ClusterMarkers_0_sub_45', 'ClusterMarkers_0_sub_46', 'ClusterMarkers_0_sub_47', 'ClusterMarkers_0_sub_48', 'ClusterMarkers_0_sub_49', 'ClusterMarkers_0_sub_5', 'ClusterMarkers_0_sub_50', 'ClusterMarkers_0_sub_51', 'ClusterMarkers_0_sub_52', 'ClusterMarkers_0_sub_53', 'ClusterMarkers_0_sub_54', 'ClusterMarkers_0_sub_55', 'ClusterMarkers_0_sub_56', 'ClusterMarkers_0_sub_57', 'ClusterMarkers_0_sub_58', 'ClusterMarkers_0_sub_59', 'ClusterMarkers_0_sub_6', 'ClusterMarkers_0_sub_60', 'ClusterMarkers_0_sub_61', 'ClusterMarkers_0_sub_62', 'ClusterMarkers_0_sub_63', 'ClusterMarkers_0_sub_64', 'ClusterMarkers_0_sub_65', 'ClusterMarkers_0_sub_66', 'ClusterMarkers_0_sub_67', 'ClusterMarkers_0_sub_68', 'ClusterMarkers_0_sub_69', 'ClusterMarkers_0_sub_7', 'ClusterMarkers_0_sub_70', 'ClusterMarkers_0_sub_71', 'ClusterMarkers_0_sub_72', 'ClusterMarkers_0_sub_8', 'ClusterMarkers_0_sub_9', 'ClusterMarkers_1', 'ClusterMarkers_2', 'ClusterMarkers_3', 'ClusterMarkers_4', 'ClusterMarkers_5', 'ClusterMarkers_6', 'ClusterMarkers_7', 'Regulons'; obsm: 'ClusterID'. This is from publicaly available data. so what i would like to do is plot their published tsne or umap and compare a few things from it. If I simply run sc.pl.tsne(loom_file, color=['louvain']) I get error msg: ValueError: no field of name X_tsne. This makes sense as there is not X_tsne on the object. How could I get pass this without re-clustering myself? At the moment I am only interested in pulling out 2 of their annotated clusters... if there is an easy way to do this via scanpy please let me know.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/933:2502,avail,available,2502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/933,2,"['avail', 'error']","['available', 'error']"
Availability,"_Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`!; > ; > The following code should reproduce the error:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. -------------------------------. On current release this errors:. <details>; <summary> </summary>. ```python; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-1-4c43dbe94eaf> in <module>; 4 ; 5 pbmc = sc.datasets.pbmc68k_reduced(); ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,2,['error'],"['error', 'errors']"
Availability,"__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs); 816 if error_occured[0]:; --> 817 raise embedded.RRuntimeError(_rinterface._geterrmessage()); 818 return res. RRuntimeError: Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. During handling of the above exception, another exception occurred:. RInterpreterError Traceback (most recent call last); Cell In[48], line 1; ----> 1 get_ipython().run_cell_magic('R', '-i data -i data_tod -i genes -i cells -i soupx_groups -o out', '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster inf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:2138,Error,Error,2138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,1,['Error'],['Error']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57575,ERROR,ERROR,57575,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58911,ERROR,ERROR,58911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55905,ERROR,ERROR,55905,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"_counts_mt""). sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=3). sc.pp.scrublet(adata, batch_key=""sample""). # Saving count data; adata.layers[""counts""] = adata.X.copy(). # Normalizing to median total counts; sc.pp.normalize_total(adata); # Logarithmize the data; sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key=""sample""); sc.pl.highly_variable_genes(adata). sc.tl.pca(adata). sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True). sc.pp.neighbors(adata); sc.tl.umap(adata); sc.tl.leiden(; adata, key_added=""clusters"", flavor=""igraph"", directed=False, n_iterations=2; ). sc.pl.pca(; adata,; color=[""sample"", ""sample"", ""pct_counts_mt"", ""pct_counts_mt""],; dimensions=[(0, 1), (2, 3), (0, 1), (2, 3)],; ncols=2,; size=2,; ). sc.pp.neighbors(adata). sc.pl.umap(; adata,; color=""sample"",; # Setting a smaller point size to get prevent overlap; size=2,; ). ### runs forever:; sc.tl.leiden(adata, flavor=""igraph"", n_iterations=2); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; Exception ignored in: <class 'Val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228:2895,Error,Error,2895,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228,1,['Error'],['Error']
Availability,_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1518,ERROR,ERROR,1518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46488,Error,Error,46488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_trackspl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5132,Error,Error,5132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5019,ERROR,ERROR,5019,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2898,ERROR,ERROR,2898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._he,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7478,ERROR,ERROR,7478,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24256,ERROR,ERROR,24256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - I,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8310,ERROR,ERROR,8310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs); --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs); 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:3042,error,error,3042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"_pass, internal_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53); ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160:7470,error,errors,7470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160,2,['error'],['errors']
Availability,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:3969,avail,available,3969,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,1,['avail'],['available']
Availability,_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13846,ERROR,ERROR,13846,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14681,ERROR,ERROR,14681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4862,ERROR,ERROR,4862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.read(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_proxy.pyx in h5py._proxy.H5PY_H5Dread(). OSError: Can't read data (file read failed: time = Sat Aug 1 13:27:54 2020; , filename = '/path.../filtered_gene_bc_matrices.h5ad', file descriptor = 47, errno = 5, error message = 'Input/output error', buf = 0x55ec782e9031, total read size = 7011, bytes this sub-read = 7011, bytes actually read = 18446744073709551615, offset = 0). During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-14-faac769583f8> in <module>; 17 #while True:; 18 #try:; ---> 19 adatas.append(sc.read_h5ad(file)); 20 file_diffs.append('_'.join([file.split('/')[i] for i in diff_path_idx])); 21 #break. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 411 d[k] = read_dataframe(f[k]); 412 else: # Base case; --> 413 d[k] = read_attribute(f[k]); 414 ; 415 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/envs/rpy2_3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 else:; 161 parent = _get_parent(elem); --> 162 raise AnnDataReadError(; 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions:; ```; scanpy==1.5.1 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351:3218,error,error,3218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351,2,['error'],['error']
Availability,"_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). AnnData object with n_obs × n_vars = 8757 × 20679 ; obs: 'SeqRun', 'Biological replicate', 'nCount_RNA', 'nCount_SCT', 'nFeature_RNA', 'nFeature_SCT', 'novelty', 'orig_ident', 'percent_mt', 'sc_leiden_res_48.75', 'State', 'ImmGen'; var: 'Selected', 'sct_detection_rate', 'sct_gmean', 'sct_residual_mean', 'sct_residual_variance', 'sct_variable', 'sct_variance'; uns: 'Biological replicate_colors', 'ImmGen_colors', 'State_colors', 'leiden', 'neighbors', 'state'; obsm: 'X_pca', 'X_umap'; varm: 'pca_feature_loadings'; layers: 'norm_data', 'scale_data'; obsp: 'connectivities', 'distances'; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-208-9f15be957dd9> in <module>; 1 sc.external.exporting.spring_project(adata, '/Users/mariusmessemaker/Documents/Project/mempel/SPRING', 'X_umap', subplot_name='Mempel', cell_groupings=['State', 'ImmGen', 'Biological replicate'], ; ----> 2 custom_color_tracks=None, total_counts_key='nCount_RNA', neighbors_key='neighbors', overwrite=False). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in spring_project(adata, project_dir, embedding_method, subplot_name, cell_groupings, custom_color_tracks, total_counts_key, neighbors_key, overwrite); 179 ; 180 # Write graph in two formats for backwards compatibility; --> 181 edges = _get_edges(adata, neighbors_key); 182 _write_graph(subplot_dir / 'graph_data.json', E.shape[0], edges); 183 _write_edges(subplot_dir / 'edges.csv', edges). ~/miniconda3/envs/py36-sc/lib/python3.6/site-packages/scanpy/external/exporting.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1260:1289,Error,Error,1289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1260,1,['Error'],['Error']
Availability,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58577,ERROR,ERROR,58577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56907,ERROR,ERROR,56907,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"_rank_genes_groups.py, gene names are trimmed down to 50 characters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/753:46,down,down,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753,1,['down'],['down']
Availability,_scrublet_plots[scrublet] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_no_threshold] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_with_batches] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../..,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:3890,ERROR,ERROR,3890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"`E ImportError: cannot import name 'settings' from partially initialized module 'scanpy' (most likely due to a circular import) (/home/vsts/work/1/s/scanpy/__init__.py); `. Meh, it's hell to track this down now. I assume that autopep8 removed an unused variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785044073:202,down,down,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785044073,1,['down'],['down']
Availability,"`_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>; <summary> possible solution </summary>. ```python; from numba import njit, prange; import numpy as np. @njit(parallel=True); def nanmean_lowlevel(data, indices, indptr, shape):; N, M = shape; sums = np.zeros(N, dtype=np.float64); nans = np.zeros(N, dtype=np.int64); for i in prange(N):; start = indptr[i]; stop = indptr[i+1]; window = data[start:stop]; n_nan = np.int64(0); i_sum = np.float64(0.); for j_val in window:; if np.isnan(j_val):; n_nan += 1; else:; i_sum += j_val; sums[i] = i_sum; nans[i] = n_nan; sums /= (M - nans); return sums; ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1894:757,error,error,757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894,1,['error'],['error']
Availability,"```; $ python -m scanpy.tests.blackdiff 10. /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/travis/build/theislab/scanpy"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/travis/virtualenv/python3.7.1/bin/python: No module named scanpy.tests.blackdiff; ```. Not sure why this happened, but we well we're using black with pre-commit now anyways so w/e. Does this need fixing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785089639:209,error,errors,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785089639,2,['error'],['errors']
Availability,"```; FAILED scanpy/tests/test_plotting.py::test_violin - AssertionError: Error: Im...; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AssertionError: E...; ```. Sigh, again not related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1974#issuecomment-900226530:73,Error,Error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974#issuecomment-900226530,1,['Error'],['Error']
Availability,"```; Python 3.9.15 (main, Nov 24 2022, 14:31:59) ; [GCC 11.2.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. - [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2445:1479,error,error,1479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445,1,['error'],['error']
Availability,"```; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/plotting/_anndata.py:docstring of scanpy.plotting._anndata.dendrogram:31:Exception occurred in plotting scanpy-pl-dendrogram-1; from /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/docs/generated/scanpy.pl.dendrogram.rst:; Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/matplotlib/sphinxext/plot_directive.py"", line 517, in _run_code; exec(code, ns); File ""<string>"", line 3, in <module>; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/tools/_dendrogram.py"", line 139, in dendrogram; corr_condensed = distance.squareform(1 - corr_matrix); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2363, in squareform; is_valid_dm(X, throw=True, name='X'); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2444, in is_valid_dm; raise ValueError(('Distance matrix \'%s\' diagonal must '; ValueError: Distance matrix 'X' diagonal must be zero.; ```. Some dendrogram issue. The RTD build is also flaky.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590,1,['error'],['error']
Availability,"```; Warning, treated as error:; failed to reach any of the inventories with the following issues:; intersphinx inventory 'https://docs.scipy.org/doc/scipy/reference/objects.inv' not fetchable due to <class 'requests.exceptions.HTTPError'>: 404 Client Error: Not Found for url: https://docs.scipy.org/doc/scipy/reference/objects.inv; ```. Not my fault I guess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1974#issuecomment-891043388:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974#issuecomment-891043388,3,"['Error', 'error', 'fault']","['Error', 'error', 'fault']"
Availability,```; sc.__version__; '1.8.0.dev78+gc488909a'; ```. It seems to be working but I'm currently on a different dataset. What I noticed was that if I didn't have the same ID columns in my `adata.var` when setting adata.raw I couldn't use `gene_symbols`. After setting `adata.var` so it had the same IDs before setting `adata.raw` made it possible. ; In other words if adata.raw was missing the notation it failed for me (different error though). ; I will give an update when I get back to the dataset above. Just to make sure it's the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758#issuecomment-816317537:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758#issuecomment-816317537,1,['error'],['error']
Availability,"```py; >>> from math import sqrt ; >>> sqrt(-1); ValueError: math domain error; ```. I assume it’s the square root throwing this. Assuming that it only happens when you pass a negative argument, the term inside can only become negative if `ns[imask] < 0` or `ns[imask] > n_cells`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-477933420:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-477933420,1,['error'],['error']
Availability,"```py; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; categories_order=['0','1','9','8','2','5','4','7','3','6','10']; sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order); ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441:383,error,error,383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441,1,['error'],['error']
Availability,"```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed exec> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_pca.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 201 ); 202 ; --> 203 output = _pca_with_sparse(X, n_comps, solver=svd_solver); 204 # this is just a wrapper for the results; 205 X_pca = output['X_pca']. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_pca.py in _pca_with_sparse(X, npcs, solver, mu, random_state); 293 return XHmat(x) - mhmat(ones(x)); 294 ; --> 295 XL = LinearOperator(; 296 matvec=matvec,; 297 dtype=X.dtype,. TypeError: __init__() got an unexpected keyword argument 'rmatmat'; ```. I got this error once with the new spare PCA. @atarashansky do we need to write an explicit scipy version as dependency? It might be something weird with my setup too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-636055632:827,error,error,827,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-636055632,1,['error'],['error']
Availability,"```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385, in RMagics.eval(self, code); 383 try:; 384 # Need the newline in case the last line in code is a comment.; --> 385 value, visible = ro.r(""withVisible({%s\n})"" % code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459, in R.__call__(self, string); 458 p = rinterface.parse(string); --> 459 res = self.eval(p); 460 return conversion.get_conversion().rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:9,Error,Error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,2,"['Error', 'error']","['Error', 'error']"
Availability,"```pytb; package=scanpy; pversion=1.5.1 #found in docs/release-latest.rst after git download; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; cd /usr/common/src; git clone https://github.com/theislab/scanpy.git; cd scanpy; module load python3-libraries #for PYTHONPATH; python3 ./setup.py install \; --install-scripts=$TOPDIR/bin --prefix /usr/common \; 2>&1 | tee ../install_2020_06_10.log; #setup a module ""scanpy"" which puts $TOPDIR/bin on path and; #defines PYTHONPATH, then do; module load scanpy; scanpy; /home/common/lib/python3.6/site-packages/anndata/base.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; Traceback (most recent call last):; File ""/usr/common/modules/el8/x86_64/software/scanpy/1.5.1-CentOS-vanilla/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==1.5.2.dev7+ge33a2f33', 'console_scripts', 'scanpy')(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 490, in load_entry_point; return get_distribution(dist).load_entry_point(group, name); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2862, in load_entry_point; return ep.load(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2462, in load; return self.resolve(); File ""/usr/common/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2468, in resolve; module = __import__(self.module_name, fromlist=['__name__'], level=0); File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/__init__.py"", line 3, in <module>; from ._utils import pkg_version, check_versions, annotate_doc_types; File ""/home/common/lib/python3.6/site-packages/scanpy-1.5.2.dev7+ge33a2f33-py3.6.egg/scanpy/_utils.py"", line 17, in <module>; from anndata import AnnData; File ""/home/common/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273:84,down,download,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273,2,"['avail', 'down']","['available', 'download']"
Availability,"```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean""); ```. ```; AnnData object with n_obs × n_vars = 11 × 765; obs: 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; layers: 'mean'; ```. ```python; sc.get.aggregate(adata.obsm[""X_umap""], by=adata.obs[""louvain""].array, func=""mean""); ```. ```; {'mean': array([[ -6.18019123, -6.12846152],; [ -3.10995685, 8.4991954 ],; [ 6.30307056, -2.15245383],; [ -4.72268065, -3.24033642],; [-11.94002487, -5.39480163],; [ -1.39242794, 6.6239316 ],; [ 4.3991326 , -0.16749119],; [ 4.847834 , -9.30549509],; [-10.41891144, -1.15700949],; [ -7.91249486, -4.06782072],; [ 1.12418592, -6.94506866]])}; ```. So it returns an `AnnData` when an `AnnData` is passed, but a dict when a less structured object is passed. This is probably because it's `singledispatched` under the hood, but IDK that this behaviour is great. I think it could make more sense for this to either:. * Always return an `AnnData`; * Throw an error if something other than an AnnData is passed in. A third option is that we document this behaviour, but I generally don't love it. There are other places that we do something like this, i.e. return a different type depending on the input. However, I feel like there's more of a loss of information here and less of an obvious return type. Maybe in future this could get a `return_type: type[AnnData] | type[Dict] | type[xr.Dataset] = AnnData` argument that controls what is returned?. WDYT @ilan-gold @Intron7?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2930:1054,error,error,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2930,1,['error'],['error']
Availability,"```python; import scanpy as sc; import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); pbmc.write(""tmp.h5ad'); ```. ```pytb; NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>; <summary> Full traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 187 try:; --> 188 return func(elem, key, val, *args, **kwargs); 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs); 144 raise NotImplementedError(; --> 145 f""Failed to write value for {key}, ""; 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-2-1dd6b1c7e996> in <module>; 4 pbmc = sc.datasets.pbmc68k_reduced(); 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)); ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1988 compression_opts=compression_opts,; 1989 force_dense=force_dense,; -> 1990 as_dense=as_dense,; 1991 ); 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:365,error,error,365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,1,['error'],['error']
Availability,"``python; print(sc.__version__); # 1.10.3. # Randomly select 1000 cell indices; selected_cells = np.random.choice(adata.obs.index, size=1000, replace=False); # Create a subset AnnData object; subset_adata = adata[selected_cells].copy(); subset_adata.write(save_fold + ""subset_adata.h5ad""). #subset_known_markers = dict(list(filtered_known_markers.items())[:2]); tmp = ['Isl1', 'Tcf21', 'Tlx1'] ; [gene for gene in tmp if gene in subset_adata.var_names] == tmp # True; tmp = ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2'] ; [gene for gene in tmp if gene in subset_adata.var_names] == tmp # True; subset_known_markers = {; 'Anterior cardiopharyngeal progenitors_Imaz2024': ['Isl1', 'Tcf21', 'Tlx1'], ; 'Cardiomyocytes FHF 1_Imaz2024': ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2']; }; ; tmp = sc.tl.score_genes(subset_adata, gene_list= subset_known_markers, copy=True ; #,use_raw=True ; #,n_bins = 150 , ctrl_size =100; ) # ctrl_size = 50 by default ; n_bins = 25 by default; ```. ### Error output. ```pytb; WARNING: genes are not in var_names and ignored: ['Anterior cardiopharyngeal progenitors_Imaz2024', 'Cardiomyocytes FHF 1_Imaz2024']; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/project/xyang2/anaconda/py38/lib/python3.8/site-packages/scanpy/tools/_score_genes.py"", line 115, in score_genes; raise ValueError(""No valid genes were passed for scoring.""); ValueError: No valid genes were passed for scoring.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.4.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2023.5.0; dateutil 2.9.0.post0; h5py 3.11.0; igraph 0.11.6; importlib_resources NA; jinja2 3.1.4; joblib 1.4.2; kiwisolver 1.4.7; leidenalg 0.10.2; llvmlite 0.41.1; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.7.5; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.6; numpy 1.24.4; packaging 24.1; pandas 2.0.3; psutil 6.0.0; pyarrow 17.0.0; pyparsing 3.1.4; pytz 2024.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3266:1581,Error,Error,1581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3266,1,['Error'],['Error']
Availability,"`anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/167:164,error,error,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167,1,['error'],['error']
Availability,`clustermap` with sparse matrix throwing value error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['error'],['error']
Availability,"`compute_neighbors` method of the Neighbors class has a nice option called `write_knn_indices` which saves kNN indices into the Neighbors object. But this object and its members are not accessible from sc.pp.neighbors since we don't save the reference to it. . Making the write_knn_indices option available from `sc.pp.neighbors` gives access to knn indices which provide additional information on top of connectivities and distances since these matrices are symmetrized. . With knn_indices one can do cool things like building a mutual kNN graph, e.g.:. ```python; import scipy.sparse as sp. lm = sp.lil_matrix((adata.n_obs, adata.n_obs)); lm.rows = adata.uns['neighbors']['knn_indices']; lm.data = np.ones_like(adata.uns['neighbors']['knn_indices']); lm = lm.tocsr(); lm.setdiag(0); lm.eliminate_zeros(); lm = lm.multiply(lm.T) # build mnn mask. adata.uns['neighbors']['distances'] = adata.uns['neighbors']['distances'].multiply(lm); adata.uns['neighbors']['connectivities'] = adata.uns['neighbors']['connectivities'].multiply(lm); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/820:297,avail,available,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820,2,"['avail', 'mask']","['available', 'mask']"
Availability,`gprofiler` functionality is being added to scanpy? I have a small wrapper for that as well... the main components being a try-catch wrapper around it as it can give an error when there are no results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367,1,['error'],['error']
Availability,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:366,error,errors,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754,1,['error'],['errors']
Availability,"`louvain` and `leiden` have a lot of redundant documentation. After having learned in #557, I could file a PR to deduplicate this. Would it be valid to shuffle the arguments in such a way that the shared documentation is grouped together? Otherwise, one would have to introduce many short strings and puzzle them together.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/570:37,redundant,redundant,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570,1,['redundant'],['redundant']
Availability,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364331145:12,down,downloaded,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364331145,1,['down'],['downloaded']
Availability,"`pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0 py39hca03da5_0 ; appnope 0.1.2 py39hca03da5_1001 ; argon2-cffi 21.3.0 pyhd3eb1b0_0 ; argon2-cffi-bindings 21.2.0 py39h1a28f6b_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5167,error,error,5167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['error'],['error']
Availability,`plot_scatter` throws error when sparse layers used for color,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/700:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/700,1,['error'],['error']
Availability,`sc.datasets.paul15_raw()` fails with `attempted relative import beyond top-level package` error due to the wrong module path in `sc.utils.check_presence_download `. . Simply run `sc.datasets.paul15_raw()` or `sc.datasets.paul15()` to reproduce.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/67:91,error,error,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/67,1,['error'],['error']
Availability,`sc.external.pp.scrublet` Key error due to internal sc.pp.filter_cells/genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2377:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377,1,['error'],['error']
Availability,"`sc.pl.clustermap` fails with an error:. ```python; import scanpy as sc; adata = sc.datasets.krumsiek11(); sc.pl.clustermap(adata, obs_keys='cell_type'); ```. Output:. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-2-15436b6f0954> in <module>; 3 ; 4 adata = sc.datasets.krumsiek11(); ----> 5 sc.pl.clustermap(adata, obs_keys='cell_type'). ~/Code/scanpy/scanpy/plotting/_anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 777 adata.uns[obs_keys + '_colors'])); 778 row_colors = adata.obs[obs_keys].map(lut); --> 779 g = sns.clustermap(df, row_colors=row_colors, **kwds); 780 else:; 781 g = sns.clustermap(df, **kwds). ~/Code/seaborn/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,4,"['error', 'mask']","['error', 'mask']"
Availability,`sc.pl.paga` was throwing and error when the color list in `.uns` was not previously set. While fixing the error I realized that some functionality was duplicated between legacy scatter plots and the embedding plots and removed the code duplication.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/869:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869,2,['error'],['error']
Availability,"`sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True)`. always get the error. ```; TypeError Traceback (most recent call last); <ipython-input-40-5bc1cab6ebf2> in <module>; ----> 1 sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True). ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_stacked_violin.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 717 return vp; 718 else:; --> 719 vp.make_figure(); 720 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 721 show = settings.autoshow if show is None else show. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in make_figure(self); 738 if self.legends_width > 0:; 739 legend_ax = self.fig.add_subplot(gs[0, 1]); --> 740 self._plot_legend(legend_ax, return_ax_dict, normalize); 741 ; 742 self.ax_dict = return_ax_dict. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 535 color_legend_ax = fig.add_subplot(legend_gs[1]); 536 ; --> 537 self._plot_colorbar(color_legend_ax, normalize); 538 return_ax_dict['color_legend_ax'] = color_legend_ax; 539 . ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_colorbar(self, color_legend_ax, normalize); 508 import matplotlib.colorbar; 509 ; --> 510 matplotlib.colorbar.Colorbar(; 511 color_legend_ax, orientation='horizontal', cmap=cmap, norm=normalize; 512 ). TypeError: __init__() missing 1 required positional argument: 'mappable'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118,1,['error'],['error']
Availability,"`scanpy/scanpy/datasets/_datasets.py/starfish_to_anndata()` function coverts starfish expression matrix into AnnData object. Beside storing genes expression in X, var and obs it stores segmentioan/cell spatial data in obsm. . There are two issues unclear for me:. 1. Which module is the best place for such a function? I placed it in `_datasets.py` since it is a tool for converting one data type to another. 2. Travis CI build raises an error: ""docstring should start with one-line description"" but it has a one-line description.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362:438,error,error,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362,1,['error'],['error']
Availability,"`twine check` is not great at telling you why it's failing. It would be easier to figure out what caused the break if we were continuously checking for this. Inspired by finding out that `authors` can't have new lines, via an error that says `long_description` can't have section headings (which definitely isn't true).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1585:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585,1,['error'],['error']
Availability,"a can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 try:; ---> 66 from skmisc.loess import loess; 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); Cell In[14], line 1; ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'); 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:1629,error,error,1629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"a.obs[groups_key].astype(str).values; 731 if reference == 'rest':. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value); 2936 else:; 2937 # set column; -> 2938 self._set_item(key, value); 2939 ; 2940 def _setitem_slice(self, key, value):. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value); 2997 """"""; 2998 ; -> 2999 self._ensure_valid_index(value); 3000 value = self._sanitize_column(key, value); 3001 NDFrame._set_item(self, key, value). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value); 3052 if not len(self.index) and is_list_like(value) and len(value):; 3053 try:; -> 3054 value = Series(value); 3055 except (ValueError, NotImplementedError, TypeError):; 3056 raise ValueError(. ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/miniconda3/envs/scrna/lib/python3.7/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 480 elif subarr.ndim > 1:; 481 if isinstance(data, np.ndarray):; --> 482 raise Exception(""Data must be 1-dimensional""); 483 else:; 484 subarr = com.asarray_tuplesafe(data, dtype=dtype). Exception: Data must be 1-dimensional; ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.3 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.6.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1199:2440,Error,Error,2440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199,1,['Error'],['Error']
Availability,a.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2179,Error,Error,2179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,a.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_vi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1924,Error,Error,1924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"a/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:5806,avail,available,5806,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['avail'],['available']
Availability,"a/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4609,down,downgraded,4609,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['down'],['downgraded']
Availability,"a3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True.; @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)); * parameterized; In definition 0:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; In definition 1:; TypeError: norm_impl() got an unexpected keyword argument 'x'; raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>); [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:; def l2_norm(in_matrix):; return np.linalg.norm(x=in_matrix, axis=1); ^. @jit(float32[:](float32[:, :]), nogil=True); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:; @jit(float32[:](float32[:, :]), nogil=True); def l2_norm(in_matrix):; ^. state.func_ir.loc)); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167:1804,error,error,1804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167,8,['error'],['error']
Availability,"a3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 233 palette=palette,; 234 use_raw=use_raw,; --> 235 gene_symbols=gene_symbols,; 236 ); 237 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1035 ] # TODO: Throw helpful error if this doesn't work; 1036 if use_raw and value_to_plot not in adata.obs.columns:; -> 1037 values = adata.raw.obs_vector(value_to_plot); 1038 else:; 1039 values = adata.obs_vector(value_to_plot, layer=layer). /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:2313,error,error,2313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['error'],['error']
Availability,"a_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2480,Error,Error,2480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['Error'],['Error']
Availability,able_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4789,ERROR,ERROR,4789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"ace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m); ); dblX = pos * adata.X; # TODO: Downsample total counts; srcs = np.sort(combos.reshape(n_doublets, 2), axis=1); obs = pd.DataFrame(srcs, columns=[""src1"", ""src2""]); var = pd.DataFrame(index=adata.var_names); return sc.AnnData(dblX, obs=obs, var=var). # Load data. # http: // cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5; pbmc = sc.read_10x_h5(""./data/10x/pbmc_10k_v3_filtered_feature_bc_matrix.h5""); pbmc.var[""gene_symbols""] = pbmc.var.index; pbmc.var.set_index(""gene_ids"", inplace=True). dblt = simulate_doublets(pbmc); dblt.var[""gene_symbols""] = pbmc.var[""gene_symbols""]. pbmc.raw = pbmc; dblt.raw = dblt. pbmc = preprocess(pbmc); dblt = preprocess(dblt). sc.pp.pca(pbmc); pca_update(dblt, pbmc). umap = UMAP(); pbmc.obsm[""X_umap""] = umap.fit_transform(pbmc.obsm[""X_pca""]); dblt.obsm[""X_umap""] = umap.transform(dblt.obsm[""X_pca""]). sc.tl.embedding_density(pbmc, ""umap""); sc.tl.embedding_density(dblt, ""umap""); ```; </details>. <details> ; <summary> Getting setup for datashader plots (much sh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:2035,Down,Downsample,2035,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384,1,['Down'],['Downsample']
Availability,"acked, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 484 d[key] = None; 485 else:; --> 486 _read_key_value_from_h5(f, d, key, chunk_size=chunk_size); 487 # backwards compat: save X with the correct name; 488 if 'X' not in d:. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 508 d[key_write] = OrderedDict() if key == 'uns' else {}; 509 for k in f[key].keys():; --> 510 _read_key_value_from_h5(f, d[key_write], key + '/' + k, k, chunk_size); 511 return; 512 . /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in _read_key_value_from_h5(f, d, key, key_write, chunk_size); 542 return key, value; 543 ; --> 544 key, value = postprocess_reading(key, value); 545 d[key_write] = value; 546 return. /opt/miniconda3/envs/py37/lib/python3.7/site-packages/anndata/readwrite/read.py in postprocess_reading(key, value); 539 new_dtype = [((dt[0], 'U{}'.format(int(int(dt[1][2:])/4))); 540 if dt[1][1] == 'S' else dt) for dt in value.dtype.descr]; --> 541 value = value.astype(new_dtype); 542 return key, value; 543 . ValueError: invalid shape in fixed-type tuple.; ```. Any idea what is going on or what I can do to make it past this error? It only started happening after I updated my operating system to Ubuntu 18 and my Python to 3.7 and reinstalled scanpy from conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832:3652,error,error,3652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832,1,['error'],['error']
Availability,"aconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate; raise ArpackError(self.info, infodict=self.iterate_infodict); scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > ; <!-- Relevant screenshots -->. Thanks; Patrick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2473:2300,error,error,2300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473,1,['error'],['error']
Availability,"actual bug or me using the package wrong. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; from anndata import AnnData. p_value_threshold = 0.05; # Create a minimalistic AnnData object; data = np.random.rand(1000, 5) # 1000 cells, 5 genes; obs = pd.DataFrame(index=[f'cell{i}' for i in range(1000)]); var = pd.DataFrame(index=[f'gene{i}' for i in range(5)]); adata = AnnData(X=data, obs=obs, var=var). # Add a 'gene' column to obs to use as groupby; adata.obs['gene'] = np.random.choice(['sample0', 'sample1', 'sample2', 'sample3', 'sample4'], size=1000). # Define groups; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:1911,mask,mask,1911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,4,['mask'],['mask']
Availability,"adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430:3862,toler,tolerance,3862,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430,1,['toler'],['tolerance']
Availability,"add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:1557,error,error,1557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,1,['error'],['error']
Availability,add a mask argument,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234:6,mask,mask,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234,1,['mask'],['mask']
Availability,add robust installation instructions again,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1140:4,robust,robust,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140,1,['robust'],['robust']
Availability,added a downsample function to downsample the counts,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/99:8,down,downsample,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/99,2,['down'],['downsample']
Availability,"after I have used bbknn and ump these two steps, when I use the louvain, It gives me a System Error. ; Note: my dataset is too big. I want help!! thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1980#issuecomment-899489219:94,Error,Error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980#issuecomment-899489219,1,['Error'],['Error']
Availability,"after running sc.pp.highly_variable_genes, the sc.pp.scale get error？？？",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738,1,['error'],['error']
Availability,aga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1781,Error,Error,1781,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,age files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3207,Error,Error,3207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,age files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_mat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3832,Error,Error,3832,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,aggregate throws error when aggregating `obsm` or `varm`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,1,['error'],['error']
Availability,"ah it seems a really minor tolerance thingy, try to increase it to 16 should be fine; ```; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266:27,toler,tolerance,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266,1,['toler'],['tolerance']
Availability,al' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42274,Error,Error,42274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"al\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4479,down,downloads,4479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['down'],['downloads']
Availability,alize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13425,ERROR,ERROR,13425,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,alize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13217,ERROR,ERROR,13217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11539,ERROR,ERROR,11539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11964,ERROR,ERROR,11964,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6402,ERROR,ERROR,6402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11324,ERROR,ERROR,11324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11749,ERROR,ERROR,11749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15323,ERROR,ERROR,15323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,als_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18473,ERROR,ERROR,18473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ame, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in sanitize_ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:1783,Mask,MaskedArray,1783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885,1,['Mask'],['MaskedArray']
Availability,ames to fa2.egg-info/top_level.txt; writing manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/ve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:5742,error,error,5742,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1916,error,errors,1916,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010,1,['error'],['errors']
Availability,an...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62692,ERROR,ERROR,62692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,and fixed an error with plotting functions that I think I caused when I merged with master. I will set this PR as work in progress as I will be adding more tests.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207,1,['error'],['error']
Availability,"anges from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(fold_change_matrix)) > np.log2(min_fold_change))` (similar to @gianasco's suggestion, but handles downregulated fold changes more appropriately). I noted this issue separately in #1325",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:1898,down,downregulated,1898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,2,['down'],['downregulated']
Availability,anhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20548,ERROR,ERROR,20548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61221,ERROR,ERROR,61221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example; ```python; import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data; adata = sc.read_h5ad(dataset_path, backed='r'); print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here; ```. #### Error output; ```pytb; # I printed the AnnData object to ensure it was backed; AnnData object with n_obs × n_vars = 4166 × 16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'; obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'; var: 'gene_symbol', 'n_cells'; obsm: 'X_tsne'. # Actual error after calling log1p; Traceback (most recent call last):; File ""log1p_test.cgi"", line 129, in <module>; main(); File ""log1p_test.cgi"", line 81, in main; adata.raw = sc.pp.log1p(adata, copy=True); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p; data = data.copy(); File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy; ""To copy an AnnData object in backed mode, ""; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`.; ```. #### Versions:; scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:1261,error,error,1261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,1,['error'],['error']
Availability,anpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10997,mask,mask-,10997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,anpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68586,ERROR,ERROR,68586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70053,ERROR,ERROR,70053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71043,ERROR,ERROR,71043,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65002,ERROR,ERROR,65002,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62368,ERROR,ERROR,62368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preproce,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63680,ERROR,ERROR,63680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metric,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67940,ERROR,ERROR,67940,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2592:1932,error,error,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592,2,['error'],['error']
Availability,"are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community feedback into the development of scanpy / anndata. All this said, your tools do provide a bunch of amazing functionality that I rely on for my PhD. I really appreciate all the effort you've put in. I especially love how easy it is to run louvain / leiden, and how supportive you've been to people adding external tools to scanpy so they can be made accessible to the broader community of single cell users in Python. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:1714,down,down,1714,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,1,['down'],['down']
Availability,"are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:1034,Error,Error,1034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['Error'],['Error']
Availability,"args; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in fillna(self, value, method, limit); 1871 elif is_hashable(value):; 1872 if not isna(value) and value not in self.categories:; -> 1873 raise ValueError(""fill value must be in categories""); 1874 ; 1875 mask = codes == -1. ValueError: fill value must be in categories; ```. That's because `colors = colors.fillna('white')` line in the seaborn code is trying to add a new category to a categorical variable, which is not allowed in pandas. I simply converted the color categorical variable to numpy array and added tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:3652,mask,mask,3652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['mask'],['mask']
Availability,arson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkn,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22829,ERROR,ERROR,22829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3456 if self.columns.nlevels > 1:; 3457 return self._getitem_multilevel(key); -> 3458 indexer = self.columns.get_loc(key); 3459 if is_integer(indexer):; 3460 indexer = [indexer]. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 ; 3365 if is_scalar(key) and isna(key) and not self.hasnans:. KeyError: 1; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053:2455,toler,tolerance,2455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053,1,['toler'],['tolerance']
Availability,"as the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:6293,error,errors,6293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,1,['error'],['errors']
Availability,as2-0.3.5/examples/geometric_graph.png; x forceatlas2-0.3.5/examples/grid_graph.png; x forceatlas2-0.3.5/fa2/; x forceatlas2-0.3.5/fa2/__init__.py; x forceatlas2-0.3.5/fa2/fa2util.c; x forceatlas2-0.3.5/fa2/fa2util.pxd; x forceatlas2-0.3.5/fa2/fa2util.py; x forceatlas2-0.3.5/fa2/forceatlas2.py; x forceatlas2-0.3.5/setup.py; test@mac ~/PythonPackages$ cd forceatlas2-0.3.5/; test@mac ~/PythonPackages/forceatlas2-0.3.5$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2-0.3.5; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; error: subprocess-exited-with-error; ; × python setup.py bdist_wheel did not run successfully.; │ exit code: 1; ╰─> [214 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running bdist_wheel; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; creating fa2.egg-info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; writing manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:3934,error,error,3934,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,['error'],['error']
Availability,"as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\pandas\core\internals\construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). ~\AppData\Local\Continuum\anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/924:2271,Mask,MaskedArray,2271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/924,1,['Mask'],['MaskedArray']
Availability,"ase be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the clipping part of scaling function. ; | | Time(sec)|; | -----------| ----- |; | Original | 11.82 |; | Updated | 1.59 |; | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100:1047,Down,Downloading,1047,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100,1,['Down'],['Downloading']
Availability,"at this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I tried to run the code below on a Windows laptop and received the error (also below). I've tried uninstalling and reinstalling igraph, leidenalg, and scanpy. I tried running the code with flavor=""leidenalg"" and got the same/basically the same error. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"", ; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; TypeError Traceback (most recent call last); Cell In[159], line 1; ----> 1 sc.tl.leiden( #So leidan is identifying and coloring clusters for you, but not changing the shape of the graph.; 2 adata, #lets just pretend that I understand what each of those things mean; 3 resolution=0.9,; 4 random_state=0,; 5 flavor=""igraph"", #did pip install leidenalg and started receiving the no flavor keyword error; https://github.com/scverse/scanpy/issues/350 indicates this is to be expected, but https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.leiden.html indicates it should have it ; 6 n_iterations=2,; 7 directed=False,; 8 ). File ~\miniconda3\Lib\site-packages\scanpy\tools\_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 msg = 'In the future, the default backend for leiden will be igraph instead of leidenalg.\n\n To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph\'s implementation.'; 143 _utils.warn_once(msg, FutureWarning, stacklevel=3); --> 144 except ImportError:; 145 raise ImportError(; 146 ""Please install the leiden algorithm: `conda install -c conda-forge leidenalg` or `pip3 install leidenalg`.""; 147 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981:1116,error,error,1116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981,1,['error'],['error']
Availability,"atched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:6557,error,error,6557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['error'],['error']
Availability,"ategories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 ); 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'; ```. First, what's up with the printed error?. Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>; <summary> </summary>. ```python; -----; anndata 0.7.7.dev4+g49739eb; scanpy 1.9.0.dev7+g092376d2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:2142,error,error,2142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,1,['error'],['error']
Availability,atial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1371,ERROR,ERROR,1371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"b.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32744,error,errors,32744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,"b/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (401)>, 306: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (402)>, 118: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397)>}Var(parfor_index.271, _qc.py:397)"" at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (397). This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ```; numba is 0.47.0 but 0.43.1 gave the same error.; It seems that ```top_segment_proportions_sparse_csr``` is new for scanpy 1.4.5. Please help. Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:4918,error,errors,4918,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,3,['error'],"['error', 'errors']"
Availability,b/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ############################################################################# | 100% ; libev-4.33 | 104 KB | ############################################################################# | 100% ; libnghttp2-1.46.0 | 680 KB | ############################################################################# | 100% ; libcurl-7.82.0 | 342 KB | ############################################################################# | 100% ; libssh2-1.10.0 | 233 KB | ###########################################################,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2265:2132,Down,Downloading,2132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265,1,['Down'],['Downloading']
Availability,"b/theislab/paga/blob/master/blood/dahlin18/dahlin18.ipynb). And in the part where it calls the UMAP function providing it with the PAGA initial points (line 28 in the notebook: `sc.tl.umap(adata, init_pos='paga')`), I'm getting this error message:. ```; computing UMAP; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/nr/miniconda3/lib/python3.7/site-packages/scanpy/tools/_umap.py"", line 145, in umap; verbose=settings.verbosity > 3,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 1005, in simplicial_set_embedding; verbose=verbose,; File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 401, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py"", line 344, in error_rewrite; reraise(type(e), e, None); File ""/home/nr/miniconda3/lib/python3.7/site-packages/numba/six.py"", line 668, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)) with parameters (array(float64, 1d, C), array(float32, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f8ffd913050>)); [2] During: typing of call at /home/nr/miniconda3/lib/python3.7/site-packages/umap/umap_.py (795). File ""miniconda3/lib/python3.7/site-packages/umap/umap_.py"", line 795:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/948:1086,error,errors,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/948,1,['error'],['errors']
Availability,"baforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; ============================== 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55) ==============================; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7875,Error,Error,7875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,4,['Error'],['Error']
Availability,bbknn error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/632:6,error,error,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/632,1,['error'],['error']
Availability,"bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:2426,Error,Error,2426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,"bors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). ```; This outputs the following. ```; 0; 134513; 37696; 0 659; 1 605; 2 398; 3 352; 4 342; 5 174; 6 118; 7 41; 8 11; Name: leiden, dtype: int64; 0 527; 1 484; 2 398; 3 324; 4 320; 5 301; 6 174; 7 109; 8 52; 9 11; Name: leiden, dtype: int64. 0; 134127; 37278; 0 646; 1 617; 2 382; 3 362; 4 334; 5 173; 6 129; 7 46; 8 11; Name: leiden, dtype: int64; 0 646; 1 631; 2 408; 3 349; 4 334; 5 170; 6 106; 7 45; 8 11; Name: leiden, dtype: int64. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions(). -->; scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187:4253,Error,Error,4253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187,1,['Error'],['Error']
Availability,"bs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); plt.show(); ```. Essentially the same thing but colored by the percentage of mitochondrial counts.; Only one legend seems to be drawn and this one is not looking as expected. Plus, I cannot remove the legend from the first plot. ; This is how it looks:; ![image](https://user-images.githubusercontent.com/50995210/83322257-6f838980-a256-11ea-83a5-bd0b4dfa4180.png). Why doesn't it behave in the same way like in the example above?; Is there a way I can share the same legend with a scale from 0 to 1 (0%-100%) for both plots in this case?; As you can see, the line removing the legend from `sc_ax1` is commented out because `get_legend()` returns `None` in this case, which would lead to the error below:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-154-702da93b63cb> in <module>; 2 sc_fig, (sc_ax1, sc_ax2) = plt.subplots(1,2, figsize=(12,5)); 3 sc.pl.scatter(adata_raw, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax1, show=False, title=""all counts""); ----> 4 sc_ax1.get_legend().remove(); 5 sc.pl.scatter(adata_raw[adata_raw.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, ax=sc_ax2, show=False, title=""< 1000 counts""); 6 plt.show(). AttributeError: 'NoneType' object has no attribute 'remove'; ```; Shouldn't the legends be attached to the individual axes objects?; I cannot access them and I wonder where they are stored in this case. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.2.dev5+ge5d246aa anndata==0.7.1 umap==0.4.3 numpy==1.18.4 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.23.0 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258:2488,Error,Error,2488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258,1,['Error'],['Error']
Availability,"but when i run ; sc.pl.pca(adata, color='CST3'); it return the error,how could i fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802,1,['error'],['error']
Availability,"by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons; - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object; - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:; ```python; if img is _empty:; 	ax.invert_yaxis(); ```; This is the behviour; ```python; sc.pl.embedding(adata, color=""leiden"", basis=""spatial""); ```. <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python; sc.pl.spatial(adata, color=""leiden"", img_key=None); ```. <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. -------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514:3012,down,down,3012,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514,1,['down'],['down']
Availability,c 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55402,ERROR,ERROR,55402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6619,ERROR,ERROR,6619,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15751,ERROR,ERROR,15751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15965,ERROR,ERROR,15965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,calculate_qc_metrics error in scanpy 1.4.5 and above,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1241#issuecomment-635926781:25,failure,failure,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241#issuecomment-635926781,1,['failure'],['failure']
Availability,can...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61545,ERROR,ERROR,61545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"canpy. I have an AnnData object:. print(adata). AnnData object with n_obs × n_vars = 77430 × 1988 ; obs: 'CONDITION', 'input.path', 'experiment', 'Sample type', 'BiOmics Sample Name', 'PatientID', 'SampleID', 'Response', 'Respond', 'Response2', 'Adjuvant', 'CIT', 'CIT2', 'Lesion2', 'Lesion', 'Stage', 'Fresh', 'CD3IHC', 'CD3IHC_RICZ', 'Mutation2', 'Mutation', 'Site', 'Age', 'Gender', 'PBMCs', 'PBMCs2', 'Seq samples', 'Quality', 'n_counts', 'n_genes', 'percent_mito', 'n_cPg', 'n_cPg2', 'batch', 'louvain'; var: 'symbol', 'n_cells'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'. To label the dotplot with gene symbols instead of ensemblID (index column) I use the gene_symbols parameter:. sc.pl.dotplot(adata=adata, var_names = ['ENSG00000104814','ENSG00000043462'], gene_symbols='symbol'). But I get the following error:. Error: Gene symbol 'ENSG00000104814' not found in given gene_symbols column: 'symbol'; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-58-6d92e2cc2451> in <module>; 4 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, save=title+'_'+myg_geneID+'.png'); 5 if type(myg_geneID_orig) == list:; ----> 6 sc.pl.dotplot(adata, myg, groupby=condition,dot_min=0,dot_max=0.2,vmin=0,vmax=0.2, gene_symbols='symbol', save=title+'_multiple_genes'+'.png'). /pstore/apps/bioinfo/scseq/modules/software/Scanpy/1.4.1-foss-2018b-Python-3.7.1-2018.12/lib/python3.7/site-packages/scanpy-1.4.1-py3.7.egg/scanpy/plotting/_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, figsize, dendrogram, gene_symbols, var_group_positions, standard_scale, smallest_dot, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1383 var_names = [var_names]; 1384 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1412:1089,Error,Error,1089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1412,1,['Error'],['Error']
Availability,"canpy/datasets/; [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent; ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │; ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent; ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │; │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │; │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │; │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │; │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │; │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │; │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │; │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │; ╰───┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────╯; ```. > What was stopping this before? […] why wouldn't we want to download the data everytime?. someone implementing the caching, so nothing much really",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252:2127,down,download,2127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252,1,['down'],['download']
Availability,"canpy/preprocessing/utils.py in _get_mean_var(X); 16 mean_sq = np.multiply(X, X).mean(axis=0); 17 # enforece R convention (unbiased estimator) for variance; ---> 18 var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); 19 else:; 20 from sklearn.preprocessing import StandardScaler. ~/miniconda3/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py in pow(self, other); 226; 227 def pow(self, other):; --> 228 return matrix_power(self, other); 229; 230 def ipow(self, other):. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in matrix_power(a, n); 600 a = asanyarray(a); 601 _assertRankAtLeast2(a); --> 602 _assertNdSquareness(a); 603; 604 try:. ~/miniconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py in _assertNdSquareness(*arrays); 213 m, n = a.shape[-2:]; 214 if m != n:; --> 215 raise LinAlgError('Last 2 dimensions of the array must be square'); 216; 217 def _assertFinite(*arrays):; ```. </details>. Versions of my modules:; scanpy==1.3.7 anndata==0.6.17 numpy==1.15.4 scipy==1.2.0 pandas==0.24.0 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. I have downgraded pandas to 0.23.4, however, it not works. But I figured out where the problem lies in. ```py; adata.X /= adata.obs['size_factors'].values[:,None]; ```. This step transform the adata.X to a structure of matrix.; Before the adata.X is. ```; <6242x15065 sparse matrix of type '<class 'numpy.float32'>'; with 19234986 stored elements in Compressed Sparse Row format>; ```. But after performing this step, the adata.X is; This is my adata.X looks like right now:. ```py; matrix([[0. , 0. , 0. , ..., 0. , 0. , 0. ],; [0. , 0. , 1.203, ..., 0. , 0. , 0. ],; [0. , 1.096, 0. , ..., 0. , 0. , 0. ],; ...,; [0. , 0. , 2.042, ..., 0. , 0. , 0. ],; [0. , 0. , 0. , ..., 0.926, 0. , 0. ],; [0. , 0. , 2.951, ..., 0. , 0. , 0. ]]),; ```. And this format of adata.X caused error of sc.pp.highly_variable_genes. But I don't know how to fix it. Looking forward your response!; Thank you !",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456:2206,down,downgraded,2206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456,2,"['down', 'error']","['downgraded', 'error']"
Availability,canpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_ra,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66125,ERROR,ERROR,66125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,canpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60571,ERROR,ERROR,60571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,canpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64008,ERROR,ERROR,64008,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"cast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=value, limit=limit); 1937 return [; 1938 self.make_block_same_class(. /usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 206 else:; 207 kwargs[new_arg_name] = new_arg_value; --> 208 return func(*args, **kwargs); 209 ; 210 return wrapper. /usr/local/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in fillna(self, value, method, limit); 1871 elif is_hashable(value):; 1872 if not isna(value) and value not in self.categories:; -> 1873 raise ValueError(""fill value must be in categories""); 1874 ; 1875 mask = codes == -1. ValueError: fill value must be in categories; ```. That's because `colors = colors.fillna('white')` line in the seaborn code is trying to add a new category to a categorical variable, which is not allowed in pandas. I simply converted the color categorical variable to n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2911,down,downcast,2911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,2,['down'],['downcast']
Availability,cation); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - Impo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2034,ERROR,ERROR,2034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"cc: @Zethson @grst. Hey, . In principle this sounds good, but I'd like to hear a little bit more about the usecase. For context on our side, there are some other paths for speeding up DE available (probably some form of calculating statistics via https://github.com/scverse/anndata/pull/564). There're also increased momentum on more featureful DE in the scverse ecosystem. If you are specifically looking for faster scanpy DE, this makes sense, though there may be some easier paths forward (at least to me). If you need anything fancier or even just different, it could be good to check in with other efforts. E.g. . * https://github.com/theislab/pertpy/issues/189",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639:187,avail,available,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639,1,['avail'],['available']
Availability,"ce.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:4377,error,errors,4377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"cell cycle**; The lower part of the plot shows regress out applied to the cell cycle (following [the scanpy tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb) and the 'alternative approach' described in the [seurat vignette](https://satijalab.org/seurat/cell_cycle_vignette.html#assign-cell-cycle-scores), i.e. I regressed out the difference between the G2M and S phase scores):; ```; adata.obs[""cell_cycle_diff""] = adata.obs[""S_score""] - adata.obs[""G2M_score""]; sc.pp.regress_out(adata, ['cell_cycle_diff']); ```; Like that, the differences between dividing and non-dividing cells should be preserved. ; Again, in the *Savas* dataset, after regressing out the cell cycle effects, G1 is correctly separated from G2M/S. In *Lambrechts*, there is no clear separation. Having eyeballed at the UMAP-plot (below) it seems that the cell-cycle labels correlate with the cell type (i.e. cancer cells and myeloid cells got the G1 label assigned more likely than T cells). . **What is 'best practice'?**; I quickly discussed this offline with @flying-sheep, and he encouraged me to create this issue. . * Is it just a problem with visualizing the first PC's and `regress_out` should be applied regardless; * Should `regress_out` be skipped and only applied in a more downstream step when focusing on a single cell type? ; * Are there any other situations where `regress_out` could do more harm than good? . **PCA plots before and after `regress_out`**; ![regress_out](https://user-images.githubusercontent.com/7051479/54083302-f088f500-4321-11e9-877a-1cbef6f4f489.png). **UMAP-plots**; The cell cycle label correlates with the cell type (other dataset, but to show what I mean): ; ![2019-03-10_11:20:31_384x234](https://user-images.githubusercontent.com/7051479/54083671-29779880-4327-11e9-94d6-9be34383b909.png); ![2019-03-10_11:25:30_428x231](https://user-images.githubusercontent.com/7051479/54083675-3a280e80-4327-11e9-954f-34ef1404961b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526:2507,down,downstream,2507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526,1,['down'],['downstream']
Availability,center-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4971,Error,Error,4971,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"ception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed; backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read; **kwargs,; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read; is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download; _download(backup_url, path); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download; urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open; response = self._open(req, data); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open; '_open', req); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open; context=self._context, check_hostname=self._check_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open; raise URLError(err); urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:3520,error,error,3520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,2,['error'],['error']
Availability,cessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71381,ERROR,ERROR,71381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a lon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1402,down,download,1402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['download']
Availability,"cipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; ============================== 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55) ====",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7742,Error,Error,7742,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,cloudpickle 3.0.0; colorama 0.4.6; colorlog NA; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; dragonnfruit 0.3.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; filelock 3.13.1; fqdn NA; fsspec 2024.3.1; goatools 1.3.11; google NA; h5py 3.10.0; hdf5plugin 4.4.0; idna 3.6; igraph 0.11.4; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 0.9.24; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.13.0; jupyterlab_server 2.25.4; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.6.2; mpl_toolkits NA; msgpack 1.0.8; mudata 0.2.3; muon 0.1.5; mygene 3.2.2; natsort 8.4.0; nbformat 5.10.3; networkx 3.2.1; numba 0.59.1; numexpr 2.9.0; numpy 1.26.4; optree 0.10.0; optuna 3.6.0; overrides NA; packaging 24.0; pandas 1.5.3; pandas_flavor NA; parso 0.8.3; patsy 0.5.6; pingouin 0.5.4; pkg_resources NA; platformdirs 4.2.0; plotly 5.20.0; prometheus_client NA; prompt_toolkit 3.0.43; psutil 5.9.8; pure_eval 0.2.2; pyBigWig 0.3.22; pyarrow 15.0.2; pychromvar 0.0.4; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 2.0.0; pyfaidx 0.8.1.1; pygments 2.17.2; pyjaspar 3.0.0; pynndescent 0.5.11; pyparsing 3.1.2; pysam 0.22.0; pythonjsonlogger NA; pytz 2024.1; ray 2.10.0; referencing NA; requests 2.31.0; requests_cache 1.2.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; rpds NA; scipy 1.12.0; seaborn 0.13.2; send2trash NA; session_info 1.0.0; setproctitle 1.2.2; simplejson 3.19.2; sitecustomize NA; six 1.16.0; sklearn 1.4.1.post1; sniffio 1.3.1; stack_data 0.6.3; statsmodels 0.14.1; swig_runtime_data4 NA; tabulate 0.9.0; tensorboard 2.16.2; texttable 1.7.0; threadpoolctl 3.4.0; torch 2.2.1+cu121; torchgen NA; tornado 6.4; tqdm 4.66.2; traitlets 5.14.2; typing_extensions N,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3014:3009,ping,pingouin,3009,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014,1,['ping'],['pingouin']
Availability,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1886,avail,available,1886,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103,1,['avail'],['available']
Availability,"code:. ```py; sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['13'], reference= '18' ). Error:; ValueError: reference = 18 needs to be one of group_by = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]; ```. I think the problem is the code comfuse str(18) and int(18). could you solve it? Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/94:97,Error,Error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94,1,['Error'],['Error']
Availability,"column to obs to use as groupby; adata.obs['gene'] = np.random.choice(['sample0', 'sample1', 'sample2', 'sample3', 'sample4'], size=1000). # Define groups; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA; apport_python_hook NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; cairo 1.20.1; certifi 2024.07.04; cffi 1.16.0; chardet 4.0.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.4; comm 0.2.2; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.8.0; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; gi 3.42.1; gio NA; glib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:2386,mask,mask,2386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,4,['mask'],['mask']
Availability,combat processing errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170,1,['error'],['errors']
Availability,"conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:5866,avail,available,5866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['avail'],['available']
Availability,"copy&paste without having any data). ```python; import scanpy; acc = ""E-MTAB-4888""; ad_df = scanpy.datasets.ebi_expression_atlas(acc); ```. ```pytb; File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response); [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:1419,error,error,1419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,1,['error'],['error']
Availability,"coxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!. _Originally posted by @HKanenew in https://github.com/theislab/scanpy/issues/530#issuecomment-505305611_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:2302,error,error,2302,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Version('0.10.6')>; ```. </details>. Interesting to see that this seems to work now!. I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:1188,Down,Downloading,1188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,"cs.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:1096,avail,available,1096,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,2,"['avail', 'error']","['available', 'error']"
Availability,"cs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```; modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership); q = modularity_part.quality(); ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :); > ; > A couple follow up points on this and @LuckyMD's points; > ; > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores.; > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088:2951,avail,available,2951,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088,1,['avail'],['available']
Availability,csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4113,ERROR,ERROR,4113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"cted keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608:1395,error,error,1395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608,1,['error'],['error']
Availability,d 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_gen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2486,Error,Error,2486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"d'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 43",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1652,Error,Error,1652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['Error'],['Error']
Availability,"d/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: Can't convert 'list' object to str implicitly; ; ----------------------------------------; Failed building wheel for scanpy; Running setup.py clean for scanpy; Running setup.py bdist_wheel for anndata ... done; Stored in directory: /root/.cache/pip/wheels/f1/f0/02/ea67db3107825884bae91e3806e425718f10062c631e2b1367; Running setup.py bdist_wheel for networkx ... done; Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91; Successfully built anndata networkx; Failed to build scanpy; Installing collected packages: six, python-dateutil, pytz, numpy, pandas, scipy, h5py, natsort, anndata, pyparsing, cycler, kiwisolver, matplotlib, seaborn, numexpr, tables, scikit-learn, patsy, statsmodels, decorator, networkx, joblib, llvmlite, numba, scanpy; Running setup.py install for scanpy ... error; Complete output from command /usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile:; /usr/lib/python3.5/distutils/dist.py:261: UserWarning: Unknown distribution option: 'python_requires'; warnings.warn(msg); running install; running build; running build_py; creating build; creating build/lib; creating build/lib/scanpy; copying scanpy/settings.py -> build/lib/scanpy; copying scanpy/readwrite.py -> build/lib/scanpy; copying scanpy/_version.py -> build/lib/scanpy; copying scanpy/__init__.py -> build/lib/scanpy; copying scanpy/utils.py -> build/lib/scanpy; copying scanpy/logging.py -> build/lib/scanpy; copying scanpy/exporting.py -> build/lib/scanpy; creating build/lib/scanpy/preprocessing; copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing; copying scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:3388,error,error,3388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,1,['error'],['error']
Availability,"d; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:2782,down,downloads,2782,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,2,"['ERROR', 'down']","['ERROR', 'downloads']"
Availability,"dFragment-->; </body>; </html>. Both tutorial adatas after a successful ingest:; ```. (AnnData object with n_obs × n_vars = 700 × 208; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap', 'rep'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 2638 × 208; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. Now my data, adata_ref:. <html><body>; <!--StartFragment--><div class=""lm-Widget p-Widget lm-Panel p-Panel jp-Cell-inputWrapper""><div class=""lm-Widget p-Widget jp-InputArea jp-Cell-inputArea"">.   | celltype | louvain; -- | -- | --; cell1 | hepatic stellate cells | 1; cell2 | cholangiocytes | 1; ... | ... | ... <p>8439 rows × 2 columns</p>; </div></div><!--EndFragment-->; </body>; </html>. and my adata that I wish to ingest:. <html><body>; <!--StartFragment-->.   | louvain; -- | --; cell1 | 0; cell2 | 0; ... <!--EndFragment-->; </body>; </html>. Both my adata files have the same 40 variables and pca/umaps, they look like this:. ```; (AnnData object with n_obs × n_vars = 8989 × 40; obs: 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 8439 × 40; obs: 'celltype', 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. I suspect the error stems from the Nearest Neighbours. Or maybe my number of variables (40) is too small?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383:3230,error,error,3230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383,1,['error'],['error']
Availability,"da3/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py in wrapper(*args, **kwargs); 367 f""%(removal)s. If any parameter follows {name!r}, they ""; 368 f""should be pass as keyword, not positionally.""); --> 369 return func(*args, **kwargs); 370 ; 371 return wrapper. ~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py in imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs); 5669 resample=resample, **kwargs); 5670 ; -> 5671 im.set_data(X); 5672 im.set_alpha(alpha); 5673 if im.get_clip_path() is None:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py in set_data(self, A); 688 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 689 raise TypeError(""Invalid shape {} for image data""; --> 690 .format(self._A.shape)); 691 ; 692 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```; If I convert the `adata.X` to sparse matrix format, I have the following error:; ```python; adata.X = sci.sparse.csr_matrix(adata.X); sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-29-a9471349c389> in <module>; ----> 1 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). ~/Documents/Python/scanpy/scanpy/plotting/_tools/paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax); 1057 if as_heatmap:; 1058 img = ax.imshow(; -> 1059 X, aspect='auto', interpolation='nearest', cmap=color_map; 1060 ); 1061 if show_yticks:. ~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py in i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953:2982,error,error,2982,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953,1,['error'],['error']
Availability,"dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4310,ERROR,ERROR,4310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"data.uns['paga']['connectivities_tree'] = paga.connectivities_tree. C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in compute_connectivities(self); 126 def compute_connectivities(self):; 127 if self._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values); 144 ns = vc.sizes(); 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key); 2925 if self.columns.nlevels > 1:; 2926 return self._getitem_multilevel(key); -> 2927 indexer = self.columns.get_loc(key); 2928 if is_integer(indexer):; 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2657 return self._engine.get_loc(key); 2658 except KeyError:; -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'; ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:; ```; {'commit_hash': 'd774f565b',; 'commit_source': 'installation',; 'default_encoding': 'cp1252',; 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',; 'ipython_version': '7.4.0',; 'os_name': 'nt',; 'platform': 'Windows-10-10.0.1836",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:2405,toler,tolerance,2405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,1,['toler'],['tolerance']
Availability,"data[:, ['gene-0']]. site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```; * `key` in both `adata.obs.columns` and `adata.var.index`: I changed this to raise a ValueError. I though about reverting back to the original implementation as you suggest but this will not work with `_anndata._prepare_dataframe` as I introduced some changes to work with this function. . The just added changes should mimic the response from 1.6 except for duplicate names in var_names which I think should respond similarly like when doing a slicing on the `AnnData` object. I added new tests based on your examples. I added checks to test for unique adata.obs.columns",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601:2220,toler,tolerance,2220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601,1,['toler'],['tolerance']
Availability,"dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3021,toler,tolerance,3021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,"dding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1713,Error,Error,1713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['Error'],['Error']
Availability,"de (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the clipping part of scaling function. ; | | Time(sec)|; | -----------| ----- |; | Original | 11.82 |; | Updated | 1.59 |; | Speedup | 7.433962264 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3100:1082,down,download,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100,1,['down'],['download']
Availability,"de is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self); 391 """"""; 392 assert self.state.func_ir is None; --> 393 return self._compile_core(); 394 ; 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 371 self.state.status.fail_reason = e; 372 if is_final_pipeline:; --> 373 raise e; 374 else:; 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 362 res = None; 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:; 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 345 (self.pipeline_name, pass_desc); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 ; 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 336 pass_inst = _pass_registry.get(pss).pass_inst; 337 if isinstance(pass_inst, CompilerPass):; --> 338 self._runPass(idx, pass_inst, state); 339 else:; 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:9140,avail,available,9140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['avail'],['available']
Availability,default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1225,ERROR,ERROR,1225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,dimension flattening error when slicing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332,1,['error'],['error']
Availability,"dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:8135,error,error,8135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['error']
Availability,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1309646072:87,error,error,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1309646072,1,['error'],['error']
Availability,"do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):; <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):; <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(); ```. ### Error output. ```pytb; (Error output is a bad plot, included in the description above.); ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; IPython 8.13.2; PIL 10.0.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.10.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; dot_parser NA; entrypoints 0.4; exceptiongroup 1.1.1; executing 1.2.0; fasteners 0.17.3; flytekitplugins NA; gmpy2 2.1.2; google NA; h5py 3.8.0; icu 2.11; igraph 0.11.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.8.3; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; natsort 8.3.1; numba 0.59.1; numcodecs 0.11.0; numexpr 2.7.3; numpy 1.26.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; plotly 5.14.1; prompt_toolkit 3.0.38; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3062:1908,Error,Error,1908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062,1,['Error'],['Error']
Availability,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946:2813,Error,Error,2813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946,5,"['Error', 'error', 'fault']","['Error', 'error', 'fault']"
Availability,documentation error for pl.violin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1294:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1294,1,['error'],['error']
Availability,"does the problem also happen in matrixplot or heatmap? seems to me like an; issue with the underlying seaborn violin plot. On Fri, Aug 31, 2018 at 6:25 PM a-munoz-rojas <notifications@github.com>; wrote:. > Thanks for all the work in developing this package, it's truly fantastic.; >; > I ran into what seems like a bug in the new plotting function; > sc.pl.rank_genes_groups_stacked_violin. It seems that when the ranked genes; > between 2 groups are similar (e.g. 'Tnf' is a highly ranked gene between; > two groups), then 'Tnf' is only plotted once on the first group, and any; > following groups with the same gene are truncated. You can see this in the; > toy example image I attached - when comparing groups M1 and M1+M2, 'Tnf'; > should be plotted for each group, but it is only plotted on group M1,; > therefore truncating group M2. When I plot the same data using; > rank_genes_groups_dotplot, this error doesn't happen and 'Tnf' is correctly; > plotted twice.; >; > I know this is a small bug that most people will probably not run across,; > but just in case you're comparing expression across similar groups this; > might be a useful fix. Thanks!; >; > [image: stacked_violin_global]; > <https://user-images.githubusercontent.com/37122760/44924265-bd353000-ad18-11e8-84d0-a0136083dbdd.png>; >; > [image: dotplot_global]; > <https://user-images.githubusercontent.com/37122760/44924244-aa226000-ad18-11e8-9351-4b28d11a7ee5.png>; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/252>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Z1BA7WgQycvMb5E4fHkMuW1p1idks5uWWNxgaJpZM4WVgcM>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252#issuecomment-417836666:908,error,error,908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252#issuecomment-417836666,1,['error'],['error']
Availability,dont think to csv is actually coded; to xlsx raises error: pandas.core.common.PandasError: DataFrame constructor not properly called!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/6:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/6,1,['error'],['error']
Availability,dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Asser,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47209,Error,Error,47209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,dtype fixes for downsample and normalization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865:16,down,downsample,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865,1,['down'],['downsample']
Availability,duals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9629,ERROR,ERROR,9629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,duals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4674,ERROR,ERROR,4674,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,duals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12172,ERROR,ERROR,12172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,duals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16172,ERROR,ERROR,16172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"dx.query(test, k, epsilon); 472 ; 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1061 self._distance_func,; 1062 self.rng_state,; -> 1063 self.diversify_prob,; 1064 ); 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951:3164,error,errors,3164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951,1,['error'],['errors']
Availability,"e 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pygments 2.9.0; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.10.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 0.57.0; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2144,down,down,2144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['down'],['down']
Availability,"e and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:66, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 try:; ---> 66 from skmisc.loess import loess; 67 except ImportError:. ModuleNotFoundError: No module named 'skmisc'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); Cell In[14], line 1; ----> 1 doublet_training_data = sc.pp.highly_variable_genes(adata, n_top_genes=6000, subset=True, flavor='seurat_v3'); 2 doublet_training_data. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:1744,error,error,1744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"e conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. During preprocessing of concatenated adata file for scvi-based label transfer, processing fails when applying ""sc.pp.highly_variable_genes"" function with ""ValueError: b'Extrapolation not allowed with blending'"". ### Minimal code sample. ```python; aadata = aadata.concatenate(ref_data_WT). aadata.X; <15445x13343 sparse matrix of type '<class 'numpy.float64'>'; 	with 107849393 stored elements in Compressed Sparse Row format>. # pre-processing:; aadata.layers[""counts""] = aadata.X.copy(); sc.pp.normalize_total(aadata, target_sum=1e4); sc.pp.log1p(aadata); aadata.raw = aadata. sc.pp.highly_variable_genes(aadata, flavor = 'seurat_v3', n_top_genes=2000,; layer = ""counts"", batch_key=""batch"", subset = True)#, span =0.5; ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); Cell In[37], line 7; 4 sc.pp.log1p(aadata); 5 aadata.raw = aadata; ----> 7 sc.pp.highly_variable_genes(aadata, flavor = 'seurat_v3', n_top_genes=2000,; 8 layer = ""counts"", batch_key=""batch"", subset = True)#, span =0.5. File ~/mambaforge/envs/soupxEnv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:441, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 439 sig = signature(_highly_variable_genes_seurat_v3); 440 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 441 return _highly_variable_genes_seurat_v3(; 442 adata,; 443 layer=layer,; 444 n_top_genes=n_top_genes,; 445 batch_key=batch_key,; 446 check_values=check_values,; 447 span=span,; 448 subset=subset,; 449 inplace=inplace,; 450 ); 452 if batch_key is None:; 453 df = _highly_variable_genes_single_batch(; 454 adata,; 455 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853:1021,Error,Error,1021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853,1,['Error'],['Error']
Availability,"e error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df); 1226 if len(c.categories) >= len(c):; 1227 continue; ...; 1232 ""AnnData, not on this view. You might encounter this""; 1233 ""error message while copying or writing to disk.""; 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'; ```. ### Versions. <details>. ```; anndata 0.7.8; scanpy 1.9.3; -----; PIL 10.0.0; asttokens NA; backcall 0.2.0; clustergrammer2 0.18.0; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7.post1; decorator 5.1.1; executing 1.2.0; google NA; h5py 3.9.0; igraph 0.10.6; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; jedi 0.19.0; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.9.0; ...; Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:2925,error,error,2925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability,"e has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttoke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:1090,error,error,1090,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,1,['error'],['error']
Availability,"e of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1145,down,downloaded,1145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['downloaded']
Availability,"e the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. cc @jakirkham @pentschev. > However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue. I would be curious to know what's going on here if you find out. >> Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. > The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. +1 on profiling. I suggest that you first start with `compute(scheduler=""single-threaded"")` and the cProfile module. This will avoid any parallelism, and hopefully let you use profiling techniques that are more familiar to you. I personally like snakeviz. . If you want to get on a screenshare some time I'm happy to look at dashboard plots with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:2209,down,down,2209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,1,['down'],['down']
Availability,"e, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:5049,error,error,5049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,['error'],['error']
Availability,"e, use_fast_tsne, n_jobs, copy); 108 if X_tsne is None:; 109 from sklearn.manifold import TSNE; --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19; 111 ; 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>; 32 verbose: int = 0,; 33 args: Iterable[Any] = (),; ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),; 35 ) -> Tuple[np.ndarray, float, int]:; 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters); 1338 "" Got %.100r."" % (args,)); 1339 parameters = (tuple(args), result); -> 1340 return self.__getitem_inner__(parameters); 1341 ; 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds); 680 except TypeError:; 681 pass # All real errors (not unhashable args) are raised below.; --> 682 return func(*args, **kwds); 683 return inner; 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0); 1348 return super().__getitem__((_TypingEllipsis, result)); 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type.""; -> 1350 args = tuple(_type_check(arg, msg) for arg in args); 1351 parameters = args + (result,); 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg); 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg); 373 ):; --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)); 375 # Bare Union etc. are not valid as type arguments; 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.; ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1067:2643,down,downgrading,2643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067,1,['down'],['downgrading']
Availability,"e/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1883) encoding=self.options.get(""encoding"", None),; [1884](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1884) compression=self.options.get(""compression"", None),; [1885](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1885) memory_map=self.options.get(""memory_map"", False),; [1886](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1886) is_text=is_text,; [1887](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:14807,error,errors,14807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,"e:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback); 129 value = type(); 130 try:; --> 131 self.gen.throw(type, value, traceback); 132 except StopIteration as exc:; 133 # Suppress StopIteration *unless* it's the same exception that; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 ; ; LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32; ; File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^; ; During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:9625,error,errors,9625,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,"e; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks like an endless error. What's wrong with the `!pip install scanpy[leiden]`? It installed so many incompatible packages which never happened before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:8491,error,error,8491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['error'],['error']
Availability,"e; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/minic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4630,error,error,4630,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['error'],['error']
Availability,"e=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python; sc.tl.leiden(; adata, ; resolution=0.9,; random_state=0,; flavor=""igraph"",; n_iterations=2,; directed=False,; ); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; bottleneck 1.3.7; brotli 1.0.9; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 2.0.4; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.4; ipykernel 6.29.3; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.1; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_ser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028:1629,Error,Error,1629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028,1,['Error'],['Error']
Availability,"e[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24998,error,errors,24998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['error'],['errors']
Availability,"e[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 pypi_0 pypi; coverage 7.4.4 pypi_0 pypi; cycler 0.12.1 pypi_0 pypi; dask 2024.4.1 pypi_0 pypi; dask-expr 1.0.10 pypi_0 pypi; distlib 0.3.8 pypi_0 pypi; execnet 2.1.1 pypi_0 pypi; fasteners 0.19 pypi_0 pypi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:25115,failure,failures,25115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,2,['failure'],"['failure', 'failures']"
Availability,e] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1932,ERROR,ERROR,1932,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"e_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 Please use .at[] or .iat[] accessors.; 910 ; --> 911 Parameters; 912 ----------; 913 index : label. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 -------; 952 series : Series; --> 953 If label is contained, will be reference to calling Series,; 954 otherwise a new object; 955 """""". ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4344 ; 4345 elif not is_list_like(value):; -> 4346 new_data = self._data.fillna(value=value, limit=limit,; 4347 inplace=inplace,; 4348 downcast=downcast). ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4357 return self._constructor(new_data).__finalize__(self); 4358 ; -> 4359 def ffill(self, axis=None, inplace=False, limit=None, downcast=None):; 4360 """"""; 4361 Synonym for :meth:`DataFrame.fillna(method='ffill') <DataFrame.fillna>`. ~/miniconda3/envs/spols190117/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 # in which case we are going to conform to the passed Categorical; 502 new_target = np.asarray(new_target); --> 503 if is_categorical_dtype(target):; 504 new_target = target._shallow_copy(new_target, name=self.name); 505 else:. ValueError: cannot reindex with a non-unique indexer. **; ```; The error is gone with pandas 0.23.4. There was a change in the API of reindex in pandas: http://pandas.pydata.org/pandas-docs/stable/whatsnew/v0.24.0.html",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450:1965,toler,tolerance,1965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450,4,"['down', 'error', 'toler']","['downcast', 'error', 'tolerance']"
Availability,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10564,error,error,10564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,"e_list); 152 ; --> 153 X_list = _adata[:, gene_list].X; 154 if issparse(X_list):; 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance); 3170 if not self.is_unique:; 3171 raise InvalidIndexError(; -> 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ); 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1862:4141,toler,tolerance,4141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862,1,['toler'],['tolerance']
Availability,e_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12588,ERROR,ERROR,12588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,e_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16586,ERROR,ERROR,16586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,e_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14895,ERROR,ERROR,14895,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"e_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compat 1.6 pypi_0 pypi; asciitree 0.3.3 pypi_0 pypi; attrs 23.2.0 pypi_0 pypi; bzip2 1.0.8 hd590300_5 conda-forge; ca-certificates 2024.2.2 hbcca054_0 conda-forge; cfgv 3.4.0 pypi_0 pypi; click 8.1.7 pypi_0 pypi; cloudpickle 3.0.0 pypi_0 pypi; contourpy 1.2.1 pypi_0 pypi; coverage 7.4.4 pypi_0 pypi; cycler 0.12.1 pypi_0 pypi; dask 2024.4.1 pypi_0 pypi; dask-expr 1.0.10 pypi_0 pypi; distlib 0.3.8 pypi_0 pypi; execnet 2.1.1 pypi_0 pypi; fasteners 0.19 pypi_0 pypi; filelock 3.13.3 pypi_0 pypi; fonttools 4.51.0 pypi_0 pypi; fsspec 2024.3.1 pypi_0 pypi; h5py 3.10.0 pypi_0 pypi; identify 2.5.35 pypi_0 pypi; igraph 0.11.4 pypi_0 pypi; imageio ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:25310,failure,failures,25310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['failure'],['failures']
Availability,e_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20721,ERROR,ERROR,20721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,earson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4226,ERROR,ERROR,4226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"ection to initialize the face and edgecolors; 541 # just in case it is a scalarmappable with a colormap.; --> 542 self.update_scalarmappable(); 543 offsets = self.get_offsets(); 544 if len(offsets) > 0:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/collections.py:926, in Collection.update_scalarmappable(self); 924 # pcolormesh, scatter, maybe others flatten their _A; 925 self._alpha = self._alpha.reshape(self._A.shape); --> 926 self._mapped_colors = self.to_rgba(self._A, self._alpha); 928 if self._face_is_mapped:; 929 self._facecolors = self._mapped_colors. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/cm.py:359, in ScalarMappable.to_rgba(self, x, alpha, bytes, norm); 357 x = ma.asarray(x); 358 if norm:; --> 359 x = self.norm(x); 360 rgba = self.cmap(x, alpha=alpha, bytes=bytes); 361 return rgba. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/colors.py:1193, in Normalize.__call__(self, value, clip); 1191 result.fill(0) # Or should it be all masked? Or 0.5?; 1192 elif vmin > vmax:; -> 1193 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1194 else:; 1195 if clip:. ValueError: minvalue must be less than or equal to maxvalue. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/formatters.py:339, in BaseFormatter.__call__(self, obj); 337 pass; 338 else:; --> 339 return printer(obj); 340 # Finally look for special method names; 341 method = get_real_method(obj, self.print_method). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/pylabtools.py:151, in print_figure(fig, fmt, bbox_inches, base64, **kwargs); 148 from matplotlib.backend_bases import FigureCanvasBase; 149 FigureCanvasBase(fig); --> 151 fig.canvas.print_figure(bytes_io, **kw); 152 data = bytes_io.getvalue(); 153 if fmt == 'svg':. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:4820,mask,masked,4820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['mask'],['masked']
Availability,"ed graph is prohibitive computationally (memory and CPU time wise).; > Intuitively, I'd think having a more complete graph with weighted edges is more representative of the data than an arbitrary k neighbors. Even if you do use a hard cutoff on number of neighbors, I don't see how discounting all distance information would give a more accurate result. I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture. That's just speculation to me. I never saw convincing benchmarks. No one claims that ""discounting all distance information gives a more accurate result"". It's just that it's computationally cheaper. I acknowledge that a ""non-fixed-degree knn graph"" varying say, between 5 and 100, would be computationally tractable and would carry information about the sampling density of the data in the given representation. This information is only indirectly available in the fixed-degree knn graph (more loops etc. in high-density regions). I never investigated this as I never saw fundamental results on such a non-fixed-degree knn graph. As it's also hard to benchmark this, I'd be afraid of getting into this if one doesn't have the time to get the fundamentals right. I want to note that even in the context of diffusion processes, we managed to obtain meaningful results with kNN graphs in practice. And this clearly contradicts the fundamental results found in all the Coifman papers. Having said that: if the code is simple, I don't mind at all to have the possibility that you suggest, @ivirshup. Please go ahead with a pull request and I'll see whether the changes are simple enough. The user will still use the default plain knn version, which is also what is done in Seurat. But my philosophy rests the same: rather than engineering the clustering or any other aspect of the manifold analysis, one should engineer the representation. Sorry that this got a b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777:1915,avail,available,1915,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777,1,['avail'],['available']
Availability,ed_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncN,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49319,Error,Error,49319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"elf, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:4261,error,errors,4261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,"elf._model == 'v1.2':; --> 128 return self._compute_connectivities_v1_2(); 129 elif self._model == 'v1.0':; 130 return self._compute_connectivities_v1_0(). C:\Anaconda\lib\site-packages\scanpy\tools\_paga.py in _compute_connectivities_v1_2(self); 141 g = utils.get_igraph_from_adjacency(ones, directed=True); 142 vc = igraph.VertexClustering(; --> 143 g, membership=self._adata.obs[self._groups_key].cat.codes.values); 144 ns = vc.sizes(); 145 n = sum(ns). C:\Anaconda\lib\site-packages\pandas\core\frame.py in __getitem__(self, key); 2925 if self.columns.nlevels > 1:; 2926 return self._getitem_multilevel(key); -> 2927 indexer = self.columns.get_loc(key); 2928 if is_integer(indexer):; 2929 indexer = [indexer]. C:\Anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 2657 return self._engine.get_loc(key); 2658 except KeyError:; -> 2659 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2660 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2661 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'louvain'; ```. </details>. I am a beginner in Python, so I fully realise that the background information may not be complete. Below is my system info:; ```; {'commit_hash': 'd774f565b',; 'commit_source': 'installation',; 'default_encoding': 'cp1252',; 'ipython_path': 'C:\\Anaconda\\lib\\site-packages\\IPython',; 'ipython_version': '7.4.0',; 'os_name': 'nt',; 'platform': 'Windows-10-10.0.18362-SP0',; 'sys_executable': 'C:\\Anaconda\\python.exe',; 'sys_platform': 'win32',; 'sys_version': '3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit '; '(AMD64)]'}; ```. Thank you very much for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/755:2601,toler,tolerance,2601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755,2,['toler'],['tolerance']
Availability,"elopment version:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-36-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 733 """"""; --> 734 return embedding(adata, 'pca', **kwargs); 735 ; 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 243 itertools.product(color, idx_components); 244 ):; --> 245 color_source_vector = _get_color_source_vector(; 246 adata,; 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1016 ):; 1017 # We should probably just make an index for this, and share it over runs; -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1019 0; 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344:1328,Down,Downloads,1328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344,2,"['Down', 'error']","['Downloads', 'error']"
Availability,"en reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When we calculate `X*X` for variance, we preserve the data type of the incoming `X`, but this actually can cause downstream inaccuracies from overflow differences. This has been the [case for many years](https://github.com/scverse/scanpy/blame/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_utils.py#L10). Really we should do something like `np.multiply(X, X, dtype=""float64)`. This would be more accurate/sensible. This came up in the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post0; decorator 5.1.1; defusedxml 0.7.1; distutils 3.12.3; executing 2.0.1; h5py 3.11.0; igraph 0.11.5; j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:1086,down,downstream,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['down'],['downstream']
Availability,"en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|; | -----------| ----- |; | Original | 297|; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110:1141,Down,Downloading,1141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110,1,['Down'],['Downloading']
Availability,"ent destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4445,ERROR,ERROR,4445,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"ent values; 232 self.extract_function_arguments(); --> 233 entry_block_tail = self.lower_function_body(); 234 ; 235 # Close tail of entry block. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self); 257 bb = self.blkmap[offset]; 258 self.builder.position_at_end(bb); --> 259 self.lower_block(block); 260 self.post_lower(); 261 return entry_block_tail. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 271 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 272 loc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:13109,error,errors,13109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,"ent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:3696,error,errors,3696,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73005,ERROR,ERROR,73005,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=153) impl,; [155](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=154) args=args, return_type=return_type,; [156](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=155) flags=flags, locals=self.locals,; [157](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=156) pipeline_class=self.pipeline_class); [158](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Min",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:17829,error,error,17829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['error']
Availability,epos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizatio,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68427,ERROR,ERROR,68427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,eprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cann,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71713,ERROR,ERROR,71713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"er group ""CellType_Category"", it worked. These two groups are in the same type. Could you tell me how to fix it?; Look forward to your response, thanks a lot!. ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata_sc, groupby=""Manuscript_Identity"", use_raw=False). adata_sc.obs['CellType_Category'].cat.categories; Index(['Endothelial', 'Epithelial', 'Lymphoid', 'Multiplet', 'Myeloid',; 'Stromal'],; dtype='object'); adata_sc.obs['Manuscript_Identity'].cat.categories; Index(['ATI', 'ATII', 'Aberrant_Basaloid', 'B', 'B_Plasma', 'Basal',; 'Ciliated', 'Club', 'DC_Langerhans', 'DC_Mature', 'Fibroblast',; 'Goblet', 'ILC_A', 'ILC_B', 'Ionocyte', 'Lymphatic', 'Macrophage',; 'Macrophage_Alveolar', 'Mast', 'Mesothelial', 'Multiplet',; 'Myofibroblast', 'NK', 'PNEC', 'Pericyte', 'SMC', 'T', 'T_Cytotoxic',; 'T_Regulatory', 'VE_Arterial', 'VE_Capillary_A', 'VE_Capillary_B',; 'VE_Peribronchial', 'VE_Venous', 'cDC1', 'cDC2', 'cMonocyte',; 'ncMonocyte', 'pDC'],; dtype='object'); ```. ### Error output. ```pytb; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 592, in rank_genes_groups; test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); File ""/udd/rekso/.conda/envs/rekso_tangram_env/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 106, in __init__; raise ValueError(; ValueError: Could not calculate statistics for groups Ionocyte since they only contain one sample.; ```. ### Versions. <details>. ```; setuptools 69.0.3; shapely 2.0.2; six 1.16.0; skimage 0.20.0; sklearn 1.3.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.15; squidpy 1.3.1; stack_data 0.6.2; statsmodels 0.14.1; sympy 1.12; tangram 1.0.4; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tifffile 2023.12.9; tlz 0.12.0; toolz 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:1459,Error,Error,1459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,1,['Error'],['Error']
Availability,"er, after running a new embedding and clustering on `adata_sub`, I have noticed that I can plot genes that shouldn't be in `adata_sub` (but were in `adata`), and that when I run `sc.tl.rank_genes_groups` my results aren't restricted to my 990 genes of interest. I am guessing that I subsetted my data incorrectly (though, why would I have the correct shape?). ### Minimal code sample (that we can copy&paste without having any data). ```python; # subset adata to genes of interest; adata_sub = adata[:, [g in genes_list for g in adata.var_names]].copy(). # filter out cells that don't express any genes of interest; sc.pp.filter_cells(adata_sub, min_genes=1). # run new embedding and clustering; sc.pp.pca(adata_sub, n_comps=50, use_highly_variable=False, svd_solver='arpack'); sc.pp.neighbors(adata_sub); sc.tl.umap(adata_sub); sc.tl.leiden(adata_sub, key_added='leiden_sub'); ```. When I use `sc.pl.umap(adata_sub)` to plot expression of a gene that is _not_ one of my genes of interest, it is still plotted (I would expect an error telling me that the gene is not found in my `adata_sub` object). Similarly, the results of `sc.tl.rank_genes_groups(adata_sub, groupby='leiden_sub', key_added='rank_genes_sub', method='wilcoxon')` returns top ranked genes that are not (or should not be) in my `adata_sub` object. Thank you for any help/clarification as to what's going on!. #### Versions. <details>; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2019.11.28; cffi 1.14.6; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.4.3; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.4.0; idna 2.8; igraph 0.9.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.4; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2007:1713,error,error,1713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007,1,['error'],['error']
Availability,"er.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:4312,error,errors,4312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"erance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities adjacency (adata.uns); 'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); --> added 'pos', the PAGA positions (adata.uns['paga']); ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leavi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3917,Toler,Tolerance,3917,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['Toler'],['Tolerance']
Availability,erplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:54899,ERROR,ERROR,54899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"error as using ""sc.pp.regress_out(adata, ['n_counts', 'percent_mito'])""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/212:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/212,1,['error'],['error']
Availability,error in dpt_scatter when 'groups' parameter set,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/32:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/32,1,['error'],['error']
Availability,error in readwrite.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3071:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071,1,['error'],['error']
Availability,error in sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821,1,['error'],['error']
Availability,error in scanpy first tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158,1,['error'],['error']
Availability,error: 'i' format requires -2147483648 <= number <= 2147483647 when using de.test.wald(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1874:0,error,error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874,1,['error'],['error']
Availability,"ersion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running the tests with pytest<=8, the doctest for `scanpy.preprocessing._simple.filter_cells` errors in a way I can't quite figure out how to fix. . I think what's happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most recent call last):; File ""/mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/doctest.py"", line 1353, in __run; exec(compile(example.source, filename, ""single"",; File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:1113,FAILURE,FAILURES,1113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,1,['FAILURE'],['FAILURES']
Availability,"es/numba/core/decorators.py?line=218) disp.compile(sig); [220](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=219) disp.disable_compile(); [221](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=220) return disp. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:965, in Dispatcher.compile(self, sig); [963](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=962) with ev.trigger_event(""numba:compile"", data=ev_details):; [964](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=963) try:; --> [965](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=964) cres = self._compiler.compile(args, return_type); [966](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=965) except errors.ForceLiteralArg as e:; [967](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=966) def folded(args, kws):. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); [124](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=123) def compile(self, args, return_type):; --> [125](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompile",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:14657,error,errors,14657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,"escr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 397 if self.state.cr is not None:; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:5651,avail,available,5651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['avail'],['available']
Availability,"escription of what the bug is: -->; I am calculating custom connectivities using hsnw on rep 'X', I don't want to calculate PCA, I want to compute UMAP using these connectivities. ; sc.tl.umap falls back to pca in:; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_umap.py#L153; https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/tools/_utils.py#L23. how to get sc.tl.umap to run on the precomputed 'X 'connectivities?; ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; from scvelo.pp import neighbors; adata; #AnnData object with n_obs × n_vars = 4329 × 192; #obs: 'BARCODE', 'sample', 'detectable.features'; #var: 'gene_ids', 'feature_types'; #layers: 'normalized.counts'. neighbors(adata, n_neighbors = 20, use_rep = ""X"",knn = True,random_state = 0,method = 'hnsw',metric = ""euclidean"",metric_kwds = {""M"":20,""ef"":200,""ef_construction"":200},num_threads=1). adata.uns[""neighbors""]['params']; #{'n_neighbors': 20, 'method': 'hnsw', 'metric': 'euclidean', 'n_pcs': None}. sc.tl.umap(adata). #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; #WARNING: .obsp[""connectivities""] have not been computed using umap; #WARNING: You’re trying to run this on 192 dimensions of `.X`, if you really want this, set `use_rep='X'`.; # Falling back to preprocessing with `sc.pp.pca` and default params. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.19.0 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 leidenalg==0.8.1; > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1318:1461,Error,Error,1461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1318,1,['Error'],['Error']
Availability,esiduals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10899,ERROR,ERROR,10899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11109,ERROR,ERROR,11109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21988,ERROR,ERROR,21988,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._h,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22200,ERROR,ERROR,22200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22412,ERROR,ERROR,22412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,esiduals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (un,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22624,ERROR,ERROR,22624,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"est.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:1296,Down,Download,1296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,3,"['Down', 'error']","['Download', 'error']"
Availability,est/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57076,ERROR,ERROR,57076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,est_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2944,ERROR,ERROR,2944,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,est_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18217,ERROR,ERROR,18217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,est_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73681,ERROR,ERROR,73681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,est_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74011,ERROR,ERROR,74011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67288,ERROR,ERROR,67288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"et, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 92 filename = Path(filename) # allow passing strings; 93 if is_valid_filename(filename):; ---> 94 return _read(; 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 489 else:; 490 ext = is_valid_filename(filename, return_ext=True); --> 491 is_present = check_datafile_present_and_download(; 492 filename,; 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url); 745 path.parent.mkdir(parents=True); 746 ; --> 747 download(backup_url, path); 748 return True; 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path); 722 ; 723 path.parent.mkdir(parents=True, exist_ok=True); --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:; 725 def update_to(b=1, bsize=1, tsize=None):; 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs); 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1; 207 total = self.total * unit_scale if self.total else self.total; --> 208 self.container = self.status_printer(; 209 self.fp, total, self.desc, self.ncols); 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols); 101 except NameError:; 102 # #187 #451 #558; --> 103 raise ImportError(; 104 ""FloatProgress not found. Please update jupyter and ipywidgets.""; 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1130:2442,down,download,2442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130,1,['down'],['download']
Availability,"et_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5726,error,error,5726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"eturn a float; cosine = np.dot(A, B) / (norm(A) * norm(B)); return cosine; transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance); sc.pp.neighbors(adata, transformer=transformer,n_pcs=0); sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics; dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15); adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(; knn_indices = tmp[0],; knn_dists = tmp[1],; n_obs = dis_mat.shape[0],; n_neighbors = 15,; ); adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}; sc.tl.umap(adata,random_state =42); sc.tl.leiden(adata,resolution=10); clusters= np.array(adata.obs[""leiden""]).astype(int); print('num of clusters: '+str(len(set(clusters)))); ```. ### Error output. ```pytb; num of clusters: 85; num of clusters: 170; num of clusters: 183; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.10.1; -----; IPython 8.22.2; PIL 10.2.0; asttokens NA; console_thrift NA; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; decorator 5.1.1; executing 2.0.1; h5py 3.10.0; igraph 0.11.4; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.1; numpy 1.26.4; packaging 24.0; pandas 2.2.1; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.42; psutil 5.9.0; pure_eval 0.2.2; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.11; pyparsing 3.1.2; pytz 2024.1; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.4.0; tqdm 4.66.2; traitlets 5.14.2; typing_extensions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3021:2452,Error,Error,2452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021,1,['Error'],['Error']
Availability,"eturn plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, downcast); 1934 def fillna(self, value, limit=None, inplace=False, downcast=None):; 1935 values = self.values if inplace else self.values.copy(); -> 1936 values = values.fillna(value=val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:2105,down,downcast,2105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,1,['down'],['downcast']
Availability,"eturn_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:6669,avail,available,6669,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['avail'],['available']
Availability,"eurat_v3(; 656 adata,; 657 flavor=flavor,; 658 layer=layer,; 659 n_top_genes=n_top_genes,; 660 batch_key=batch_key,; 661 check_values=check_values,; 662 span=span,; 663 subset=subset,; 664 inplace=inplace,; 665 ); 667 cutoff = _Cutoffs.validate(; 668 n_top_genes=n_top_genes,; 669 min_disp=min_disp,; (...); 672 max_mean=max_mean,; 673 ); 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:4409,error,error,4409,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['error'],['error']
Availability,"even with scanpy 1.4.1 my very simple (copied from the tutorial) script; doesn't work. I'm getting the well-known ""TypeError: Categorical is not; ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one"". So; I downgraded anndata, which lead to another new error. I guess I'd also; have to downgrade pandas now. This makes me wonder if there is some testing; with a standard pipeline done before a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508769252:251,down,downgraded,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508769252,3,"['down', 'error']","['downgrade', 'downgraded', 'error']"
Availability,"ew weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'); pairs_set = list(set(pairs)); s = sorted(pairs_set); half = int((len(s)/2)); list1 = s[:half]; list2 = s[half:]; lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(); for i in lz_cluster_method:; sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method); result = adata.u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:1573,error,error,1573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"ewidth=self.linewidth). AttributeError: 'numpy.ndarray' object has no attribute 'fill_betweenx'; ```. #### Option 2: group with two keys, passing first of two axes. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, axes = plt.subplots(1, 2); sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes[0]); ```. No traceback, but the second axis is simply not plotted. <img width=""388"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453540-76f48a6b-8d22-40bd-86fe-435d0878deb3.png"">. #### Option 3: group with two keys, passing one axis. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, ax = plt.subplots(); sc.pl.violin(adata, keys=['CD8A', 'CD8B'], groupby=""group"", ax=ax); ```. No traceback, even though this should error. Plots just the first of the two keys. <img width=""377"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; idna 3.1; igraph 0.9.8; importlib_resources NA; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.4.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; nbformat 5.1.3; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packagi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2136:3991,error,error,3991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136,1,['error'],['error']
Availability,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). ; This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for; ```python; markers={; 	""foo"":[""gene1"", ""gene2""],; 	""bar"":[""gene3""]; }; ```; but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-734861544:420,error,error,420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-734861544,1,['error'],['error']
Availability,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2472:6050,error,error,6050,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472,1,['error'],['error']
Availability,"f_size=30):; <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:; @numba.njit(parallel=True); def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):; ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state; /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:3210,error,errors,3210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['error'],['errors']
Availability,fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1077,ERROR,ERROR,1077,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"first try the following and check that you don't have any errors. ; ```; cd scanpy/scanpy/tests; py.test test_plotting.py; ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739930301:58,error,errors,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739930301,1,['error'],['errors']
Availability,fix an error when figsize is given,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/546:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/546,1,['error'],['error']
Availability,fix scrublet test tolerance,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2103:18,toler,tolerance,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2103,1,['toler'],['tolerance']
Availability,"for very large data (`pp.log1p` and `pp.pca`), where it already gives remarkable memory use reduction in `memory` mode. Of course, this is considerably slower than feeding in the full data matrix. We'll use AnnData's chunked functionality in other tools, soon. We're also using it when working with tensorflow. At some point, when you open an AnnData in `backed` mode, the whole pipeline will run through by processing chunks and the user won't have to do a single change to his or her code. By that, code that has been written for data that fits into memory will automatically scale to many millions of observations. Also, there will be global settings that allow to manually determine whether the whole pipeline should run on chunks but still load the basic data matrix into memory, something we've found useful in several occasions.; - not returning `None` when modifying a reference inplace: the very first draft of Scanpy was written this way. then @flying-sheep remarked, that it shouldn't and I agreed with him right away: if you return the changed object, you'll allow two different variable names for the same reference. This is a dangerous source for bugs - this was one of the few instances where I produced more bugs than in C++, where one would always write inplace functions (taking pointers or references) that return `void`. In addition, returning `None` directly tells the user that the typical code for writing pipelines does not have to be redundant: `function(adata)` instead of `adata = function(adata)`. Finally: all of Scanpy is consistently written using these principles and it would cause a lot of trouble both changing it in a simple function and changing it everywhere. Why do you think that _it allows for a more functional style of writing a processing pipeline_?. Hence, I'm sorry that I tend to not merge your pull request as is. Either you restore everything else that was there and solely add the inplace `np.log1p` or I'd do that. :smile:. Have a good Sunday!; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196:2327,redundant,redundant,2327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196,1,['redundant'],['redundant']
Availability,fyi there is scranpy available i have been using it for a while,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3255#issuecomment-2368341703:21,avail,available,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255#issuecomment-2368341703,1,['avail'],['available']
Availability,"g a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1296,down,downstream,1296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['down'],['downstream']
Availability,"g exists on the main branch of scanpy. ### What happened?. I have non zarr format Visium HD data. ; I tried reading it with sdata = visium_hd(path_read). it keeps asking me for a dataset_id which is not there in the feature_slice file name or my folder. ; Nonetheless, I kept setting it to None or """" or other possible dataset id values. I cannot find any tech support on the error either. . (I also tried specifying the file path to the different binned folders). ### Minimal code sample. path_read = '/Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs'; sdata = visium_hd(path_read). ### Error output. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3342:2111,Down,Downloads,2111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3342,1,['Down'],['Downloads']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56070,ERROR,ERROR,56070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60078,ERROR,ERROR,60078,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58412,ERROR,ERROR,58412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ga_continuous_multiple'); ; sc.pl.paga_compare(pbmc, legend_fontoutline=2, **common); save_and_compare_images('master_paga_compare'); ; sc.pl.paga_compare(pbmc, color='CST3', legend_fontsize=5, **common); save_and_compare_images('master_paga_compare_continuous'); ; sc.pl.paga_compare(pbmc, basis='X_pca', legend_fontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:2971,toler,tolerance,2971,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,1,['toler'],['tolerance']
Availability,"ge, row_colors, col_colors, mask, **kwargs); 1316 row_colors=row_colors, col_colors=col_colors,; 1317 z_score=z_score, standard_scale=standard_scale,; -> 1318 mask=mask); 1319 ; 1320 return plotter.plot(metric=metric, method=method,. ~/Code/seaborn/seaborn/matrix.py in __init__(self, data, pivot_kws, z_score, standard_scale, figsize, row_colors, col_colors, mask); 772 ; 773 self.row_colors, self.row_color_labels = \; --> 774 self._preprocess_colors(data, row_colors, axis=0); 775 self.col_colors, self.col_color_labels = \; 776 self._preprocess_colors(data, col_colors, axis=1). ~/Code/seaborn/seaborn/matrix.py in _preprocess_colors(self, data, colors, axis); 827 # Replace na's with background color; 828 # TODO We should set these to transparent instead; --> 829 colors = colors.fillna('white'); 830 ; 831 # Extract color values and labels from frame/series. /usr/local/lib/python3.7/site-packages/pandas/core/series.py in fillna(self, value, method, axis, inplace, limit, downcast, **kwargs); 4343 limit=limit,; 4344 downcast=downcast,; -> 4345 **kwargs; 4346 ); 4347 . /usr/local/lib/python3.7/site-packages/pandas/core/generic.py in fillna(self, value, method, axis, inplace, limit, downcast); 6256 ; 6257 new_data = self._data.fillna(; -> 6258 value=value, limit=limit, inplace=inplace, downcast=downcast; 6259 ); 6260 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in fillna(self, **kwargs); 573 ; 574 def fillna(self, **kwargs):; --> 575 return self.apply(""fillna"", **kwargs); 576 ; 577 def downcast(self, **kwargs):. /usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py in apply(self, f, axes, filter, do_integrity_check, consolidate, **kwargs); 436 kwargs[k] = obj.reindex(b_items, axis=axis, copy=align_copy); 437 ; --> 438 applied = getattr(b, f)(**kwargs); 439 result_blocks = _extend_blocks(applied, result_blocks); 440 . /usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py in fillna(self, value, limit, inplace, do",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/809:1892,down,downcast,1892,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809,3,['down'],['downcast']
Availability,gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48357,Error,Error,48357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:2934,error,error,2934,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,3,"['down', 'error']","['downloaded', 'error']"
Availability,"ges/anndata/_core/merge.py in <listcomp>(.0); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(index=new_index) for df in dfs]; 532 # New dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, ne",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:2828,toler,tolerance,2828,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,get.obs_df and get.var_df produce an error when there is only 1 key,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1315:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1315,1,['error'],['error']
Availability,"get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 1046 ); -> 1047 return fmt.DataFrameRenderer(formatter).to_html(notebook=True); 1048 else:; 1049 return None. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in to_html(self, buf, encoding, classes, notebook, border, table_id, render_links); 1027 render_links=render_links,; 1028 ); -> 1029 string = html_formatter.to_string(); 1030 return save_to_buf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5917,mask,mask,5917,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,getting an error in scanpy after 'successfully' installing it through anaconda prompt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587,1,['error'],['error']
Availability,"ggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes. **random_state** : `int` or `None`, optional (default: 0). Change this to use different intial states for the optimization. If `None`,; the initial state is not reproducible. **use_fast_tsne** : `bool`, optional (default: `True`). Use the MulticoreTSNE package by D. Ulyanov if it is installed. **n_jobs** : `int` or `None` (default: `sc.settings.n_jobs`). Number of jobs. **copy** : `bool` (default: `False`). Return a copy instead of writing to adata. :Returns:. Depending on `copy`, returns or updates `adata` with the following fields. . **X_tsne** : `np.ndarray` (`adata.obs`, dtype `float`); ```. Now let's look at `pp.neighbors` where you're reading the type annotations from the signature.; - Obviously, the signature itself now is a mess for humans to read. But ok, that's fine if the docstring is easy to read.; - There is an error ` <class 'inspect._empty'>`; - The rest looks good to me, except for the superficial stylistic remarks above.; ```; Signature: sc.pp.neighbors(adata:anndata.base.AnnData, n_neighbors:int=15, n_pcs:Union[int, NoneType]=None, use_rep:Union[str, NoneType]=None, knn:bool=True, random_state:Union[int, mtrand.RandomState, NoneType]=0, method:str='umap', metric:Union[str, Callable[[numpy.ndarray, numpy.ndarray], float]]='euclidean', metric_kwds:Mapping[str, Any]={}, copy:bool=False) -> Union[anndata.base.AnnData, NoneType]; Docstring:; Compute a neighborhood graph of observations [McInnes18]_. The neighbor search efficiency of this heavily relies on UMAP [McInnes18]_,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='diffmap'`,; connectivities are computed according to [Coifman05]_, in the adaption of; [Haghverdi16]_. :Parameters:. **adata** : AnnData, optional (default: <class 'inspect._empty'>). ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:3924,error,error,3924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,1,['error'],['error']
Availability,"github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressing objects: 100% (109/109), done.; Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s; fatal: The remote end hung up unexpectedly MiB | ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:1117,error,error,1117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,2,"['Down', 'error']","['Download', 'error']"
Availability,good catch! Thank you for reporting this. ; Pinging @Koncopd since I believe you were involved in major refactoring of this. ; Thank you @rpeys,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1292#issuecomment-704767951:44,Ping,Pinging,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292#issuecomment-704767951,1,['Ping'],['Pinging']
Availability,groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55740,ERROR,ERROR,55740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"h, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:5596,error,error,5596,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"hard to say what could cause that, there are a lot of changes between the two envs. but we might be able to pin it down with that, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3116#issuecomment-2185889395:115,down,down,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116#issuecomment-2185889395,1,['down'],['down']
Availability,"hat this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botoc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:1056,ERROR,ERROR,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,1,['ERROR'],['ERROR']
Availability,"have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2479:1006,Error,Error,1006,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479,1,['Error'],['Error']
Availability,"hbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:2012,error,error,2012,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60243,ERROR,ERROR,60243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57905,ERROR,ERROR,57905,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59241,ERROR,ERROR,59241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56569,ERROR,ERROR,56569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58074,ERROR,ERROR,58074,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"he conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0 py39hca03da5_0 ; appnope 0.1.2 py39hca03da5_1001 ; argon2-cffi 21.3.0 pyhd3eb1b0_0 ; argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 ; arpack 3.9.1 nompi_h593882a_101 conda-forge; array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge; asttokens 2.0.5 pyhd3eb1b0_0 ; async-lru 2.0.4 py39hca03da5_0 ; attrs 23.1.0 py39hca03da5_0 ; babel 2.11.0 py39hca03da5_0 ; backcall 0.2.0 pyhd3eb1b0_0 ; beautifulsoup4 4.12.3 py39hca03da5_0 ; blas 1.0 openblas ; bleach 4.1.0 pyhd3eb1b0_0 ; blosc2 2.0.0 pypi_0 pypi; brotli 1.1.0 hb547adb_1 conda-forge; brotli-bin 1.1.0 hb547adb_1 conda-forge; brotli-python 1.0.9 py39h313beb8_8 ; bzip2 1.0.8 h80987f9_6 ; c-ares 1.28.1 h93a5062_0 conda-forge; ca-certificates 2024.7.4 hf0a4a13_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2024.6.2 py39hc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5901,Error,Error,5901,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,1,['Error'],['Error']
Availability,"he functionalities and setup and it does look very nice!. - BCR makes sense to add, there seems to be generally less happening in this space in single-cell though right now, compared to TCR. Would be good to have somebody on board who actually works on this data.; - [tcellmatch](https://github.com/theislab/tcellmatch)'s primary purpose is specificity prediction, this could be easily added ontop of this, I will look into your data structure and will think about the necessary changes. I am in the process of making this code public anyway, hopefully next week or so.; - You mentioned distance metrics, this is definitely an interesting and relevant area, in [tcellmatch](https://github.com/theislab/tcellmatch), we implicitly use 1. manhatten distances, 2. euclidian distances in BLOSUM embedding and 3. learned embedding distances, 2. and maybe 3. could be potentially integrated, would be worth discussing in any case.; - Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs? These anticipated use cases would determine how and whether this makes sense i think.; - Potentially additionally relevant: An integration with dextramer counts to ""stain"" TCR specificity? There is the purely numeric, standard multi-modal single-cell, nature to this data that can be covered by standard scanpy work flows. This data is especially useful in the context of clonotypes etc which then would require additional functionalities, which could be built on what you have here. I have been looking into this type of analysis a lot in context of tcellmatch. Would be to contribute but also happy to see what other people do here, too!. Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Great docs otherwise though!. Best,; David",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254:1042,down,downloads,1042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254,1,['down'],['downloads']
Availability,"he version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 # For data is list-like, or Iterable (will consume into list); 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ); 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point; 345 index, columns = _get_axes(; 346 values.shape[0], values.shape[1], index=index, columns=columns; 347 ); --> 349 _check_values_indices_shape_match(values, index, columns); 351 if typ == ""array"":; 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns); 418 passed = val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:1745,error,error,1745,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['error'],['error']
Availability,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1969,toler,tolerance,1969,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,5,['toler'],['tolerance']
Availability,"hecked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193:1054,down,downgrade,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193,1,['down'],['downgrade']
Availability,"hello, I am trying to use normalisation part of scanpy and encounter this error. I tried to install Louvain but it is not helping. could anyone please help me. Thank you",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1566:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566,1,['error'],['error']
Availability,"hello, recently I use the scanpy package to preprocess the single cell rna-seq data, the following is my process step. But when I go to the last step, namely I want to scale the dataset, the error occurs. I have 4271 cells and 1024 genes after running ""adata = adata[:, adata.var[""highly_variable""]]"". But the error says the 4271 is not equal to 1024 in the dimension 0. I do not know the reason, so can you give me an answer?Thanks very much.; sc.pp.filter_genes(adata, min_counts = filter_min_counts); sc.pp.filter_cells(adata, min_counts = filter_min_counts); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True); adata = adata[:, adata.var[""highly_variable""]]; sc.pp.scale(adata)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738:191,error,error,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738,2,['error'],['error']
Availability,"hey, thanks for the interest and very good questions, my 2 cents:. > Can we infer from such an analysis how much a pathway is upregulated? (e.g. by calculating the FC of the mean?) . It would be great to conclude for example, that Pathway X is 30% more active, in condition Y. I think you could yes, maybe complementary to some standard approaches like hypergeometric test?. > How does in your opinion class-imbalance affect the analysis? For example, Condition A has 10 samples, while for Condition B,C.. I only have 3 each?. since you have densitieis, it should be ok (?). you could also try subsampling the condition where you have more samples n times. > I am happy to provide the code for the density distributions to visualise the results of the gene-set-score function. thanks, very much appreciated! Actually I don't think we have really a class/example of density/line plots in scanpy. Not sure if it can be of broad use/scope. . pinging @dawe (original author of the function).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1629#issuecomment-776883494:939,ping,pinging,939,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1629#issuecomment-776883494,1,['ping'],['pinging']
Availability,hi @Hrovatin ; so was it useful for your task? Curious to hear. Couple of questions:; - why having a tool redundant between two packages? ; - what is SEMITONES?; thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724:106,redundant,redundant,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724,1,['redundant'],['redundant']
Availability,"hi @MertDemirdizen @sophieRAIBAUD ; sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288:261,ping,ping,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288,1,['ping'],['ping']
Availability,"hi @Tycooner, the same error happened to me recently when clustering using leiden, is there any idea what happened here and if you have any solution?. similar situation here: with large dataset and tried to set different resolution parameters when run sc.tl.leiden",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1980#issuecomment-1042669892:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980#issuecomment-1042669892,1,['error'],['error']
Availability,"hi @jlause ,. thanks again for moving the code over `experimental` and sorry for the delay. I give up with the docs, they keep failing on a very weird issue that I can't address (now it's request error from scipy, but before was some stupid indentation that I could not fix). . I realized that you forgot to copy over the `recipes`. Now it's there and working, I have a minor comment on copying over `X_pca` to `X_pearson_residuals_pca`. I think it should remain `X_pca` since the normalization is performed on `X`. Or am I missing something for such return to be chosen?. Meanwhile I'd also like to ping @ivirshup for taking a look at the experimental API and whether he agrees on the current structure as well as docs. remaining TOD:. - [ ] fix docs; - [ ] add tutorial to docs (should be done when tutorial has been reviewed)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-890768314:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-890768314,2,"['error', 'ping']","['error', 'ping']"
Availability,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2332223204:282,robust,robust,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2332223204,1,['robust'],['robust']
Availability,"hi, ; I installed the scanpy-master , but when I type `scanpy --help` in bash the error occurred. I noticed that diffrank was replaced by rank_genes_groups, but I don't know how to fix it. ; ```; Traceback (most recent call last):; File ""/public/bioapps/ana/anaconda3/envs/python35/bin/scanpy"", line 11, in <module>; load_entry_point('scanpy==0+unknown', 'console_scripts', 'scanpy')(); File ""/public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/scanpy-0+unknown-py3.5-linux-x86_64.egg/scanpy/__main__.py"", line 278, in main; init_main_parser().print_help(); File ""/public/bioapps/ana/anaconda3/envs/python35/lib/python3.5/site-packages/scanpy-0+unknown-py3.5-linux-x86_64.egg/scanpy/__main__.py"", line 117, in init_main_parser; descr = 78*'-' + '\n' + getattr(tools, key).__doc__; AttributeError: module 'scanpy.api.tools' has no attribute 'diffrank'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/30:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/30,1,['error'],['error']
Availability,"hi, it is actually just one line code. here it is:; ad['leiden'] = rapids_scanpy_funcs.leiden(ad). rapids_scanpy_funcs.leiden can be downloaded from the link",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932:133,down,downloaded,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932,1,['down'],['downloaded']
Availability,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360,1,['error'],['error']
Availability,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725,1,['error'],['error']
Availability,highly variable genes + batch_key --> reciprocal condition number error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669,1,['error'],['error']
Availability,highly_variable_genes variance computation on dense matrix - Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/785:61,Error,Error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/785,1,['Error'],['Error']
Availability,"highly_variable_genes with batch_key results in a ""division by zero"" error, if there is a batch with a single sample",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103,1,['error'],['error']
Availability,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5134,ERROR,ERROR,5134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"hold] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_plotting.py::test_scrublet_plots[scrublet_with_batches] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4026,ERROR,ERROR,4026,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,"hon-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:2761,error,error,2761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,"hon3.6/site-packages/umap/umap_.py"", line 467:; def fuzzy_simplicial_set(; <source elided>; if knn_indices is None or knn_dists is None:; knn_indices, knn_dists, _ = nearest_neighbors(; ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]); WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.; WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: detected group with only [] cells; ```. </details>; <details><summary>Traceback</summary>. ```pytb; ValueError Traceback (most recent call last); ~/dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:5664,error,errors,5664,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['error'],['errors']
Availability,"hon3.9/site-packages/_pytest/main.py"", line 273 in wrap_session; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/main.py"", line 320 in pytest_cmdline_main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_callers.py"", line 102 in _multicall; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_manager.py"", line 119 in _hookexec; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/pluggy/_hooks.py"", line 501 in __call__; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/config/__init__.py"", line 175 in main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/_pytest/config/__init__.py"", line 198 in console_main; File ""/opt/hostedtoolcache/Python/3.9.18/x64/bin/pytest"", line 8 in <module>; /home/vsts/work/_temp/1dc6f140-196e-4393-a84a-ebdaa5dcda61.sh: line 1: 1811 Illegal instruction (core dumped) pytest. ##[error]Bash exited with code '132'.; ##[section]Finishing: PyTest; ```. ### Versions. <details>. ```; anndata 0.10.5.post1; annoy 1.17.3; array_api_compat 1.4.1; asciitree 0.3.3; attrs 23.2.0; cfgv 3.4.0; click 8.1.7; cloudpickle 3.0.0; contourpy 1.2.0; coverage 7.4.1; cycler 0.12.1; dask 2024.2.0; dask-glm 0.3.2; dask-ml 2023.3.24; decorator 5.1.1; Deprecated 1.2.14; distlib 0.3.8; distributed 2024.2.0; exceptiongroup 1.2.0; fasteners 0.19; fbpca 1.0; filelock 3.13.1; fonttools 4.49.0; fsspec 2024.2.0; future 0.18.3; geosketch 1.2; get-annotations 0.1.2; graphtools 1.5.3; h5py 3.10.0; harmonypy 0.0.9; identify 2.5.35; igraph 0.11.4; imageio 2.34.0; importlib-metadata 7.0.1; importlib-resources 6.1.1; iniconfig 2.0.0; intervaltree 3.1.0; Jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; lazy_loader 0.3; legacy-api-wrap 1.4; leidenalg 0.10.2; llvmlite 0.42.0; locket 1.0.0; magic-impute 3.0.0; MarkupSafe 2.1.5; matplotlib 3.8.3; msgpack 1.0.7; multipledispatch 1.0.0; natsort 8.4.0; networkx 3.2.1; nodeenv 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866:6837,error,error,6837,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866,1,['error'],['error']
Availability,how does sc.queries.enrich handle up- and down-regulated genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1901:42,down,down-regulated,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901,1,['down'],['down-regulated']
Availability,"html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /tmp/ipykernel_134148/2515279522.py in <module>; 1 embedding_anterior = np.concatenate(integrated_anterior, axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143:1380,down,downloaded,1380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143,1,['down'],['downloaded']
Availability,"https://docs.python.org/3/library/warnings.html#temporarily-suppressing-warnings. ```py; import numba; import warnings. with warnings.catch_warnings():; warnings.simplefilter('ignore', numba.errors.NumbaDeprecationWarning):; do_thing(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555:191,error,errors,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555,1,['error'],['errors']
Availability,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1996:305,down,downgrade,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996,1,['down'],['downgrade']
Availability,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910,2,['error'],['error']
Availability,i met the same error when using sc.pl.dotplot. did you fix that?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400,1,['error'],['error']
Availability,ial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2470:838,down,downsampled,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470,1,['down'],['downsampled']
Availability,id not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46230,Error,Error,46230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,iduals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10474,ERROR,ERROR,10474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ies.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1847,toler,tolerance,1847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['toler'],['tolerance']
Availability,"ighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409:2074,echo,echo,2074,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409,1,['echo'],['echo']
Availability,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper; raise type(e)(; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /; /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>; _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2432:4231,error,error,4231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432,1,['error'],['error']
Availability,iles did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43318,Error,Error,43318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"imal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs × n_vars = 9999 × 1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2526:1774,FAILURE,FAILURES,1774,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526,1,['FAILURE'],['FAILURES']
Availability,import error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/855:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/855,1,['error'],['error']
Availability,"in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import numpy as np; 11 ; ---> 12 from umap.utils import norm; 13 ; 14 locale.setlocale(locale.LC_NUMERIC, ""C""). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/utils.py in <module>; 38 ; 39 @numba.njit(""i4(i8[:])""); ---> 40 def tau_rand_int(state):; 41 """"""A fast (pseudo)-random number generator.; 42 . ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:2794,error,errors,2794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['error'],['errors']
Availability,"in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-17-f0b30fa7797a> in <module>; ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:3854,error,error,3854,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = call $12load_method.4(func=$12load_method.4, args=[], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5017); D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:8923,error,error,8923,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['error']
Availability,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1921:3600,avail,available,3600,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921,1,['avail'],['available']
Availability,"info using `.uns[""dendrogram_['groups']""]`; WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; Storing dendrogram info using `.uns['dendrogram_groups']`; ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1521:1688,down,down,1688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521,1,['down'],['down']
Availability,"ing up your package via pip, as instructed. This crashed out very quickly:. 	mib111492i:~ kp9$ pip install scanpy; 	Collecting scanpy; 	 Downloading scanpy-0.2.9.1.tar.gz (208kB); 		100% |################################| 215kB 2.8MB/s ; 		Complete output from command python setup.py egg_info:; 		Traceback (most recent call last):; 		 File ""<string>"", line 1, in <module>; 		 File ""/private/tmp/pip-build-cx2i4lbu/scanpy/setup.py"", line 39, in <module>; 			readme = readme_f.read(); 		 File ""/Users/kp9/anaconda3/lib/python3.6/encodings/ascii.py"", line 26, in decode; 			return codecs.ascii_decode(input, self.errors)[0]; 		UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 296: ordinal not in range(128); 	; 		----------------------------------------; 	Command ""python setup.py egg_info"" failed with error code 1 in /private/tmp/pip-build-cx2i4lbu/scanpy/. The offender seems to be the stylised README file, so I downloaded the source code, got rid of it, and proceeded with the installation. I'm unsure how representative the following encountered issues are of an ideal pip installation, but I figured I'd bring them to your attention anyway just in case they're relevant:. - h5py crashed out on account of not having hdf5 available. This was remedied via `brew install hdf5`, and it seems like the most likely of these issues to affect other users.; - The installer ignored my 2.1.0 setup of matplotlib, tried to install 2.0.0 in some weird way and crashed out. Installing 2.0.0 via pip (absolutely painlessly, mind you - what was that weird installer that crashed the thing out?) allowed the setup to proceed past this point. This might be an isolated incident, but it seemed weird enough to alert you of just in case.; - As is, louvain crashes immediately and uninformatively when attempts are made to pip it in. Installing from the GitHub source code still works fine though. I'll notify the louvain team of this situation, but this may be of relevance to you too. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/49:1270,avail,available,1270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/49,1,['avail'],['available']
Availability,"ing... done. # All requested packages already installed. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - scanpy. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. Error: one or more Python packages failed to install [error code 1]; ```. If I switch to the terminal and try `pip` or `conda` I get:. ```; pip install scanpy; ```. ```; Requirement already satisfied: scanpy in /home/tsundoku/anaconda3/lib/python3.7/site-packages (1.4.5.post2); Requirement already satisfied: setuptools-scm in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (3.3.3); Requirement already satisfied: scipy>=1.3 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (1.3.2); Requirement already satisfied: pandas>=0.21 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.25.3); Requirement already satisfied: packaging in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (19.2); Requirement already satisfied: natsort in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (7.0.0); Requirement already satisfied: statsmodels>=0.10.0rc2 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.10.1); Requirement alre",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:1169,Error,Error,1169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,2,"['Error', 'error']","['Error', 'error']"
Availability,ing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: canno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19845,ERROR,ERROR,19845,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ER,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2336,ERROR,ERROR,2336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59410,ERROR,ERROR,59410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizati,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59909,ERROR,ERROR,59909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56738,ERROR,ERROR,56738,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58243,ERROR,ERROR,58243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python; import scanpy as sc; import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_versions(); sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(); adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. # start from scratch; del adata.obs[""louvain""]; adata.uns = {}; adata_ref.uns = {}. # example code for ingest function:; sc.pp.neighbors(adata_ref); sc.tl.umap(adata_ref); sc.tl.ingest(adata, adata_ref, obs=""louvain""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[11], line 23; 21 sc.pp.neighbors(adata_ref); 22 sc.tl.umap(adata_ref); ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 138 labeling_method = labeling_method * len(obs); 140 ing = Ingest(adata_ref, neighbors_key); --> 141 ing.fit(adata); 143 for ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:1317,Error,Error,1317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,1,['Error'],['Error']
Availability,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32865,error,errors,32865,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,3,['error'],['errors']
Availability,int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8775,ERROR,ERROR,8775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ion(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 . ~/.conda/envs/rpy/lib/python3.9/contextlib.py in __exit__(self, type, value, traceback); 133 value = type(); 134 try:; --> 135 self.gen.throw(type, value, traceback); 136 except StopIteration as exc:; 137 # Suppress StopIteration *unless* it's the same exception that. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32. File ""../../../../../../../.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^. During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /public/home/ycxiang_zju/.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py (52); ```; ​; sc.pp.filter_cells(unspliced, min_genes=200); dyn.pl.basic_stats(spliced)`; I am wondering how to solve this problem. Will I need to re-create a virtual environment with lower python verison?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:9559,error,errors,9559,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['error'],['errors']
Availability,ion); FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_quer,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:1877,ERROR,ERROR,1877,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ion, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:1829,error,error,1829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,ions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55571,ERROR,ERROR,55571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"is doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 323 # make the scatter plot; 324 if projection == '3d':; --> 325 cax = ax.scatter(; 326 coords[:, 0],; 327 coords[:, 1],; 328 coords[:, 2],; 329 marker=""."",; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:1564,error,error,1564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['error'],['error']
Availability,"isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1885:5309,error,error,5309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885,1,['error'],['error']
Availability,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. you’re right, we should probably do it. the only reason we didn’t yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, it’ll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343484072:323,down,down,323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343484072,1,['down'],['down']
Availability,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you!; I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702374437:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702374437,1,['error'],['error']
Availability,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748670360:1452,avail,available,1452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-748670360,1,['avail'],['available']
Availability,"ite-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . adata = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...'pca', 'rank_genes_groups', 'log1p'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'. def _subset_genes(; adata: AnnData,; *,; mean: NDArray[np.float64] | DaskArray,; dispersion_norm: NDArray[np.float64] | DaskArray,; cutoff: _Cutoffs | int,; ) -> NDArray[np.bool_] | DaskArray:; """"""Get boolean mask of genes with normalized dispersion in bounds.""""""; if isinstance(cutoff, _Cutoffs):; > dispersion_norm[np.isnan(dispersion_norm)] = 0 # similar to Seurat; E ValueError: assignment destination is read-only. scanpy/preprocessing/_highly_variable_genes.py:365: ValueError; ```. </details>. Dependencies are different, looks like a dask update and a pyarrow added dep. I suspect this has to do with the new dask-expr. ----. I can replicate locally by install the new dask, dask-expr, and pyarrow. ----. Importing dask.dataframe changes the settings for pandas somehow:. ```python; In [1]: import pandas as pd. In [2]: pd.DataFrame({""a"": [1,2,3, None]})[""a""].to_numpy().flags; Out[2]: ; C_CONTIGUOUS : True; F_CONTIGUOUS : True; OWNDATA : False; WRITEABLE : True; ALIGNED : True; WRITEBACKIFCOPY : False. In [3]: import dask.dataframe as ddf. In [4]: pd.DataFrame({""a"": [1,2,3, None]})[""a""].to_numpy().flags; Out[4]: ; C_CONTIGUOUS : True; F_CONTIGUOUS : True; OWNDATA : False; WRITEABLE : False; ALIGNED : T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:5900,mask,mask,5900,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['mask'],['mask']
Availability,"ite-packages/matplotlib/collections.py:1198, in PolyCollection.__init__(self, verts, sizes, closed, **kwargs); 1178 def __init__(self, verts, sizes=None, *, closed=True, **kwargs):; 1179 """"""; 1180 Parameters; 1181 ----------; (...); 1196 Forwarded to `.Collection`.; 1197 """"""; -> 1198 super().__init__(**kwargs); 1199 self.set_sizes(sizes); 1200 self.set_verts(verts, closed). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/collections.py:206, in Collection.__init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, offset_transform, norm, cmap, pickradius, hatch, urls, zorder, **kwargs); 203 self._offset_transform = offset_transform; 205 self._path_effects = None; --> 206 self._internal_update(kwargs); 207 self._paths = None. File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1216, in Artist._internal_update(self, kwargs); 1209 def _internal_update(self, kwargs):; 1210 """"""; 1211 Update artist properties without prenormalizing them, but generating; 1212 errors as if calling `set`.; 1213 ; 1214 The lack of prenormalization is to maintain backcompatibility.; 1215 """"""; -> 1216 return self._update_props(; 1217 kwargs, ""{cls.__name__}.set() got an unexpected keyword argument ""; 1218 ""{prop_name!r}""). File ~/miniconda3/envs/scarf_env/lib/python3.12/site-packages/matplotlib/artist.py:1190, in Artist._update_props(self, props, errfmt); 1188 func = getattr(self, f""set_{k}"", None); 1189 if not callable(func):; -> 1190 raise AttributeError(; 1191 errfmt.format(cls=type(self), prop_name=k)); 1192 ret.append(func(v)); 1193 if ret:. AttributeError: PolyCollection.set() got an unexpected keyword argument 'rotation'; ```. ### Versions. <details>. ```; numpy 1.26.4; pandas 2.2.2; scanpy 1.10.2; session_info 1.0.0; -----. PIL 10.3.0; anndata 0.10.8; anyio NA; arrow 1.3.0; asciitree NA; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.15.0; certifi 2024.06.02; cffi 1.16.0; charset_norma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3140:7792,error,errors,7792,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140,1,['error'],['errors']
Availability,"ite-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1736:2447,error,error,2447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736,1,['error'],['error']
Availability,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2105:2891,error,error,2891,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105,1,['error'],['error']
Availability,"ith #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:2064,error,error,2064,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,1,['error'],['error']
Availability,"ith non-model species and the majority of gene names are non-informative like ""nbis-gene-11111"", but I am interested in some genes of actin that I deposited in GenBank. I would like to put GB accessions into the plot.) I created the column with following code: [""bob"" is the dataset name]. bob.var['GB_IDs'] = bob.var_names.copy(); ID_dict = {; ""nbis-gene-777"":""MT451954"",; ""nbis-gene-775"":""MT451955"",; ""nbis-gene-3785"":""MT451956"",; ""nbis-gene-3784"":""MT451957"",; ""nbis-gene-23114"":""MT451958"",; ""nbis-gene-25113"":""MT451959"",; ""nbis-gene-3783"":""MT518195""; }; bob.var['GB_IDs'].replace(ID_dict, inplace=True). After that GB_IDs column was present in the dataframe.; And then I tried to plot the dotplot:. dict = {; ""Actin 1"": [""nbis-gene-777""],; ""Actin 2"": [""nbis-gene-775""],; ""Actin 3"": [""nbis-gene-3785""],; ""Actin 4"": [""nbis-gene-3784""],; ""Actin 5"": [""nbis-gene-23114""],; ""Actin 6"": [""nbis-gene-25113""],; ""Actin 7"": [""nbis-gene-3783""]; }; dp=sc.pl.dotplot(bob, dict, ""scGate_multi"", dendrogram=False, return_fig=True, cmap='YlGnBu', gene_symbols='GB_IDs'). This results in an error: . ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/software/SAMap/lib/python3.9/site-packages/pandas/core/indexes/base.py:3791, in Index.get_loc(self, key); 3790 try:; -> 3791 return self._engine.get_loc(casted_key); 3792 except KeyError as err:. File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc(). File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'GB_IDs'. If I correctly understand the docs (https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.dotplot.html), this code should work. I tried also to create such additional column in adata.raw.var, but that did not help as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788:1348,error,error,1348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788,1,['error'],['error']
Availability,ize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12796,ERROR,ERROR,12796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13011,ERROR,ERROR,13011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_reci,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:22922,mask,mask-,22922,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-floa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2634,ERROR,ERROR,2634,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"k(func, compiler_state); 274 def check(func, compiler_state):; --> 275 mangled = func(compiler_state); 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 406 # TODO: Pull this out into the pipeline; --> 407 NativeLowering().run_pass(state); 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state); 348 metadata=metadata); --> 349 lower.lower(); 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self); 231 # Materialize LLVM Module; --> 232 self.library.add_ir_module(self.module); 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module); 200 ir = cgutils.normalize_ir_text(str(ir_module)); --> 201 ll_module = ll.parse_assembly(ir); 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 25 mod.close(); ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-21-b19e785cf655> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(pe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:4911,error,error,4911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['error']
Availability,kends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57245,ERROR,ERROR,57245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,known location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21352,ERROR,ERROR,21352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,known location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `cli,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2670,ERROR,ERROR,2670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"l last); <ipython-input-37-b22ada65a1cd> in <module>; 1 # Create Concatenated anndata object for all timepoints; 2 #alldays = e125.concatenate(e135, e145, e155, uns_merge=""unique""); ----> 3 alldays = e125.concatenate(e135). ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1696 all_adatas = (self,) + tuple(adatas); 1697 ; -> 1698 out = concat(; 1699 all_adatas,; 1700 axis=0,. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 799 [dim_indices(a, axis=1 - axis) for a in adatas], join=join; 800 ); --> 801 reindexers = [; 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 - axis)) for a in adatas; 803 ]. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in <listcomp>(.0); 800 ); 801 reindexers = [; --> 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 - axis)) for a in adatas; 803 ]; 804 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in gen_reindexer(new_var, cur_var); 393 [1., 0., 0.]], dtype=float32); 394 """"""; --> 395 return Reindexer(cur_var, new_var); 396 ; 397 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in __init__(self, old_idx, new_idx); 265 self.no_change = new_idx.equals(old_idx); 266 ; --> 267 new_pos = new_idx.get_indexer(old_idx); 268 old_pos = np.arange(len(new_pos)); 269 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 2731 ; 2732 if not self.is_unique:; -> 2733 raise InvalidIndexError(; 2734 ""Reindexing only valid with uniquely valued Index objects""; 2735 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875:3749,toler,tolerance,3749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875,1,['toler'],['tolerance']
Availability,late_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2751,ERROR,ERROR,2751,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,latest version error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601,1,['error'],['error']
Availability,"lel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:1841,error,errors,1841,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['errors']
Availability,let_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2420,ERROR,ERROR,2420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,lization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71552,ERROR,ERROR,71552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,lization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23647,ERROR,ERROR,23647,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"lize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:3752,toler,tolerance,3752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,2,['toler'],['tolerance']
Availability,lize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23034,ERROR,ERROR,23034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isn’t great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2744:1724,error,error,1724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744,2,['error'],['error']
Availability,loat32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7270,ERROR,ERROR,7270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 37",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2364:4521,toler,tolerance,4521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364,1,['toler'],['tolerance']
Availability,"lon=epsilon; 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1054 ); 1055 else:; -> 1056 diversify_csr(; 1057 reverse_graph.indptr,; 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2406:3855,error,errors,3855,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406,1,['error'],['errors']
Availability,lpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2178,ERROR,ERROR,2178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5492,ERROR,ERROR,5492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626,1,['ERROR'],['ERROR']
Availability,"lt colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://github.com/theislab/scanpydoc/blob/875b441212830678cf9fc81c52f5af29bbb8715f/scanpydoc/elegant_typehints/formatting.py#L101-L107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1633:1592,down,downside,1592,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633,1,['down'],['downside']
Availability,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1375,avail,available,1375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,1,['avail'],['available']
Availability,m 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10572,mask,mask-,10572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"m__(cls, name); 356 def __getitem__(cls, name):; --> 357 return cls._member_map_[name]; 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'); ```. <details>; <summary>Versions</summary>. Package Version; ----------------------- ------------; absl-py 1.1.0; aiohttp 3.8.1; aiosignal 1.2.0; anndata 0.7.5; anndata2ri 1.0.6; annoy 1.17.0; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; asn1crypto 1.4.0; async-timeout 4.0.2; asynctest 0.13.0; attrs 20.3.0; backcall 0.2.0; beautifulsoup4 4.11.1; bleach 5.0.0; boto3 1.17.66; botocore 1.20.66; brotlipy 0.7.0; cached-property 1.5.2; cachetools 5.2.0; certifi 2020.12.5; cffi 1.14.5; chardet 4.0.0; charset-normalizer 2.0.12; chex 0.1.3; click 8.1.3; colormath 3.0.0; commonmark 0.9.1; conda 4.6.14; conda-package-handling 1.7.3; cryptography 3.4.7; cycler 0.10.0; Cyth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:1734,error,error,1734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['error'],['error']
Availability,macOS matplotlib error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567,1,['error'],['error']
Availability,mage files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); F,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4386,Error,Error,4386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,magic() error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/206:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/206,1,['error'],['error']
Availability,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I would expect that when you call sc.pp.highly_variable_genes on the same dataset and request the same number of genes, that you would get the same output. The below example suggests that this is not the case. . ### Minimal code sample. ```python; adata_sub = sc.read_h5ad(""your_favourite_object.h5ad""); n_genes = 1491; for i in range(10):; sc.pp.highly_variable_genes(adata_sub, n_top_genes=n_genes). unique_genes = list(adata_sub.var['highly_variable'][adata_sub.var['highly_variable'] == True].index). if i == 0:; all_unique = list(set(unique_genes)); print(f""total {len(all_unique)} unique genes""); else:; all_unique = list(set(all_unique+unique_genes)); print(f""total {len(all_unique)} unique genes""); ```. ### Error output. ```pytb; total 1491 unique genes; total 1814 unique genes; total 2042 unique genes; total 2163 unique genes; total 2237 unique genes; total 2305 unique genes; total 2356 unique genes; total 2401 unique genes; total 2437 unique genes; total 2453 unique genes; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2579:1007,Error,Error,1007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579,1,['Error'],['Error']
Availability,malization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23850,ERROR,ERROR,23850,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,mask parameter added to pca method in _pca.py ; test_pca_mask added to test_pca.py; Deprecation warning on use_highly_variable parameter added to test_deprecations.py. ### [rendered docs](https://icb-scanpy--2272.com.readthedocs.build/en/2272/generated/scanpy.pp.pca.html),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2272:0,mask,mask,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272,1,['mask'],['mask']
Availability,"master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2321:1192,error,error,1192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321,1,['error'],['error']
Availability,"matrix'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-102-4378df4ffefd> in <module>; ----> 1 adpt.write_h5ad('../data/ra19_10_liverprimary_yubin_latest.h5ad.gz'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1844 filename = self.filename; 1845 ; -> 1846 _write_h5ad(; 1847 Path(filename),; 1848 self,. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 90 elif not (adata.isbacked and Path(adata.filename) == Path(filepath)):; 91 # If adata.isbacked, X should already be up to date; ---> 92 write_attribute(f, ""X"", adata.X, dataset_kwargs=dataset_kwargs); 93 if ""raw/X"" in as_dense and isinstance(; 94 adata.raw.X, (sparse.spmatrix, SparseDataset). ~/miniconda3/envs/scrna/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 189 except Exception as e:; 190 parent = _get_parent(elem); --> 191 raise type(e)(; 192 f""{e}\n\n""; 193 f""Above error raised while writing key {key!r} of {type(elem)}"". NotImplementedError: Failed to write value for X, since a writer for type <class 'scipy.sparse.csr.csr_matrix'> has not been implemented yet. Above error raised while writing key 'X' of <class 'h5py._hl.files.File'> from /.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783799732:2496,error,error,2496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783799732,2,['error'],['error']
Availability,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3275,error,error,3275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,mbedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47923,Error,Error,47923,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"mc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity; >>> ; >>> # This",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:2431,error,errors,2431,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"md64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/; ----------------------------------------; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Running setup.py install for fa2 ... error. ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record 'C:\Users\xkalaj\AppData\Local\Temp\pip-record-y21s2idm\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\Include\fa2'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running install; running build; running build_py; creating build; creating build\lib.win-am",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:3007,ERROR,ERROR,3007,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,2,"['ERROR', 'error']","['ERROR', 'errored']"
Availability,me 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_de,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20023,ERROR,ERROR,20023,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"miniforge3/envs/perturb-vs-tissue-env/lib/python3.10/site-packages/scanpy/get/get.py:328, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 325 if keys:; 326 df = df[keys]; --> 328 for k, idx in obsm_keys:; 329 added_k = f""{k}-{idx}""; 330 val = adata.obsm[k]. ValueError: too many values to unpack (expected 2); ```; The function works if you pass a list of Tuples:; ```; sc.get.obs_df(adata, obsm_keys = [('X_pca', 1)]); ```; So perhaps the parameter descriptions should say `List of Tuples of (key, column)`? Or the case of extracting a single column should be handled. . 2. The input for the `keys` is described as [""keys""](https://github.com/scverse/scanpy/blob/39c6532d276ca83cc0548546c3d73ebee6eec0c1/src/scanpy/get/get.py#L238-L239), but if you pass only one key as a string, the function returns a `pd.Series` instead of a `pd.DataFrame`. This is not a massive problem, unless you also pass something to `obsm_keys`. When you do that, the function gives no error but the `obsm` column is concatenated as an extra row; Example:; ```py; sc.get.obs_df(adata, keys='louvain', obsm_keys = [('X_pca', 1)]); ```; ```pytb; index; AAACATACAACCAC-1 CD4 T cells; AAACATTGAGCTAC-1 B cells; AAACATTGATCAGC-1 CD4 T cells; AAACCGTGCTTCCG-1 CD14+ Monocytes; AAACCGTGTATGCG-1 NK cells; ... ; TTTCTACTGAGGCA-1 B cells; TTTCTACTTCCTCG-1 B cells; TTTGCATGAGAGGC-1 B cells; TTTGCATGCCTCAC-1 CD4 T cells; X_pca-1 [0.2577139, 7.4819846, -1.5836583, -1.3685299,...; Name: louvain, Length: 2639, dtype: object; ```; You get the expected output if you pass the keys as a List; ```py; sc.get.obs_df(adata, keys=['louvain'], obsm_keys = [('X_pca', 1)]); ```; Again, the quick fix would be to change the parameter description for `keys` to `List of keys`.; . ### Versions. <details>. ```; -----; anndata 0.10.8; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.15.0; brotli 1.1.0; certifi 2024.07.04; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3310:2011,error,error,2011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310,1,['error'],['error']
Availability,mmh true that should probably be 1-corr_matrix. I'll ping @flying-sheep he might have a better answer,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1288#issuecomment-702366534:53,ping,ping,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288#issuecomment-702366534,1,['ping'],['ping']
Availability,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665,4,['error'],['error']
Availability,"move `*` if you think there should be some positional ones, especially for pearson residuals). > the ""is median rank a good way to do HVG selection across batches""-issue (see this code comment). thanks for the explanation @jlause , I think is clear and it makes sense that it's the same as Seurat V3. > the question what the final names of the functions should be (see @ivirshup's last post). for `normalize_pearson_residual`, i think it makes sense to keep `normalize` in, as it's not the same type of transformation compared to `log1p`. For the HVG genes, I understand that same API but different function is not nice, but I also think is not nice if the function name change after functions get outside experimental module. For instance, as it is now, it would be `sc.experimental.pp.highly_variable_genes` -> `sc.pp.highly_variable_genes`. Otherwise, it would be `sc.experimental.pp.pearson_deviant_genes ` -> `sc.pp.highly_variable_genes` , which I don't think it is a smooth transition. ; If/when we eventually refactor `highly_variable_genes`, it wouldn't matter (there would be changes in function name anyway), but then again we'd have to consider backward compatibility as well. Furthermore, as it is now, it is true that it's the same `highly_variable_genes` API, but it belongs to the experimental module. Therefore, users would/should not assume the same functionality. In my opinion it's clearer this way as `sc.experimental.pp.highly_variable_genes` provides method in the experiemntal module that do HVG selection (and for now, it happens that only pearson residuals are available). > docs consistency (see @ivirshup's last post); > A number of parameters are available in multiple functions. Would it make sense to use some of our tooling so there's only one place to edit these?. what do you have in mind @ivirshup ? happy to help out but don't think I know what you are referring to. . I will be on vacation until 14th of Sept, will have a look at remaining comments when I'm back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-909055513:1841,avail,available,1841,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-909055513,2,['avail'],['available']
Availability,"mport UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799:3851,error,errors,3851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799,1,['error'],['errors']
Availability,mportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5337,ERROR,ERROR,5337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ms to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608:1423,Error,Error,1423,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608,1,['Error'],['Error']
Availability,"n highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147:2545,error,error,2545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147,2,['error'],['error']
Availability,"n reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I install scanpy==1.9.6 with pip (anndata==0.10.4), something wrong and adata.X.nnz is 0.; I changed the version of anndata to 0.9.2, it works normal. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(my_sample, # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=False) # write a cache file for faster subsequent reading; # sc.pl.highest_expr_genes(adata, n_top=20, ); adata.X.nnz; ```. ### Error output. _No response_. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.5; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; bottleneck 1.3.5; cffi 1.16.0; comm 0.1.2; cycler 0.12.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 4.4.2; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; hurry NA; ipykernel 6.25.0; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.7; numpy 1.26.0; packaging 23.2; pandas 1.5.3; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.11; pyparsing 3.0.9; pytz 2023.3.pos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2822:1099,Error,Error,1099,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2822,1,['Error'],['Error']
Availability,"n reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new. ...; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > ... [Version](url) of the packages in path : ; scanpy 1.4.4.post1; anndata 0.6.22.post1; anndata2ri 1.0.1; umap-learn 0.3.10; numpy 1.16.5; scipy 1.3.1; pandas 1.0.1; scikit-learn 0.21.3; statsmodels 0.10.1; python-igraph 0.7.1.post6; louvain 0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:4131,error,errors,4131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,2,['error'],"['error', 'errors']"
Availability,n residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: canno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6185,ERROR,ERROR,6185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"n the context of https://github.com/scverse/scanpy/pull/3099/files#diff-afb2fb35cbde7ff5e7d9b79874ede22605918cdba923250dd554f23353702e45R65-R67 where @Intron7 was casting first, and then multiplying (because it should be more accurate), but this revealed that we are _not_ doing this at the moment, despite the fact that it is more accurate. And then downstream analyses can change quite a bit. Thus we should remedy this for the next minor release as it is a breaking change to e.g., https://dev.azure.com/scverse/scanpy/_build/results?buildId=7094&view=logs&j=5ea502cf-d418-510c-3b5f-c4ba606ae534&t=534778bb-2f86-5739-7d3c-59518f7b5a2b&l=2171; <img width=""731"" alt=""Screenshot 2024-06-26 at 16 21 27"" src=""https://github.com/scverse/scanpy/assets/43999641/6c58d0a1-aa44-4f42-87ca-16250d3de641"">. ### Minimal code sample. ```python; import numpy as np; arr = np.random.random((10, 10_000)).astype(""float32""). print(np.multiply(arr, arr, dtype=""float64"")); print(np.multiply(arr, arr)); ```. ### Error output. ```pytb; N/A; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.0rc2.dev74+g1c98fd19; -----; IPython 8.24.0; PIL 10.3.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.5.1; dateutil 2.9.0.post0; decorator 5.1.1; defusedxml 0.7.1; distutils 3.12.3; executing 2.0.1; h5py 3.11.0; igraph 0.11.5; jedi 0.19.1; jinja2 3.1.4; joblib 1.4.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; louvain 0.8.2; markupsafe 2.1.5; matplotlib 3.9.0; mpl_toolkits NA; msgpack 1.0.8; natsort 8.4.0; numba 0.59.1; numcodecs 0.12.1; numpy 1.26.4; packaging 24.0; pandas 2.2.2; parso 0.8.4; pkg_resources NA; prompt_toolkit 3.0.45; psutil 5.9.8; pure_eval 0.2.2; pyarrow 16.1.0; pygments 2.18.0; pyparsing 3.1.2; pytz 2024.1; scipy 1.13.1; session_info 1.0.0; setuptools 70.0.0; setuptools_scm NA; sitecustomize NA; six 1.16.0; sklearn 1.5.0; sparse 0.15.4; sphinxcontrib NA; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3127:1731,Error,Error,1731,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3127,1,['Error'],['Error']
Availability,n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43947,Error,Error,43947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,n...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69246,ERROR,ERROR,69246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,n12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6130,Error,Error,6130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"n3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:6179,error,error,6179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"n3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-3-69925a75d466> in <module>; 1 #calcular e visualizar metricas de QC por estudo; ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), ; 3 percent_top=None, layer=None, use_raw=False, inplace=True,; 4 log1p=False, parallel=None); 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 304 X.eliminate_zeros(); 305 ; --> 306 obs_metrics = describe_obs(; 307 adata,; 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1925:3180,toler,tolerance,3180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925,1,['toler'],['tolerance']
Availability,"n; 4 from ._highly_variable_genes import highly_variable_genes; 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in; 4 from anndata import AnnData; 5; ----> 6 from . import _simple as pp; 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1797:1991,error,errors,1991,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797,1,['error'],['errors']
Availability,"nDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'); ```. <details>; <summary>Versions</summary>. Package Version; ----------------------- ------------; absl-py 1.1.0; aiohttp 3.8.1; aiosignal 1.2.0; anndata 0.7.5; anndata2ri 1.0.6; annoy 1.17.0; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; asn1crypto 1.4.0; async-timeout 4.0.2; asynctest 0.13.0; attrs 20.3.0; backcall 0.2.0; beautifulsoup4 4.11.1; bleach 5.0.0; boto3 1.17.66; botocore 1.20.66; brotlipy 0.7.0; cached-property 1.5.2; cachetools 5.2.0; certifi 2020.12.5; cffi 1.14.5; chardet 4.0.0; charset-normalizer 2.0.12; chex 0.1.3; click 8.1.3; colormath 3.0.0; commonmark 0.9.1; conda 4.6.14; conda-package-handling 1.7.3; cryptography 3.4.7; cycler 0.10.0; Cython 0.29.30; decorator 5.0.7; defusedxml 0.7.1; dill 0.3.3; dm-tree 0.1.7; docrep 0.3.2; entrypoints 0.4; et-xmlfile 1.1.0; fa2 0.3.5; fastjsonschema 2.15.3; flatbuffers 2.0; flax 0.5.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:1857,error,error,1857,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['error'],['error']
Availability,n_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10049,ERROR,ERROR,10049,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,n_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10259,ERROR,ERROR,10259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,n_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15109,ERROR,ERROR,15109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:3071,error,error,3071,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,2,['error'],['error']
Availability,"nal) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`; - Enabled `return_fig`; - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python; import scanpy as sc; import anndata as ad; import pandas as pd; import numpy as np. obs = pd.DataFrame(np.arange(100), ; columns=['a'], ; index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5); adata = ad.AnnData(X=X, obs=obs); sc.tl.pca(adata); sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca; ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]); KeyError: ''; ```. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev128+g616d5803; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.3; numpy 1.23.4; packaging 21.3; pandas 1.5.1; pkg_resources NA; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.3; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.1.3; threadpoolctl 3.1.0; typing_extensions NA; zoneinfo NA; -----; Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]; macOS-<redacted>-arm64-arm-64bit; -----; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2681:1197,Error,Error,1197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681,1,['Error'],['Error']
Availability,"name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:4053,error,error,4053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"narios. The USP of h5 files, however, is that you can index and slice them on disk as if they were in memory. This way I could greatly reduce the data size before loading it into memory. However, when I attempt to filter on a backed anndata object, I encounter a TypeError. The case of gene filtering should be just a column-sum, comparing it against a threshold and then saving it as a boolean index mask. It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; h5py 3.10.0; igraph 0.11.4; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; packaging 23.2; pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:1542,Error,Error,1542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['Error'],['Error']
Availability,nd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66785,ERROR,ERROR,66785,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"nent, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 756 with warnings.catch_warnings():; 757 warnings.simplefilter(""ignore""); --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'); 759 # draw directed edges; 760 else:. /usr/local/lib/python3.6/dist-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds); 609 # value globally, since the user can instead provide per-edge alphas; 610 # now. Only set it globally if provided as a scalar.; --> 611 if cb.is_numlike(alpha):; 612 edge_collection.set_alpha(alpha); 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ```. I've been searching online and found some related threads like [this](https://github.com/palash1992/GEM/issues/51) and [this](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). Is there a solution that doesn't require me to downgrade my matplotlib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227:2591,down,downgrade,2591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227,1,['down'],['downgrade']
Availability,nes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42759,Error,Error,42759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,nes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48626,Error,Error,48626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,new AnnData `.is_view` causes error.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151,1,['error'],['error']
Availability,"ng(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:2914,error,error,2914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,1,['error'],['error']
Availability,"niconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2122:2726,down,downgrade,2726,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122,1,['down'],['downgrade']
Availability,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2376:1679,error,error,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376,3,['error'],['error']
Availability,nked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image file,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49034,Error,Error,49034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17811,ERROR,ERROR,17811,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14258,ERROR,ERROR,14258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14052,ERROR,ERROR,14052,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Imag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47661,Error,Error,47661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,nown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19661,ERROR,ERROR,19661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"npy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. aggregate throws error when aggregating `obsm` or `varm`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.get.aggregate(adata, by=""louvain"", func=""mean"", obsm=""X_umap""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[3], line 1; ----> 1 sc.get.aggregate(pbmc, by=""louvain"", func=""mean"", obsm=""X_umap""). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/functools.py:909, in singledispatch.<locals>.wrapper(*args, **kw); 905 if not args:; 906 raise TypeError(f'{funcname} requires at least '; 907 '1 positional argument'); --> 909 return dispatch(args[0].__class__)(*args, **kw). File /mnt/workspace/repos/scanpy/scanpy/get/_aggregated.py:272, in aggregate(adata, by, func, axis, mask, dof, layer, obsm, varm); 264 # Actual computation; 265 layers = aggregate(; 266 data,; 267 by=categorical,; (...); 270 dof=dof,; 271 ); --> 272 result = AnnData(; 273 layers=layers,; 274 obs=new_label_df,; 275 var=getattr(adata, ""var"" if axis == 0 else ""obs""),; 276 ); 278 if axis == 1:; 279 return result.T. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:271, in AnnData.__init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, obsp, varp, oidx, vidx); 269 self._init_as_view(X, oidx, vidx); 270 else:; --> 271 self._init_as_actual(; 272 X=X,; 273 obs=obs,; 274 var=var,; 275 uns=uns,; 276 obsm=obsm,; 277 varm=varm,; 278 raw=raw,; 279 layers=layers,; 280 dtype=dtype,; 281 shape=shape,; 282 obsp=obsp,; 283 varp=varp,; 284 filename=filename,; 285 filemode=filemode,; 286 ). File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/anndata/_core/anndata.py:501, in AnnData._init_as_actual(self, X, obs, var, uns, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2929:1147,mask,mask,1147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2929,1,['mask'],['mask']
Availability,npy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70371,ERROR,ERROR,70371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,npy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72037,ERROR,ERROR,72037,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-69be169f6a4f> in <module>; ----> 1 sc.get.obs_df(adata, [""var_id""]). ~/miniconda3/envs/scanpy-1.6/lib/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:2116,error,error,2116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability,"nse for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_counts` be? At the time I figured it didn't matter, since anything downstream should be able to deal with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:2279,down,downstream,2279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['down'],['downstream']
Availability,"numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:13071,error,error,13071,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,['error'],['error']
Availability,"number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return self._repopulate_pool_static(self._ctx, self.Process,; 304 self._processes,; 305 self._pool, self._inqueue,; 306 self._outqueue, self._initializer,; 307 self._initargs,; 308 self._maxtasksperchild,; 309 self._wrap_exception). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:326, in Pool._repopulate_pool_static(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception); 325 w.daemon = True; -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2506:1461,Error,Error,1461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506,1,['Error'],['Error']
Availability,"number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-69be169f6a4f> in <module>; ----> 1 sc.get.obs_df(adata, [""var_id""]). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 171 for k, l in zip(keys, lookup_keys):; 172 if not use_raw or k in adata.obs.columns:; --> 173 df[k] = adata.obs_vector(l, layer=layer); 174 else:; 175 df[k] = adata.raw.obs_vector(l). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/anndata.py in obs_vector(self, k, layer); 1362 ); 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:2843,error,errors,2843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability,"nvs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 255 if sz == 0:; 256 raise ValueError(""Cannot cut empty array""); --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)); 259 mn, mx = (mi + 0.0 for mi in rng); 261 if np.isinf(mn) or np.isinf(mx):; 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds); 145 result = alt(values, axis=axis, skipna=skipna, **kwds); 146 else:; --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds); 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs); 401 if datetimelike and mask is None:; 402 mask = isna(values); --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs); 406 if datetimelike:; 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask); 1086 if values.size == 0:; 1087 return _na_for_min_count(values, axis); -> 1089 values, mask = _get_values(; 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask; 1091 ); 1092 result = getattr(values, meth)(axis); 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask); 314 if datetimelike or _na_ok_dtype(dtype):; 315 values = values.copy(); --> 316 np.putmask(values, mask, fill_value); 317 else:; 318 # np.where will promote if needed; 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array; ```. ### Versions. <details>. ```; scanpy 1.10.1; numpy 1.26.0. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:11468,mask,mask,11468,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,8,['mask'],['mask']
Availability,oarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19094,ERROR,ERROR,19094,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,oat32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4230,ERROR,ERROR,4230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"oc=self.loc, errcls_=defaulterrcls):; --> 273 self.lower_inst(inst); 274 self.post_block(block); 275 . ~\AppData\Local\Continuum\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 750 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 751 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 752 reraise(type(newerr), newerr, tb); 753 ; 754 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\utils.py in reraise(tp, value, tb); 79 if value.__traceback__ is not tb:; 80 raise value.with_traceback(tb); ---> 81 raise value; 82 ; 83 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. File ""..\..\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 412:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. During: lowering ""id=13[LoopNest(index_variable = parfor_index.264, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (412)>, 400: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (418)>, 402: <ir.Block at C:\Users\tpeng\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (419)>, 276: <ir.Block at C:\Users\tpeng\AppData\L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:13727,error,error,13727,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],['error']
Availability,"ocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 ; ```. I was also surprised since this should be the first few functions people run.; ```calculate_qc_metrics``` was there for a long time. But ```top_segment_proportions_sparse_csr``` seems to be a new version since 1.4.5- I checked the _qc.py in the tar.gz files. Sorry my previous description was not accurate.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572708303:1929,error,errors,1929,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572708303,1,['error'],['errors']
Availability,"ocker pull dynverse/ti_paga_issue. # enter the container ; docker run --entrypoint bash -it dynverse/ti_paga_issue. # create an example dataset and save it at /input.h5; /code/example.sh /input.h5. # enter python; python; ```; Inside python; ```python; import dynclipy; task = dynclipy.main([""--dataset"", ""/input.h5"", ""--output"", ""/output.h5""]). import scanpy.api as sc; import anndata. counts = task[""counts""]. adata = anndata.AnnData(counts); sc.pp.recipe_zheng17(adata, n_top_genes=101); sc.tl.pca(adata, n_comps=50); sc.pp.neighbors(adata, n_neighbors=15); ```; Which generates the following warning:; ```; /usr/local/lib/python3.7/site-packages/umap/umap_.py:349: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 467:; def fuzzy_simplicial_set(; <source elided>; if knn_indices is None or knn_dists is None:; knn_indices, knn_dists, _ = nearest_neighbors(; ^. @numba.jit(); /usr/local/lib/python3.7/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. self.func_ir.loc)); /usr/local/lib/python3.7/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""usr/local/lib/python3.7/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/688:2481,error,errors,2481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688,1,['error'],['errors']
Availability,ode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43156,Error,Error,43156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"odepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ""9""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:346: in impl; if min_ver is not None and version < min_ver:; ~/.conda/envs/custom/lib/python3.8/distutils/version.py:52: in __lt__; c = self._cmp(other); ~/.conda/envs/custom/lib/python3.8/distutils/version.py:337: in _cmp; if self.version < other.version:; E TypeError: '<' not supported between instances of 'str' and 'int''`; I have the current ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1515,error,errors,1515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. **In fact, that's not a real bug report, but a suggestion about safe design to plot with scanpy.**. It may happen when our celltype name is too long to show in the plotting figure.; The problem happens here:. https://github.com/scverse/scanpy/blob/a20334f02e6f2a0b56dd6dd862b07d5bdd4d879e/scanpy/plotting/_baseplot_class.py#L1059-L1061. It cut off the string in functions `dotplot`/`matrixplot(var_group_labels=)` , as the function `_plot_var_groups_brackets(group_labels=)`. So, when we use code like the sample, the veryvery long labels will be cut off & we got an Error; Because Var `celltype_order` is a list, and function `_plot_var_groups_brackets` (PATH: [scanpy/plotting/_baseplot_class.py](https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_baseplot_class.py)) will affect the string in list,; then if affect the `celltype_order` itself, so. when called with the `categories_order`, it has been changed by `_plot_var_groups_brackets`, then the Error happened. I suggest to add one copy, for parameter `group_labels` in function `_plot_var_groups_brackets`; It may help someone are not so skillful on coding, to solve the problem maybe happen. For example: add the code `group_labels = copy.deepcopy(group_labels)` at the top of function `_plot_var_groups_brackets`. Thank you very much for your attention. ### Minimal code sample. ```python; adata: any anndata; markers: gene list include in var_names; group: obs key; celltype_order = ['short', 'veryveryverylong_name', 'others', ...]. sc.pl.dotplot(; 	adata, markers, group, show=False, swap_axes=True,; 	categories_order=celltype_order, var_group_labels=celltype_order, var_group_positions=pos_markers,; ); ```. ### Error output. ```pytb; KeyError: ""['veryvery.'] not in index""; # (in fact the 'veryvery.' comes from the 'veryveryverylong_name' in celltype_order ); ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3081:1252,Error,Error,1252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3081,2,['Error'],['Error']
Availability,"ok, I solved the error by uninstalling umap and installing umap-learn; it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1202#issuecomment-624926006:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202#issuecomment-624926006,1,['error'],['error']
Availability,"ok, finished also with tests (I took what you had already for gearys C that tested for different types and consistency). Had to change to float32 cause I was having reproducibility errors (possibly due to overflow). ready to review, thank you!; btw I took a fair bit of code from gearysc re design and tests, so if you think should add better acknowledgment or co-author this PR, please go ahead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-800582076:181,error,errors,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-800582076,1,['error'],['errors']
Availability,"ols/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds); 376 if self.stats is None:; 377 idx = pd.MultiIndex.from_tuples([(group_name, first_col)]); --> 378 self.stats = pd.DataFrame(columns=idx); 379 ; 380 if n_genes_user is not None:. /usr/local/lib/python3.8/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 433 ); 434 elif isinstance(data, dict):; --> 435 mgr = init_dict(data, index, columns, dtype=dtype); 436 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2121:3312,Mask,MaskedArray,3312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121,1,['Mask'],['MaskedArray']
Availability,om 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21140,ERROR,ERROR,21140,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"on); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 90 df['dispersions'] = dispersion; 91 if flavor == 'seurat':; ---> 92 df['mean_bin'] = pd.cut(df['means'], bins=n_bins); 93 disp_grouped = df.groupby('mean_bin')['dispersions']; 94 disp_mean_bin = disp_grouped.mean(). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/pandas/core/reshape/tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates); 226 # GH 24314; 227 raise ValueError(; --> 228 ""cannot specify integer `bins` when input data contains infinity""; 229 ); 230 elif mn == mx: # adjust end points before binning. ValueError: cannot specify integer `bins` when input data contains infinity; ```. I am assuming its something wrong with the dataset (it's a publicly available one which I needed to convert from a Seurat Object), but I can't figure out what. . I have checked if there are any Inf values included in adata.X or adata.raw.X but there are not. Also both adata.X and adata.raw.X are sparse matrices. Any ideas would be greatly appreciated. . ![Screen Shot 2020-03-13 at 6 09 35 PM](https://user-images.githubusercontent.com/15019107/76643678-d6e24500-6555-11ea-88c0-c16f097432e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:3217,avail,available,3217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['avail'],['available']
Availability,on.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17408,ERROR,ERROR,17408,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,on_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:12380,ERROR,ERROR,12380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,on_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.dat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16379,ERROR,ERROR,16379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,onda-forge; libstdcxx-ng 13.1.0 hfd8a6a1_0 conda-forge; libuuid 2.38.1 h0b41bf4_0 conda-forge; libzlib 1.2.13 hd590300_5 conda-forge; lightning 2.0.5 pypi_0 pypi; lightning-cloud 0.5.37 pypi_0 pypi; lightning-utilities 0.9.0 pypi_0 pypi; lit 15.0.7 pypi_0 pypi; llvmlite 0.40.1 pypi_0 pypi; markdown-it-py 3.0.0 pypi_0 pypi; markupsafe 2.1.2 pypi_0 pypi; matplotlib 3.7.2 pypi_0 pypi; matplotlib-inline 0.1.6 pyhd8ed1ab_0 conda-forge; mdurl 0.1.2 pypi_0 pypi; ml-collections 0.1.1 pypi_0 pypi; ml-dtypes 0.2.0 pypi_0 pypi; mpmath 1.2.1 pypi_0 pypi; msgpack 1.0.5 pypi_0 pypi; mudata 0.2.3 pypi_0 pypi; multidict 6.0.4 pypi_0 pypi; multipledispatch 1.0.0 pypi_0 pypi; muon 0.1.5 pypi_0 pypi; natsort 8.4.0 pypi_0 pypi; ncurses 6.4 hcb278e6_0 conda-forge; nest-asyncio 1.5.6 pyhd8ed1ab_0 conda-forge; networkx 3.1 pypi_0 pypi; numba 0.57.1 pypi_0 pypi; numpy 1.24.4 pypi_0 pypi; numpyro 0.12.1 pypi_0 pypi; openssl 3.1.1 hd590300_1 conda-forge; opt-einsum 3.3.0 pypi_0 pypi; optax 0.1.5 pypi_0 pypi; orbax-checkpoint 0.2.7 pypi_0 pypi; ordered-set 4.1.0 pypi_0 pypi; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 pypi_0 pypi; parasail 1.3.4 pypi_0 pypi; parso 0.8.3 pyhd8ed1ab_0 conda-forge; patsy 0.5.3 pypi_0 pypi; pexpect 4.8.0 pyh1a96a4e_2 conda-forge; pickleshare 0.7.5 py_1003 conda-forge; pillow 10.0.0 pypi_0 pypi; pip 23.2.1 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; protobuf 4.23.4 pypi_0 pypi; psutil 5.9.5 py311h2582759_0 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pydantic 1.10.11 pypi_0 pypi; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pypi_0 pypi; pynndescent 0.5.10 pypi_0 pypi; pyparsing 3.0.9 pypi_0 pypi; pyro-api 0.1.2 pypi_0 pypi; pyro-ppl 1.8.5 pypi_0 pypi; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.11.4 hab00c5b_0_cpython conda-forge; p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:5147,checkpoint,checkpoint,5147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['checkpoint'],['checkpoint']
Availability,one-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3840,ERROR,ERROR,3840,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"onfirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2645:1068,error,error,1068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645,1,['error'],['error']
Availability,"ontweight='normal', **common); save_and_compare_images('master_paga_compare_pca'); ; colors = {; c: {cm.Set1(_): 0.33 for _ in range(3)}; for c in pbmc.obs[""bulk_labels""].cat.categories; }; colors[""Dendritic""] = {cm.Set2(_): 0.25 for _ in range(4)}; ; sc.pl.paga(pbmc, color=colors, colorbar=False); > save_and_compare_images('master_paga_pie'). scanpy/tests/test_plotting.py:917: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. basename = 'master_paga_pie', tolerance = 30. def save_and_compare(basename, tolerance=None):; path_actual.mkdir(parents=True, exist_ok=True); out_path = path_actual / f'{basename}.png'; pyplot.savefig(out_path, dpi=40); pyplot.close(); if tolerance is None:; tolerance = tol; res = compare_images(; str(path_expected / f'{basename}.png'), str(out_path), tolerance; ); > assert res is None, res; E AssertionError: Error: Image files did not match.; E RMS Value: 36.26034272194439; E Expected: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/_images/master_paga_pie.png; E Actual: ; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie.png; E Difference:; E /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png; E Tolerance: ; E 30; E assert 'Error: Image files did not match.\n RMS Value: 36.26034272194439\n Expected: \n /Users/philipp/Documents/python... /Users/philipp/Documents/python/scanpy/scanpy/tests/figures/master_paga_pie-failed-diff.png\n Tolerance: \n 30' is None. scanpy/tests/conftest.py:35: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------------------------------------; running PAGA; finished: added; 'paga/connectivities', connectivities",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418:3249,toler,tolerance,3249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418,2,"['Error', 'toler']","['Error', 'tolerance']"
Availability,opying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __att,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:6064,error,error,6064,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability,"or: assignment destination is read-only; FAILED scanpy/tests/test_preprocessing_distributed.py::test_write_zarr[dask] - ValueError: buffer source array is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[sparse] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet[dense] - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4174,ERROR,ERROR,4174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['ERROR'],['ERROR']
Availability,or: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20928,ERROR,ERROR,20928,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,or: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - A,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46380,Error,Error,46380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"orLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc); 246 # Init argument values; 247 self.extract_function_arguments(); --> 248 entry_block_tail = self.lower_function_body(); 249 ; 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self); 271 bb = self.blkmap[offset]; 272 self.builder.position_at_end(bb); --> 273 self.lower_block(block); 274 ; 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block); 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback); 128 value = type(); 129 try:; --> 130 self.gen.throw(type, value, traceback); 131 except StopIteration as exc:; 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 723 from numba import config; 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None; --> 725 six.reraise(type(newerr), newerr, tb); 726 ; 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb); 667 if value.__traceback__ is not tb:; 668 raise value.with_traceback(tb); --> 669 raise value; 670 ; 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'; %"".2726"" = icmp eq i32 %"".2724"", %"".2725""; ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype); for i in numba.prange(indptr.size - 1):; ^. [1] During: lowering ""id=13[LoopNe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:12521,error,errors,12521,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,"orceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:443... connected.; HTTP request sent, awaiting response... 302 Found; Location: https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5 [following]; --2022-03-24 02:54:21-- https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5; Resolving codeload.github.com (codeload.github.com)... 140.82.114.9; Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.; HTTP request sent, awaiting response... 200 OK; Length: unspecified [application/x-gzip]; Saving to: ‘v0.3.5.tar.gz’. v0.3.5.tar.gz [ <=> ] 434.98K 1.03MB/s in 0.4s . 2022-03-24 02:54:22 (1.03 MB/s) - ‘v0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:1669,error,error,1669,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability,"ore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.11.1 python-igraph==0.9.6 pynndescent==0.5.4. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:1679,error,errors,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,2,"['Down', 'error']","['Downloads', 'errors']"
Availability,"orhood_enrichment; import schist as scs; with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4053,Error,Error,4053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['Error'],['Error']
Availability,"orkflow and speed up review.; -->; <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Hi,; We are submitting PR for speed up of the regress_out function. Here we finding coefficient using Linear regression (Linear Least Squares) rather then GLM for non categorical data. | | Time(sec)|; | -----------| ----- |; | Original | 297|; | Updated | 14.91 |; | Speedup | 19.91 |. experiment setup : AWS r7i.24xlarge. ```python; import time; import numpy as np. import pandas as pd. import scanpy as sc; from sklearn.cluster import KMeans. import os; import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '); warnings.simplefilter('ignore'); input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):; print('Downloading import file...'); wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes; MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out; markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells; min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed; max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes; min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this; n_top_genes = 4000 # Number of highly variable genes to retain. # PCA; n_components = 50 # Number of principal components to compute. # t-SNE; tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means; k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs; sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(); tr=t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3110:1176,down,download,1176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110,1,['down'],['download']
Availability,orkspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERRO,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72838,ERROR,ERROR,72838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ormalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24053,ERROR,ERROR,24053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ormalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16793,ERROR,ERROR,16793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ormat.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 1046 ); -> 1047 return fmt.DataFrameRenderer(formatter).to_html(notebook=True); 1048 else:; 1049 return None. ~/.miniconda3/envs/cellrank/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5679,mask,mask,5679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57740,ERROR,ERROR,57740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59076,ERROR,ERROR,59076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56404,ERROR,ERROR,56404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59579,ERROR,ERROR,59579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ortError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2599,ERROR,ERROR,2599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,os/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62849,ERROR,ERROR,62849,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,os/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66451,ERROR,ERROR,66451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,os/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74810,ERROR,ERROR,74810,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,otplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpe,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50005,Error,Error,50005,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,otplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: E,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48907,Error,Error,48907,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"ouch, it’s pretty error prone to just guess! What if a column is in both `.var` and `.obs`? People will never figure out what they need to do in order to get what they want. I don’t like replicating that or that it ever went into any function. Explicit is better than implicit. We could throw a nice error if the column isn’t in `.obs` but is in `.var` instead, like. > You specified column “dropout_per_gene” which is not in `.obs`, but in `.var`. Did you mean to call `sc.pl.violin(adata.T, ...)`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441214996:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441214996,2,['error'],['error']
Availability,"ould be the solution? Thank you. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python; _, axs = pl.subplots(ncols=3, figsize=(6, 2.5), gridspec_kw={'wspace': 0.05, 'left': 0.12}); pl.subplots_adjust(left=0.05, right=0.98, top=0.82, bottom=0.2); for ipath, (descr, path) in enumerate(paths):; _, data = sc.pl.paga_path(; adata, path, gene_names,; show_node_names=False,; ax=axs[ipath],; ytick_fontsize=8,; left_margin=0.15,; n_avg=50,; annotations=['distance'],; show_yticks=True if ipath==0 else False,; show_colorbar=False,; color_map='Greys',; groups_key='clusters',; color_maps_annotations={'distance': 'viridis'},; title='{} path'.format(descr),; return_data=True,; show=False); data.to_csv('./write/paga_path_{}.csv'.format(descr)); pl.savefig('./figures/paga_path_panglao.pdf'); pl.show(); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csr_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-8-86ecf06e6589> in <module>(); 18 title='{} path'.format(descr),; 19 return_data=True,; ---> 20 show=False); 21 data.to_csv('./write/paga_path_{}.csv'.format(descr)); 22 pl.savefig('./figures/paga_path_panglao.pdf'). 5 frames; <__array_function__ internals> in cumsum(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds); 45 except AttributeError:; 46 wrap = None; ---> 47 result = getattr(asarray(obj), method)(*args, **kwds); 48 if wrap:; 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence.; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; > scanpy==1.5.1 anndata==0.7.3 umap==0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295:1187,Error,Error,1187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295,1,['Error'],['Error']
Availability,"ow. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though!. /Alma. ### Minimal code sample. ```python; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['connectivities']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k; np.testing.assert_equal(nn,k); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; anyio NA; arrow 1.2.3; asciitree NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2587:2842,Error,Error,2842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587,1,['Error'],['Error']
Availability,"p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2396:1537,error,errors,1537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396,1,['error'],['errors']
Availability,"p.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 262, in cut; raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. --------------------------------------------. Concerns:; 1. I am not sure if its the way I created the anndata that is causing this problem.; 2. I have already log_normalized my data object and I am not sure what else to do. ; 3. I have also read the GitHub issues and tried to fix the problems but I am unable to. ; 4. I am attaching my own code here, which is exactly the one found on the website above. The error code is in the last few lines of my script. Not sure if anything I am doing before is causing the problem. [scanpy.txt]; (https://github.com/scverse/scanpy/files/8536536/scanpy.txt). Thank you.; Regards,; Shamini A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2242:2623,error,error,2623,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242,1,['error'],['error']
Availability,"p\__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 . C:\ProgramData\Anaconda3\lib\site-packages\umap\umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,. C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\decorators.py in wrapper(func); 217 with typeinfer.register_dispatcher(disp):; 218 for sig in sigs:; --> 219 disp.compile(sig); 220 disp.disable_compile(); 221 return disp. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 123 ; 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:6060,error,errors,6060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,p_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5677,Error,Error,5677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"p_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; markupsafe 2.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685:2449,Error,Error,2449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685,1,['Error'],['Error']
Availability,pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16681,mask,mask-,16681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2464,ERROR,ERROR,2464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"pe({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 285 for sub_key, sub_value in value.items():; --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs); 287 ; 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 193 f""Above error raised while writing key {key!r} of {type(elem)}""; 194 f"" from {parent}.""; --> 195 ) from e; 196 ; 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /.; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1131:5342,error,error,5342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131,2,['error'],['error']
Availability,pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7887,ERROR,ERROR,7887,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - Impor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8104,ERROR,ERROR,8104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"ph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python; import urllib.request; import scanpy as sc. # load the data; h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad""; urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") ; adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10; k=10; sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True); adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32); print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold; max_neighbors = np.max(adjacency.sum(axis=0)); print(f""Max neighbors={max_neighbors}""); ```. ### Error output. ```pytb; adjacency matrix (k=10) shape: (1011, 1011); Max neighbors=91; ```. ### Versions. <details>. ```; -----; anndata 0.10.6; scanpy 1.9.8; -----; Bio 1.83; MOODS NA; PIL 10.2.0; absl NA; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.2.0; attrs 23.2.0; babel 2.14.0; biothings_client 0.3.1; bpnetlite 0.6.0; cattr NA; cattrs NA; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.6; colorlog NA; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; dragonnfruit 0.3.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; filelock 3.13.1; fqdn NA; fsspec 2024.3.1; goatools 1.3.11; google NA; h5py 3.10.0; hdf5plugin 4.4.0; idna 3.6; igraph 0.11.4; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 0.9.24; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3014:1574,Error,Error,1574,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014,1,['Error'],['Error']
Availability,"ple who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a reference for the community. For example:. ![image](https://user-images.githubusercontent.com/1140359/38873972-4953977a-4257-11e8-8675-a238738eb558.png). Another question is other single cell Python packages like magic, ZIFA or DCA, for example. There will hopefully be more in the future. A contrib repo might include these, as well i.e. `sc.tl.magic`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:1721,mainten,maintenance,1721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['mainten'],['maintenance']
Availability,plot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49599,Error,Error,49599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,plot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44117,Error,Error,44117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,port name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:20200,ERROR,ERROR,20200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,portError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5761,ERROR,ERROR,5761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"port_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all?. ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921); - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1898:3929,avail,available,3929,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898,1,['avail'],['available']
Availability,pos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65807,ERROR,ERROR,65807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G', 'H',; 'I', 'J',; 'K', 'L']; adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].cat.rename_categories(new_cluster_names); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, threshold=0.03); sc.tl.draw_graph(adata, init_pos='paga'); sc.pl.draw_graph(adata, color=['seurat_clusters'], legend_loc='right margin'); adata.uns['iroot'] = np.flatnonzero(adata.obs['seurat_clusters'] == 'C')[0]; sc.tl.dpt(adata); adata.obs['dpt_pseudotime']; adata; sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']); ```pytb; [Paste the error output produced by the above code here]; ```; ![1634300003(1)](https://user-images.githubusercontent.com/92583306/137486504-8a01bfc7-cbdf-409f-a730-dfec94f8c4f7.png). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2015:2607,error,error,2607,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015,1,['error'],['error']
Availability,"ps; group1 = 'sample0'; perts = ['sample1', 'sample2', 'sample3', 'sample4']. # Run the loop to get p-values; for group2 in perts:; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=[group2],; reference=group1,; method='wilcoxon'); result = adata.uns[""rank_genes_groups""]; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals). print('______________________________________________'); # Run all at once; sc.tl.rank_genes_groups(adata,; groupby='gene',; groups=perts,; reference=group1,; method='wilcoxon'). result = adata.uns[""rank_genes_groups""]; for group2 in perts:; #mask = result['pvals_adj'][group2] < p_value_threshold; filtered_genes = result['names'][group2]#[mask]; filtered_pvals = result['pvals_adj'][group2]#[mask]; filtered_scores = result['scores'][group2]#[mask]; print(filtered_pvals); ```. ### Error output. ```pytb; I would expect to see different adjusted p-values for the first and the second case. When looping (first case) the method does not see other comparisons coming from the loop, while in the second case the method does see them but still does not correct for them.; ```. ### Versions. <details>. ```; -----; anndata 0.10.7; scanpy 1.10.2; -----; PIL 10.4.0; anyio NA; apport_python_hook NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; cairo 1.20.1; certifi 2024.07.04; cffi 1.16.0; chardet 4.0.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.4; comm 0.2.2; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.8.0; dateutil 2.9.0.post0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; exceptiongroup 1.2.1; executing 2.0.1; fastjsonschema NA; fqdn NA; gi 3.42.1; gio NA; glib NA; gobject NA; gtk NA; h5py 3.11.0; idna 3.3; igraph 0.11.5; ipykernel 6.29.4; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.2; json5 0.9.25;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3221:2627,Error,Error,2627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3221,1,['Error'],['Error']
Availability,ps[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48780,Error,Error,48780,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,psutil error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35,1,['error'],['error']
Availability,"py.api as sc; from scipy import sparse; A = sparse.rand(100, 100, 0.1, ""csr""). # This works; sc.pl.clustermap(sc.AnnData(A.toarray())). # This throws an error; sc.pl.clustermap(sc.AnnData(sparse.rand(100, 100, 0.1, ""csr""))); ```. <details>; <summary> Traceback: </summary>. ```python; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-13-f65606c38b22> in <module>; ----> 1 sc.pl.clustermap(sc.AnnData(A)). ~/github/scanpy/scanpy/plotting/anndata.py in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 750 g = sns.clustermap(df, row_colors=row_colors, **kwds); 751 else:; --> 752 g = sns.clustermap(df, **kwds); 753 show = settings.autoshow if show is None else show; 754 if show: pl.show(). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in clustermap(data, pivot_kws, method, metric, z_score, standard_scale, figsize, cbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, row_colors, col_colors, mask, **kwargs); 1299 row_cluster=row_cluster, col_cluster=col_cluster,; 1300 row_linkage=row_linkage, col_linkage=col_linkage,; -> 1301 **kwargs). /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot(self, metric, method, colorbar_kws, row_cluster, col_cluster, row_linkage, col_linkage, **kws); 1126 colorbar_kws = {} if colorbar_kws is None else colorbar_kws; 1127 self.plot_dendrograms(row_cluster, col_cluster, metric, method,; -> 1128 row_linkage=row_linkage, col_linkage=col_linkage); 1129 try:; 1130 xind = self.dendrogram_col.reordered_ind. /usr/local/lib/python3.6/site-packages/seaborn/matrix.py in plot_dendrograms(self, row_cluster, col_cluster, metric, method, row_linkage, col_linkage); 1019 self.dendrogram_row = dendrogram(; 1020 self.data2d, metric=metric, method=method, label=False, axis=0,; -> 1021 ax=self.ax_row_dendrogram, rotate=True, linkage=row_linkage); 1022 else:; 1023 self.ax_row_dendrogram.set_xticks([]). /usr/local/lib/python3.6/site-packages/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/356:1105,mask,mask,1105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/356,1,['mask'],['mask']
Availability,py/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_norm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61378,ERROR,ERROR,61378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,py/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63183,ERROR,ERROR,63183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"py/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.14; psutil 5.8.0; ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701:4645,error,error,4645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701,1,['error'],['error']
Availability,"py:777) ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__(self, filename, mode, compresslevel, fileobj, mtime); [190](file:///C:/Program%20Files/Python312/Lib/gzip.py:190) mode += 'b'; [191](file:///C:/Program%20Files/Python312/Lib/gzip.py:191) if fileobj is None:; --> [192](file:///C:/Program%20Files/Python312/Lib/gzip.py:192) fileobj = self.myfileobj = builtins.open(filename, mode or 'rb'); [193](file:///C:/Program%20Files/Python312/Lib/gzip.py:193) if filename is None:; [194](file:///C:/Program%20Files/Python312/Lib/gzip.py:194) filename = getattr(fileobj, 'name', ''). FileNotFoundError: [Errno 2] No such file or directory: 'GSE212966\\GSM6567159_PDAC2_features.tsv.gz'; ```. I have tried with other datasets which are originally named ad matrix, features and barcodes, and those are working properly. Any idea?. ### Minimal code sample. ```python; data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], line 1; ----> 1 data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); 2 data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:560, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 558 prefix = """" if prefix is None else prefix; 559 is_legacy = (path / f""{prefix}genes.tsv"").is_file(); --> 5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:19972,Error,Error,19972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Error'],['Error']
Availability,py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown lo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23444,ERROR,ERROR,23444,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1677,Error,Error,1677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2035,Error,Error,2035,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,pynndescent error when trying to use a custom metric with scanpy neghbors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['error']
Availability,"python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:6195,down,downgrade,6195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['down'],['downgrade']
Availability,"quick practical comment on this very interesting discussion.; @ivirshup shall we have this here or moved to the other package under development? We need to take a decision on this because we'll have to see how it works with rest of functions. Pinging @Koncopd as well.; Sorry to put pressure but we are on a tight schedule 😅 . re: networkx discussion, also agree with Isaac on having these operations external to networkx.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707590491:243,Ping,Pinging,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707590491,1,['Ping'],['Pinging']
Availability,"r branch of scanpy. ### What happened?. I'm trying to use `sc.pl.spatial` with the dataset that is available on 10X Visium with the sample ID `CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma`. I can open and do some basic QC just fine, but when I try to plot, I get the error `TypeError: can't multiply sequence by non-int of type 'float`. ### Minimal code sample. ```python; import scanpy as sc; import anndata as an; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as plt; import seaborn as sns; import scanorama. sc.set_figure_params(facecolor=""white"", figsize=(8, 8)); sc.settings.verbosity = 3. # Loading dataset; adata = sc.read_visium(; path=r""\external"",; count_file=""CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5"",; load_images=True,; source_image_path=r""\spatial"",; ). adata.var_names_make_unique(). # Quality control; adata.var[""mito""] = adata.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(; adata, qc_vars=[""mito""], percent_top=None, log1p=False, inplace=True; ); sc.pl.spatial(adata); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""\scanpy\plotting\_tools\scatterplots.py"", line 1002, in spatial; File ""\plotting\_tools\scatterplots.py"", line 391, in embedding; # if user did not set alpha, set alpha to 0.7; File ""\scanpy\plotting\_utils.py"", line 1107, in circles; if scale_factor != 1.0:; TypeError: can't multiply sequence by non-int of type 'float'; ```; The json file on the spatial folder with the scale factors is as follows:. ```json; {; ""regist_target_img_scalef"": 0.16836435,; ""tissue_hires_scalef"": 0.056121446,; ""tissue_lowres_scalef"": 0.016836435,; ""fiducial_diameter_fullres"": 384.18505640709947,; ""spot_diameter_fullres"": 256.12337093806633; }; ```. `tissue_hires_scalef` is being passed as `scale_factor` variable and hence why it's throwing the error; ### Versions. <details>. ```; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778:1352,Error,Error,1352,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778,2,"['Error', 'error']","['Error', 'error']"
Availability,"r, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; return True; ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:2289,robust,robust,2289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,1,['robust'],['robust']
Availability,"r: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import scanpy.external as sce; import pandas as pd; import numpy as np; import matplotlib as mpl; import matplotlib.pyplot as pl; from scipy.stats import mode; from collections import Counter; import loompy. sc.settings.verbosity = 3; sc.set_figure_params(color_map='viridis'); sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'); adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20); sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim); sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2); ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-10-973f72fa2eb5> in <module>; ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 541 single_component=single_component,; 542 arrowsize=arrowsize,; --> 543 pos=pos,; 544 ); 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094:1054,Error,Error,1054,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094,1,['Error'],['Error']
Availability,r: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ra,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3508,Error,Error,3508,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,r: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47511,Error,Error,47511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,r: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4536,Error,Error,4536,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"r: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:3962,error,error,3962,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"r['gene_symbol'].astype('object'); ```. ### Minimal code sample. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. sc.pl.highest_expr_genes(adata, n_top=20, gene_symbols='gene_symbol', show=True, save="".png""); ```. I also tried this with the same results. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. adata.var.index = adata.var.gene_symbol; sc.pl.highest_expr_genes(adata, n_top=20, show=True, save="".png""); ```. ### Error output. ![349265437-b0a6e963-5d56-40e6-9922-5e4a543c08cf](https://github.com/user-attachments/assets/478c6a20-817f-4e39-92a3-62f5c2a62ed0). Above is a boxplot from `sc.pl.highest_expr_genes` that shows all the Categorical genes in addition to the top-20 as specified in the function argument. <img width=""1077"" alt=""Screenshot 2024-07-17 at 1 23 27 PM"" src=""https://github.com/user-attachments/assets/cfbdb40d-57f5-4da6-bf69-b4f4f3c489cc"">. Above is the correct boxplot, after my hack was applied to force the adata.var.gene_symbols to be mixed-object datatype instead of Categorical. ### Versions. <details>. python-3-10-4. ```; aiohttp==3.8.3; anndata==0.10.6; biocode==0.10.0; biopython==1.79; cairosvg==2.7.1; dash-bio==1.0.2; #diffxpy==0.7.4; Flask==3.0.0; Flask-RESTful==0.3.9; gunicorn; h5py==3.10.0; itsdangerous==2.1.2 # See -> https://stackoverflow.com/a/71206978; jupyterlab==4.0.5; jupyter==1.0.0; kaleido==0.2.1; leidenalg==0.10.2; llvmlite==0.41.1; matplotlib==3.9.0; mod-wsgi==4.9.4; more_itertools==9.0.0; mysql-connector-python==8.4.0; numba==0.58.1; numexpr==2.8.4; numpy==1.26.0; opencv-python==4.5.5.64; openpyxl==3.1.5; pandas==2.2.1; Pillow==10.2.0; pika==1.3.1; plotly==5.6.0; python-dotenv==0.20.0; requests==2.31.0; rpy2==3.5.1 # 3.5.2 and up gives errors with rpy2py and py2rpy; sanic; scanpy==1.10.1; scikit-learn==1.0.2; scipy==1.11.04; seaborn==0.13.2; SQLAlchemy==1.4.32; tables==3.9.2 # Read hdf5 files into pandas; xlrd==1.2.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3158:3377,error,errors,3377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3158,1,['error'],['errors']
Availability,r_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:6836,ERROR,ERROR,6836,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,racksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49452,Error,Error,49452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"rallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 316, in error_rewrite; reraise(type(e), e, None); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/six.py"", line 658, in reraise; raise value.with_traceback(tb); numba.errors.TypingError: Failed at nopython (nopython frontend); Unknown attribute 'partition' of type Module(<module 'numpy' from '/n/app/python/3.7.4-ext/lib/python3.7/site-packages/numpy/__init__.py'>). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. [1] During: typing of get attribute at /home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../../../home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def _top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; elif (end - start) > maxidx:; partitioned[i, :] = -(np.partition(-data[start:end], maxidx))[:maxidx]; ^. This is not usually a problem with Numba itself but instead often caused by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:2809,error,errors,2809,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,1,['error'],['errors']
Availability,rams2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:4648,ERROR,ERROR,4648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rank genes groups errors on less than 2 cells in a category,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3118:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3118,1,['error'],['errors']
Availability,rank_genes_group error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467,1,['error'],['error']
Availability,rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1530:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530,1,['error'],['error']
Availability,"rating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:1515,Error,Error,1515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['Error'],['Error']
Availability,"rcent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent_top); 115 for i, n in enumerate(percent_top):; 116 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 377 mtx = csr_matrix(mtx); 378 return top_segment_proportions_sparse_csr(; --> 379 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 380 ); 381 else:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:6706,error,errors,6706,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,read_10x_h5 errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/132:12,error,errors,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132,1,['error'],['errors']
Availability,read_loom on HCA loom files returns error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2040:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040,1,['error'],['error']
Availability,regress_out() error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1171:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1171,1,['error'],['error']
Availability,repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69896,ERROR,ERROR,69896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449:1893,error,error,1893,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449,1,['error'],['error']
Availability,residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - Import,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19279,ERROR,ERROR,19279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(; 'data/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`; adata; sc.pl.highest_expr_genes(adata, n_top=20, ); sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0-4, multi_panel=True); ```. ### Error output. ```pytb; Kernel Restarting; The kernel for Tests/scanpytutorial/Untitled.ipynb appears to have died. It will restart automatically.; ```. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; asttokens NA; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; exceptiongroup 1.2.0; executing 2.0.1; h5py 3.10.0; igraph 0.11.3; ipykernel 6.29.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.2; mpl_toolkits NA; natsort 8.4.0; nt NA; numba 0.59.0; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pickleshare 0.7.5; platformdirs 4.1.0; prompt_toolkit 3.0.42; psutil 5.9.8; pure_eval 0.2.2; pyarrow 15.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pyparsing 3.1.1; pythoncom NA; pytz 2023.4; pywin32_system32 NA; pywintypes NA; scipy 1.12.0; session_info 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2840:1897,Error,Error,1897,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2840,1,['Error'],['Error']
Availability,"return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2310:2645,error,error,2645,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310,1,['error'],['error']
Availability,"rgs); 5657 self.set_aspect(aspect); 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,; 5659 interpolation=interpolation, origin=origin,; 5660 extent=extent, filternorm=filternorm,; 5661 filterrad=filterrad, resample=resample,; 5662 interpolation_stage=interpolation_stage,; 5663 **kwargs); -> 5665 im.set_data(X); 5666 im.set_alpha(alpha); 5667 if im.get_clip_path() is None:; 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A); 706 self._A = self._A[:, :, 0]; 708 if not (self._A.ndim == 2; 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; --> 710 raise TypeError(""Invalid shape {} for image data""; 711 .format(self._A.shape)); 713 if self._A.ndim == 3:; 714 # If the input data has values outside the valid range (after; 715 # normalisation), we issue a warning and then clip X to the bounds; 716 # - otherwise casting wraps extreme values, hiding outliers and; 717 # making reliable interpretation impossible.; 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.10.1; -----; PIL 9.5.0; anyio NA; arrow 1.3.0; asttokens NA; astunparse 1.6.3; attr 23.1.0; attrs 23.1.0; babel 2.13.0; backcall 0.2.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.0; fastjsonschema NA; fqdn NA; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.2; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.19.1; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.3; jupyterlab_server 2.25.0; kiwi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:5011,reliab,reliable,5011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['reliab'],['reliable']
Availability,"rings(); 1272 return _make_fixed_width(fmt_values, self.justify); 1273 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 10",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5538,mask,mask,5538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,rix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7053,ERROR,ERROR,7053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer corrected table of counts and rount to integer\nout = adjustCounts(sc, roundToInt = TRUE)\n'.; R error message: 'Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : \n duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:5794,error,error,5794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,2,"['Error', 'error']","['Error', 'error']"
Availability,"rmalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:; #; # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.7 pypi_0 pypi; array-api-compa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24667,ERROR,ERROR,24667,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rmalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:13631,ERROR,ERROR,13631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"rn AnnData(; 224 **{; 225 # This is covering up backwards compat in the anndata initializer; 226 # In most cases we should be able to call `func(elen[k])` instead; --> 227 k: read_dispatched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551:6427,error,error,6427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551,1,['error'],['error']
Availability,"rn/decomposition/pca.py in fit_transform(self, X, y); 358 ; 359 """"""; --> 360 U, S, V = self._fit(X); 361 U = U[:, :self.n_components_]; 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X); 380 ; 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,; --> 382 copy=self.copy); 383 ; 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator); 556 "" a minimum of %d is required%s.""; 557 % (n_features, array.shape, ensure_min_features,; --> 558 context)); 559 ; 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required.; ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:; ```; if use_highly_variable is True and 'highly_variable' not in adata.var.keys():; raise ValueError('Did not find adata.var[\'highly_variable\']. '; 'Either your data already only consists of highly-variable genes '; 'or consider running `pp.highly_variable_genes` first.'); if use_highly_variable is None:; use_highly_variable = True if 'highly_variable' in adata.var.keys() else False; if use_highly_variable:; logg.info(' on highly variable genes'); adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```; ```pytb; adata.var.keys(); Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',; 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',; 'n_cells', 'highly_variable', 'means', 'dispersions',; 'dispersions_norm', 'highly_variable_nbatches',; 'highly_variable_intersection'],; dtype='object'); ```. #### Versions:; <!-- Output of scanpy.loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032:2630,error,error,2630,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032,1,['error'],['error']
Availability,rocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73852,ERROR,ERROR,73852,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ror output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:2344,error,errors,2344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['error'],['errors']
Availability,ror: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3357,Error,Error,3357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,roups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48464,Error,Error,48464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,roups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49732,Error,Error,49732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,rror: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Er,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4856,Error,Error,4856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"rror: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ValueError: assignment destination is read-only; FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ValueError: assignment destination is read-only; ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ValueError: assignment destination is read-only. ```. </details>. <details>; <summary> Test failure traceback </summary>. ```pytb; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; ../../mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_highly_variable_genes.py:651: in highly_variable_genes; df = _highly_variable_genes_single_batch(; scanpy/preprocessing/_highly_variable_genes.py:288: in _highly_variable_genes_single_batch; df[""highly_variable""] = _subset_genes(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . adata = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...'pca', 'rank_genes_groups', 'log1p'; ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2902:4617,failure,failure,4617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2902,1,['failure'],['failure']
Availability,"rror: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3702,error,error,3702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"rs, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 126 and (color is None or color in adata.obs.keys() or color in adata.var.index); 127 ):; --> 128 return _scatter_obs(**args); 129 if (; 130 (x in adata.var.keys() or x in adata.obs.index). ~/.local/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in _scatter_obs(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 273 palettes = [palette for _ in range(len(keys))]; 274 for i, palette in enumerate(palettes):; --> 275 palettes[i] = _utils.default_palette(palette); 276 ; 277 if basis is not None:. TypeError: 'str' object does not support item assignment; ```. I get no error if I use any of `sc.pl.palettes`. I also get no error setting `palette=""Set2""` in `sc.pl.umap`, `sc.pl.draw_graph` etc... #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; atac_utils NA; atomicwrites 1.3.0; attr 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:1775,error,error,1775,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['error'],['error']
Availability,"rs/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5230,error,error,5230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,"rs/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=128) value = type(); [130](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32485,error,errors,32485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,rt name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2132,ERROR,ERROR,2132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rt name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23332,mask,mask-,23332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,rtError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5549,ERROR,ERROR,5549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,rtionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - Asser,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4694,Error,Error,4694,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"rue)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ﻿﻿; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:1345,Error,Error,1345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['Error'],['Error']
Availability,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1197,avail,available,1197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627,1,['avail'],['available']
Availability,"s happening is that the ""error on warning"" isn't being overridden correctly when we expect the test to warn. Possibly related to https://github.com/pytest-dev/pytest/issues/11759. @flying-sheep any ideas how to fix? I will just pin pytest for now. ### Minimal code sample. ```python; Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); ```. ### Error output. ```pytb; ======================================================================================================================= FAILURES =======================================================================================================================; _________________________________________________________________________________________________ [doctest] scanpy.preprocessing._simple.filter_cells __________________________________________________________________________________________________; 081 Boolean index mask that does filtering. `True` means that the; 082 cell is kept. `False` means the cell is removed.; 083 number_per_cell; 084 Depending on what was thresholded (`counts` or `genes`),; 085 the array stores `n_counts` or `n_cells` per gene.; 086 ; 087 Examples; 088 --------; 089 >>> import scanpy as sc; 090 >>> adata = sc.datasets.krumsiek11(); UNEXPECTED EXCEPTION: UserWarning('Observation names are not unique. To make them unique, call `.obs_names_make_unique`.'); Traceback (most recent call last):; File ""/mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/doctest.py"", line 1353, in __run; exec(compile(example.source, filename, ""single"",; File ""<doctest scanpy.preprocessing._simple.filter_cells[1]>"", line 1, in <module>; File ""/mnt/workspace/repos/scanpy/scanpy/datasets/_datasets.py"", line 109, in krumsiek11; adata = read(filename, first_column_names=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/mnt/workspace/mambafor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2836:1511,mask,mask,1511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2836,1,['mask'],['mask']
Availability,"s that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, but the error message could definitley be better. ## What should we do about this?. My current inclination is to revert most changes to `obs_df` and `var_df` from this PR and #1499. This should leave the use of indices as groupby untouched. Also, the loss of perfomance from reverting #1499 should be partially mitigated by improvements in pandas (see https://github.com/pandas-dev/pandas/issues/37954). We would keep all the user facing changes, and all the tests from both PRs. We can then make a release now, and can patch in performance boosts during the release cycle. Do you agree with this assessment? If not, could you propose an alternat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:5163,toler,tolerance,5163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['toler'],['tolerance']
Availability,"s() on my gene expression data, I do get separate matrices for names, scores, pvals, and pvals_adj. However, the scores don't match the pvals. In other words, with decreasing pvals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What's the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [NOTE: This doesn't just depend on a specific type of clustering technique. Irrespective of whether I try the in-built Leiden clustering technique, or the Schit library, or even cluster the cells randomly, this issue keeps occuring--which makes me think it's ether a bug, or I don't quite understand how the score generation works, maybe both. I've provided a little code snipper below.]. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12243486/ClusterOneVsRest.csv). ### Minimal code sample. ```python; import pickle; import numpy as np; import pandas as pd; from PIL import Image; import glob; import matplotlib.pyplot as plt; from skimage.morphology import convex_hull_image; from skimage import data, img_as_float; from skimage.util import invert; from scipy.spatial import ConvexHull, convex_hull_plot_2d; from multiprocessing import Pool; i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:1315,down,down,1315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['down'],['down']
Availability,"s); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:5997,error,error,5997,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"s, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:6803,error,errors,6803,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,s.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4904,ERROR,ERROR,4904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,s.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4338,ERROR,ERROR,4338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"s/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2139:1651,error,errors,1651,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139,1,['error'],['errors']
Availability,s/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56235,ERROR,ERROR,56235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,s/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74486,ERROR,ERROR,74486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"s__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. I installed the latest version of scanpy 1.9.3 and python 3.9, my computer is MacBook Pro 2020. ### Minimal code sample. ```python; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. ### Error output. ```pytb; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. ### Versions. <details>. ```. ```. </details>; 1.9.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2949:1881,Error,Error,1881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2949,1,['Error'],['Error']
Availability,s_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1663,ERROR,ERROR,1663,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,s_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5824,Error,Error,5824,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,s_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:7686,ERROR,ERROR,7686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,s_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18680,ERROR,ERROR,18680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"same error in 1.4.4; ```; sc.pp.calculate_qc_metrics(adata, inplace=True, parallel=True); ```; Maybe because sc.pp.calculate_qc_metrics was running in non parallel by default in 1.4.4 and before. the parallel= option has been removed since 1.4.5 and calculate_qc_metrics is running in parallel by default. That's why the error wasn't reported. I don't know enough about numba.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572718846:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572718846,2,['error'],['error']
Availability,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-1322433329:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-1322433329,1,['error'],['error']
Availability,"same here, we are having CI failing in squidpy cause we use the dataset, pinging @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856:73,ping,pinging,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856,1,['ping'],['pinging']
Availability,sc.datasets.ebi_expression_atlas errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082:33,error,errors,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082,1,['error'],['errors']
Availability,sc.datasets.ebi_expression_atlas http errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['errors']
Availability,sc.external.pp.scurblet normalization error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1957:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957,1,['error'],['error']
Availability,sc.get.obs_df() gives an error when `obsm_keys` is given and keys are not given,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1634:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1634,1,['error'],['error']
Availability,sc.pl.dotplot Keyvalue error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,sc.pl.dpt error if n_branchings=0 in sc.tl.dpt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,1,['error'],['error']
Availability,sc.pl.highest_expr_genes() with layer errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3318:38,error,errors,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318,1,['error'],['errors']
Availability,sc.pl.matrixplot index error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114,1,['error'],['error']
Availability,sc.pl.paga value error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381,1,['error'],['error']
Availability,sc.pl.paga_path error in dimensions of array passed to ax.imshow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3025:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025,1,['error'],['error']
Availability,sc.pl.rank_genes_groups use_raw wrong error raised when use_raw=True,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1929:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929,1,['error'],['error']
Availability,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027:278,error,errors,278,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027,1,['error'],['errors']
Availability,sc.pl.umap error message if sc.tl.umap has not been computed.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460,1,['error'],['error']
Availability,sc.pl.violin throws error if adata does not have .raw,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1546:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546,1,['error'],['error']
Availability,sc.pp.calculate_qc_metrics Runtime Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:35,Error,Error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['Error'],['Error']
Availability,sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2304:57,Error,Error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304,1,['Error'],['Error']
Availability,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042,2,['error'],['error']
Availability,sc.pp.neighbors error: api_export.__init__() got an unexpected keyword argument 'metaclass',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3143:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3143,1,['error'],['error']
Availability,sc.pp.regress_out segmentation fault Mac OS X 10.13.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/194:31,fault,fault,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194,1,['fault'],['fault']
Availability,sc.pp.scale and sc.pp.regress_out error on first run of copied object,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731,1,['error'],['error']
Availability,"sc.pp.scale is giving me an error when I run it for the first time, then running fine on the second. This occurs when I run on an object generated using .copy() . ![Screen Shot 2019-07-08 at 10 55 34 AM](https://user-images.githubusercontent.com/26631928/60820560-a8fb6400-a16f-11e9-9915-7d808561af69.png). In terms of the numbers at the end--I have 2176 cells and 1600 highly variable genes. . If I run on an object not generated using copy, I get ""Trying to set attribute `.obs` of view, making a copy."" but it finishes on first run. . If I try to regress out counts first, I get. ![Screen Shot 2019-07-08 at 11 12 57 AM](https://user-images.githubusercontent.com/26631928/60821330-58850600-a171-11e9-9a50-666694bf2c1c.png). One additional oddity--if I run sc.pphighly_variable_genes with flavor = 'seurat' instead of flavor = 'cell_ranger' and call sc.pp.regress_out(Bcell, 'n_counts') prior to running sc.pp.scale(Bcell, max_value = 10) I don't get any error. If I don't run regress_counts but have the 'seurat' flavor I get ; ![Screen Shot 2019-07-08 at 11 22 04 AM](https://user-images.githubusercontent.com/26631928/60822004-9f273000-a172-11e9-814d-dfc83155b488.png). Really not sure what's happening but figured I should let you know. Thanks!. sc.settings.verbosity = 3. scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.4 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731,2,['error'],['error']
Availability,sc.pp.scale(adata) generates NaN error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/64:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/64,1,['error'],['error']
Availability,sc.tl.PAGA error: object of type 'numpy.float64' has no len(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695,1,['error'],['error']
Availability,sc.tl.dpt with error: detected group with only [] cells,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33,1,['error'],['error']
Availability,sc.tl.embedding_density errors when a category has one observation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:24,error,errors,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,1,['error'],['errors']
Availability,"sc.tl.leiden(adata,use_weights=False) ERROR; ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339:38,ERROR,ERROR,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339,1,['ERROR'],['ERROR']
Availability,"sc.tl.louvain() works fine in pandas==0.25.3; but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1017:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017,1,['error'],['error']
Availability,sc.tl.pca error: no field of name X_pca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/504:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504,1,['error'],['error']
Availability,sc.tl.rank_genes_groups return errors,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1478:31,error,errors,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478,1,['error'],['errors']
Availability,"sc.tl.umap error with init_pos=""paga""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769,1,['error'],['error']
Availability,"sc.tl.umap numba error when used with init_pos=""paga""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['error'],['error']
Availability,"scTransform is easily usable if you use rpy2 and anndata2ri. I use directly; the vst R function at this address to make it work; https://github.com/ChristophH/sctransform/blob/master/R/vst.R. Den søn. 23. feb. 2020 kl. 00.44 skrev MalteDLuecken <; notifications@github.com>:. > Hi, It's not available in scanpy at the moment, but I wrote a wrapper for; > it via rpy2 and anndata2ri which is available here:; >; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1068?email_source=notifications&email_token=ACC66UMYH2ZHSMFFQS35FRLREG2ENA5CNFSM4KZJFJP2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMVNJCY#issuecomment-590009483>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACC66UJ2GVSPUTR4WLWM2V3REG2ENANCNFSM4KZJFJPQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590049395:291,avail,available,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590049395,2,['avail'],['available']
Availability,scale for sparse matrixes and mask,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2941:30,mask,mask,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2941,1,['mask'],['mask']
Availability,scanpy conda installation error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990,1,['error'],['error']
Availability,scanpy.pp.log1p with backed h5ad produces copy error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1153:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153,1,['error'],['error']
Availability,scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_resid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16267,mask,mask-,16267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72355,ERROR,ERROR,72355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 sk",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74981,ERROR,ERROR,74981,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72681,ERROR,ERROR,72681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70214,ERROR,ERROR,70214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65332,ERROR,ERROR,65332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67773,ERROR,ERROR,67773,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:19476,ERROR,ERROR,19476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_util,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64501,ERROR,ERROR,64501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64668,ERROR,ERROR,64668,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64169,ERROR,ERROR,64169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2217,ERROR,ERROR,2217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73343,ERROR,ERROR,73343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python ; B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(); sc.pp.scale(B); sc.tl.pca(B, svd_solver='arpack'); ```. Yet I encounter an error:; `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2163:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163,2,['error'],['error']
Availability,"scent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2635:3529,down,downgrade,3529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635,1,['down'],['downgrade']
Availability,"scverse/scanpy/assets/59059267/3dd49231-ed62-4b7f-be1d-a950714667fc"">. but when I change the type of adata.X to float, the value of adata.raw will be changed with adata.X, I get following result; ```py; import numpy as np; import pandas as pd; import anndata as ad; from scipy.sparse import csr_matrix; print(ad.__version__). mtx = np.array([[1.2,2.1,3.9],[2.01,3.99,4.23],[4.21,5.12,6.87],[0,20.12,100.96]]). adata = sc.AnnData(mtx); adata.raw = adata; print(adata); print(adata.X). sc.pp.normalize_total(adata,target_sum=1e4); sc.pp.log1p(adata); print(adata.X) . print(adata.raw.X[0:10,0:10]); ```; I get following result; <img width=""525"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/5eec641b-3542-471b-be22-51ef8e8f31a8"">. It sems strange for me? Shouldn't I save raw data for float data? Could you give some suggestions? My environment is; <img width=""647"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/2267345f-1a2b-4708-90f9-d1892adfb42f"">. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.1; scanpy 1.9.5; -----; CoreFoundation NA; Foundation NA; PIL 9.4.0; PyObjCTools NA; anyio NA; appnope 0.1.2; asttokens NA; attr 22.1.0; babel 2.11.0; backcall 0.2.0; bottleneck 1.3.5; brotli NA; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2748:1816,Error,Error,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748,1,['Error'],['Error']
Availability,"se make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2673:1004,Error,Error,1004,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673,1,['Error'],['Error']
Availability,"se:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 419 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 420 raise e; 421 ; 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws); 351 argtypes.append(self.typeof_pyval(a)); 352 try:; --> 353 return self.compile(tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:7327,error,errors,7327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,"seems like you did something wrong. the commit you added (74540cc133ca9cfe0744ca9d3b250454a76a9c4d) reverts a lot of changes we made since. i assume you just copied all your code over the current master branch, and not the version of the master branch as it was when you made the changes. you need to find the version of scanpy that you downloaded before you made your changes and modify that one to have just the changes you want to commit. otherwise we have no idea what your actual changes are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-489194292:337,down,downloaded,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-489194292,1,['down'],['downloaded']
Availability,setting scipy==1.2 fixes several errors but there is another one maybe related to matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495629061:33,error,errors,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495629061,1,['error'],['errors']
Availability,"should be gene_symbols in plural. On Thu, Mar 14, 2019 at 9:46 AM csijcs <notifications@github.com> wrote:. > Hello, I'm having a bit of trouble with this. I know the issues is closed,; > but I thought it might be better to continue this discussion rather than; > start a new one, though I can do that if you prefer. I have an AnnData; > object adata with ensembl ids as adata.var_name and mouse gene symbols; > under the column adata.var[“gene_name”]. When I call:; > sc.pl.umap(adata, color=['ENSMUSG00000074637']); > It plots no problem. However, when I call:; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); > I get the following error:; >; > Traceback (most recent call last):; >; >; >; > File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; >; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; >; > return plot_scatter(adata, basis='umap', **kwargs); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; >; > use_raw=use_raw, gene_symbols=gene_symbols); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; >; > .format(value_to_plot, adata.obs.columns)); >; >; >; > ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; >; > 'louvain'],; >; > dtype='object'); >; >; > Inspecting adata.var[""gene_name""] give:; >; > index; >; > ENSMUSG00000002459 Rgs20; >; > ENSMUSG00000033740 St18; >; > ENSMUSG00000067879 3110035E14Rik; >; > ENSMUSG00000025912 Mybl1; >; > ENSMUSG00000016918 Sulf1; >; > ENSMUSG00000025938 Slco5a1; >; > ENSMUSG00000025930 Msc; >; > ENSMUSG00000025921 Rdh10; >; > ENSMUSG00000025777 Gdap1; >; > ENSMUSG00000025776 Crispld1; >; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788:648,error,error,648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788,1,['error'],['error']
Availability,"sion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 pynndescent==0.5.10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2580:1813,error,error,1813,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580,1,['error'],['error']
Availability,sion; Gm26206-4 ENSMUSG00000064842 Gene Expression; ... ... ...; Gm26206-55445 ENSMUSG00000064842 Gene Expression; Gm26206-55446 ENSMUSG00000064842 Gene Expression; Gm26206-55447 ENSMUSG00000064842 Gene Expression; Gm26206-55448 ENSMUSG00000064842 Gene Expression; Gm26206-55449 ENSMUSG00000064842 Gene Expression. [55450 rows x 2 columns]; ```. ### Expected. ```pycon; >>> # then anndata=0.10.3; >>> print(adata.var); gene_ids feature_types; 4933401J01Rik ENSMUSG00000102693 Gene Expression; Gm26206 ENSMUSG00000064842 Gene Expression; Xkr4 ENSMUSG00000051951 Gene Expression; Gm18956 ENSMUSG00000102851 Gene Expression; Gm37180 ENSMUSG00000103377 Gene Expression; ... ... ...; mt-Nd6 ENSMUSG00000064368 Gene Expression; mt-Te ENSMUSG00000064369 Gene Expression; mt-Cytb ENSMUSG00000064370 Gene Expression; mt-Tt ENSMUSG00000064371 Gene Expression; mt-Tp ENSMUSG00000064372 Gene Expression. [55450 rows x 2 columns]; ```. ### Versions. `import scanpy; scanpy.logging.print_versions()`. # **session with an error**. <Details>. ```; -----; anndata 0.10.4; scanpy 1.9.6; -----; PIL 10.2.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; brotli 1.1.0; certifi 2023.11.17; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.10.0; idna 3.6; ipykernel 6.28.0; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.20.0; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.12.4; jupyterlab_server 2.25.2; kiwisolver 1.4.5; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.58.1; numpy 1.26.3; overrides NA; packaging 23.2; pandas 2.1.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 4.1.0; prometheus_client NA; prompt_toolkit 3.0.42; psutil 5.9.7; ptyprocess 0.7.0; pure_eval,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:8520,error,error,8520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,1,['error'],['error']
Availability,"slab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressing objects: 100% (109/109), done.; Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s; fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s; fatal: early EOF; fatal: index-pack failed; ```. however, i can successfully install scanpy 1.4.4 with. ```; pip install scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:1464,Down,Downloading,1464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,2,"['Down', 'down']","['Downloading', 'downloaded']"
Availability,"so have been running into issues when trying to use the `gene_symbols` parameter with the `sc.pl.dotplot()` function despite the column with the proper `gene_symbols` being in my `adata.var` Data Frame. . ```; $ adata.var.columns; $ sc.pl.dotplot(adata, marker_genes, 'clusters', dendrogram=True, gene_symbols='alternate_gene_symbols'). ==============================================================================. Index(['gene_symbols', 'feature_types', 'n_cells', 'highly_variable', 'means',; 'dispersions', 'dispersions_norm', 'mean', 'std',; 'alternate_gene_symbols'],; dtype='object'). ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621, in Index.get_loc(self, key, method, tolerance); 3620 try:; -> 3621 return self._engine.get_loc(casted_key); 3622 except KeyError as err:. File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:136, in pandas._libs.index.IndexEngine.get_loc(). File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:163, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:5198, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:5206, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'alternate_gene_symbols'; ... ```. When I tried setting `adata.var['gene_symbols'] = adata.var['alternate_gene_symbols']` and trying to generate a `dotplot` with a random gene present in `alternate_gene_symbols`, I ran into the following error: . ```; ...; KeyError: ""Could not find keys '['KH.C1.159.']' in columns of `adata.obs` or in adata.raw.var['gene_symbols'].""; ```. It seems that `sc.pl.dotplot()` is expecting `gene_symbols` that are present in the `adata.raw.var` Data Frame versus the `adata.var` Data Frame. Is this the expected behavior for this parameter?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963:1679,error,error,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963,1,['error'],['error']
Availability,son_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:10684,ERROR,ERROR,10684,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,son_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:5076,ERROR,ERROR,5076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,son_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21776,ERROR,ERROR,21776,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,space/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65968,ERROR,ERROR,65968,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,spatial dataset download issue,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:16,down,download,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,1,['down'],['download']
Availability,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2057:1958,down,downregulated,1958,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057,1,['down'],['downregulated']
Availability,ssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from ',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5986,Error,Error,5986,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"st numpy package:; https://github.com/numpy/numpy/issues/13431. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; # I have already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:1714,ERROR,ERROR,1714,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,1,['ERROR'],['ERROR']
Availability,"st(x, y):; 40 """"""Reduced Euclidean distance.; 41 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\decorators.py in wrapper(func); 217 with typeinfer.register_dispatcher(disp):; 218 for sig in sigs:; --> 219 disp.compile(sig); 220 disp.disable_compile(); 221 return disp. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 123 ; 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipel",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:6569,error,errors,6569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,"st_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================; ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally?. ### Environment info. My environments are both using ubuntu. <details>; <summary> My working env </summary>. ```; # packages in environm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:24459,ERROR,ERROR,24459,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,st_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:8516,ERROR,ERROR,8516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,st_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71880,ERROR,ERROR,71880,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,st_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2075,ERROR,ERROR,2075,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"stances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; jobli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:3631,error,error,3631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,1,['error'],['error']
Availability,"ster branch of scanpy. ---. I noticed that running the same single-cell analyses on different nodes of our HPC produces different results. ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014:1222,avail,available,1222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014,1,['avail'],['available']
Availability,sting/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59744,ERROR,ERROR,59744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,sts/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63851,ERROR,ERROR,63851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,subgrouping error?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833,1,['error'],['error']
Availability,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day!. I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:; p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'); adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)); sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/751#issuecomment-515740613:553,error,error,553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751#issuecomment-515740613,1,['error'],['error']
Availability,"sue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i] = np.sum(data[start:end]); ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.271, range = (0, $100.6, 1))]{386: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (403)>, 388: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (404)>, 264: <ir.Block at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:3011,error,error,3011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,1,['error'],['error']
Availability,"sure, we’ll talk in 10 days or so, after my holidays 😄. except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents don’t survive a reboot). ```py; # python gives you a context manager that deletes the file after its block; with tempfile.TemporaryFile() as fp:; use(fp); # fp and the file are gone now; ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457:815,reboot,reboot,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457,2,['reboot'],['reboot']
Availability,symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map(),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49894,Error,Error,49894,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"t 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-15-2e1cefb9ad47> in <module>; ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 194 adata = adata.copy(); 195 else:; --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start); 197 return adata; 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start); 207 if not genome:; 208 if len(children) > 1:; --> 209 raise ValueError(; 210 f""'{filename}' contains more than one genome. For legacy 10x h5 ""; 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```. #### Versions. <details>. 1.8.2. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149:3029,Avail,Available,3029,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149,1,['Avail'],['Available']
Availability,"t I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1070,down,downloaded,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['downloaded']
Availability,"t aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, but the error message could definitley be better. ## What should we do about this?. My current inclination is to revert most changes to `obs_df` and `var_df` from this PR and #1499. This should leave the use of indices as groupby untouched. Also, the loss of perfomance from reverting #1499 should be partially mitigated by improvements in pandas (see https://github.com/pandas-dev/pandas/issues/37954). We would keep all the user facing changes, and all the tests from both PRs. We can then make a release now, and can patch in performance boosts during the release cycle. Do you agree with this assessment? If not, could you propose an alternative?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:5476,error,error,5476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,2,['error'],['error']
Availability,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2328:2310,error,error,2310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328,1,['error'],['error']
Availability,"t force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,. ImportError: DLL load failed while importing _loess: The specified module could not be found. During",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:1082,ERROR,ERROR,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['ERROR'],['ERROR']
Availability,"t having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bins_to_cuts(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered); 399 if len(unique_bins) < len(bins) and len(bins) != 2:; 400 if duplicates == ""raise"":; --> 401 raise ValueError(; 402 f""Bin edges must be unique: {repr(bins)}.\n""; 403 f""You can drop duplicate edges by setting the 'duplicates' kwarg"". ValueError: Bin edges must be unique: array([ -inf, 1.00000000e-12, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1560:1524,robust,robust,1524,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560,1,['robust'],['robust']
Availability,t import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2783,ERROR,ERROR,2783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"t of arguments. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 806 self._cache_misses[sig] += 1; 807 try:; --> 808 cres = self._compiler.compile(args, return_type); 809 except errors.ForceLiteralArg as e:; 810 def folded(args, kws):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:7812,error,errors,7812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,1,['error'],['errors']
Availability,"t pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> 343 def sparse_alternative_jaccard(ind1, data1, ind2, data2):; 344 num_non_zero = arr_union(ind1, ind2).shape[0]; 345 num_equal = arr_intersect(ind1, ind2).shape[0]. ~/.local/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 216 with typeinfer.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652:3863,error,errors,3863,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652,1,['error'],['errors']
Availability,"t); <ipython-input-13-a0665160cba0> in <module>; 1 import anndata; ----> 2 import scanpy as sc; 3 import igraph; 4 ; 5 C6665_new = anndata.AnnData(C6665_encoded). ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\__init__.py in <module>; 30 # the actual API; 31 from ._settings import settings, Verbosity # start with settings as several tools are using it; ---> 32 from . import tools as tl; 33 from . import preprocessing as pp; 34 from . import plotting as pl. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\__init__.py in <module>; 8 from ._rank_genes_groups import rank_genes_groups, filter_rank_genes_groups; 9 from ._dpt import dpt; ---> 10 from ._leiden import leiden; 11 from ._louvain import louvain; 12 from ._sim import sim. ~\anaconda3\envs\ms-sy-code\lib\site-packages\scanpy\tools\_leiden.py in <module>; 13 ; 14 try:; ---> 15 from leidenalg.VertexPartition import MutableVertexPartition; 16 except ImportError:; 17 class MutableVertexPartition: pass. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\__init__.py in <module>; 33 not immediately available in :func:`leidenalg.find_partition`.; 34 """"""; ---> 35 from .functions import ALL_COMMS; 36 from .functions import ALL_NEIGH_COMMS; 37 from .functions import RAND_COMM. ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\functions.py in <module>; 21 return graph.__graph_as_cobject(); 22 ; ---> 23 from .VertexPartition import *; 24 from .Optimiser import *; 25 . ~\anaconda3\envs\ms-sy-code\lib\site-packages\leidenalg\VertexPartition.py in <module>; 6 PY3 = (sys.version > '3'); 7 ; ----> 8 class MutableVertexPartition(_ig.VertexClustering):; 9 """""" Contains a partition of graph, derives from :class:`ig.VertexClustering`.; 10 . AttributeError: module 'igraph' has no attribute 'VertexClustering'`. ```; I might be wrong, but looks like Scanpy is directly calling igraph.vertexclustering, while vertex clustering is a module under clustering. Shouldn't it be referred as ig.clustering.vertexclustering?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/961:1341,avail,available,1341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961,1,['avail'],['available']
Availability,"t, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 133 ; 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs; --> 135 datas, mnn_list, angle_list = mnn_correct(; 136 *datas,; 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 120 if var_subset is not None and set(adata_vars) == set(var_subset):; 121 var_subset = None; --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,; 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,; 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 176 new_batch_out = out_batches[target]; 177 print(' Looking for MNNs...'); --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,; 179 n_jobs=n_jobs); 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}; ---------------------------------------------------------------------------. ```. #### Versions; python 3.9. <details>; The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2436:3174,error,error,3174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436,1,['error'],['error']
Availability,"t.py"", line 974, in run_command; cmd_obj.run(); File ""/usr/lib/python3.5/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/usr/lib/python3.5/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/usr/lib/python3.5/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/pip-build-33o4crd7/scanpy/versioneer.py"", line 1559, in run; _build_py.run(self); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 52, in run; self.build_package_data(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 107, in build_package_data; for package, src_dir, build_dir, filenames in self.data_files:; File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 65, in __getattr__; self.data_files = self._get_data_files(); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 79, in _get_data_files; return list(map(self._get_pkg_data_files, self.packages or ())); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 91, in _get_pkg_data_files; for file in self.find_data_files(package, src_dir); File ""/usr/lib/python3/dist-packages/setuptools/command/build_py.py"", line 98, in find_data_files; + self.package_data.get(package, [])); TypeError: Can't convert 'list' object to str implicitly; ; ----------------------------------------; Command ""/usr/bin/python3 -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-33o4crd7/scanpy/setup.py';exec(compile(getattr(tokenize, 'open', open)(__file__).read().replace('\r\n', '\n'), __file__, 'exec'))"" install --record /tmp/pip-65l8zi0l-record/install-record.txt --single-version-externally-managed --compile"" failed with error code 1 in /tmp/pip-build-33o4crd7/scanpy/; You are using pip version 8.1.1, however version 18.1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command.; ```. Same error message after upgrading pip. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/355:11778,error,error,11778,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/355,3,"['avail', 'error']","['available', 'error']"
Availability,t_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18014,ERROR,ERROR,18014,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:23239,ERROR,ERROR,23239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:21564,ERROR,ERROR,21564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,t_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: can,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2718,ERROR,ERROR,2718,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"t_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16752,error,error,16752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2510,down,down,2510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['down']
Availability,tch.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3067,Error,Error,3067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"te that I can't update numpy to a newer version because of other packages I'm using, but `1.23` is more recent that what scanpy requires anyway (i.e., `numpy>=1.17.0`). For instance, the `spatialdata` library requires `numpy<=1.23.4` because of `xarray-spatial`: thus, it seems that the latest version of `scanpy` is not compatible with `spatialdata` (cc @LucaMarconato for information). The error seems to be due to this commit in `_validate_palette`: https://github.com/scverse/scanpy/commit/d1fe8da28ab4865b6c2b3d9cd151a8186f148844 (@flying-sheep). ### Minimal code sample. ```python; # Just plotting a dummy UMAP. import anndata; import pandas as pd; import numpy as np; import scanpy as sc. n_obs = 10. adata = anndata.AnnData(; X=np.random.randint(0, 5, size=(n_obs, 8)),; obs=pd.DataFrame({; ""cell_type"": np.random.choice([""A"", ""B"", ""C""], size=n_obs)},; index=[str(i) for i in range(n_obs)]; ),; ). sc.pp.neighbors(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""cell_type""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); Cell In[6], line 1; ----> 1 sc.pl.umap(adata, color=""cell_type""). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:674, in umap(adata, **kwargs); 615 @_wraps_plot_scatter; 616 @_doc_params(; 617 adata_color_etc=doc_adata_color_etc,; (...); 621 ); 622 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:; 623 """"""\; 624 Scatter plot in UMAP basis.; 625 ; (...); 672 tl.umap; 673 """"""; --> 674 return embedding(adata, 'umap', **kwargs). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830:1464,Error,Error,1464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830,1,['Error'],['Error']
Availability,"te the ""full dataset"". This makes more sense now. In that case however I would say that having just raw counts in `adata.raw.X` is fine, no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement for `.raw` as a version of the data that is used for DE analysis but not `.X`. This distinction is quite useful ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:1098,mask,masks,1098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,['mask'],"['mask', 'masks']"
Availability,te-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; =,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7615,Error,Error,7615,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"te-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). I am running scanpy using python v3.9 with numba v0.55. . _Originally posted by @gatocor in https://github.com/theislab/scanpy/issues/1652#issuecomment-779686831_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418:7539,error,errors,7539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418,2,['error'],['errors']
Availability,"te: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16733,error,errors,16733,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['errors']
Availability,"te_qc_metrics(em_adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True); em_adata.obs[""outlier_mt""] = em_adata.obs.pct_counts_mt > 15; em_adata.obs[""outlier_total""] = em_adata.obs.total_counts > 30000; em_adata.obs[""outlier_ngenes""] = em_adata.obs.n_genes_by_counts > 6000; em_adata = em_adata[~em_adata.obs[""outlier_mt""], :]; em_adata = em_adata[~em_adata.obs[""outlier_total""], :]; em_adata = em_adata[~em_adata.obs[""outlier_ngenes""], :]; sc.pp.filter_genes(em_adata,min_cells=1). sc.pp.scrublet(em_adata); em_adata.layers['counts'] = em_adata.X.copy(); sc.pp.normalize_total(em_adata); sc.pp.log1p(em_adata); sc.pp.highly_variable_genes(em_adata,flavor='seurat'); sc.pl.highly_variable_genes(em_adata); em_adata = em_adata[:, em_adata.var[""highly_variable""]]; em_adata.shape; # [out] -> (41749, 1425); sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```. ### Error output. ```pytb; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32; ```. ### Versions. <details>. ```; conda env:; # Name Version Build Channel; _r-mutex 1.0.0 anacondar_1; anndata 0.10.6 pypi_0 pypi; anyio 4.3.0 pypi_0 pypi; argon2-cffi 23.1.0 pypi_0 pypi; argon2-cffi-bindings 21.2.0 py311h2bbff1b_0; array-api-compat 1.5.1 pypi_0 pypi; arrow 1.3.0 pypi_0 pypi; asttokens 2.4.1 pypi_0 pypi; async-lru 2.0.4 py311haa95532_0; attrs 23.2.0 pypi_0 pypi; babel 2.14.0 pypi_0 pypi; beautifulsoup4 4.12.3 pypi_0 pypi; bleach 6.1.0 pypi_0 pypi; brotli-python 1.0.9 py311hd77b12b_7; bzip2 1.0.8 h2bbff1b_5; ca-certificates 2023.12.12 haa95532_0; certifi 2024.2.2 py311haa95532_0; cffi 1.16.0 py311h2bbff1b_0; charset-normalizer 3.3.2 pypi_0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969:1967,Error,Error,1967,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969,1,['Error'],['Error']
Availability,"ted.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. ; I find this issue really weird because categories_order works just fine when I am generating a dotplot.; Maybe I am missing something fundamental. ### Minimal code sample. ```python; ##code that does not reorder ( I tried both options 'order' and 'categories_order'; sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders; sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 19.0.0; PIL 10.0.0; apport_python_hook NA; backcall 0.2.0; certifi 2019.11.28; cffi 1.15.0; chardet 3.0.4; cloudpickle 2.2.1; colorama 0.4.3; colorcet 3.0.1; cryptography 2.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gseapy 1.0.5; h5py 3.7.0; idna 2.8; igraph 0.10.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.6.1; matplotlib_inline NA; more_itertools NA; mpl_toolkits NA; natsort 8.2.0; netifaces 0.10.4; numba 0.56.3; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.2; patsy 0.5.3; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.15.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pyarrow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2611:1106,Error,Error,1106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611,1,['Error'],['Error']
Availability,"teresting that if I ran your PBMC tutorial without filtering out the non-HVG then I get this error. But I thought these filtering steps in the beginning already eliminated the empty rows and columns?; ```py; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/230#issuecomment-596790394:93,error,error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/230#issuecomment-596790394,1,['error'],['error']
Availability,test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3349,ERROR,ERROR,3349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportEr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67455,ERROR,ERROR,67455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2549,ERROR,ERROR,2549,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49178,Error,Error,49178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normali,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:11637,mask,mask-,11637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16060,mask,mask-,16060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['mask'],['mask-']
Availability,"th repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ------------------------------------------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:1909,error,error,1909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability,th signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neig,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55233,ERROR,ERROR,55233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding?. indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image?. in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper).; It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042); For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-741689756:768,mask,mask,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-741689756,1,['mask'],['mask']
Availability,"thank you very much! one thing that we could consider is renaming this to ""downsample_counts""; for some people, ""downsampling observations"" is an alias to ""subsampling observations"" and for these the function name is not descriptive enough. what do you think? can I make this change?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100#issuecomment-371090054:113,down,downsampling,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100#issuecomment-371090054,1,['down'],['downsampling']
Availability,"thanks for everyone's input. I tried to solve this problem by downgrading pandas to 1.1.5. the cause of this problem may be that in python 3.9 and above, pandas modifies the matrix function",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-981383663:62,down,downgrading,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-981383663,1,['down'],['downgrading']
Availability,"thanks for getting this started!. since this new modality has different signal characteristics, I wanted to bring up for discussion:. ### normalization choice: for the incoming geometric normalization, any justification for choosing that one over others? . in your https://github.com/theislab/scanpy-tutorials/pull/14 (10x PBMC dataset of ~30 Totalseq antibodies), the antibody panel is similar to that used in mass cytometry datasets, but different papers seem to prefer different transforms -- which begs the question, now that similar panels are being used, which transform makes the most sense in terms of:; - preserving visual interpretation of absent/low/med/high (corresponding to expectations of cell subsets); - handling a variety of marker distribution shapes (unimodal/bimodal/trimodal, skewed shapes); - making it easier to spot nonspecific antibody staining / off-target effects; - not introducing more bias in downstream differential comparisons (fits with assumptions about variable distribution properties, based on the commonly used statistical testing methods). absent a convincing answer, it may be worth implementing multiple as options, leaving the choice to the user, and just documenting these use-cases through citations; eventually, someone can make a notebook that compares the behaviors, biological expectations, and/or impacts on statistical comparisons to inform which method should be the default. While the CITEseq paper applied CLR, it's not obvious that one is better than the ones used in more time-tested fields like mass cytometry and flow cytometry. ```python; def CLR_transform(df):; '''; implements the CLR transform used in CITEseq (need to confirm in Seurat's code); https://doi.org/10.1038/nmeth.4380; '''; logn1 = np.log(df + 1); T_clr = logn1.sub(logn1.mean(axis=1), axis=0); return T_clr. def asinh_transform(df, cofactor=5):; '''; implements the hyperbolic arcsin transform used in CyTOF/mass cytometry; https://doi.org/10.1038/nmeth.4380; '''; T_cytof = ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691:924,down,downstream,924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691,1,['down'],['downstream']
Availability,"that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them ha",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1165,down,downloaded,1165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,1,['down'],['downloaded']
Availability,"the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:1747,error,error,1747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['error'],['error']
Availability,"then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: ; ```; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). ; Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : ; `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python; #read the data; Data1_adata= sc.read_10x_mtx(; '/Data_1/filtered_feature_bc_matrix', ; var_names='gene_symbols', index); cache=True) ; #concatenate; adata = Data1_adata.concatenate(Data2_adata); # save raw counts in raw slot.; adata.raw = adata ; # normalize to depth 10 000; sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize; sc.pp.log1p(adata). #check adata.raw ; print(adata.raw.X[1:10,1:10]); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.7; scanpy 1.10.0; -----; PIL 8.4.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; backcall 0.2.0; bottleneck 1.3.7; brotli NA; certifi 2024.02.02; cffi 1.16.0; chardet 5.2.0; charset_normalizer 3.3.2; cloudpickle 3.0.0; colorama 0.4.6; comm 0.2.1; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2024.2.0; dateutil 2.8.2; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.0; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.7.0; idna 3.6; igraph 0.11.4; importlib_resources NA; ipykernel 6.29.2; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.9.0; jupyter_server 2.12.5; jupyterlab_server 2.25.3; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.40.0; louvain 0.8.0; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.8.0; matplotlib_inline ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073:1368,Error,Error,1368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073,1,['Error'],['Error']
Availability,"this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp; ---------------------------------------------------------------------------; View of AnnData object with n_obs × n_vars = 52078 × 6200; obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'; uns: 'spatial'; obsm: 'spatial', 'spatial_fov'; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2486:1194,error,error,1194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486,1,['error'],['error']
Availability,"this is not related to scanpy, but to sam (scanpy external). Please report the bug in the original repo: https://github.com/atarashansky/self-assembling-manifold; pinging @atarashansky who is possibly most helpful in this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293#issuecomment-702362311:163,ping,pinging,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293#issuecomment-702362311,1,['ping'],['pinging']
Availability,"this issue!! I just spent many hours digging into the source code to figure out why `filter_rank_genes_groups` was filtering out genes that reported really high fold changes from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(fold_change_matri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:1000,down,down,1000,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,1,['down'],['down']
Availability,"this makes it possible to use `pip install` without installing numpy. it also includes automation for cython again, as currently the `python setup.py build_ext` command will never use cython, even if available. once the .pyx is changed and `build_ext` is executed, this now refreshes the `.c` file.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/38:200,avail,available,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/38,1,['avail'],['available']
Availability,"thon3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2018:3556,toler,tolerance,3556,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018,1,['toler'],['tolerance']
Availability,"thon3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 . TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)); [2] During: typing of call at /opt/conda/lib/python3.7/site-packages/umap/umap_.py (776). File ""../../../opt/conda/lib/python3.7/site-packages/umap/umap_.py"", line 776:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new; ```. What I basically do from raw UMI counts:. 1. total counts normalization / logarithmization; 2. PCA, bbknn, louvain; 3. combat, HVG, PCA, UMAP (works well); 4. Paga (with louvain from 2., works well); 5. UMAP (with positions from 4., does not work). Any idea? Any further info needed?; Best,; Jens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:3089,error,errors,3089,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,2,['error'],"['error', 'errors']"
Availability,"tically. However, I'm wary of abandoning a critical discussion of imputation methods in this space because other portions of the typical workflow have issues as well. Further, I think there are important distinctions to be made between different classes of methodology that are (mis)used in this problem space. I. Methods that are fundamentally flawed by their assumptions or algorithm. These should obviously be avoided.; II. Methods that are fundamentally sound but are not sufficiently validated, e.g. the validation doesn't exist in this problem space, isn't sufficiently comprehensive/relevant, performs poorly against other fundamentally sound methodologies, or has such restrictive assumptions it isn't broadly useful/applicable.; III. Methods that are fundamentally sound in assumption/algorithm and can be used by a competent practitioner but still have the potential to be abused through applying it to data that violate those assumptions. I'd consider t-SNE and a great deal of the clustering algorithms to be in class III for the reasons you said; they're valid, functional tools but can be applied in assumption-violating or quasi-valid ways. I'm pretty sure that scImpute, for example, belongs in class I because its description of dropout and simulated test cases are inappropriate. I'd put MAGIC and several other currently available imputation methods in class II as they've got strong foundations but currently insufficient validation IMO. I'm not trying to pick on MAGIC or any specific imputation method. Instead I'd like to have an open discussion about the benefits, limitations, and relative performance of the various imputation methods available with the goal leading to something like @gokceneraslan suggested. Well, and since you brought it up, batch correction and multimodal integration methods are in definite need of the same open discussion, which I'd be happy to have, and I think they should have the same disclaimer regarding their limitations in the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893:1516,avail,available,1516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893,2,['avail'],['available']
Availability,"till read to memory, even in backed mode.; As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-pat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2365:1529,down,download,1529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365,1,['down'],['download']
Availability,ting._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2820,ERROR,ERROR,2820,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,tion.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:17613,ERROR,ERROR,17613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"tl.dpt with no branching events works:; ```; sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True); yields; performing Diffusion Pseudotime analysis; initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`; eigenvalues of transition matrix; [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917; 0.45321003 0.35327435 0.33786523 0.29598442]; finished (0:01:09.57) --> added; 'dpt_pseudotime', the pseudotime (adata.obs); ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0?. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2524 try:; -> 2525 return self._engine.get_loc(key); 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-102-eb7d1d859c99> in <module>(); ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save); 677 """"""; 678 colors = ['dpt_pseudotime']; --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']; 680 if color is not None: colors = color; 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/129:547,error,error,547,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129,2,"['error', 'toler']","['error', 'tolerance']"
Availability,toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_scrublet.py::test_scrubl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:18887,ERROR,ERROR,18887,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Version('0.10.6')>; ```. </details>. Interesting to see that this seem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:1056,Down,Downloading,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,"tput in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; HTTPError Traceback (most recent call last); <ipython-input-6-0ae186d1a0d7> in <module>; ----> 1 adata = sc.datasets.ebi_expression_atlas(""E-MTAB-4888""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in ebi_expression_atlas(accession, filter_boring); 117 pass; 118 ; --> 119 download_experiment(accession); 120 ; 121 logg.info(f""Downloaded {accession} to {experiment_dir.absolute()}""). ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession); 41 ; 42 _download(; ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",; 44 ); 45 _download(. ~/anaconda3/envs/sc-py/lib/python3.6/site-packages/scanpy/readwrite.py in _download(url, path); 877 ; 878 try:; --> 879 urlretrieve(url, str(path), reporthook=update_to); 880 except Exception:; 881 # Make sure file doesn’t exist half-downloaded. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data); 246 url_type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:1525,down,downloaded,1525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['down'],['downloaded']
Availability,"tribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:6088,error,error,6088,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"tructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),; (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),; (; ""master_paga_continuous_multiple"",; partial(sc.pl.paga, color=['CST3', 'GATA2']),; ),; (""master_paga_compare"", partial(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2459:1204,FAILURE,FAILURES,1204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459,1,['FAILURE'],['FAILURES']
Availability,try fixing h5py error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1113:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113,1,['error'],['error']
Availability,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1714:2157,error,error,2157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714,4,"['Error', 'error']","['Error', 'error']"
Availability,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2043:2987,mask,masked,2987,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043,5,"['error', 'mask']","['error', 'mask', 'masked']"
Availability,ts/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73510,ERROR,ERROR,73510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ts/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71210,ERROR,ERROR,71210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ttps://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [766](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:766) filename=handle,; [767](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:767) mode=ioargs.mode,; [768](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:16485,error,error,16485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['error']
Availability,"tuple(argtypes)); 354 except errors.ForceLiteralArg as e:; 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig); 766 self._cache_misses[sig] += 1; 767 try:; --> 768 cres = self._compiler.compile(args, return_type); 769 except errors.ForceLiteralArg as e:; 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type); 75 ; 76 def compile(self, args, return_type):; ---> 77 status, retval = self._compile_cached(args, return_type); 78 if status:; 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type); 89 ; 90 try:; ---> 91 retval = self._compile_core(args, return_type); 92 except errors.TypingError as e:; 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type); 107 args=args, return_type=return_type,; 108 flags=flags, locals=self.locals,; --> 109 pipeline_class=self.pipeline_class); 110 # Check typing error if object mode is used; 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 549 pipeline = pipeline_class(typingctx, targetctx, library,; 550 args, return_type, flags, locals); --> 551 return pipeline.compile_extra(func); 552 ; 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func); 329 self.state.lifted = (); 330 self.state.lifted_from = None; --> 331 return self._compile_bytecode(); 332 ; 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:7793,error,errors,7793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['error'],['errors']
Availability,type error in scale_factor with sc.pl.spatial function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494,1,['error'],['error']
Availability,"type, path = splittype(url); 247 ; --> 248 with contextlib.closing(urlopen(url, data)) as fp:; 249 headers = fp.info(); 250 . ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context); 221 else:; 222 opener = _opener; --> 223 return opener.open(url, data, timeout); 224 ; 225 def install_opener(opener):. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in open(self, fullurl, data, timeout); 530 for processor in self.process_response.get(protocol, []):; 531 meth = getattr(processor, meth_name); --> 532 response = meth(req, response); 533 ; 534 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_response(self, request, response); 640 if not (200 <= code < 300):; 641 response = self.parent.error(; --> 642 'http', request, response, code, msg, hdrs); 643 ; 644 return response. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in error(self, proto, *args); 568 if http_err:; 569 args = (dict, 'default', 'http_error_default') + orig_args; --> 570 return self._call_chain(*args); 571 ; 572 # XXX probably also want an abstract factory that knows when it makes. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in _call_chain(self, chain, kind, meth_name, *args); 502 for handler in handlers:; 503 func = getattr(handler, meth_name); --> 504 result = func(*args); 505 if result is not None:; 506 return result. ~/anaconda3/envs/sc-py/lib/python3.6/urllib/request.py in http_error_default(self, req, fp, code, msg, hdrs); 648 class HTTPDefaultErrorHandler(BaseHandler):; 649 def http_error_default(self, req, fp, code, msg, hdrs):; --> 650 raise HTTPError(req.full_url, code, msg, hdrs, fp); 651 ; 652 class HTTPRedirectHandler(BaseHandler):. HTTPError: HTTP Error 500: ; ```. #### Versions:; <!-- Output of scanpy.logging.print_versions() -->; My local version:; > scanpy==1.4.6 anndata==0.7.1 umap==0.4.2 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.0 statsmodels==0.11.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1221:2588,error,error,2588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221,1,['error'],['error']
Availability,uals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:9839,ERROR,ERROR,9839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,uals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:15537,ERROR,ERROR,15537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,ublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/external/test_harmony_integrate.py; ERROR scanpy/tests/external/test_harmony_timeseries.py; ERROR scanpy/tests/external/test_palantir.py; ERROR scanpy/tests/external/test_sam.py; ERROR scanpy/tests/external/test_scanorama_integrate.py; ERROR scanpy/tests/external/test_wishbone.py; ERROR scanpy/tests/test_aggregated.py; ERROR scanpy/tests/test_clustering.py; ERROR scanpy/tests/test_dendrogram.py; ERROR scanpy/tests/test_deprecations.py; ERROR scanpy/tests/test_embedding.py; ERROR scanpy/tests/test_embedding_density.py; ERROR scanpy/tests/test_embedding_plots.py; ERROR scanpy/tests/test_filter_rank_genes_groups.py; ERROR scanpy/tests/test_get.py; ERROR scanpy/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:2256,ERROR,ERROR,2256,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"uce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 147 ; --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1866:1412,error,error,1412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866,1,['error'],['error']
Availability,"uces the bug in the code block below: -->; ```python; #!/usr/bin/env python; import os, sys ; import scanpy as sc; import scanpy.external as sce; import scipy as sp; import numpy as np; import pandas as pd; os.getcwd(). #sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); #sc.logging.print_versions() #this also give segmentation fault error . #1102 external eg file ; #curl -o pbmc_1k_v2_filtered_feature_bc_matrix.h5 -O http://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_1k_v2/pbmc_1k_v2_filtered_feature_bc_matrix.h5. #load file; ext_AD = sc.read_10x_h5('/home/pjb40/scratch/KimCarla_Timeseries_scRNAseq_lung_cancer_organoids_hbc03856_scrathDir/data/TimeSeries_epithelial_ScanpyNotebook/ext_data/pbmc_1k_v2_filtered_feature_bc_matrix.h5', gex_only = True). ext_AD.var_names_make_unique(). print(ext_AD). sc.pp.calculate_qc_metrics(ext_AD, inplace=True). print (ext_AD). ...; ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 65, in <module>; sc.pp.calculate_qc_metrics(ext_AD, inplace=True); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 274, in calculate_qc_metrics; parallel=parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 102, in describe_obs; proportions = top_segment_proportions(X, percent_top, parallel); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 355, in top_segment_proportions; mtx.data, mtx.indptr, np.array(ns, dtype=np.int), parallel; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py"", line 383, in top_segment_proportions_sparse_csr; return _top_segment_proportions_sparse_csr_cached(data, indptr, ns); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/numba/dispatcher.py"", line 349, in _compile_for_args; error_rewrite(e, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193:1465,Error,Error,1465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193,1,['Error'],['Error']
Availability,"uested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, target",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:4842,error,errors,4842,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['error'],['errors']
Availability,ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42613,Error,Error,42613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"uild_update; len(to_build)); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 311, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/1204/lib/python3.6/site-packages/sphinx/util/logging.py"", line 415, in filter; raise SphinxWarning(location + "":"" + str(message)); sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string. Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/1204/scanpy/plotting/_dotplot.py:docstring of scanpy.pl.dotplot:122:Inline strong start-string without end-string.; ```. </details>. I get the same error locally from just running `make html`, and was able to get rid of it by adding a page for the `DotPlot` class (though more errors came up after that).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1307:2965,error,errors,2965,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1307,4,['error'],"['error', 'errors']"
Availability,"ule>; ----> 1 sc.tl.umap(adata, init_pos='paga'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy); 137 neigh_params.get('metric', 'euclidean'),; 138 neigh_params.get('metric_kwds', {}),; --> 139 verbose=max(0, verbosity-3)); 140 adata.obsm['X_umap'] = X_umap # annotate samples with UMAP coordinates; 141 logg.info(' finished', time=True, end=' ' if _settings_verbosity_greater_or_equal_than(3) else '\n'). /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 . TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)); [2] During: typing of call at /opt/conda/lib/python3.7/site-packages/umap/umap_.py (776). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:1571,error,errors,1571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['error'],['errors']
Availability,"ule>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/prepr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2113:2342,avail,available,2342,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113,1,['avail'],['available']
Availability,"ull this out into the pipeline; --> 442 NativeLowering().run_pass(state); 443 lowered = state['cr']. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 369 metadata=metadata); --> 370 lower.lower(); 371 if not flags.no_cpython_wrapper:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 216 # Materialize LLVM Module; --> 217 self.library.add_ir_module(self.module); 218 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\codegen.py in add_ir_module(self, ir_module); 205 ir = cgutils.normalize_ir_text(str(ir_module)); --> 206 ll_module = ll.parse_assembly(ir); 207 ll_module.name = ir_module.name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context); 24 mod.close(); ---> 25 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)); 26 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend); LLVM IR parsing error; <string>:4079:36: error: '%.2747' defined with type 'i64' but expected 'i32'; %"".2748"" = icmp eq i32 %"".2746"", %"".2747""; ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-10-a83dc5279093> in <module>; ----> 1 sc.pp.calculate_qc_metrics(adata, qc_vars=[""mt""], inplace=True). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 294 inplace=inplace,; 295 X=X,; --> 296 log1p=log1p,; 297 ); 298 var_metrics = describe_var(. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 112 if percent_top:; 113 percent_top = sorted(percent_top); --> 114 proportions = top_segment_proportions(X, percent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:4810,error,error,4810,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['error'],['error']
Availability,"umap expects a list as group, so it will work if you do:. ```python; sc.pl.umap(adata, color='blobs', groups=['Zero']); ````. the improvement that I would consider is to automatically convert a string into a list to avoid the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960,1,['error'],['error']
Availability,"umap(adata, color, use_raw, edges, edges_width, edges_color, arrows, arrows_kwds, sort_order, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, size, title, show, save, ax); 290 show=False,; 291 save=False,; --> 292 ax=ax); 293 if edges: utils.plot_edges(axs, adata, basis, edges_width, edges_color); 294 if arrows: utils.plot_arrows(axs, adata, basis, arrows_kwds). ~/software/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 104 show=show,; 105 save=save,; --> 106 ax=ax); 107 elif x is not None and y is not None:; 108 if ((x in adata.obs.keys() or x in adata.var.index). ~/software/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax); 409 raise ValueError('""' + name + '"" is invalid!'; 410 + ' specify valid name, one of '; --> 411 + str(adata.obs[key].cat.categories)); 412 else:; 413 iname = np.flatnonzero(adata.obs[key].cat.categories.values == name)[0]. ValueError: ""Z"" is invalid! specify valid name, one of Index(['Zero', '1', '2', '3', '4'], dtype='object'); ```; The last call `sc.pl.umap` gives and error but I would expect it to work. It seems that scanpy iterates over the string `'Zero'` in the last call of `sc.pl.umap`. Of course, it is easy to work around by explicitly passing a list with one element as in the second call, but it took me a while to figure this out. `sc.logging.print_versions()` prints `scanpy==1.2.2+96.g28f5034 anndata==0.6.4 numpy==1.15.0 scipy==1.1.0 pandas==0.23.0 scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/231:2452,error,error,2452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/231,1,['error'],['error']
Availability,"umba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=135) pass; [138](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=137) try:; --> [139](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=138) retval = self._compile_core(args, return_type); [140](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=139) except errors.TypingError as e:; [141](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=140) self._failed_cache[key] = e. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); [149](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=148) flags = self._customize_flags(flags); [151](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=150) impl = self._get_implementation(args, {}); --> [152](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:16206,error,errors,16206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,unexpected error in sc.pl.dpt_timeseries and dpt_groups_pseudotime,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086,1,['error'],['error']
Availability,"up and it does look very nice. Well, I learned a lot from `scanpy` here ;) . > tcellmatch's primary purpose is specificity prediction, this could be easily added ontop of this,. Scirpy currently supports the construction of clonotype similarity networks based on Levenshtein distance and BLOSUM62 pairwise sequence alignments. With these networks, we, indeed, had in mind, that clonotypes forming a connected subgraph should recognize the same antigen. Supporting `tcellmatchs`'s learned embedding distances would be a great addition. Dou you think this could be implemented as a subclass of the `_DistanceCalculator` [here](https://github.com/icbi-lab/scirpy/blob/master/scirpy/_preprocessing/_tcr_dist.py#L20)? Feel free to open an issue in `scirpy` for that! . I'd also be curious how the BLOSUM embedding relates to our alignment distance. (How) does the embedding handle gaps?. > Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs?. Exactly! I think it would be helpful if we could find a way to automatically annotate clonotypes with known epitopes (e.g. to identify clonotypes that are specific to common viral antigens which could represent ""bystander T-cells"" in cancer). I believe using our alignment-based approach or `tcellmatch` could improve over the existing database-queries that rely on Levenshtein distance. We can continue a more in-depth discussion in https://github.com/icbi-lab/scirpy/issues/54. > An integration with dextramer counts to ""stain"" TCR specificity? . Interesting! Do you have an example where this was used with single cells? . > Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Great docs otherwise though!. There's already some information [at the beginning of the tutorial]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910:1072,down,downloads,1072,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910,1,['down'],['downloads']
Availability,"update:. managed to get a confidence thresholding with this type of logic:. ```py; def _knn_classify(self, labels):; # ensure it's categorical; cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""); values = []; confidences = []. for inds in self._indices:; mode_value = cat_array.iloc[inds].mode()[0]; mode_count = (cat_array.iloc[inds] == mode_value).sum(); confidence = mode_count / len(inds); values.append(mode_value); confidences.append(confidence); ; # Create a DataFrame for better readability; classification_df = pd.DataFrame({; ""Mode Values"": values,; ""Confidences"": confidences; }); print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):; """"""\; Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`; from existing labels in `adata.obs`.; `method` can be only 'knn'.; """"""; if method == ""knn"":; classified_labels, confidences = self._knn_classify(labels); mask = confidences >= confidence_threshold; ; filtered_labels = [; label if mask[idx] else np.nan ; for idx, label in enumerate(classified_labels); ]; ; classified_labels = pd.Categorical(; filtered_labels,; categories=classified_labels.categories; ); ; self._adata_new.obs[labels] = classified_labels; self._adata_new.obs[labels + '_confidence'] = confidences; else:; raise NotImplementedError(""Ingest supports knn labeling for now.""); ```; . would love to get input on whether or not this makes sense",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3160#issuecomment-2270570908:1058,mask,mask,1058,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160#issuecomment-2270570908,2,['mask'],['mask']
Availability,ups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: ma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50145,Error,Error,50145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"ure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. First, the argument is named ""percent""_top, suggesting a fraction in the range [0,1] or at a stretch [0, 100]. Second, the description starts with ""Which proportion"", again suggesting a fraction. But then, the description goes on to say that `percent_top=[50]` would use the 50 most expressed genes, NOT the 50% most expressed genes. So in the end, it's not a percentage but an absolute number. This is further supported by the fact that the default values are `(50, 100, 200, 500)`, which are clearly not percentages.; See: https://github.com/scverse/scanpy/blob/585f58c9e4dd82dd7809a831538c4e230b008818/scanpy/preprocessing/_qc.py#L237. ### Minimal code sample. ```python; # No code, issue is in documentation; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.4; scanpy 1.9.6; -----; PIL 10.0.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.13.1; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.2.0; comm 0.2.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.10.0; idna 3.4; igraph 0.10.8; ipykernel 6.27.1; ipython_genutils 0.2.0; ipywidgets 8.1.1; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.20.0; jsonschema_specifications NA; jupyter_server 1.24.0; jupyterlab_server 2.25.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.7.2; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.58.1; numpy 1.25.2; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.9.0; platformdirs 4.1.0; plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2842:1013,Error,Error,1013,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2842,1,['Error'],['Error']
Availability,"use `cmap`. In general you can use any option available for; `matplotlib.pyplot.scatter` including vmin, vmax, etc. On Mon, Nov 26, 2018 at 11:01 PM aopisco <notifications@github.com> wrote:. > @falexwolf <https://github.com/falexwolf> @fidelram; > <https://github.com/fidelram> how to we change the color palette for; > numerical variables? currently setting palette = 'Oranges' only works for; > the categorical ones; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/156#issuecomment-441815667>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RFS_19jC__9pOo04OZkjN_hVZvvks5uzGTBgaJpZM4UCLlA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/156#issuecomment-441950074:46,avail,available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156#issuecomment-441950074,1,['avail'],['available']
Availability,use_raw=False always create errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-976191715:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-976191715,1,['error'],['errors']
Availability,"ut from being displayed; 2496 # when using magics with decorator @output_can_be_silenced; 2497 # when the last Python token in the expression is a ';'.; 2498 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer cor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:4743,error,error,4743,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,1,['error'],['error']
Availability,"ut_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2181:3379,error,error,3379,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181,1,['error'],['error']
Availability,"ute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1982:5875,error,error,5875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982,1,['error'],['error']
Availability,"v4_R_fixed.loom'). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names); 142 filename = fspath(filename) # allow passing pathlib.Path objects; 143 from loompy import connect; --> 144 with connect(filename, 'r') as lc:; 145 ; 146 if X_name not in lc.layers.keys(): X_name = ''. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in connect(filename, mode, validate, spec_version); 1151 Note: if validation is requested, an exception is raised if validation fails.; 1152 	""""""; -> 1153 return LoomConnection(filename, mode, validate=validate, spec_version=spec_version). ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/loompy/loompy.py in __init__(self, filename, mode, validate, spec_version); 82 lv = loompy.LoomValidator(version=spec_version); 83 if not lv.validate(filename):; ---> 84 raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); 85 ; 86 self._file = h5py.File(filename, mode). ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'Regulons' dtype [('SPI1_extended_(1805g)', 'u1'), ('SPI1_(1756g)', 'u1'), ('KLF5_extended_(1521g)', 'u1'), ('EHF_extended_(1513g)', 'u1'), ('STAT1_extended_(1443g)', 'u1'), ('ELF3_extended_(1249g)', 'u1'), ('STAT1_(1212g)', 'u1'), ('CEBPB_extended_(1162g)', 'u1'), ('CEBPB_(1045g)', 'u1'), ('KLF5_(1038g)', 'u1'), ('ELF1_extended_(987g)', 'u1'), ('ETS2_extended_(932g)', 'u1'), ('IRF8_extended_(923g)', 'u1'), ('JUND_extended_(789g)', 'u1'), ('EHF_(762g)', 'u1'), ('ELF1_(753g)', 'u1'), ('TFEC_extended_(694g)', 'u1'), ('ETS2_(688g)', 'u1'), ('IRF7_extended_(688g)', 'u1'), ('IRF8_(687g)', 'u1'), ('XBP1_extended_(669g)', 'u1'), ('IRF1_extended_(662g)', 'u1'), ('ETS1_extended_(647g)', 'u1'), ('IRF1_(617g)', 'u1'), ('IRF7_(616g)', 'u1'), ('XBP1_(587g)', 'u1'), ('ETS1_(577g)', 'u1'), ('UQCRB_(573g)', 'u1'), ('PRDM1_extende",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/320:1843,error,errors,1843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/320,1,['error'],['errors']
Availability,"ve already read in an Ann data object from an h5ad existing file; sc.tl.pca(adata, n_comps=30, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=15); sc.tl.umap(adata). k = 15; communities, graph, Q = sc.external.tl.phenograph(pd.DataFrame(adata.obsm['X_pca']),k=k); adata.obs['PhenoGraph_clusters'] = pd.Categorical(communities); adata.uns['PhenoGraph_Q'] = Q; adata.uns['PhenoGraph_k'] = k. path_to_h5ad_file = '~/test.h5ad'; adata.write_h5ad(path_to_h5ad_file) # works. # but if I run; sc.tl.rank_genes_groups(adata, n_genes=21515,groupby='PhenoGraph_clusters', method='wilcoxon'); rcParams['figure.figsize'] = 4,4; rcParams['axes.grid'] = True; sc.pl.rank_genes_groups(adata); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5). path_to_h5ad_file = '~/test.h5ad' # works; adata.write_h5ad(path_to_h5ad_file) # gives ERROR bellow. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-cb0bc3c267ae> in <module>; ----> 1 adata = sc.read(path_to_h5ad_file). ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. ~/miniconda3/lib/python3.7/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/miniconda3/lib/python3.7/site-packages/anndata/readwrite/read.py in read_h5ad(filename, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/937:1747,Error,Error,1747,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/937,1,['Error'],['Error']
Availability,"ve confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1971:1130,error,error,1130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971,1,['error'],['error']
Availability,"ve no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas on how to solve this?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/706:1394,error,error,1394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/706,1,['error'],['error']
Availability,"version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:1082,error,error,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,1,['error'],['error']
Availability,"very interesting, also new to me. I think this boils down to issues in `pynndescent` not being able to handle such edge cases. I wonder if this happens with other metrics as well... @TiongSun can you update us on whether this is a similar issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802857928:53,down,down,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802857928,1,['down'],['down']
Availability,"vice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite?. Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->; ```python; import scanpy as sc; import pandas as pd; import numpy as np; import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True); ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->; ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs); 716 try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:974,Error,Error,974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,2,"['Error', 'error']","['Error', 'errors']"
Availability,"vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:123) if is_valid_filename(filename):; --> [124](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:124) return _read(; [125](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:125) filename,; [126](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:126) backed=backed,; [127](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:127) sheet=sheet,; [128](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:128) ext=ext,; ...; [65](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/anndata/_core/aligned_df.py:65) anno = anno.copy(deep=False); [66](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/anndata/_core/aligned_df.py:66) if not is_string_dtype(anno.index):. ValueError: Observations annot. `var` must have as many rows as `X` has columns (1), but has 33538 rows.; Error raised while reading key '' of <class 'h5py._hl.files.File'> from /; Output is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?21de049a-219f-41e8-9d9d-5aabf61d8031) or open in a [text editor](command:workbench.action.openLargeOutput?21de049a-219f-41e8-9d9d-5aabf61d8031). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...; ```; This is my version:; ```; print(sc.__version__); print(ad.__version__); 1.10.0; 0.10.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/323#issuecomment-2041512845:4114,Error,Error,4114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323#issuecomment-2041512845,1,['Error'],['Error']
Availability,"w, log, num_categories, color_map, dot_max, dot_min, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1350 if isinstance(var_names, str):; 1351 var_names = [var_names]; -> 1352 categories, obs_tidy = _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer=layer); 1353 ; 1354 # for if category defined by groupby (if any) compute for each var_name. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer); 1983 matrix = adata[:, var_names].layers[layer]; 1984 elif use_raw:; -> 1985 matrix = adata.raw[:, var_names].X; 1986 else:; 1987 matrix = adata[:, var_names].X. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 495 ; 496 def __getitem__(self, index):; --> 497 oidx, vidx = self._normalize_indices(index); 498 if self._adata is not None or not self._adata.isbacked: X = self._X[oidx, vidx]; 499 else: X = self._adata.file['raw.X'][oidx, vidx]. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_indices(self, packed_index); 523 obs, var = super()._unpack_index(packed_index); 524 obs = _normalize_index(obs, self._adata.obs_names); --> 525 var = _normalize_index(var, self.var_names); 526 return obs, var; 527 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _normalize_index(index, names); 268 raise KeyError(; 269 'Indices ""{}"" contain invalid observation/variables names/indices.'; --> 270 .format(index)); 271 return positions.values; 272 else:. KeyError: 'Indices ""[\'mamo\', \'mab21\', \'ChaT\', \'VGlut\']"" contain invalid observation/variables names/indices.'; ```. I do NOT get the error when I select to 'color' for either genes in the sc.pl.umap command. Moreover my adata contains all genes since the beggining so it is not subsetting anything. . All the help is appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/593:2302,error,error,2302,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/593,1,['error'],['error']
Availability,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2454799672:31,failure,failure,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2454799672,1,['failure'],['failure']
Availability,"what if i told you that we can have our cake and eat it too? as said before:. > We could throw a nice error if the column isn’t in `.obs` but is in `.var` instead, like; > ; > > You specified column “dropout_per_gene” which is not in `.obs`, but in `.var`. Did you mean to call `sc.pl.violin(adata.T, ...)`?. Near zero frustration, because people can just do what the error tells them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441263484:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441263484,2,['error'],['error']
Availability,"when run sc.utils.sanitize_anndata(adata), it returns:; AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error?; the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2410:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410,1,['error'],['error']
Availability,"with `umap-lean==0.5.0` and `numba=0.53.1` I get a different error. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.pp.neighbors(adata); ```. <details>; <summary>Details</summary>. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-5d47edb05ae7> in <module>; ----> 1 sc.pp.neighbors(adata). ~/Projects/scanpy/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/umap_.py in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import nump",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['error'],['error']
Availability,"with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:4095,error,error,4095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['error'],['error']
Availability,"workx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.0.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.0; pylab NA; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; requests 2.23.0; requests_cache 0.5.2; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; socks 1.7.1; soupsieve 2.0.1; statsmodels 0.12.0; storemagic NA; tables 3.6.1; terminado 0.8.3; tornado 6.0.4; traitlets 5.0.4; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; xlsxwriter 1.3.3; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.8; notebook 6.1.4; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-4.4.0-142-generic-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2020-09-16 11:03; ```. Here is the error message:. ```; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-37-b22ada65a1cd> in <module>; 1 # Create Concatenated anndata object for all timepoints; 2 #alldays = e125.concatenate(e135, e145, e155, uns_merge=""unique""); ----> 3 alldays = e125.concatenate(e135). ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1696 all_adatas = (self,) + tuple(adatas); 1697 ; -> 1698 out = concat(; 1699 all_adatas,; 1700 axis=0,. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 799 [dim_indices(a, axis=1 - axis) for a in adatas], join=join; 800 ); --> 801 reindexers = [; 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875:1851,error,error,1851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875,1,['error'],['error']
Availability,"x that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python; # Read the count matrix ; adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names; adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]; adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names; sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample; for sample in sample_list:; sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```; However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. ; ```pytb; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); Input In [5], in <cell line: 2>(); 1 # iterate through the sample names and create a new AnnData object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402:1138,error,error,1138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402,1,['error'],['error']
Availability,"xception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-13-02/ipykernel_2124423/1009160698.py in <module>; ----> 1 sc.pp.neighbors(adata_pbmc3k). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x150524c6cdc0>) returned a result with an error set. time: 3 s (started: 2021-08-23 11:59:12 +01:00); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863:2900,error,error,2900,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863,1,['error'],['error']
Availability,"xit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3777,avail,available,3777,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['avail'],['available']
Availability,"y in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 . ~/.conda/envs/rpy/lib/python3.9/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,. ~/.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_typ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:3974,error,errors,3974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['error'],['errors']
Availability,"y with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib import rcParams; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_13940/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\anaconda3\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\anaconda3\en",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:5247,error,error,5247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['error'],['error']
Availability,"y(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2758:3036,error,error,3036,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758,1,['error'],['error']
Availability,y/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68266,ERROR,ERROR,68266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,y/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66618,ERROR,ERROR,66618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,y/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4450,ERROR,ERROR,4450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,y/tests/test_highly_variable_genes.py; ERROR scanpy/tests/test_ingest.py; ERROR scanpy/tests/test_metrics.py; ERROR scanpy/tests/test_neighbors_key_added.py; ERROR scanpy/tests/test_paga.py; ERROR scanpy/tests/test_pca.py; ERROR scanpy/tests/test_plotting.py; ERROR scanpy/tests/test_preprocessing.py; ERROR scanpy/tests/test_queries.py; ERROR scanpy/tests/test_rank_genes_groups.py; ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportErr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:3554,ERROR,ERROR,3554,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,y/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67616,ERROR,ERROR,67616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"y48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:463, in CompilerBase._compile_core(self); [461](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=460) res = None; [462](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=461) try:; --> [463](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=462) pm.run(self.state); [464](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=463) if self.state.cr is not None:; [465](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=464) break. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:353, in PassManager.run(self, state); [350](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:21418,avail,available,21418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['avail'],['available']
Availability,y::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:16998,ERROR,ERROR,16998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,"y_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'pct_counts_hb', 'percent_mt2', 'n_counts', 'sample', 'group', 'disease_status', 'leiden'; var: 'gene_ids', 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'log1p', 'pca', 'neighbors', 'umap', 'leiden', 'leiden_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'. ```. Ive tried to check whether the data is maybe different or something, but i dont see anything that could be causing these differences, could you please help trying to figure out why the leiden clustering suddenly produces different results? . ### Minimal code sample. ```python; sc.pp.neighbors(adata, n_pcs = 30, n_neighbors = 20); sc.tl.umap(adata); sc.tl.leiden(adata, resolution = 0.2) ; sc.pl.umap(adata, color='leiden'); ```. ### Error output. _No response_. ### Versions. <details>. ```; sc.logging.print_versions(); -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 9.4.0; PyQt5 NA; adjustText 1.0.4; asttokens NA; atomicwrites 1.4.1; bottleneck 1.3.5; brotli NA; bs4 4.12.2; certifi 2024.02.02; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.2.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.8; executing 2.0.1; gseapy 1.1.2; h5py 3.9.0; html5lib 1.1; idna 3.4; igraph 0.11.3; ipykernel 6.29.2; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.10.2; llvmlite 0.42.0; lxml 5.1.0; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; matplotlib_inline 0.1.6; mkl 2.4.1; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.4; numpy 1.24.3; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pickleshare 0.7.5; platformdirs 3.10.0; prompt_toolkit 3.0.42; psuti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956:2703,Error,Error,2703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2956,1,['Error'],['Error']
Availability,"y_variable""] (regardless of the value of the batch_key option), using adata.var[""highly_variable_intersection""] for filtering is not a good idea. If there is confusion between adata.var[""highly_variable""] and adata.var[""highly_variable_intersection""]:. If the user specifies n_top_genes, adata.var[""highly_variable""] contains top variable genes in the list of genes sorted by number of batches they are detected as variable (ties broken using dispersion). If mean/dispersion filters are provided, we apply these cutoffs to mean mean/dispersion across batches to construct a unified adata.var[""highly_variable""]. adata.var[""highly_variable_intersection""] is a very strict definition that I personally avoid using at all, but it also depends on the experimental setting and batch_key itself. Therefore, there is a mistake in the following code:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```. This possibly removes many genes that are identified as highly variable in adata.var.highly_variable because adata_hvg = adata[:, adata.var.highly_variable_intersection] keeps only a subset of highly variable genes (see the definitions above). If one wants to use the strict definition, correct usage would be:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata.var.highly_variable = adata.var.highly_variable_intersection; sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```. which is what @LuckyMD proposes, IIUC. I think what we should do here is to print a more informative error in PCA, smt like `HVGs identified by sc.pp.highly_variable_genes cannot be found in adata.`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607:1366,error,error,1366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607,3,['error'],['error']
Availability,y_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44640,Error,Error,44640,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"yes very good point, the tutorial needs to be fixed for sure because now it would fail.; trowing error in the heatmap is also probably the best way to go.; Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723090290:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723090290,1,['error'],['error']
Availability,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`; ; our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/61#issuecomment-355082458:1003,down,down,1003,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61#issuecomment-355082458,1,['down'],['down']
Availability,"ygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1997:2764,down,downgrading,2764,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997,1,['down'],['downgrading']
Availability,"you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here?. Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks; -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good!. > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes.; > ...; > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway?. > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here?. No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443:1793,avail,available,1793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443,2,"['avail', 'robust']","['available', 'robust']"
Availability,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57410,ERROR,ERROR,57410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58746,ERROR,ERROR,58746,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ython3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3178,toler,tolerance,3178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,"ython; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns; import anndata; import matplotlib as mpl; import scipy. sc.logging.print_versions(); # scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 ; # pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. sp = sc.datasets.pbmc3k(); sc.pp.normalize_total(sp,target_sum=1e6,key_added='norm_factor'); sc.pp.log1p(sp); sp.raw=sp; sc.pp.highly_variable_genes(sp, n_top_genes=2000); sc.pl.highly_variable_genes(sp); sp = sp[:, sp.var['highly_variable']]; sc.pp.scale(sp, max_value=10); sc.tl.pca(sp, svd_solver='arpack'); sc.pl.pca_variance_ratio(sp, log=True); sc.pp.neighbors(sp, n_neighbors=10, n_pcs=30); sc.tl.diffmap(sp); sc.pp.neighbors(sp, n_neighbors=20, use_rep='X_diffmap'); sc.tl.louvain(sp,resolution=1); sc.tl.paga(sp); _, axs = plt.subplots(ncols=1, figsize=(24, 10), gridspec_kw={'wspace': 0.05, 'left': 0.12}); # Modified this call because pos_coord wasn't defined:; # sc.pl.paga(sp,color='louvain',layout='fa',pos=pos_coord,threshold=0.2,ax=axs) ; sc.pl.paga(sp,color='louvain',layout='fa',threshold=0.2,ax=axs); from scanpy.tools._utils import get_init_pos_from_paga as init; sc.tl.umap(sp,init_pos=init(sp)); sc.pl.umap(sp,color='louvain'); ```. The final plot looks normal enough:. ![image](https://user-images.githubusercontent.com/8238804/69206364-8c9d1880-0ba0-11ea-8180-3bbd0b8c825e.png). Right now, there are a lot of variables in this script. There's a few things to try:. * Check if `pos_coord` is causing the issue; * I noticed your scanpy version wasn't the same as the current release, could you update that?; * If you run the script with the dataset I used, does your plot still have those strange rectangular layouts?; * Can you cut down the number of commands you used, and potentially even the amount of data? This will limit the number of variables that could be causing the behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868:2088,down,down,2088,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868,1,['down'],['down']
Availability,"ython\Python312\site-packages\pandas\io\parsers\readers.py:620, in _read(filepath_or_buffer, kwds); 617 _validate_names(kwds.get(""names"", None)); 619 # Create the parser.; --> 620 parser = TextFileReader(filepath_or_buffer, **kwds); 622 if chunksize or iterator:; 623 return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); 1617 self.options[""has_index_names""] = kwds[""has_index_names""]; 1619 self.handles: IOHandles | None = None; -> 1620 self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1880, in TextFileReader._make_engine(self, f, engine); 1878 if ""b"" not in mode:; 1879 mode += ""b""; -> 1880 self.handles = get_handle(; 1881 f,; 1882 mode,; 1883 encoding=self.options.get(""encoding"", None),; 1884 compression=self.options.get(""compression"", None),; 1885 memory_map=self.options.get(""memory_map"", False),; 1886 is_text=is_text,; 1887 errors=self.options.get(""encoding_errors"", ""strict""),; 1888 storage_options=self.options.get(""storage_options"", None),; 1889 ); 1890 assert self.handles is not None; 1891 f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); 761 if compression == ""gzip"":; 762 if isinstance(handle, str):; 763 # error: Incompatible types in assignment (expression has type; 764 # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> 765 handle = gzip.GzipFile( # type: ignore[assignment]; 766 filename=handle,; 767 mode=ioargs.mode,; 768 **compression_args,; 769 ); 770 else:; 771 handle = gzip.GzipFile(; 772 # No overload variant of ""GzipFile"" matches argument types; 773 # ""Union[str, BaseBuffer]"", ""str"", ""Dict[str, Any]""; (...); 776 **compression_args,; 777 ). File c:\Program Files\Python312\Lib\gzip.py:192, in GzipFile.__init__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:23789,error,errors,23789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['error'],['errors']
Availability,yup! genes you filtered out are not available unless you use `use_raw`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2068#issuecomment-2268851567:36,avail,available,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2068#issuecomment-2268851567,1,['avail'],['available']
Availability,"z=2019.3=pypi_0; pyyaml=5.3.1=py37h8f50634_0; pyzmq=19.0.0=py37hac76be4_1; readline=8.0=h7b6447c_0; requests=2.23.0=pyh8c360ce_2; scanpy=1.4.6=pypi_0; scikit-learn=0.22.2.post1=pypi_0; scipy=1.4.1=pypi_0; seaborn=0.10.1=pypi_0; send2trash=1.5.0=py_0; setuptools=46.1.3=py37_0; setuptools-scm=3.5.0=pypi_0; six=1.14.0=py_1; sqlite=3.31.1=h62c20be_1; statsmodels=0.11.1=pypi_0; tables=3.6.1=pypi_0; tbb=2020.0.133=pypi_0; terminado=0.8.3=py37hc8dfbb8_1; testpath=0.4.4=py_0; texttable=1.6.2=py_0; tk=8.6.8=hbc83047_0; tornado=6.0.4=py37h8f50634_1; tqdm=4.45.0=pypi_0; traitlets=4.3.3=py37hc8dfbb8_1; umap-learn=0.4.1=pypi_0; urllib3=1.25.9=py_0; wcwidth=0.1.9=pyh9f0ad1d_0; webencodings=0.5.1=py_1; wheel=0.34.2=py37_0; xorg-kbproto=1.0.7=h14c3975_1002; xorg-libice=1.0.10=h516909a_0; xorg-libsm=1.2.3=h84519dc_1000; xorg-libx11=1.6.9=h516909a_0; xorg-libxau=1.0.9=h14c3975_0; xorg-libxdmcp=1.1.3=h516909a_0; xorg-libxext=1.3.4=h516909a_0; xorg-libxrender=0.9.10=h516909a_1002; xorg-renderproto=0.11.1=h14c3975_1002; xorg-xextproto=7.3.0=h14c3975_1002; xorg-xproto=7.0.31=h14c3975_1007; xz=5.2.5=h7b6447c_0; yaml=0.2.4=h516909a_0; zeromq=4.3.2=he1b5a44_2; zipp=3.1.0=py_0; zlib=1.2.11=h7b6447c_3; ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash; # Where the output you pasted above is in scanpy_1183_env.txt; $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt; $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt; $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt; $ conda activate scanpy1183; $ pip install -r scanpy_1183_pip.txt; ```. Then I tested this using:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); sc.pp.normalize_total(adata, target_sum=1e4); ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575:4504,error,error,4504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575,3,['error'],['error']
Availability,ze_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location); ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2993:14473,ERROR,ERROR,14473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993,1,['ERROR'],['ERROR']
Availability,~~But it seems to throw an error if I combine it with `-k`:~~. ```; ValueError: limit_multithreading did not yield a value; ```. Fixed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934363564:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934363564,1,['error'],['error']
Availability,"⠀⠂⠠⢠⡁⡄⡌⠀⠀⠠⢅⠀⠄⠀⢕⢐⠀⠄⡂⢀⠂⠀⠂⠈⡸⠂; ⠀⠀⠀⢐⡂⠀⢀⠐⠀⠰⡀⠑⡀⠀⠠⠀⠐⢀⠈⠆⠤⠄⢀⠀⣀⠢⡀⠀; ⠂⢀⢪⢘⠀⢀⠩⠅⢄⠄⠠⠠⠐⠀⠀⢀⠠⠂⠀⠁⡘⠀⠀⠐⠢⡐⠀⠀; ⢀⠌⡘⠘⠂⠄⢀⠀⢠⠔⠈⢀⠈⠀⠀⠠⡀⡂⠄⢀⠀⠀⠀⠁⠔⢈⢰⠀; ⠁⠐⡀⡠⠀⠐⠠⠈⠀⢀⠀⠘⠂⠀⠀⠀⠐⠰⠄⡡⠠⡀⠀⠀⠂⠠⠁⠐; ```. While this is one with blocks along the diagonal:. ```; ⠿⣧⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠿⠿⠿⠿⣧⣤⣤⣤⣤⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠛⠛⠛⠛⠛⠛⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⣧⣤⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢻⣶⣶⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠛⢻⣶⡆⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⣿⣿; ```. When you have blocks of dense values, you can just store those dense blocks as regular arrays along with offsets. > but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask. Yes, this should be fine. The issue I was thinking of is more when you want to do something like `scale`-ing your expression. > Or mito/ribo genes are filtered out sometimes, which might be needed later on e.g. to redo qc etc. > In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. If don't want them to be used as features for any analyses on `X`, they could be stored in `obsm`. If you want to use them for some analyses, (like DE), then they can just be masked out for others. > I would be a bit hesitant to not have a replacement for .raw. I think `layers` satisfies this. It just doesn't allow you to have a different set of variables (that is, not just a subset) for DE than the rest of the object has. But, having the different set of variables is what makes `raw` difficult to work with. > introduce a new .frozenraw or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I'd note that `.raw` is already supposed to be read-only.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:4105,mask,masked,4105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,1,['mask'],['masked']
Availability,"⠈⢀⠌⠚⠀⠀⠃; ⠁⠂⡃⠈⠀⢀⠀⠙⢀⠥⠀⠀⠄⡁⠀⠠⠈⠀⠈⠃⠂⠠⣀⠀⠈⣁⠁⠆; ⡀⠐⠐⠠⠀⠐⢐⡄⣂⠀⠀⠘⠀⠀⠀⠠⠂⠀⡀⠨⠁⠀⠀⠀⠁⠁⠣⠤; ⠀⡐⢀⢢⠀⠁⠔⠀⠁⠀⠃⠀⢀⢀⠐⠃⠄⠀⡇⠊⠄⠀⡈⢀⠀⠀⣀⠆; ⠀⢐⣤⡄⠠⠂⠃⡈⠘⠀⠀⠀⡂⠰⢄⠊⡂⠀⠐⠂⠀⠄⠀⠀⢱⠩⠈⢀; ⢁⠀⠑⠚⠁⠂⠂⠐⠁⠀⠀⢀⠠⠀⠐⠈⠈⡨⠀⠂⠀⡈⠈⠁⡐⣀⢁⠂; ⠀⠀⠀⠁⠀⠠⠅⠁⡠⠇⢐⠀⠀⠖⢉⣀⠀⢀⠀⠠⡀⠀⡀⢰⠁⠂⢉⠂; ⠀⠀⠀⠂⠠⢠⡁⡄⡌⠀⠀⠠⢅⠀⠄⠀⢕⢐⠀⠄⡂⢀⠂⠀⠂⠈⡸⠂; ⠀⠀⠀⢐⡂⠀⢀⠐⠀⠰⡀⠑⡀⠀⠠⠀⠐⢀⠈⠆⠤⠄⢀⠀⣀⠢⡀⠀; ⠂⢀⢪⢘⠀⢀⠩⠅⢄⠄⠠⠠⠐⠀⠀⢀⠠⠂⠀⠁⡘⠀⠀⠐⠢⡐⠀⠀; ⢀⠌⡘⠘⠂⠄⢀⠀⢠⠔⠈⢀⠈⠀⠀⠠⡀⡂⠄⢀⠀⠀⠀⠁⠔⢈⢰⠀; ⠁⠐⡀⡠⠀⠐⠠⠈⠀⢀⠀⠘⠂⠀⠀⠀⠐⠰⠄⡡⠠⡀⠀⠀⠂⠠⠁⠐; ```. While this is one with blocks along the diagonal:. ```; ⠿⣧⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠿⠿⠿⠿⣧⣤⣤⣤⣤⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠛⠛⠛⠛⠛⠛⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⣧⣤⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢻⣶⣶⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠛⢻⣶⡆⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⣿⣿; ```. When you have blocks of dense values, you can just store those dense blocks as regular arrays along with offsets. > but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask. Yes, this should be fine. The issue I was thinking of is more when you want to do something like `scale`-ing your expression. > Or mito/ribo genes are filtered out sometimes, which might be needed later on e.g. to redo qc etc. > In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. If don't want them to be used as features for any analyses on `X`, they could be stored in `obsm`. If you want to use them for some analyses, (like DE), then they can just be masked out for others. > I would be a bit hesitant to not have a replacement for .raw. I think `layers` satisfies this. It just doesn't allow you to have a different set of variables (that is, not just a subset) for DE than the rest of the object has. But, having the different set of variables is what makes `raw` difficult to work wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:3427,mask,masks,3427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,2,['mask'],"['mask', 'masks']"
Availability,"细胞分析\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,; lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,; lung_ti_p4,lung_ts1_p4,lung_ts2_p4,; lung_P2, lung_P5, lung_P8, lung_P9,; lung_P13, lung_P16,; lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,; lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,; batch_categories = [""TI-P2"", ""TM-P2"",; ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',; ""TI-P4"",'TS1-P4','TS2-P4',; 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',; 'lung_P13', 'lung_P16',; 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',; 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],; join='outer'). print('Begin of post doublets removal and QC plot'); sc.pp.scrublet(alldata, n_neighbors=10); alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(); n1 = alldata.shape[0]; print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'); print(f'End of post doublets removal and QC plots.'); ```. ### Error output. ```pytb; Begin of post doublets removal and QC plot; Running Scrublet; normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts; warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00); WARNING: adata.X seems to be already log-transformed.; extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p; np.log1p(X, out=X). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[59], line 2; 1 print('Begin of post doublets removal and QC plot'); ----> 2 sc.pp.scrublet(alldata, n_neighbors=10); 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(); 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3070:6105,Error,Error,6105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070,1,['Error'],['Error']
Deployability," 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; lazy_loader NA; leidenalg 0.10.1; llvmlite 0.40.0; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; matplotlib_venn 0.11.9; mkl 2.4.0; mpl_toolkits NA; msgpack 1.0.5; multipledispatch 0.6.0; multiscale_spatial_image 0.11.2; mygene 3.2.2; natsort 7.1.1; nbinom_ufunc NA; neighborhood_enrichment NA; networkx 3.1; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; ome_zarr NA; openpyxl 3.1.2; packaging 23.0; pandas 2.0.3; param 1.13.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; pooch v1.4.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pyct 0.5.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygeos 0.14; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyproj 3.6.0; pytz 2022.7; pywt 1.4.1; requests 2.31.0; rich NA; rtree 1.0.1; schist v0.7.16; scipy 1.8.0; seaborn 0.12.2; session_info 1.0.0; setuptools 68.0.0; shapely 2.0.1; sip NA; six 1.16.0; skimage 0.20.0; sklearn 1.2.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.12; sphinxcontrib NA; spyder 5.4.3; spyder_kernels 2.4.3; spydercustomize NA; squidpy 1.3.0; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tifffile 2021.7.2; tlz 0.12.0; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; umap 0.5.3; urllib3 1.26.16; validators 0.20.0; wcwidth 0.2.5; wurlitzer 3.0.2; xarray 2022.12.0; xarray_dataclasses 1.6.0; xarray_schema 0.0.3; xrspatial 0.3.7; yaml 6.0; zarr 2.16.0; zipp NA; zmq 25.1.0; zoneinfo NA; zstandard 0.19.0; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:50:29) [Clang 14.0.6 ]; macOS-11.6-x86_64-i386-64bit; -----; Session information updated at 2023-08-02 20:20. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586:7787,update,updated,7787,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586,1,['update'],['updated']
Deployability," 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.8.0; jupyterlab_server 2.6.0; kiwisolver 1.2.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; nbinom_ufunc NA; numba 0.53.1; numcodecs 0.8.0; numexpr 2.7.2; numpy 1.21.0; packaging 20.9; pandas 1.2.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2020.1; requests 2.25.1; scanpy 1.9.0.dev7+g092376d2; scipy 1.7.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; snappy NA; sniffio 1.2.0; socks 1.7.1; sparse 0.12.0+21.gc96cc1a; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.6.0; terminado 0.8.3; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.61.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 1.1.0; yaml 5.3.1; zappy NA; zarr 2.8.3; zmq 19.0.2; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-07-01 15:01; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1915:4595,update,updated,4595,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915,1,['update'],['updated']
Deployability, 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0; importlib-metadata 6.8.0; importlib-resources 6.1.0; incremental 22.10.0; inflection 0.5.1; iniconfig 2.0.0; intake 0.7.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680:5031,patch,patch,5031,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680,1,['patch'],['patch']
Deployability," 127 if fmt == 'svg':. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs); 2261 orientation=orientation,; 2262 bbox_inches_restore=_bbox_inches_restore,; -> 2263 **kwargs); 2264 finally:; 2265 if bbox_inches and restore_bbox:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs); 515 ; 516 def print_png(self, filename_or_obj, *args, **kwargs):; --> 517 FigureCanvasAgg.draw(self); 518 renderer = self.get_renderer(); 519 original_dpi = renderer.dpi. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py in draw(self); 435 # if toolbar:; 436 # toolbar.set_cursor(cursors.WAIT); --> 437 self.figure.draw(self.renderer); 438 # A GUI class may be need to update a window using this draw, so; 439 # don't forget to call the superclass. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/artist.py in draw_wrapper(artist, renderer, *args, **kwargs); 53 renderer.start_filter(); 54 ; ---> 55 return draw(artist, renderer, *args, **kwargs); 56 finally:; 57 if artist.get_agg_filter() is not None:. ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/figure.py in draw(self, renderer); 1491 ; 1492 mimage._draw_list_compositing_images(; -> 1493 renderer, self, artists, self.suppressComposite); 1494 ; 1495 renderer.close_group('figure'). ~/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/image.py in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 139 if not_composite or not has_images:; 140 for a in artists:; --> 141 a.draw(renderer); 142 else:; 143 # Composite any adjacent images together. ~/.pyenv/versions/3.6.5/Py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264:6741,update,update,6741,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264,1,['update'],['update']
Deployability," 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:79) if len(args_all) <= n_positional:; ---> [80](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:80) return fn(*args_all, **kw); [82](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:82) args_pos: P.args; [83](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:83) args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:560, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); [558](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:1998,Pipeline,PipelineDevelope,1998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability," 20.2.0; backcall 0.2.0; brotli NA; cellrank 1.0.0-rc.10; certifi 2020.06.20; cffi 1.14.3; chardet 3.0.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; datacache 1.1.5; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; gtfparse 1.2.0; h5py 2.10.0; idna 2.10; igraph 0.8.2; importlib_metadata 0.23; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.14.0; jsonschema 3.2.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.1; libpetsc4py NA; llvmlite 0.34.0; louvain 0.6.1+2.g8073db7; markupsafe 1.1.1; matplotlib 3.3.2; memoized_property NA; more_itertools NA; mpl_toolkits NA; natsort 6.0.0; nbformat 5.0.7; networkx 2.3; numba 0.51.2; numexpr 2.7.0; numpy 1.19.1; packaging 20.4; palantir 1.0.0; pandas 1.1.2; parso 0.7.1; petsc4py 3.13.0; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.0; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.7; psutil 5.7.2; ptyprocess 0.6.0; pvectorc NA; py 1.8.0; pyensembl 1.8.7; pygam 0.8.0; pygments 2.7.1; pyparsing 2.4.2; pyrsistent NA; pytest 5.2.1; python_utils NA; pytz 2019.2; requests 2.24.0; rpy2 3.3.5; scanpy 1.6.0; scipy 1.5.2; scvelo 0.2.2; seaborn 0.11.0; send2trash NA; serializable 0.2.1; setuptools_scm NA; simplejson 3.17.2; sinfo 0.3.1; six 1.15.0; sklearn 0.21.3; slepc4py 3.13.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; terminado 0.9.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typechecks NA; typing_extensions NA; tzlocal NA; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.1.2; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:25:08) [GCC 7.5.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-09-30 12:20. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438:4044,update,updated,4044,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438,1,['update'],['updated']
Deployability," 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64::harfbuzz==1.8.8=hffaf4a1_0; - conda-forge/linux-64::leidenalg==0.8.2=py38habedc41_0; - defaults/linux-64::pango==1.42.4=h049681c_0; - defaults/linux-64::pycairo==1.19.1=py38h708ec4a_0; - conda-forge/linux-64::python-igraph==0.7.1.post7=py38h516909a_0; - r/linux-64::r==3.6.0=r36_0; - r/linux-64::r-base==3.6.1=haffb61f_2; - r/noarch::r-boot==1.3_20=r36h6115d3f_0; - r/linux-64::r-class==7.3_15=r36h96ca727_0; - r/linux-64::r-cluster==2.0.8=r36ha65eedd_0; - r/noarch::r-codetools==0.2_16=r36h6115d3f_0; - r/linux-64::r-foreign==0.8_71=r36h96ca727_0; - r/linux-64::r-kernsmooth==2.23_15=r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2699,update,updated,2699,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['update'],['updated']
Deployability," ; 1807 inner.__doc__ = _add_data_doc(inner.__doc__,. [...]/lib/python3.6/site-packages/matplotlib/axes/_axes.py in pcolor(self, alpha, norm, cmap, vmin, vmax, *args, **kwargs); 5762 kwargs.setdefault('snap', False); 5763 ; -> 5764 collection = mcoll.PolyCollection(verts, **kwargs); 5765 ; 5766 collection.set_alpha(alpha). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, verts, sizes, closed, **kwargs); 931 %(Collection)s; 932 """"""; --> 933 Collection.__init__(self, **kwargs); 934 self.set_sizes(sizes); 935 self.set_verts(verts, closed). [...]/lib/python3.6/site-packages/matplotlib/collections.py in __init__(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, offset_position, zorder, **kwargs); 164 ; 165 self._path_effects = None; --> 166 self.update(kwargs); 167 self._paths = None; 168 . [...]/lib/python3.6/site-packages/matplotlib/artist.py in update(self, props); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. [...]/lib/python3.6/site-packages/matplotlib/artist.py in <listcomp>(.0); 914 ; 915 with cbook._setattr_cm(self, eventson=False):; --> 916 ret = [_update_property(self, k, v) for k, v in props.items()]; 917 ; 918 if len(ret):. [...]/lib/python3.6/site-packages/matplotlib/artist.py in _update_property(self, k, v); 910 func = getattr(self, 'set_' + k, None); 911 if not callable(func):; --> 912 raise AttributeError('Unknown property %s' % k); 913 return func(v); 914 . AttributeError: Unknown property standard_scale; ```; Any idea of why I'm getting this? . Package info:. ```; scanpy==1.4 anndata==0.6.18 numpy==1.16.2 scipy==1.2.0 pandas==0.24.1 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Thank you!. PS: this happens also when I just use the example data as in [here](https://scanpy-tutorials.readth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/559:2365,update,update,2365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/559,1,['update'],['update']
Deployability," <details>. ```; -----; anndata 0.10.7; scanpy 1.10.1; -----; PIL 10.3.0; anyio NA; arrow 1.3.0; asttokens NA; attr 23.2.0; attrs 23.2.0; babel 2.14.0; brotli 1.1.0; certifi 2024.02.02; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0; debugpy 1.8.1; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.7; igraph 0.10.8; ipykernel 6.29.3; ipywidgets 8.1.2; isoduration NA; jedi 0.19.1; jinja2 3.1.3; joblib 1.4.0; json5 0.9.25; jsonpointer 2.4; jsonschema 4.21.1; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.0; jupyterlab_server 2.27.0; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.42.0; markupsafe 2.1.5; matplotlib 3.8.4; matplotlib_inline 0.1.7; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; numba 0.59.1; numpy 1.26.4; overrides NA; packaging 24.0; pandas 1.5.3; parso 0.8.4; pickleshare 0.7.5; platformdirs 4.2.0; prometheus_client NA; prompt_toolkit 3.0.42; psutil 5.9.8; pure_eval 0.2.2; pycparser 2.22; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.17.2; pynndescent 0.5.12; pyparsing 3.1.2; pythonjsonlogger NA; pytz 2024.1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.0; send2trash NA; session_info 1.0.0; six 1.16.0; sklearn 1.4.2; sniffio 1.3.1; socks 1.7.1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.4.0; tornado 6.4; tqdm 4.66.2; traitlets 5.14.3; umap 0.5.5; uri_template NA; urllib3 2.2.1; wcwidth 0.2.13; webcolors 1.13; websocket 1.7.0; yaml 6.0.1; zmq 26.0.2; -----; IPython 8.22.2; jupyter_client 8.6.1; jupyter_core 5.7.2; jupyterlab 4.1.6; notebook 7.1.3; -----; Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]; Linux-5.4.0-150-generic-x86_64-with-glibc2.27; -----; Session information updated at 2024-05-22 17:19. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3074:5232,update,updated,5232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074,1,['update'],['updated']
Deployability," = 0.01; cvFilter = 2; nr_pcs = 50. ddata = adata.to_dict(); X = ddata['X']; # row normalize ; X = row_norm(X, max_fraction=0.05, mult_with_mean=True); # filter out genes with mean expression < 0.1 and coefficient of variance < ; # cvFilter ; X, gene_filter = filter_genes_cv(X, meanFilter, cvFilter); # compute zscore of filtered matrix ; Xz = zscore(X); # PCA ; Xpca = pca(Xz, nr_comps=nr_pcs); # update dictionary ; ddata['X'] = X; ddata['Xpca'] = Xpca; ddata['var_names'] = ddata['var_names'][gene_filter]; sett.m(0, 'Xpca has shape',; ddata['Xpca'].shape[0], 'x', ddata['Xpca'].shape[1]); from ..ann_data import AnnData; adata = AnnData(ddata); print(adata.X); ```; While the previous snippet works just as expected, when I want to do the same without a ddata object, some uncontrolled behavior comes up. Indexing doesn't work as expected anymore. @flying-sheep: could you have a look at why `adata['Xpca'] = Xpca` in the following throws an; ```py; >>> adata['Xpca'] = Xpca; IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices; ```; in the following snippet; ```py; X = adata.X; # row normalize ; X = row_norm(X, max_fraction=0.05, mult_with_mean=True); # filter out genes with mean expression < 0.1 and coefficient of variance < ; # cvFilter ; X, gene_filter = filter_genes_cv(X, meanFilter, cvFilter); # compute zscore of filtered matrix ; Xz = zscore(X); # PCA ; Xpca = pca(Xz, nr_comps=nr_pcs); # update adata ; adata.X = X; adata = adata.var_names[gene_filter] # filter genes ; adata['Xpca'] = Xpca; sett.m(0, 'Xpca has shape',; adata['Xpca'].shape[0], 'x', adata['Xpca'].shape[1]); print(adata.X); ```; I played around quite some bit, but the only solution that I got running then had the numerically incorrect result. It's quite to hard to keep this sequence of steps nicely organized. PS: the snippet appears in `scanpy/preprocess/advanced.py` and an example would be `./scanpy.py nestorowa16 diffmap -r pp`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/4:1594,update,update,1594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4,1,['update'],['update']
Deployability," E501 line too long (93 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:656:80: E501 line too long (80 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:693:80: E501 line too long (80 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:713:80: E501 line too long (88 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:735:80: E501 line too long (82 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:737:80: E501 line too long (83 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:742:80: E501 line too long (80 > 79 characters). ```. `git status` and `git diff` show the automatic changes pre-commit makes:. ```; jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git status; On branch pearson_residuals_1.7; Changes to be committed:; (use ""git reset HEAD <file>..."" to unstage). 	modified: _highly_variable_genes.py. Changes not staged for commit:; (use ""git add <file>..."" to update what will be committed); (use ""git checkout -- <file>..."" to discard changes in working directory). 	modified: _highly_variable_genes.py. Untracked files:; (use ""git add <file>..."" to include in what will be committed). 	../../.pre-commit-config.yaml. jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git diff _highly_variable_genes.py ; diff --git a/scanpy/preprocessing/_highly_variable_genes.py b/scanpy/preprocessing/_highly_variable_genes.py; index 03b01940..e2851f50 100644; --- a/scanpy/preprocessing/_highly_variable_genes.py; +++ b/scanpy/preprocessing/_highly_variable_genes.py; @@ -15,7 +15,8 @@ from ._utils import _get_mean_var; from ._distributed import materialize_as_ndarray; from ._simple import filter_genes; ; -#testedit; +# testedit; +; ; def _highly_variable_genes_seurat_v3(; adata: AnnData,; @@ -98,7 +99,9 @@ def _highly_variable_genes_seurat_v3(; else:; clip_val_broad = np.broadcast_to(clip_val, batch_counts.shape); np.putmask(; - batch_counts, batch_counts > clip_val_broad, clip_val_br",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562:8412,update,update,8412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562,1,['update'],['update']
Deployability," Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----; Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]; Linux-4.19.121-linuxkit-x86_64-with-debian-10.8; 2 logical CPU cores; -----; Session information updated at 2021-04-12 15:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1796:6936,update,updated,6936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796,1,['update'],['updated']
Deployability," I have confirmed this bug exists on the main branch of scanpy. ### What happened?. cc: @Intron7 . The array types returned for the various aggregations in `sc.get.aggregate` are different (see example). This can lead to somewhat confusing behavior downstream, especially while we are using the sparse matrix classes. I would suggest we default to a dense result and consider adding an argument `array_type` that determines the type of the arrays added to `layers`. ### Minimal code sample. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(). aggregated = sc.get.aggregate(adata, ""louvain"", [""sum"", ""count_nonzero""]); type(aggregated.layers[""sum""]); # numpy.ndarray. type(aggregated.layers[""count_nonzero""]); # scipy.sparse._csr.csr_matrix; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.5.post1; scanpy 1.10.0.dev315+gf6d5ac94; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.1; dateutil 2.8.2; decorator 5.1.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.11.3; jedi 0.19.1; jinja2 3.1.3; joblib 1.3.2; kiwisolver 1.4.5; legacy_api_wrap NA; leidenalg 0.10.2; llvmlite 0.41.1; markupsafe 2.1.4; matplotlib 3.8.2; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.3; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.9.0; prompt_toolkit 3.0.43; psutil 5.9.8; ptyprocess 0.7.0; pure_eval 0.2.2; pygments 2.17.2; pyparsing 3.1.1; pytz 2023.4; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.0; sparse 0.15.1; stack_data 0.6.3; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.1; toolz 0.12.1; traitlets 5.14.1; wcwidth 0.2.13; yaml 6.0.1; zarr 2.16.1; zipp NA; -----; Python 3.11.7 | packaged by conda-forge | (main, Dec 23 2023, 14:43:09) [GCC 12.3.0]; Linux-5.15.0-87-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-03-04 13:41; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2892:2161,update,updated,2161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2892,1,['update'],['updated']
Deployability," It seems like the case that the data is backed and not in memory - which should be the default when dealing with h5 files - is not considered in the scanpy API. Am I simply missing something here?. ### Minimal code sample. ```python; from urllib.request import urlretrieve; import scanpy as sc. # We are downloading a small dataset here, 43MB. url = ""https://datasets.cellxgene.cziscience.com/7fb8b010-50bd-4238-a466-7c598f16d061.h5ad""; filename = ""testfile.h5ad"". urlretrieve(url, filename). adata = sc.read_h5ad(filename, backed=""r+""). sc.pp.filter_genes(adata, min_cells=100); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""/home/ubuntu/test_scanpy.py"", line 11, in <module>; sc.pp.filter_genes(adata, min_cells=100); File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 237, in filter_genes; filter_genes(; File ""/mnt/storage/anaconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_simple.py"", line 258, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ^^^^^; TypeError: '>' not supported between instances of 'CSRDataset' and 'int'; ```. ### Versions. <details>. ```; Matplotlib is building the font cache; this may take a moment.; -----; anndata 0.10.5.post1; scanpy 1.9.8; -----; PIL 10.2.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; h5py 3.10.0; igraph 0.11.4; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.2; llvmlite 0.42.0; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numpy 1.26.4; packaging 23.2; pandas 2.2.1; psutil 5.9.8; pyparsing 3.1.1; pytz 2024.1; scipy 1.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.4.1.post1; texttable 1.7.0; threadpoolctl 3.3.0; typing_extensions NA; wcwidth 0.2.13; -----; Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]; Linux-5.4.0-165-generic-x86_64-with-glibc2.31; -----; Session information updated at 2024-03-05 10:07; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2894:2908,update,updated,2908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2894,1,['update'],['updated']
Deployability," NA; arrow 1.3.0; asttokens NA; attr 24.2.0; attrs 24.2.0; babel 2.16.0; certifi 2024.08.30; cffi 1.17.1; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.5; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.2; executing 2.1.0; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.8; importlib_resources NA; ipykernel 6.29.5; isoduration NA; jedi 0.19.1; jinja2 3.1.4; joblib 1.4.2; json5 0.9.25; jsonpointer 3.0.0; jsonschema 4.23.0; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.2; jupyterlab_server 2.27.3; kiwisolver 1.4.7; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.43.0; markupsafe 2.1.5; matplotlib 3.9.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; nt NA; numba 0.60.0; numpy 1.26.4; overrides NA; packaging 24.1; pandas 2.2.2; parso 0.8.4; platformdirs 4.3.2; pooch v1.8.2; prometheus_client NA; prompt_toolkit 3.0.47; psutil 6.0.0; pure_eval 0.2.3; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.18.0; pyparsing 3.1.4; pythoncom NA; pythonjsonlogger NA; pytz 2024.2; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; referencing NA; requests 2.32.3; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.1; send2trash NA; session_info 1.0.0; six 1.16.0; skimage 0.24.0; sklearn 1.5.2; sniffio 1.3.1; stack_data 0.6.3; threadpoolctl 3.5.0; tornado 6.4.1; tqdm 4.66.5; traitlets 5.14.3; typing_extensions NA; uri_template NA; urllib3 2.2.3; wcwidth 0.2.13; webcolors 24.8.0; websocket 1.8.0; win32api NA; win32com NA; win32con NA; win32trace NA; winerror NA; yaml 6.0.2; zipp NA; zmq 26.2.0; zoneinfo NA; -----; IPython 8.18.1; jupyter_client 8.6.2; jupyter_core 5.7.2; jupyterlab 4.2.5; notebook 7.2.2; -----; Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.22621-SP0; -----; Session information updated at 2024-09-12 21:33; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228#issuecomment-2348022832:2131,update,updated,2131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228#issuecomment-2348022832,1,['update'],['updated']
Deployability," See below. ```python; import scanpy as sc; x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'); x.var_names_make_unique(); print(x); sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); ```. ```pytb; AnnData object with n_obs × n_vars = 600 × 32838; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'; var: 'features'; Traceback (most recent call last):; File ""./main.py"", line 8, in <module>; sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3; model.fit(); File ""_loess.pyx"", line 899, in _loess.loess.fit; ValueError: b'reciprocal condition number 3.9554e-16\n'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.18.1; packaging 20.8; pandas 1.0.1; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-03 11:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1825:2247,update,updated,2247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825,1,['update'],['updated']
Deployability," [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:763) # error: Incompatible types in assignment (expression has type; [764](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:764) # ""GzipFile"", variable has type ""Union[str, BaseBuffer]""); --> [765](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:765) handle = gzip.GzipFile( # type: ignore[assignment]; [766](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:766) filename=handle,; [767](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:767) mode=ioargs.mode,; [768](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:768) **compression_args,; [769](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:769) ); [770](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:770) else:; [771](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:771) handle = gzip.GzipFile(; [772](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:17279,Pipeline,PipelineDevelope,17279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2062,pipeline,pipeline,2062,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183,1,['pipeline'],['pipeline']
Deployability," _getitem_view(self, index):. /usr/local/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index); 1296 def _getitem_view(self, index):; 1297 oidx, vidx = self._normalize_indices(index); -> 1298 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1299 ; 1300 # this is used in the setter for uns, if a view. /usr/local/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 674 if not isinstance(X, AnnData):; 675 raise ValueError('`X` has to be an AnnData object.'); --> 676 self._init_as_view(X, oidx, vidx); 677 else:; 678 self._init_as_actual(. /usr/local/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx); 705 self._varm = ArrayView(adata_ref.varm[vidx_normalized], view_args=(self, 'varm')); 706 # hackish solution here, no copy should be necessary; --> 707 uns_new = deepcopy(self._adata_ref._uns); 708 # need to do the slicing before setting the updated self._n_obs, self._n_vars; 709 self._n_obs = self._adata_ref.n_obs # use the original n_obs here. /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 178 y = x; 179 else:; --> 180 y = _reconstruct(x, memo, *rv); 181 ; 182 # If is its own copy, don't memoize. /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy); 278 if state is not None:; 279 if deep:; --> 280 state = deepcopy(state, memo); 281 if hasattr(y, '__setstate__'):; 282 y.__setstate__(state). /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 148 copier = _deepcopy_dispatch.get(cls); 149 if copier:; --> 150 y = copier(x, memo); 151 else:; 152 try:. /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/copy.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263:4021,update,updated,4021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263,1,['update'],['updated']
Deployability," `from skmisc.loess import loess`; ```python; from skmisc.loess import loess; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4400,install,install,4400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['install'],['install']
Deployability," `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this?. I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here?. --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good to document the escape hatches for this (`# fmt: off` for `black`). That said, we already do require that merged code goes through black before it gets merged, and a benefit of using this would be to not have commit messages like ""formatting"", ""remove unused import"", etc. The pre-commit checks would be a part of CI as well, so it would be *eventually* mandatory – just not on your machine. Does this address your concerns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635:1707,install,install,1707,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635,1,['install'],['install']
Deployability," a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:1209,update,updates,1209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['update'],['updates']
Deployability," attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python; error: subprocess-exited-with-error; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [32 lines of output]; + meson setup /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e /private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/76/3kg7fkgs3_d2gnkhxh5npt280000gn/T/pip-install-jl3ciqs5/scikit-misc_c6914ced8cef4877a07998e75e28ca3e/.mesonpy-ykxq6c1e/meson-python-native-file.ini; Preparing metadata (pyproject.toml) did not run successfully.; ```. ### Error output. _No response_. ### Versions. <details>. ```; # Name Version Build Channel; absl-py 2.1.0 pyhd8ed1ab_0 conda-forge; anndata 0.10.8 pypi_0 pypi; anyio 4.2.0 py39hca03da5_0 ; appnope 0.1.2 py39hca03da5_1001 ; argon2-cffi 21.3.0 pyhd3eb1b0_0 ; argon2-cffi-bindings 21.2.0 py39h1a28f6b_0 ; arpack 3.9.1 nompi_h593882a_101 conda-forge; array-api-compat 1.7.1 pyhd8ed1ab_0 conda-forge; asttokens 2.0.5 pyhd3eb1b0_0 ; async-lru 2.0.4 py39hca03da5_0 ; attrs 23.1.0 py39hca03da5_0 ; babel 2.11.0 py39hca03da5_0 ; ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:5386,install,install-,5386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['install'],['install-']
Deployability," beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.6.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.9.1; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; websocket 1.6.0; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.2.0; jupyter_core 5.3.1; jupyterlab 4.0.2; notebook 6.5.4; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-12.6.6-x86_64-i386-64bit; -----; Session information updated at 2023-06-23 18:00. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531:4067,update,updated,4067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531,1,['update'],['updated']
Deployability," brotli NA; celltypist 1.6.2; certifi 2023.11.17; cffi 1.16.0; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2022.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; dill 0.3.7; docrep 0.3.2; entrypoints 0.4; exceptiongroup 1.2.0; executing 0.8.3; fsspec 2023.10.0; h5py 3.7.0; idna 3.4; igraph 0.10.8; inflect NA; ipykernel 6.28.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.3; joblib 1.3.2; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.59.0; numexpr 2.8.7; numpy 1.26.3; omnipath 1.0.8; packaging 23.1; pandas 2.1.4; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prompt_toolkit 3.0.43; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydantic 1.10.12; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.11; pyparsing 3.0.9; pytz 2023.3.post1; requests 2.31.0; ruamel NA; scipy 1.11.4; seaborn 0.12.2; session_info 1.0.0; setuptools 65.6.3; six 1.16.0; sklearn 1.4.1.post1; snappy NA; socks 1.7.1; sparse 0.14.0; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.14.1; tblib 1.7.0; texttable 1.7.0; threadpoolctl 2.2.0; tlz 0.12.2; toolz 0.12.0; torch 1.12.1; tornado 6.1; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; umap 0.5.5; urllib3 1.26.18; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0.1; zipp NA; zmq 25.1.2; zoneinfo NA; zope NA; zstandard 0.19.0; -----; IPython 8.20.0; jupyter_client 7.3.4; jupyter_core 5.5.0; jupyterlab 3.5.3; notebook 6.5.2; -----; Python 3.10.13 (main, Sep 11 2023, 08:16:02) [Clang 14.0.6 ]; macOS-14.1.2-arm64-arm-64bit; -----; Session information updated at 2024-03-12 14:52; ​. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906:2934,update,updated,2934,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906,1,['update'],['updated']
Deployability," compression='gzip')` , and then read it back again from disk, the subsetting doesn't work. It only happens after saving to disk, and it seems to only happen after I've run additional analysis (UMAP, rank_genes_groups, etc.... I don't know exactly which entry is the one breaking the writing/reading). ; This is the error I get:. > Traceback (most recent call last):; > File ""<input>"", line 48, in <module>; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1230, in __getitem__; > return self._getitem_view(index); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 1234, in _getitem_view; > return AnnData(self, oidx=oidx, vidx=vidx, asview=True); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 561, in __init__; > self._init_as_view(X, oidx, vidx); > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 633, in _init_as_view; > self._raw = adata_ref.raw[oidx]; > File ""/Users/andres/miniconda3/envs/finalenv/lib/python3.7/site-packages/anndata/core/anndata.py"", line 344, in __getitem__; > new._varm = self._varm._view(self, vidx); > AttributeError: 'dict' object has no attribute '_view'. Any subsetting (of observations or variables) gives me this error. I tried removing keys from `.uns`, etc. , but nothing seems to work. These are the versions I'm running, all installed with conda:. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.2 scipy==1.3.1 pandas==0.25.2 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. I also tried using different (or no) compression to save and read, but that didn't help either. I don't know if it's related to the recent problems with h5py, but either way I am using h5py=2.9.0 and hdf5=1.10.5. Hopefully someone can help! Let me know if I should post this in the anndata repository instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/884:1678,install,installed,1678,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/884,1,['install'],['installed']
Deployability, did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:14516,pipeline,pipeline,14516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability," error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for outpu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1822,install,install-,1822,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability," exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-2-amd64-x86_64-with-glibc2.32; 4 logical CPU cores. Session information updated at 2021-11-10 22:03",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048:2073,update,updated,2073,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048,1,['update'],['updated']
Deployability," exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I tried to do dpt trajectory analysis but constantly reminded of lacking this and that attributes. When I print out the components in the scanpy directory, it does seem to lack lots of components as shown below:. ```; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. I installed the latest version of scanpy 1.9.3 and python 3.9, my computer is MacBook Pro 2020. ### Minimal code sample. ```python; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'concat', 'datasets', 'experimental', 'external', 'get', 'logging', 'metrics', 'neighbors', 'pl', 'plotting', 'pp', 'preprocessing', 'queries', 'read', 'read_10x_h5', 'read_10x_mtx', 'read_csv', 'read_excel', 'read_h5ad', 'read_hdf', 'read_loom', 'read_mtx', 'read_text', 'read_umi_tools', 'read_visium', 'readwrite', 'set_figure_params', 'settings', 'tl', 'tools', 'write']; ```. ### Error output. ```pytb; >>> print(dir(sc)); ['AnnData', 'Neighbors', 'Verbosity', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_compat', '_metadata', '_settings', '_utils', 'conc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2949:1128,install,installed,1128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2949,1,['install'],['installed']
Deployability," file `.pybiomart.sqlite` even when `use_cache=False` is used. To me this is a problem because the generated hidden file interferes with `Omnipath` and makes it crash. It used to be the case that `use_cache` used to work but not anymore. . Thank you for your time. ### Minimal code sample. ```python; import scanpy as sc. annot = sc.queries.biomart_annotations(; 'hsapiens',; ['ensembl_gene_id', 'external_gene_name'],; use_cache=False; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.8; -----; PIL 10.2.0; asttokens NA; attr 23.1.0; attrs 23.1.0; brotli 1.1.0; cattr NA; cattrs NA; certifi 2023.11.17; cffi 1.16.0; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; executing 2.0.1; future 0.18.3; h5py 3.10.0; idna 3.4; igraph 0.11.2; ipykernel 6.26.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; matplotlib 3.8.3; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.4; packaging 23.2; pandas 2.2.0; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 3.11.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 15.0.0; pybiomart 0.2.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.1.1; pytz 2024.1; requests 2.31.0; requests_cache 1.1.1; scipy 1.11.3; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; socks 1.7.1; stack_data 0.6.2; texttable 1.7.0; threadpoolctl 3.2.0; tornado 6.3.3; traitlets 5.13.0; typing_extensions NA; url_normalize 1.4.3; urllib3 2.0.7; wcwidth 0.2.9; yaml 6.0.1; zmq 25.1.1; zoneinfo NA; -----; IPython 8.17.2; jupyter_client 8.6.0; jupyter_core 5.5.0; -----; Python 3.11.6 | packaged by conda-forge | (main, Oct 3 2023, 10:40:35) [GCC 12.3.0]; Linux-6.5.0-17-generic-x86_64-with-glibc2.35; -----; Session information updated at 2024-02-16 11:40; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861:2314,update,updated,2314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861,1,['update'],['updated']
Deployability," gene in tmp if gene in subset_adata.var_names] == tmp # True; tmp = ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2'] ; [gene for gene in tmp if gene in subset_adata.var_names] == tmp # True; subset_known_markers = {; 'Anterior cardiopharyngeal progenitors_Imaz2024': ['Isl1', 'Tcf21', 'Tlx1'], ; 'Cardiomyocytes FHF 1_Imaz2024': ['Gata4', 'Nkx2-5', 'Nr2f2', 'Osr1', 'Tbx5', 'Wnt2']; }; ; tmp = sc.tl.score_genes(subset_adata, gene_list= subset_known_markers, copy=True ; #,use_raw=True ; #,n_bins = 150 , ctrl_size =100; ) # ctrl_size = 50 by default ; n_bins = 25 by default; ```. ### Error output. ```pytb; WARNING: genes are not in var_names and ignored: ['Anterior cardiopharyngeal progenitors_Imaz2024', 'Cardiomyocytes FHF 1_Imaz2024']; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/project/xyang2/anaconda/py38/lib/python3.8/site-packages/scanpy/tools/_score_genes.py"", line 115, in score_genes; raise ValueError(""No valid genes were passed for scoring.""); ValueError: No valid genes were passed for scoring.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.4.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.3; dask 2023.5.0; dateutil 2.9.0.post0; h5py 3.11.0; igraph 0.11.6; importlib_resources NA; jinja2 3.1.4; joblib 1.4.2; kiwisolver 1.4.7; leidenalg 0.10.2; llvmlite 0.41.1; lz4 4.3.3; markupsafe 2.1.5; matplotlib 3.7.5; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.6; numpy 1.24.4; packaging 24.1; pandas 2.0.3; psutil 6.0.0; pyarrow 17.0.0; pyparsing 3.1.4; pytz 2024.2; scipy 1.10.1; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.5.0; tlz 0.12.3; toolz 0.12.1; typing_extensions NA; yaml 6.0.2; zipp NA; -----; Python 3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:47:35) [GCC 12.3.0]; Linux-4.18.0-305.3.1.el8.x86_64-x86_64-with-glibc2.10; -----; Session information updated at 2024-09-26 13:44; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3266:2946,update,updated,2946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3266,1,['update'],['updated']
Deployability," get_distribution(dist); 464 dist = Requirement.parse(dist); 465 if isinstance(dist, Requirement):; --> 466 dist = get_provider(dist); 467 if not isinstance(dist, Distribution):; 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq); 340 """"""Return an IResourceProvider for the named module or requirement""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169:3936,install,installer,3936,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169,1,['install'],['installer']
Deployability," igraph 0.10.4; importlib_resources NA; ipykernel 6.23.1; ipython_genutils 0.2.0; ipywidgets 8.0.6; jax 0.4.12; jaxlib 0.4.12; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning 2.0.3; lightning_cloud NA; lightning_fabric 2.0.3; lightning_utilities 0.8.0; llvmlite 0.40.0; louvain 0.8.0; matplotlib 3.7.1; matplotlib_inline 0.1.6; ml_collections NA; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; mudata 0.2.3; multidict 6.0.4; multipart 0.0.6; multipledispatch 0.6.0; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; numpyro 0.12.1; nvfuser NA; opt_einsum v3.3.0; optax 0.1.5; ordered_set 4.1.0; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.3; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydantic 1.10.9; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.15.1; pyparsing 3.0.9; pyro 1.8.5; pytorch_lightning 2.0.3; pytz 2023.3; requests 2.31.0; rich NA; scipy 1.10.1; scvi 1.0.0; seaborn 0.12.2; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; soupsieve 2.3.2.post1; sparse 0.14.0; sphinxcontrib NA; stack_data 0.6.2; starlette 0.22.0; statsmodels 0.14.0; sympy 1.12; texttable 1.6.7; threadpoolctl 3.1.0; toml 0.10.2; toolz 0.12.0; torch 2.0.1+cu117; torchmetrics 0.11.4; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; tree 0.1.8; typing_extensions NA; urllib3 2.0.3; uvicorn 0.22.0; wcwidth 0.2.6; websocket 1.5.3; websockets 11.0.3; wrapt 1.15.0; xarray 2023.5.0; yaml 6.0; yarl 1.9.2; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.2.0; jupyter_core 5.3.1; notebook 6.5.4; -----; Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:17) [GCC 12.2.0]; Linux-4.18.0-425.19.2.el8_7.x86_64-x86_64-with-glibc2.27; -----; Session information updated at 2023-07-06 03:56; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2547:7481,update,updated,7481,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547,1,['update'],['updated']
Deployability," implement if python had generic functions. This is kinda something that's being worked on for numpy, but the assumptions a ufunc has about it's input data does not match with what an AnnData object is. I've worked on a side project of just wrapping the sklearn transformers so you can pass anndata objects, and could try and get that cleaned up for use if it'd be valuable. --------------------------------. I'm not really sure what you expect this line to do though:. ```python; adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]; ```. I would probably throw an error for that, since the var names wouldn't be the same. It's also not obvious to me which arrays would be subtracted (all of them? some of them?). If this is meant to do:. ```python; adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X; ```. I don't think that's so much more work. > I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease?. If it should return the whole object, but not update the original, then all of the values from the original need to be copied to prevent unintentional modification. This is really expensive for large objects, which single cell datasets often are. For your example of `adata = np.sqrt(adata)` vs `adata_sq = np.sqrt(adata)`, there's no way for us to tell which of those statements was made while evaluating `np.sqrt`. That would require the ability to overload assignment, and for python to have different evaluation rules. ### 2. Requirement to use .var_vector or .obs_vector for single columns. Is what you're saying that you want: `adata[:, adata.var_names[0]].X` to be one dimensional?. This used to be the behaviour, but it got confusing quickly. Suddenly, `adata.X` could be a different shape from `adata`. I would recommend reading the issues that were opened about this on `anndata` for more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:1117,update,update,1117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,1,['update'],['update']
Deployability," in compile(self, args, return_type); 76 ; 77 def compile(self, args, return_type):; ---> 78 status, retval = self._compile_cached(args, return_type); 79 if status:; 80 return retval. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 108 args=args, return_type=return_type,; 109 flags=flags, locals=self.locals,; --> 110 pipeline_class=self.pipeline_class); 111 # Check typing error if object mode is used; 112 if cres.typing_error is not None and not flags.enable_pyobject:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 601 pipeline = pipeline_class(typingctx, targetctx, library,; 602 args, return_type, flags, locals); --> 603 return pipeline.compile_extra(func); 604 ; 605 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 337 self.state.lifted = (); 338 self.state.lifted_from = None; --> 339 return self._compile_bytecode(); 340 ; 341 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 399 """"""; 400 assert self.state.func_ir is None; --> 401 return self._compile_core(); 402 ; 403 def _compile_ir(self):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 379 self.state.status.fail_reason = e; 380 if is_final_pipeline:; --> 381 raise e; 382 else:; 383 raise CompilerError(""All available pipelines exhausted""). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\numba\core\compiler.py in _compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341:8420,pipeline,pipeline,8420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341,2,['pipeline'],['pipeline']
Deployability," it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```; $ conda create -yn flit-deps python=3.8 flit; $ conda activate flit-deps; $ flit install -s --dep=develop # Make development install of scanpy; $ pip install scvelo # Install project that depends on scanty; ...; Attempting uninstall: scanpy; Found existing installation: scanpy 1.8.0.dev49-ge715cd98; Uninstalling scanpy-1.8.0.dev49-ge715cd98:; Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98; ...; # Development version of scanpy has now been uninstalled; ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852:1318,install,install,1318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852,8,"['Install', 'install']","['Install', 'install', 'installation', 'installations']"
Deployability," methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will mainly be relevant when you have biased distributions of sequencing depth between two samp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1438,integrat,integration,1438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['integrat'],['integration']
Deployability," metric, metric_kwds, verbose); 984 initial_alpha,; 985 negative_sample_rate,; --> 986 verbose=verbose,; 987 ); 988 . /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. /opt/conda/lib/python3.7/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. /opt/conda/lib/python3.7/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 . TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7fb3c827f840>)); [2] During: typing of call at /opt/conda/lib/python3.7/site-packages/umap/umap_.py (776). File ""../../../opt/conda/lib/python3.7/site-packages/umap/umap_.py"", line 776:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/dev/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/dev/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please repor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666:2086,pipeline,pipeline,2086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666,1,['pipeline'],['pipeline']
Deployability," min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 653 sig = signature(_highly_variable_genes_seurat_v3); 654 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 655 return _highly_variable_genes_seurat_v3(; 656 adata,; 657 flavor=flavor,; 658 layer=layer,; 659 n_top_genes=n_top_genes,; 660 batch_key=batch_key,; 661 check_values=check_values,; 662 span=span,; 663 subset=subset,; 664 inplace=inplace,; 665 ); 667 cutoff = _Cutoffs.validate(; 668 n_top_genes=n_top_genes,; 669 min_disp=min_disp,; (...); 672 max_mean=max_mean,; 673 ); 674 del min_disp, max_disp, min_mean, max_mean, n_top_genes. File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:68, in _highly_variable_genes_seurat_v3(adata, flavor, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 66 from skmisc.loess import loess; 67 except ImportError:; ---> 68 raise ImportError(; 69 ""Please install skmisc package via `pip install --user scikit-misc""; 70 ); 71 df = pd.DataFrame(index=adata.var_names); 72 data = _get_obs_rep(adata, layer=layer). ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. error when attempting install w/ conda; ```python. (scanpy_env) user@Mac ~ % conda install conda-forge::scikit-misc; Channels:; - defaults; - conda-forge; Platform: osx-arm64; Collecting package metadata (repodata.json): done; Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - conda-forge::scikit-misc. Current channels:. - defaults; - https://conda.anaconda.org/conda-forge. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org; ```. Im having trouble reproducing the pip3 install scikit-misc error, which i believe is due to me switching between versions of numpy, heres what I had previously copy pasted. ```python;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:4168,install,install,4168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,2,['install'],['install']
Deployability," mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 399 e.patch_message(msg); 400 ; --> 401 error_rewrite(e, 'typing'); 402 except errors.UnsupportedError as e:; 403 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 342 raise e; 343 else:; --> 344 reraise(type(e), e, None); 345 ; 346 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 666 value = tp(); 667 if value.__traceback__ is not tb:; --> 668 raise value.with_traceback(tb); 669 raise value; 670 . TypingError: Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); Invalid use of Function(<intrinsic wrap_index>) with argument(s) of type(s): (int32, int64); * parameterized; In definition 0:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; In definition 1:; ValueError: Argument types for wrap_index must match; raised from /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/array_analysis.py:72; This error is usually caused by passing an argument of a type that is unsupported by the named function.; [1] During: resolving callee type: Function(<intrinsic wrap_index>); [2] During: typing of call at /home/gzhang/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py (399). File ""../../../../../packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py"", line 399:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; start, end = indptr[i], indptr[i + 1]; sums[i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978:2414,pipeline,pipeline,2414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978,2,['pipeline'],['pipeline']
Deployability," natsort 7.1.1; nbclient 0.6.4; nbconvert 6.5.0; nbformat 5.4.0; nest-asyncio 1.5.5; networkx 2.5; notebook 6.4.11; numba 0.52.0; numexpr 2.7.3; numpy 1.19.5; numpy-groupies 0.9.17; numpyro 0.9.2; oauthlib 3.2.0; openpyxl 3.0.10; opt-einsum 3.3.0; optax 0.1.2; packaging 20.9; pandas 1.2.0; pandocfilters 1.5.0; parso 0.8.2; pathos 0.2.7; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.1.1; pip 21.1.1; pox 0.2.9; ppft 1.6.6.3; prometheus-client 0.14.1; prompt-toolkit 3.0.18; protobuf 3.19.0; protobuf3-to-dict 0.1.5; ptyprocess 0.7.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycosat 0.6.3; pycparser 2.20; pyDeprecate 0.3.1; Pygments 2.9.0; pyOpenSSL 20.0.1; pyparsing 2.4.7; pyro-api 0.1.2; pyro-ppl 1.8.1; pyrsistent 0.18.1; PySocks 1.7.1; python-dateutil 2.8.1; python-igraph 0.9.1; pytorch-lightning 1.5.10; pytz 2021.1; PyWavelets 1.3.0; PyYAML 6.0; pyzmq 22.0.3; requests 2.25.1; requests-oauthlib 1.3.1; rich 12.4.4; rpy2 3.4.2; rsa 4.8; ruamel-yaml-conda 0.15.80; ruamel.yaml 0.17.21; ruamel.yaml.clib 0.2.6; s3transfer 0.4.2; sagemaker 2.39.0.post0; scanpy 1.6.1; scikit-image 0.19.2; scikit-learn 0.24.2; scikit-misc 0.1.4; scipy 1.6.0; scrublet 0.2.3; scvi-tools 0.16.2; seaborn 0.11.1; Send2Trash 1.8.0; setuptools 59.5.0; setuptools-scm 6.0.1; sinfo 0.3.1; six 1.15.0; smdebug-rulesconfig 1.0.1; soupsieve 2.3.2.post1; spectra 0.0.11; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; tensorboard 2.9.0; tensorboard-data-server 0.6.1; tensorboard-plugin-wit 1.8.1; terminado 0.15.0; texttable 1.6.3; threadpoolctl 2.1.0; tifffile 2021.11.2; tinycss2 1.1.1; toolz 0.11.2; torch 1.11.0; torchmetrics 0.9.0; tornado 6.1; tqdm 4.60.0; traitlets 5.2.2.post1; typing-extensions 4.2.0; tzlocal 2.1; umap-learn 0.4.6; urllib3 1.26.4; wcwidth 0.2.5; webencodings 0.5.1; Werkzeug 2.1.2; wheel 0.36.2; widgetsnbextension 3.6.0; yarl 1.7.2; zipp 3.4.1; Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:5580,update,updated,5580,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['update'],['updated']
Deployability," no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement for `.raw` as a version of the data that is used for DE analysis but not `.X`. This distinction is quite useful as it is becoming more frequent that you have 1 version of the data for further embedding-based analysis, and one for moecular analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:1473,pipeline,pipeline,1473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,['pipeline'],['pipeline']
Deployability," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124:2001,update,updated,2001,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124,1,['update'],['updated']
Deployability," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:2179,patch,patching,2179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,1,['patch'],['patching']
Deployability," pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20220,pipeline,pipeline,20220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['pipeline'],['pipeline']
Deployability," remeber thinking about this as a possibility. IIRC I decided against this because I just as frequently wanted some other column, like `""gene_symbols""` as the index. I could see adding this as an option via a keyword argument now. But maybe you just want to use `sc.get.obs_df`?. ### 4. Clusters as categories creates confusing scatterplots. Well, there is no order to the categories, so I guess I see why `matplotlib` wouldn't plot those in sorted order, but agree it's a little counter intuitive. Seems like more of a matplotlib issue to me though. ### 5. Cannot pass clusters to c parameter in plt.scatter. Use one of these?. ```python; sc.pl.scatter(pbmc, x=pbmc.var_names[0], y=pbmc.var_names[1], color=""leiden"") . import seaborn as sns; sns.scatterplot(pbmc.X[:, 0], pbmc.X[:, 0], hue=pbmc.obs[""leiden""]); ```. Categorical values for scatter plots are a known issue for matplotlib, as I linked to above. Their current behaviour if you pass a numeric valued categorical (regardless of whether it's ordered) is to use a continuous color palette, which in my opinion is easily misleading. ### 6. Clusters as categories frustrate subclustering. We've used a different convention for subclustering, which is actually the reason we use strings. We're assuming you're breaking a cluster or set of clusters into smaller ones, so the new id is appended to the old one. I believe there's a tutorial with this somewhere. Do you know where this was @LuckyMD?. Basically, I'd say do something more like:. ```python; from collections.abc import Iterable; import numpy as np; import pandas as pd; from sklearn import cluster. def kmeans_subcluster(adata, orig_key, orig_clusters, key_added):; if isinstance(orig_clusters, str) or not isinstance(orig_clusters, Iterable):; orig_clusters = [orig_clusters]. subset = adata[adata.obs[orig_key].isin(orig_clusters)]; sub_clustering = cluster.KMeans(n_clusters=2).fit_predict(subset.X). # Make new clustering; ; new_clustering = adata.obs[orig_key].copy(); # Make n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:3448,continuous,continuous,3448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,1,['continuous'],['continuous']
Deployability," remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.4; pytz 2021.3; scanpy 1.7.2; scipy 1.7.3; setuptools_scm NA; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; spyder 5.1.5; spyder_kernels 2.1.3; spydercustomize NA; storemagic NA; tables 3.6.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.31.1; jupyter_client 6.1.12; jupyter_core 4.9.1; -----; Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]; Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-03-09 15:40. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172:3667,update,updated,3667,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172,1,['update'],['updated']
Deployability," return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.6.1; setuptools_scm NA; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zarr 2.14.2; zipp NA; -----; Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-04-01 09:45; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2459:6856,update,updated,6856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459,1,['update'],['updated']
Deployability," same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.36; psutil 5.9.3; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.7; scanorama 1.7.1; scipy 1.7.3; seaborn 0.12.1; session_info 1.0.0; setuptools 65.6.3; six 1.16.0; sklearn 1.0.2; sortedcontainers 2.4.0; statsmodels 0.13.5; storemagic NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; traitlets 5.8.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zarr 2.12.0; zipp NA; zmq 24.0.1; -----; IPython 7.33.0; jupyter_client 7.4.8; jupyter_core 4.11.1; jupyterlab 3.5.2; notebook 6.5.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]; Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid; -----; Session information updated at 2022-12-28 21:40; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2391:4974,update,updated,4974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391,1,['update'],['updated']
Deployability," scanpy.egg-info/top_level.txt; warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'scanpy.egg-info/SOURCES.txt'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>; 'Topic :: Scientific/Engineering :: Visualization',; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup; dist.run_commands(); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands; self.run_command(cmd); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run; File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run; self.run_command('build'); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run; self.run_command(cmd_name); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command; self.distribution.run_command(command); File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command; cmd_obj.run(); File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/148:5709,install,install,5709,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148,1,['install'],['install']
Deployability," such a method in its. ValueError: provided out is the wrong size for the reduction; ```. #### Versions. <details>. ```; -----; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fcsparser 0.2.1; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; markupsafe 1.1.1; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; palantir 1.0.0; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; rpy2 3.4.2; sca NA; scanpy 1.7.0; scipy 1.4.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-19 11:23; ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670:4631,update,updated,4631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670,1,['update'],['updated']
Deployability," suppress()); 2229 with ctx:; -> 2230 self.figure.draw(renderer); 2232 if bbox_inches:; 2233 if bbox_inches == ""tight"":. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:74, in _finalize_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 72 @wraps(draw); 73 def draw_wrapper(artist, renderer, *args, **kwargs):; ---> 74 result = draw(artist, renderer, *args, **kwargs); 75 if renderer._rasterizing:; 76 renderer.stop_rasterizing(). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/figure.py:2790, in Figure.draw(self, renderer); 2787 # ValueError can occur when resizing a window.; 2789 self.patch.draw(renderer); -> 2790 mimage._draw_list_compositing_images(; 2791 renderer, self, artists, self.suppressComposite); 2793 for sfig in self.subfigs:; 2794 sfig.draw(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/image.py:132, in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2285:7096,patch,patch,7096,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285,1,['patch'],['patch']
Deployability," the early exaggeration factor or the learning rate might be too high. **learning_rate** : `float`, optional (default: 1000). Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes. **random_state** : `int` or `None`, optional (default: 0). Change this to use different intial states for the optimization. If `None`,; the initial state is not reproducible. **use_fast_tsne** : `bool`, optional (default: `True`). Use the MulticoreTSNE package by D. Ulyanov if it is installed. **n_jobs** : `int` or `None` (default: `sc.settings.n_jobs`). Number of jobs. **copy** : `bool` (default: `False`). Return a copy instead of writing to adata. :Returns:. Depending on `copy`, returns or updates `adata` with the following fields. . **X_tsne** : `np.ndarray` (`adata.obs`, dtype `float`); ```. Now let's look at `pp.neighbors` where you're reading the type annotations from the signature.; - Obviously, the signature itself now is a mess for humans to read. But ok, that's fine if the docstring is easy to read.; - There is an error ` <class 'inspect._empty'>`; - The rest looks good to me, except for the superficial stylistic remarks above.; ```; Signature: sc.pp.neighbors(adata:anndata.base.AnnData, n_neighbors:int=15, n_pcs:Union[int, NoneType]=None, use_rep:Union[str, NoneType]=None, knn:bool=True, random_state:Union[int, mtrand.RandomState, NoneType]=0, method:str='umap', metric:Union[str, Callable[[numpy.ndarray, numpy.ndarray], float]]='euclidean', metric_kwds:Mapping[str, Any]={}, copy:bool=False) -> Union[anndata.base.AnnData, NoneType]; Docstring:; Compute a neighborhood graph of observations [McInnes18]_. The neighbor search efficiency of this heavily relies on UMAP [McI",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:3585,update,updates,3585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,1,['update'],['updates']
Deployability," the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4538,install,install-,4538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability," this can quickly get out of bounds, I'd thus suggest to; ; - constrain this discussion to `matplotlib`/`seaborn` (as this is what scanpy and afaik most of the ecosystem projects are using); - only focus on the low-level use-cases. . In brief all that is required to implement a plotting API that behaves like scanpy's. . ---. > I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on seaborn plotting classes more heavily here, potentially contributing features upstream. Here's one example mwaskom/seaborn#2487 of a feature which could fit the AnnData data model nicely. I was mostly referring to @fidelram's idea how to make plot styling more ""modular"" instead of having a vast amount of arguments for a single plotting function (#956). If this idea was to be implemented for all scanpy plotting functions, I thought that maybe an abstract base-class could provide the method signatures to ensure consistency within scanpy and ecosystem packages. Even with the current ""keyword approach"" it would be great if there was some way to ensure that common keywords are always named consistently. . What would be an example of a plot object you would like to ""move"" to seaborn? Something like a multi-panel UMAP plot? . ---. > I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is _set_color_for_categorical_obs, which I'd also like to make accessible through sc.get. Adding groupby support to anndata would help a lot here too (theislab/anndata#556). that sounds great! . ---. Finally, in terms of ""reusable building blocks"" I was thinking of, for instance, . - the ""dot size legend"" ; ![image](https://user-images.githubusercontent.com/7051479/118252952-a378ae80-b4a9-11eb-8a11-72bf46cdae20.png). - Setting up axes for a scatter plot together with the appropriate legend (continuous color bar or categorical legend)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143:2011,continuous,continuous,2011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143,1,['continuous'],['continuous']
Deployability," to start a flame war. Scanpy is an excellent piece of software, and I greatly appreciate at the work that goes into it. Responding to @LuckyMD, I again would just point out that returning cluster labels as ints is the standard for sklearn, and I would urge that scanpy serve as an access point to single cell analysis both for biologists and also for data science / machine learning researchers. Biologists will likely stick to using scanpy's plotting functions where you can handle default color maps for things that appear to be labels. We do this kind of checking in scprep: https://github.com/KrishnaswamyLab/scprep/blob/09de1bf41c4b42d331b29a4493c436110b641e07/scprep/plot/scatter.py#L206-L253. However, for machine learning researchers who likely have their own preferred plotting tools in matplotib or seaborn, might be trying to use the results from clustering in scanpy to compare to results from `sklearn.cluster`, or otherwise want to fit scanpy into their analysis pipelines, turning arrays of numerics into arrays of strings causes headaches that make the tools less accessible. The argument about the default colormap in matplotlib is continuous seems less important than making scanpy compatible with the larger ecosystem of data science tools in Python. Finally, I will note that in Python, strings are also defined ordinally, even if you might not think of them that way. Although in some respects the question, ""Is `'1'` less than `'a'`?"" is nonsensical, this is a well defined test in Python. ```python; In [1]: '1' < 'a'; Out[1]: True; ```. Again, I want to emphasize that I really love what has been done with scanpy / anndata so far. We use it in various places in our single cell workshop (https://krishnaswamylab.org/workshop), and I rely on the implementations of louvain / paga / dpt for my research. I bring up these issues here because I think changing some of these conventions could result in greater widespread adoption that I would love to see for scanpy and anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545:2108,pipeline,pipelines,2108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545,2,"['continuous', 'pipeline']","['continuous', 'pipelines']"
Deployability," try:; --> 717 yield; 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block); 287 loc=self.loc, errcls_=defaulterrcls):; --> 288 self.lower_inst(inst); 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst); 475 if isinstance(inst, _class):; --> 476 func(self, inst); 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor); 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},; --> 241 bool(alias_map), index_var_typ, parfor.races); 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races); 1168 flags,; -> 1169 locals); 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class); 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,; --> 615 lifted_from=lifted_from); 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from); 340 FixupArgs().run_pass(self.state); --> 341 return self._compile_ir(); 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self); 399 assert self.state.func_ir is not None; --> 400 return self._compile_core(); 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 372 if is_final_pipeline:; --> 373 raise e; 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self); 363 try:; --> 364 pm.run(self.state); 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state); 346 patched_exception = self._patch_error(msg, e); --> 347 raise patched_exception; 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147:2353,pipeline,pipeline,2353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147,1,['pipeline'],['pipeline']
Deployability," ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.2.0; tornado 6.3.2; traitlets 5.9.0; wcwidth 0.2.6; zmq 25.1.0; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.5-arm64-i386-64bit; -----; Session information updated at 2023-07-26 10:47; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:3519,update,updated,3519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['update'],['updated']
Deployability," ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981:3613,install,install,3613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981,1,['install'],['install']
Deployability,![image](https://github.com/scverse/scanpy/assets/21954664/1fd9d15a-7c2c-4d13-bfc6-6382e6f9f803). - [x] Release notes not necessary because: Skipping release notes because no one cares about this,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2972:104,Release,Release,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972,2,"['Release', 'release']","['Release', 'release']"
Deployability,""", ""louvain""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); louvain_colors = dict(; zip(; adata.obs[""louvain""].cat.categories, ; adata.uns[""louvain_colors""]; ); ); pts = (; ds.Canvas(1000, 1000); .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")); ). # Make images; pts_ncats = (pts != 0).sum(axis=2); overlap_idx = pts_ncats == 1; zebra_source = xr.DataArray(; diagonal_bands_like(overlap_idx, 13),; coords=overlap_idx.coords; ). color_by_cluster = tf.shade(pts, color_key=louvain_colors); tf.Images(; color_by_cluster,; tf.stack(; tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; tf.stack(; color_by_cluster,; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; ); ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. ; A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953:2817,Update,Update,2817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953,1,['Update'],['Update']
Deployability,""", False),; [1886](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1886) is_text=is_text,; [1887](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\common.py:765, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options); [761](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:761) if compression == ""gzip"":; [762](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/common.py:762) if isinstance(handle, str):; [763](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRN",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:15373,Pipeline,PipelineDevelope,15373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"""PackageNotFoundError: umap-learn"" with importlib_metadata version 0.6. Update requirements to importlib_metadata>=0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739:72,Update,Update,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739,1,['Update'],['Update']
Deployability,"# Make a dummy label column; data.obs['rand'] = np.random.randint(0, 5, data.obs.shape).astype(str). sc.pl.pca(; data,; color='rand',; legend_loc='upper right', #or any other default in matplotlib ; ); ```. You will see that the plot does not have any visible legend at all. This is consistent with other legend locations that are not 'on data' or 'None'; <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.0.1; appnope 0.1.2; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; fontTools 4.33.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jsonschema 4.5.1; kaleido 0.2.1; kiwisolver 1.3.2; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbformat 5.4.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.20.3; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.8.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pynndescent 0.5.7; pyparsing 3.0.9; pyrsistent NA; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; tenacity NA; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.64.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.2.2; jupyter_core 4.9.2; notebook 6.4.11; -----; Python 3.9.12 (main, Apr 5 2022, 01:53:17) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-05-30 13:19. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2267:2335,update,updated,2335,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2267,1,['update'],['updated']
Deployability,"## Changes / Fixes. * Change / fix `pip install scanpy[test]` to `pip install ""scanpy[test]""`. ## Related issues. Closes #1442.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1442:40,install,install,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442,2,['install'],['install']
Deployability,"## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```; git checkout 1.8.0; python -m build --sdist --wheel .; tar tzf dist/scanpy-1.8.0.tar.gz ; ```. <details>; <summary> contents of source dist </summary>. ```; scanpy-1.8.0/README.rst; scanpy-1.8.0/pyproject.toml; scanpy-1.8.0/scanpy/__init__.py; scanpy-1.8.0/scanpy/__main__.py; scanpy-1.8.0/scanpy/_compat.py; scanpy-1.8.0/scanpy/_metadata.py; scanpy-1.8.0/scanpy/_settings.py; scanpy-1.8.0/scanpy/_utils/__init__.py; scanpy-1.8.0/scanpy/_utils/compute/is_constant.py; scanpy-1.8.0/scanpy/cli.py; scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad; scanpy-1.8.0/scanpy/datasets/__init__.py; scanpy-1.8.0/scanpy/datasets/_datasets.py; scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py; scanpy-1.8.0/scanpy/datasets/_utils.py; scanpy-1.8.0/scanpy/datasets/krumsiek11.txt; scanpy-1.8.0/scanpy/datasets/toggleswitch.txt; scanpy-1.8.0/scanpy/external/__init__.py; scanpy-1.8.0/scanpy/external/exporting.py; scanpy-1.8.0/scanpy/external/pl.py; scanpy-1.8.0/scanpy/external/pp/__init__.py; scanpy-1.8.0/scanpy/external/pp/_bbknn.py; scanpy-1.8.0/scanpy/external/pp/_dca.py; scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py; scanpy-1.8.0/scanpy/external/pp/_hashsolo.py; scanpy-1.8.0/scanpy/external/pp/_magic.py; scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py; scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py; scanpy-1.8.0/scanpy/external/pp/_scrublet.py; scanpy-1.8.0/scanpy/external/tl/__init__.py; scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py; scanpy-1.8.0/scanpy/external/tl/_palantir.py; scanpy-1.8.0/scanpy/external/tl/_phate.py; scanpy-1.8.0/scanpy/external/tl/_phenograph.py; scanpy-1.8.0/scanpy/external/tl/_pypairs.py; scanpy-1.8.0/scanpy/external/tl/_sam.py; scanpy-1.8.0/scanpy/external/tl/_trimap.py; scanpy-1.8.0/scanpy/external/tl/_wishbone.py; scanpy-1.8.0/scanpy/get/__init__.py; scanpy-1.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1909:975,toggle,toggleswitch,975,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909,1,['toggle'],['toggleswitch']
Deployability,"## Description. For an easier start of potential contributors, it might be helpful to add a file such as `requirements-dev.txt` including all packages required to e.g. run unit tests locally. Otherwise, several packages (e.g. `leidenalg`, `louvain`, `scikit-misc`, `harmonypy`, `python-igraph`) have to be installed manually which is rather tedious:. ```txt; -r requirements.txt. harmonypy; leidenalg; louvain; scitkit-misc; python-igraph; ```. The wheels to install `python-igraph` under Windows can, for example, be found [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419:306,install,installed,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419,2,['install'],"['install', 'installed']"
Deployability,"## Description. In the docs for `scanpy.read_10x_mtx`, the mentioned file extensions and files are all uncompressed, _e.g._, `matrix.mtx`. However, when specifying a path which does not include the required file the `FileNotFoundError` calls it `matrix.mtx.gz`. For consistency, I think it'd be good to use either the compressed or uncompressed format in both cases, _i.e._, either update the docs or the `FileNotFoundError`. Otherwise, users might think they might have to compress the file (if there is a small typo in the provided path, for example).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2128:382,update,update,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128,1,['update'],['update']
Deployability,"## Description. The documentation in `CONTRIBUTING.md` states that all dependencies required for testing can be installed via `pip install scanpy[test]`. It should, however, be `pip install ""scanpy[test]""`. ### Minimal code sample. ```zsh; pip install scanpy[test]; zsh: no matches found: scanpy[test]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1441:112,install,installed,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441,4,['install'],"['install', 'installed']"
Deployability,"## Description. `scanpy==1.6` cannot be used with `anndata<=0.7.3` due to an import error in `scanpy/__init__.py` as `concat` cannot be imported from `anndata`. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>; from anndata import AnnData, concat; ImportError: cannot import name 'concat' from 'anndata' (/opt/anaconda3/envs/scanpy_bug/lib/python3.8/site-packages/anndata/__init__.py); ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; anndata 0.7.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; joblib 0.15.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.50.0; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.1.2; pkg_resources NA; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.4; yaml 5.3.1; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2020-10-03 14:22; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1439:1415,update,updated,1415,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439,1,['update'],['updated']
Deployability,"## Xarray and anndata. Theoretically, `AnnData` objects are kind of like a special case of `xarray.Dataset`s. While `AnnData` objects have an `obs` and a `var` dimension `xarray.Dataset` can have any number of dimensions. `AnnData` objects are just specializing to the the 2d case. I think it would make a lot of sense to eventually have `anndata` and `scanpy` be based on `xarray`, or something like it. In practice there are a number of difficulties here. The biggest one is support for sparse data, and I'll briefly point out a couple others. ### Sparse arrays. I could probably rant about this for a while, since it's always a problem. Efficient processing of scRNA-seq data needs sparse matrices. The only fully featured sparse array library in python right now is `scipy.sparse`. All of it's sparse arrays only follow the `np.matrix` interface, which is deprecated. This means that they only kind-of work like arrays, and need to be special cased pretty frequently. `xarray` seems to work pretty well with a number of different array types, as long as they act like `np.ndarray`s. They have explicit support for `pydata/sparse`, but that library isn't well supported by the rest of the ecosystem, probably because it doesn't have CSR or CSC matrices yet. This leaves `xarray` with a level of sparse array support that isn't usable for us. ### Pairwise arrays and other weird behaviour. * Having an array where multiple axes have the same name doesn't work well with `xarray`. This is a problem if you're frequently using adjacency matrices like we do.; * `xarray.DataArray`s do not necessarily have the same behaviour as numpy arrays. For example, they have specific behaviour for matrix multiplication. Any transition would be much easier if `DataArrays` could be used as drop-in replacements for numpy arrays (plus some errors for misaligned data). We need to map this out more before we could make any attempt at integrating the libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154:1922,integrat,integrating,1922,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154,1,['integrat'],['integrating']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `83.33333%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 71.83%. Comparing base [(`42e3c2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/42e3c2a04e2bee8431da4e831abd16d198bc8323?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7b6a875`)](https://app.codecov.io/gh/scverse/scanpy/commit/7b6a875a75529e41e4a53993a0e04a4ad04a9d78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 223 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&filepath=scanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL191bWFwLnB5) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2684 +/- ##; ==========================================; - Coverage 71.98% 71.83% -0.16% ; ==========================================; Files 108 108 ; Lines 11920 11921 +1 ; ==========================================; - Hits 8581 8563 -18 ; - Misses 3339 3358 +19 ; ```. | [Files with missing lines](https://a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `54.23729%` with `27 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.12%. Comparing base [(`6542113`)](https://app.codecov.io/gh/scverse/scanpy/commit/6542113d9e7f6a9e1a287aa940ec5564b60a247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1c4740e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2769 +/- ##; ==========================================; - Coverage 75.24% 75.12% -0.13% ; ==========================================; Files 116 116 ; Lines 12802 12847 +45 ; ==========================================; + Hits 9633 9651 +18 ; - Misses 3169 3196 +27 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.i,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 72.47%. Comparing base [(`bc349b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/bc349b999be62196aa51b59db6e2daa37f428322?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a0670c7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a0670c7d3ba4db77d4016365484b79b9a6a2d522?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 143 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2772 +/- ##; ==========================================; + Coverage 72.46% 72.47% +0.01% ; ==========================================; Files 111 111 ; Lines 12418 12430 +12 ; ==========================================; + Hits 8999 9009 +10 ; - Misses 3419 3421 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2772?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.29% <88.88%> (+0.02%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.71053%` with `5 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.47%. Comparing base [(`921fcca`)](https://app.codecov.io/gh/scverse/scanpy/commit/921fccaca86ce86974ad91348498991714452bc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`937c6db`)](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: Current head 937c6db differs from pull request most recent head b3581ea. Consider uploading reports for the commit b3581ea to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2856 +/- ##; ==========================================; + Coverage 75.25% 75.47% +0.22% ; ==========================================; Files 116 116 ; Lines 12788 12896 +108 ; ==========================================; + Hits 9623 9733 +110 ; + Misses 3165 3163 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_distributed.py](https://app.codecov.io/gh/scverse/scanpy/pull/2856?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2Rpc3RyaWJ1dGVkLnB5) | `95.23% <100.00%> (-4.77%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2856?src=pr&el=tr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1946002253:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1946002253,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `12 lines` in your changes are missing coverage. Please review.; > Project coverage is 74.76%. Comparing base [(`14555ba`)](https://app.codecov.io/gh/scverse/scanpy/commit/14555ba48537995acaa381b8b6ad5fc41e612510?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`626d389`)](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2873 +/- ##; ==========================================; - Coverage 74.82% 74.76% -0.07% ; ==========================================; Files 116 117 +1 ; Lines 12809 12893 +84 ; ==========================================; + Hits 9584 9639 +55 ; - Misses 3225 3254 +29 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/plotting/\_stacked\_barplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zdGFja2VkX2JhcnBsb3QucHk=) | `85.54% <85.54%> (ø)` | |. ... and [8 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/287,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2873#issuecomment-1954774755:197,Patch,Patch,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2873#issuecomment-1954774755,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2875?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`4b090c0`)](https://app.codecov.io/gh/scverse/scanpy/commit/4b090c0201bdc5e79c271d988890e3ddabda7c66?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`97e4024`)](https://app.codecov.io/gh/scverse/scanpy/commit/97e402493c3ec9ecfe7bcb94071a4052871583e7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2875 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2875?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2875?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | `87.95% <ø> (ø)` | |; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2875?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957267440:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957267440,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.22%. Comparing base [(`360e350`)](https://app.codecov.io/gh/scverse/scanpy/commit/360e3501460824906b0fef88c36f1d78364e6994?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4bc1c48`)](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2889 +/- ##; ==========================================; - Coverage 74.92% 73.22% -1.71% ; ==========================================; Files 116 116 ; Lines 12802 12765 -37 ; ==========================================; - Hits 9592 9347 -245 ; - Misses 3210 3418 +208 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2889?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `88.40% <100.00%> (ø)` | |; | [scanpy/tools/\_louvain.py](https://app.codecov.io/gh/scverse/scanpy/pull/2889?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `21.42% <0.00%> (ø)` | |. ... and [26 files with indirect coverage changes](https://app.codecov,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2889#issuecomment-1961959634:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2889#issuecomment-1961959634,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.21%. Comparing base [(`1fee6a1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1fee6a1033669db8f0d1e4ade477b861174b5722?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`45796d4`)](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2907 +/- ##; ==========================================; - Coverage 74.82% 73.21% -1.62% ; ==========================================; Files 116 116 ; Lines 12811 12763 -48 ; ==========================================; - Hits 9586 9344 -242 ; - Misses 3225 3419 +194 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2907?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <ø> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2907?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.26% <ø> (-1.54%)` | :arrow_down: |; | [scanpy/\_utils/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2907#issuecomment-1992590092:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2907#issuecomment-1992590092,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.22%. Comparing base [(`545b0a6`)](https://app.codecov.io/gh/scverse/scanpy/commit/545b0a6c167c9968233d16526380256ae5bd06ab?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cc8d153`)](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2919 +/- ##; ==========================================; - Coverage 74.82% 73.22% -1.61% ; ==========================================; Files 116 116 ; Lines 12811 12765 -46 ; ==========================================; - Hits 9586 9347 -239 ; - Misses 3225 3418 +193 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2919?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <ø> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2919?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.26% <ø> (-1.54%)` | :arrow_down: |; | [scanpy/\_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2919#issuecomment-1997461129:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2919#issuecomment-1997461129,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `78.57143%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 74.92%. Comparing base [(`b132f11`)](https://app.codecov.io/gh/scverse/scanpy/commit/b132f115385f1a917f3201dfcbf1f36dfa03235b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2632d44`)](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2923 +/- ##; ==========================================; - Coverage 74.92% 74.92% -0.01% ; ==========================================; Files 116 116 ; Lines 12802 12812 +10 ; ==========================================; + Hits 9592 9599 +7 ; - Misses 3210 3213 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/2923?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX25vcm1hbGl6YXRpb24ucHk=) | `86.95% <78.57%> (-2.07%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003898907:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003898907,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.70492%` with `15 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.51%. Comparing base [(`c68557c`)](https://app.codecov.io/gh/scverse/scanpy/commit/c68557c5ba05484b1c2fc0c0fe9489affecdc318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`35dd438`)](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2942 +/- ##; ==========================================; + Coverage 75.49% 75.51% +0.02% ; ==========================================; Files 116 117 +1 ; Lines 12911 12955 +44 ; ==========================================; + Hits 9747 9783 +36 ; - Misses 3164 3172 +8 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2942?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2942?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campai,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2014865366:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2014865366,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.25%. Comparing base [(`6542113`)](https://app.codecov.io/gh/scverse/scanpy/commit/6542113d9e7f6a9e1a287aa940ec5564b60a247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e5d904e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2943 +/- ##; =======================================; Coverage 75.24% 75.25% ; =======================================; Files 116 116 ; Lines 12802 12788 -14 ; =======================================; - Hits 9633 9623 -10 ; + Misses 3169 3165 -4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2943?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `68.70% <ø> (-0.10%)` | :arrow_down: |; | [scanpy/tools/\_paga.py](https://app.codecov.io/gh/scverse/scanpy/pull/2943?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19wYWdhLnB5) | `33.33% <25.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2943#issuecomment-2015047081:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2943#issuecomment-2015047081,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.25%. Comparing base [(`7c1e4cc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7c1e4cc6c1a076d5eaaee7702d5172425b30d7be?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d9b42b3`)](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2944 +/- ##; =======================================; Coverage 75.24% 75.25% ; =======================================; Files 116 116 ; Lines 12802 12788 -14 ; =======================================; - Hits 9633 9623 -10 ; + Misses 3169 3165 -4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2944?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `68.70% <ø> (-0.10%)` | :arrow_down: |; | [scanpy/tools/\_paga.py](https://app.codecov.io/gh/scverse/scanpy/pull/2944?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19wYWdhLnB5) | `33.33% <25.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2944#issuecomment-2015166004:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2944#issuecomment-2015166004,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.71053%` with `5 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.46%. Comparing base [(`7c1e4cc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7c1e4cc6c1a076d5eaaee7702d5172425b30d7be?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6f32147`)](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2947 +/- ##; ==========================================; + Coverage 75.24% 75.46% +0.22% ; ==========================================; Files 116 116 ; Lines 12802 12910 +108 ; ==========================================; + Hits 9633 9743 +110 ; + Misses 3169 3167 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_distributed.py](https://app.codecov.io/gh/scverse/scanpy/pull/2947?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2Rpc3RyaWJ1dGVkLnB5) | `95.23% <100.00%> (-4.77%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2947?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2947#issuecomment-2015480720:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2947#issuecomment-2015480720,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.14%. Comparing base [(`e6c7251`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6c7251d66eae3983baad37575a6b0bba8fe1318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3633712`)](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2950 +/- ##; ==========================================; - Coverage 75.48% 73.14% -2.35% ; ==========================================; Files 116 116 ; Lines 12904 12872 -32 ; ==========================================; - Hits 9741 9415 -326 ; - Misses 3163 3457 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2950?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <90.00%> (-0.62%)` | :arrow_down: |. ... and [27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2950/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2950#issuecomment-2017705266:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2950#issuecomment-2017705266,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.29%. Comparing base [(`60a0042`)](https://app.codecov.io/gh/scverse/scanpy/commit/60a0042a0d372273d47446aad463332f7664ebe4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9322058`)](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2952 +/- ##; ==========================================; - Coverage 75.48% 75.29% -0.20% ; ==========================================; Files 116 116 ; Lines 12904 12908 +4 ; ==========================================; - Hits 9741 9719 -22 ; - Misses 3163 3189 +26 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2952?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <90.00%> (-0.62%)` | :arrow_down: |. ... and [10 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2952/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2952#issuecomment-2017783436:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2952#issuecomment-2017783436,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.53%. Comparing base [(`4f6e690`)](https://app.codecov.io/gh/scverse/scanpy/commit/4f6e69005547647da24f8e212474f27f54f5da89?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7378b49`)](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2977 +/- ##; ==========================================; + Coverage 75.52% 75.53% +0.01% ; ==========================================; Files 117 117 ; Lines 12951 12950 -1 ; ==========================================; + Hits 9781 9782 +1 ; + Misses 3170 3168 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2977?src=pr&el=tree&filepath=scanpy%2Ftools%2F_leiden.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `89.55% <100.00%> (+0.98%)` | :arrow_up: |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2977?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035081129:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035081129,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2980?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `97.56098%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.54%. Comparing base [(`896e249`)](https://app.codecov.io/gh/scverse/scanpy/commit/896e24906edd8a6f03c97c590838ca20b3f1d127?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7eb31ff`)](https://app.codecov.io/gh/scverse/scanpy/commit/7eb31ffaa94b8d997d77312378e4cc31ecdbc23f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: **Current head 7eb31ff differs from pull request most recent head d58e083**; > ; > Please [upload](https://docs.codecov.com/docs/codecov-uploader) reports for the commit d58e083 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2980 +/- ##; ==========================================; - Coverage 76.31% 75.54% -0.77% ; ==========================================; Files 109 117 +8 ; Lines 12513 12971 +458 ; ==========================================; + Hits 9549 9799 +250 ; - Misses 2964 3172 +208 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2980?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2980?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.84% <100.00%> (ø)` | |; | [scanpy/experimental/pp/\_n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2980#issuecomment-2039521442:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2980#issuecomment-2039521442,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `81.96721%` with `22 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.17%. Comparing base [(`99cc32f`)](https://app.codecov.io/gh/scverse/scanpy/commit/99cc32fb75a22fa708ba24a5a410683df9a45c35?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4042018`)](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2985 +/- ##; ==========================================; - Coverage 75.49% 73.17% -2.32% ; ==========================================; Files 116 117 +1 ; Lines 12911 12919 +8 ; ==========================================; - Hits 9747 9454 -293 ; - Misses 3164 3465 +301 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2985?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2985?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2N,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2985#issuecomment-2042583820:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2985#issuecomment-2042583820,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `40.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.49%. Comparing base [(`9c8c095`)](https://app.codecov.io/gh/scverse/scanpy/commit/9c8c095daa6e411e73845ccca99d2c5171b3f059?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8e23732`)](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2992 +/- ##; ==========================================; - Coverage 75.51% 75.49% -0.02% ; ==========================================; Files 117 117 ; Lines 12955 12959 +4 ; ==========================================; + Hits 9783 9784 +1 ; - Misses 3172 3175 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2992?src=pr&el=tree&filepath=scanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `67.72% <40.00%> (-0.43%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2045167705:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2045167705,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `48.71795%` with `20 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.43%. Comparing base [(`10f4ebc`)](https://app.codecov.io/gh/scverse/scanpy/commit/10f4ebc7c0ee834897ce8586ffe717e80f78ba58?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`06c93dc`)](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2998 +/- ##; ==========================================; - Coverage 75.52% 75.43% -0.09% ; ==========================================; Files 117 117 ; Lines 12951 12986 +35 ; ==========================================; + Hits 9781 9796 +15 ; - Misses 3170 3190 +20 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2998?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_tools%2Fscatterplots.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `83.29% <48.71%> (-3.19%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2998#issuecomment-2047370580:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998#issuecomment-2047370580,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3017?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.86%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`277c1bf`)](https://app.codecov.io/gh/scverse/scanpy/commit/277c1bfb0885234aa757d0fdaeaa9103eb8568e2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3017?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3017?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | 85.71% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3017?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3017 +/- ##; ==========================================; - Coverage 75.87% 75.86% -0.01% ; ==========================================; Files 110 110 ; Lines 12533 12533 ; ==========================================; - Hits ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069245430:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069245430,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `69.23077%` with `4 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`d2a5368`)](https://app.codecov.io/gh/scverse/scanpy/commit/d2a53680e312835b998077b4e25b254e98bcb5ba?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`69f9781`)](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3031 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12799 12803 +4 ; ==========================================; + Hits 9763 9766 +3 ; - Misses 3036 3037 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3031?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.60% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_scrublet/core.py](https://app.codecov.io/gh/scverse/scanpy/pull/3031?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fcore.py&utm_medium=referral&utm_source=github&utm_content=commen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2079044440:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031#issuecomment-2079044440,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `0%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.90%. Comparing base [(`a008ab8`)](https://app.codecov.io/gh/scverse/scanpy/commit/a008ab812602abe805740c394e8f802ab56f101a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3b0e501`)](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3038 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_scrublet.py](https://app.codecov.io/gh/scverse/scanpy/pull/3038?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_scrublet.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zY3J1YmxldC5weQ==) | `23.52% <0.00%> (-70.59%)` | :arrow_down: |; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3038?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3038#issuecomment-2083379495:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3038#issuecomment-2083379495,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`cf99920`)](https://app.codecov.io/gh/scverse/scanpy/commit/cf999200f7dab9983d2c52821534def4b7ed6ea1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d228a87`)](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3039 +/- ##; =======================================; Coverage 76.27% 76.27% ; =======================================; Files 117 117 ; Lines 12795 12795 ; =======================================; Hits 9760 9760 ; Misses 3035 3035 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_scrublet.py](https://app.codecov.io/gh/scverse/scanpy/pull/3039?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_scrublet.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zY3J1YmxldC5weQ==) | `94.11% <100.00%> (ø)` | |; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3039?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | `13.44% <0.00%> (ø)` ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3039#issuecomment-2084689348:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3039#issuecomment-2084689348,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `47.72727%` with `23 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.18%. Comparing base [(`0d4554b`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d4554b44e301c9c1e78e80e21b5e4a6642e156a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`efcf8df`)](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3043 +/- ##; ==========================================; - Coverage 76.27% 76.18% -0.10% ; ==========================================; Files 117 117 ; Lines 12795 12838 +43 ; ==========================================; + Hits 9760 9780 +20 ; - Misses 3035 3058 +23 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3043?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19iYXNlcGxvdF9jbGFzcy5weQ==) | `85.21% <47.72%> (-4.68%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3043#issuecomment-2091092171:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043#issuecomment-2091092171,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `89.47368%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.28%. Comparing base [(`c26480e`)](https://app.codecov.io/gh/scverse/scanpy/commit/c26480ed0dc2f7d27b796e0e355b29a8305886c6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`57732d0`)](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3044 +/- ##; =======================================; Coverage 76.27% 76.28% ; =======================================; Files 117 117 ; Lines 12803 12802 -1 ; =======================================; Hits 9766 9766 ; + Misses 3037 3036 -1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_scrublet/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3044?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NjcnVibGV0L19faW5pdF9fLnB5) | `96.80% <100.00%> (+0.10%)` | :arrow_up: |; | [scanpy/preprocessing/\_scrublet/pipeline.py](https://app.codecov.io/gh/scverse/scanpy/pull/3044?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fpipeline.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096282888:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096282888,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.47059%` with `8 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.90%. Comparing base [(`9714250`)](https://app.codecov.io/gh/scverse/scanpy/commit/971425046f3f0411ea77a13939be208526e0c9eb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d314182`)](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3047 +/- ##; ==========================================; - Coverage 73.98% 73.90% -0.08% ; ==========================================; Files 117 117 ; Lines 12795 12763 -32 ; ==========================================; - Hits 9466 9433 -33 ; - Misses 3329 3330 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `66.66% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `6 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`6b00ea3`)](https://app.codecov.io/gh/scverse/scanpy/commit/6b00ea3b8c436b84ff64662054226381473850a5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7e0aae1`)](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3050 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12795 12799 +4 ; ==========================================; + Hits 9760 9763 +3 ; - Misses 3035 3036 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.94% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `69.23077%` with `4 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`19a0bb8`)](https://app.codecov.io/gh/scverse/scanpy/commit/19a0bb8fd3601c3b39e242ff6419fb73e59cf67a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0e14441`)](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3056 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12799 12803 +4 ; ==========================================; + Hits 9763 9766 +3 ; - Misses 3036 3037 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3056?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.60% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_scrublet/core.py](https://app.codecov.io/gh/scverse/scanpy/pull/3056?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fcore.py&utm_medium=referral&utm_source=github&utm_content=comm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109792074:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109792074,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `89.47368%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.08%. Comparing base [(`dea050f`)](https://app.codecov.io/gh/scverse/scanpy/commit/dea050f63f252d73f4716145e8a166f6ffc043dd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`968b5f1`)](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3058 +/- ##; ==========================================; - Coverage 76.27% 76.08% -0.20% ; ==========================================; Files 117 117 ; Lines 12803 12802 -1 ; ==========================================; - Hits 9766 9740 -26 ; - Misses 3037 3062 +25 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_scrublet/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3058?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NjcnVibGV0L19faW5pdF9fLnB5) | `96.80% <100.00%> (+0.10%)` | :arrow_up: |; | [scanpy/preprocessing/\_scrublet/pipeline.py](https://app.codecov.io/gh/scverse/scanpy/pull/3058?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fpipeline.py&utm_medium=referral&utm_source=github&ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110286934:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110286934,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.19%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d8d4763`)](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3061 +/- ##; ==========================================; - Coverage 75.87% 75.19% -0.68% ; ==========================================; Files 110 110 ; Lines 12533 12536 +3 ; ==========================================; - Hits 9509 9427 -82 ; - Misses 3024 3109 +85 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3061?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `68.08% <66.66%> (-25.10%)` | :arrow_down: |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3061/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2110890545:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2110890545,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3082?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.80%. Comparing base [(`b3b9d05`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3b9d0576897a8da5a4ae765b4b0b5609cebc890?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2709e08`)](https://app.codecov.io/gh/scverse/scanpy/commit/2709e08fe39d3440c904b3cfcb1913611d9bc672?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3082?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3082?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | 85.71% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3082?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3082 +/- ##; =======================================; Coverage 75.80% 75.80% ; =======================================; Files 110 110 ; Lines 12500 12501 +1 ; =======================================; + Hits 9475 9476 +,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141612509:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141612509,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3084?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `62.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 75.85%. Comparing base [(`5dc489d`)](https://app.codecov.io/gh/scverse/scanpy/commit/5dc489d5c71fa91fd0cabe6adb363172119ce5eb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6ba3676`)](https://app.codecov.io/gh/scverse/scanpy/commit/6ba36767cbb6fe59524c1ac54347b3a36de41a28?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 46 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3084?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&e,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3084#issuecomment-2141838152:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084#issuecomment-2141838152,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 78.58%. Comparing base [(`698313b`)](https://app.codecov.io/gh/scverse/scanpy/commit/698313b5f38ed726c5b8093c155482d1bfdaf4bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63253ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/63253ab59f2799350c43631bf4033362d3f913bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3097?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.16667%` with `5 lines` in your changes missing coverage. Please review.; > Project coverage is 76.35%. Comparing base [(`4f40d68`)](https://app.codecov.io/gh/scverse/scanpy/commit/4f40d68c8958ef74fd8abe5f97601c40ffee9337?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e89ebac`)](https://app.codecov.io/gh/scverse/scanpy/commit/e89ebaceddc37589fe22bfe32b1e8a9f1b5746f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 41 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3097?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&filepath=scanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | 82.35% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&filepath=scanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&utm_medium=referral&utm_source=github&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3097#issuecomment-2147774048:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097#issuecomment-2147774048,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3098?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.16667%` with `5 lines` in your changes missing coverage. Please review.; > Project coverage is 76.35%. Comparing base [(`d34e575`)](https://app.codecov.io/gh/scverse/scanpy/commit/d34e5756aa6a6f763e06d48c060efdd0a94fa468?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a01cf79`)](https://app.codecov.io/gh/scverse/scanpy/commit/a01cf79bf6dc5809357d037d17bece02d92616f5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3098?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&filepath=scanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | 82.35% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&filepath=scanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&utm_medium=referral&utm_source=githu,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3098#issuecomment-2147840847:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098#issuecomment-2147840847,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3115?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `57.14286%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`8d9a5f0`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d9a5f0d2b303abeb42f7e4c9252d505000fd05c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8fb2a0e`)](https://app.codecov.io/gh/scverse/scanpy/commit/8fb2a0eac8778931a22d70c16e76b9f516f9ef78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3115?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3115?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3115?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3115 +/- ##; ==========================================; + Coverage 76.31% 76.50% +0.18% ; ==========================================; Files 109 109 ; Lines 12515 12474 -41 ; ==========================================; - Hits 9551 9543 -8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2181074546:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2181074546,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3134?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `57.14286%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`a5eadd5`)](https://app.codecov.io/gh/scverse/scanpy/commit/a5eadd5b723799105d724b5e9f80b711e0be87ca?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`25f0c97`)](https://app.codecov.io/gh/scverse/scanpy/commit/25f0c97e81e9143bece1ded7c4838964ed7d3866?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3134?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3134?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3134?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3134 +/- ##; ==========================================; + Coverage 76.31% 76.50% +0.18% ; ==========================================; Files 109 109 ; Lines 12515 12474 -41 ; ==========================================; - Hits 9551 954,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3134#issuecomment-2202709708:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3134#issuecomment-2202709708,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3138?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `0%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.52%. Comparing base [(`208115d`)](https://app.codecov.io/gh/scverse/scanpy/commit/208115dd78046af3258da3a756f36dda34e5aba8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4ed4477`)](https://app.codecov.io/gh/scverse/scanpy/commit/4ed4477c4f000703aa42f22e4c8f5930e21eab9b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3138 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12483 12483 ; =======================================; Hits 9553 9553 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3138?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3138?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | `85.10% <0.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3138#issuecomment-2204452117:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138#issuecomment-2204452117,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`e6e5328`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6e532804a9c087ea37808f26395aa9ed038d6cb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a37840f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a37840f6d72e7b3ad980c6603c310f2e5e2305c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | 86.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3142 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files wit,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3181?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.54%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d6be2f5`)](https://app.codecov.io/gh/scverse/scanpy/commit/d6be2f5157d48deaefff8f1d97ca4715bba466b4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3181 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3181?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/3181?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_tools%2Fscatterplots.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdG9vbHMvc2NhdHRlcnBsb3RzLnB5) | `86.99% <ø> (ø)` | |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3181?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3181#issuecomment-2261315786:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3181#issuecomment-2261315786,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.58%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c895e8`)](https://app.codecov.io/gh/scverse/scanpy/commit/6c895e8b0e3ecef999924d1c3998b19affe10d8d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 52 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3185?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 74.06%. Comparing base [(`bcae3fe`)](https://app.codecov.io/gh/scverse/scanpy/commit/bcae3fe77aabcd7f8eb334d868786620cef6fbd8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`17c5c11`)](https://app.codecov.io/gh/scverse/scanpy/commit/17c5c1110bb6d7fdafed36e452558179ee84d957?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3185?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3185#issuecomment-2262723609:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3185#issuecomment-2262723609,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3191?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.61%. Comparing base [(`243a46e`)](https://app.codecov.io/gh/scverse/scanpy/commit/243a46e674f97f04c835893320dfd21543f89827?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`deb9f38`)](https://app.codecov.io/gh/scverse/scanpy/commit/deb9f3876ec6848562b1f5f3e5ce9f9a8551eead?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 49 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3191?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3191?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvZ2V0LnB5) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3191?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3191 +/- ##; ==========================================; - Coverage 76.61% 76.61% -0.01% ; ==========================================; Files 109 109 ; Lines 12529 12532 +3 ; ==========================================; + Hits 9599 9601 +2 ; - Misses 2930 2931 +1 ; ```. | [Files with missing lines](https://app,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3191#issuecomment-2263391738:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3191#issuecomment-2263391738,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3192?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.61%. Comparing base [(`a60a96f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a60a96fb7790e35abe8d007abd6f5a17b1573d7d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`fca69e6`)](https://app.codecov.io/gh/scverse/scanpy/commit/fca69e6d08e90f86c01a033fa4c8749cc2cb4ea3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3192?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3192?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvZ2V0LnB5) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3192?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3192 +/- ##; ==========================================; - Coverage 76.61% 76.61% -0.01% ; ==========================================; Files 109 109 ; Lines 12529 12532 +3 ; ==========================================; + Hits 9599 9601 +2 ; - Misses 2930 2931 +1 ; ```. | [Files with missing lines](https:/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3192#issuecomment-2263491216:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3192#issuecomment-2263491216,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3204?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 74.10%. Comparing base [(`c6766d7`)](https://app.codecov.io/gh/scverse/scanpy/commit/c6766d758b83410e9167578d22054f712d5bca4b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3a9b3f6`)](https://app.codecov.io/gh/scverse/scanpy/commit/3a9b3f6f3d463704495aca6ed6353bbf5eca87a1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3204?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_dendrogram.py](https://app.codecov.io/gh/scverse/scanpy/pull/3204?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_dendrogram.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZGVuZHJvZ3JhbS5weQ==) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3204?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3204 +/- ##; ==========================================; - Coverage 76.63% 74.10% -2.54% ; ==========================================; Files 109 109 ; Lines 12533 12537 +4 ; ==========================================; - Hits 9605 9290 -315 ; - Misses 2928 3247 +319 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3204?d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3204#issuecomment-2277865200:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3204#issuecomment-2277865200,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3209?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.08197%` with `12 lines` in your changes missing coverage. Please review.; > Project coverage is 76.69%. Comparing base [(`7ae1216`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ae12167f582935a8c6f9c06fff9cda99a4eedc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`297ed30`)](https://app.codecov.io/gh/scverse/scanpy/commit/297ed3070eaa2d67e0a1ceeed9b9b3cf74345061?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3209?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 86.48% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYmFzZXBsb3RfY2xhc3MucHk=) | 95.50% | [4 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&utm_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3209#issuecomment-2286226902:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3209#issuecomment-2286226902,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3220?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `30 lines` in your changes missing coverage. Please review.; > Project coverage is 76.73%. Comparing base [(`d4e1fb4`)](https://app.codecov.io/gh/scverse/scanpy/commit/d4e1fb4cb290d9835710fba2b5b9594d97176601?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`403dd30`)](https://app.codecov.io/gh/scverse/scanpy/commit/403dd30f9e523ae84eba4ac239c6fb72fb439585?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3220?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 25.00% | [15 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_draw\_graph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_draw_graph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZHJhd19ncmFwaC5weQ==) | 31.57% | [13 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220#issuecomment-2323386009:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220#issuecomment-2323386009,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.62%. Comparing base [(`bec794c`)](https://app.codecov.io/gh/scverse/scanpy/commit/bec794c7e7e28393e7cb6ae6624ecdbd187868ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8d1cb04`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d1cb04fbff869dd70d1b452477b83c151237e4a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | 50.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3227 +/- ##; ==========================================; - Coverage 76.63% 76.62% -0.02% ; ==========================================; Files 109 109 ; Lines 12533 12536 +3 ; ==========================================; + Hits 9605 9606 +1 ; - Misses 2928 2930 +2 ; ```. ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3230?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `30 lines` in your changes missing coverage. Please review.; > Project coverage is 76.72%. Comparing base [(`0f6acdf`)](https://app.codecov.io/gh/scverse/scanpy/commit/0f6acdf5dda52b698fbf3e675d018ef75806115c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a98157b`)](https://app.codecov.io/gh/scverse/scanpy/commit/a98157b52c1b8fa5108a348a5dcf33bd123cc5e6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3230?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 25.00% | [15 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_draw\_graph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_draw_graph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZHJhd19ncmFwaC5weQ==) | 31.57% | [13 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3230#issuecomment-2348590448:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3230#issuecomment-2348590448,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`bd75839`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd758395a669c31a6c9eaa9239750fde368d3ca7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c06bbc8`)](https://app.codecov.io/gh/scverse/scanpy/commit/c06bbc83218ee426fa54e681ab39c8006e1668c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3243 +/- ##; ==========================================; + Coverage 76.49% 76.75% +0.25% ; ==========================================; Files 109 109 ; Lines 12544 12548 +4 ; ==========================================; + Hits 9596 9631 +35 ; + Misses,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3246?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`2553c67`)](https://app.codecov.io/gh/scverse/scanpy/commit/2553c67af6e47992abde5cb13e4c9deb82a3adbc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2e3ca25`)](https://app.codecov.io/gh/scverse/scanpy/commit/2e3ca25422b317736d49b2b14a61683cb9bfa98b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3246?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3246?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3246?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3246 +/- ##; ==========================================; - Coverage 76.76% 76.71% -0.05% ; ==========================================; Files 109 109 ; Lines 12529 12533 +4 ; ==========================================; - Hits 9618 9615 -3 ; - Mis,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3246#issuecomment-2363411554:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3246#issuecomment-2363411554,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3248?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`b0597a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/b0597a9f6f114a1aee6737e0acae6b1ca403e1b8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3cce3f2`)](https://app.codecov.io/gh/scverse/scanpy/commit/3cce3f28e94d29dc907f94056bd6995f197d9f93?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3248?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scv,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3248#issuecomment-2363527588:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3248#issuecomment-2363527588,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3249?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.59459%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`1650aed`)](https://app.codecov.io/gh/scverse/scanpy/commit/1650aed30fd0141a97c01a6a6b19c2735e058c77?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b3fa09b`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3fa09ba950806f9e2a2c5060b32d3d768f0f14e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3249?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3249?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 93.10% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3249?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3249 +/- ##; ==========================================; - Coverage 76.75% 76.75% -0.01% ; ==========================================; Files 109 109 ; Lines 12551 12556 +5 ; ==========================================; + Hits 9634 9637 +3 ; - Misses 2917 2919 +2 ; ```. | [,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3249#issuecomment-2363632936:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3249#issuecomment-2363632936,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`ffebf12`)](https://app.codecov.io/gh/scverse/scanpy/commit/ffebf124f8a7da65a85622a07c7037ca477bfbef?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2b269f7`)](https://app.codecov.io/gh/scverse/scanpy/commit/2b269f7a7e579f2ab5af52f240a1e86f93c118b2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3251?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.59459%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`b325b50`)](https://app.codecov.io/gh/scverse/scanpy/commit/b325b50f942ba75d77e1a4caa181d67f83d0a057?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`408a7b5`)](https://app.codecov.io/gh/scverse/scanpy/commit/408a7b58758a609147276eea01e9f86ae16855ee?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3251?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3251?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 93.10% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3251?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3251 +/- ##; ==========================================; - Coverage 76.72% 76.71% -0.01% ; ==========================================; Files 109 109 ; Lines 12536 12541 +5 ; ==========================================; + Hits 9618 9621 +3 ; - Misses 2918 2920 +2 ; ```.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3251#issuecomment-2363756462:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3251#issuecomment-2363756462,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.74%. Comparing base [(`e27e257`)](https://app.codecov.io/gh/scverse/scanpy/commit/e27e257964c358acb3a9a83e4289cccfdfa425ae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0744da6`)](https://app.codecov.io/gh/scverse/scanpy/commit/0744da68e4f3593a81bed752d387bd2ca12a5e09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 33.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3252 +/- ##; ==========================================; - Coverage 76.75% 76.74% -0.02% ; ==========================================; Files 109 109 ; Lines 12556 12559 +3 ; ==========================================; + Hits 9637 9638 +1 ; - Misses ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3258?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.24528%` with `22 lines` in your changes missing coverage. Please review.; > Project coverage is 76.96%. Comparing base [(`8b2088d`)](https://app.codecov.io/gh/scverse/scanpy/commit/8b2088de18452ff11e555bac0c147eaf15cf27f4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1b1fbc9`)](https://app.codecov.io/gh/scverse/scanpy/commit/1b1fbc93200bdbf7b69d0dd87f01a5c0ede2bdc1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3258?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_tools%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdG9vbHMvX19pbml0X18ucHk=) | 44.44% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_sim.py](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_sim.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2ltLnB5) | 58.33% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3258#issuecomment-2371725350:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3258#issuecomment-2371725350,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3264?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `92.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.95%. Comparing base [(`d998742`)](https://app.codecov.io/gh/scverse/scanpy/commit/d9987426be03f9ef1bdab065f50959d046734ea4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9d0ffa5`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d0ffa5b52b7311999bd52f7c856096a2b3d7653?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3264?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3264?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 81.81% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3264?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3264 +/- ##; ==========================================; - Coverage 76.96% 76.95% -0.02% ; ==========================================; Files 109 109 ; Lines 12469 12466 -3 ; ==========================================; - Hits 9597 9593 -4 ; - Misses 2872 2873 +1 ; ```. | [Flag](https://app.codecov.io/gh/scvers,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3264#issuecomment-2376822003:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3264#issuecomment-2376822003,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3265?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `92.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`7ccf96d`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ccf96d4b6ac10f0a718010578f725e3de2902f7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bd99e6d`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd99e6de4235131acaf426f62649a929db32c699?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3265?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3265?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 81.81% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3265?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3265 +/- ##; ==========================================; - Coverage 76.93% 76.91% -0.02% ; ==========================================; Files 109 109 ; Lines 12454 12451 -3 ; ==========================================; - Hits 9581 9577 -4 ; - Misses 2873 2874 +1 ; ```. | [Flag](https://app.codecov.io/gh/sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3265#issuecomment-2377150033:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3265#issuecomment-2377150033,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3267?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.16129%` with `6 lines` in your changes missing coverage. Please review.; > Project coverage is 77.03%. Comparing base [(`bbcd4b1`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbcd4b173aabebb8b4793cf2cdd6ea8b31e31005?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7516acc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7516acc4474f54b86cc7a880e3508a20b8a40169?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3267?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3267?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EvX19pbml0X18ucHk=) | 93.18% | [6 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3267?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3267 +/- ##; ==========================================; + Coverage 76.95% 77.03% +0.08% ; ==========================================; Files 109 110 +1 ; Lines 12465 12492 +27 ; ==========================================; + Hits 9592 ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3267#issuecomment-2378904712:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3267#issuecomment-2378904712,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`502f738`)](https://app.codecov.io/gh/scverse/scanpy/commit/502f738b78e9ef78506fafd751e05b993d6001b3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`af65f75`)](https://app.codecov.io/gh/scverse/scanpy/commit/af65f75e459e061460b8cda5d0ef68065e2809d3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3275 +/- ##; =======================================; Coverage 77.22% 77.23% ; =======================================; Files 111 111 ; Lines 12600 12605 +5 ; =======================================; + Hits 9730 9735 +5 ; Misses 2870 2870 ; ```. | [Files with m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3283?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.94%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8268e54`)](https://app.codecov.io/gh/scverse/scanpy/commit/8268e543090721ae9b056355c0cbb8d2ac742d13?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3283?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&utm_med,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3283#issuecomment-2411417242:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283#issuecomment-2411417242,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3284?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.62500%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`60d30a4`)](https://app.codecov.io/gh/scverse/scanpy/commit/60d30a40de65b4e9dacb9578f074f9e8565621dc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9cd667d`)](https://app.codecov.io/gh/scverse/scanpy/commit/9cd667d7a99c9d4554b88edc258127bc043ccc83?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3284?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3284?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL191dGlscy5weQ==) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3284?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3284 +/- ##; ==========================================; + Coverage 77.21% 77.22% +0.01% ; ==========================================; Files 111 111 ; Lines 12597 12621 +24 ; ==========================================; + Hits 9727 9747 +20 ; - Misses 2870 2874 +4 ; ```. | [Files with missing lines](https:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284#issuecomment-2413061647:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284#issuecomment-2413061647,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`388aae5`)](https://app.codecov.io/gh/scverse/scanpy/commit/388aae5fe140ee09c1b3f8c4a84f14667823f31b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`81f4aa3`)](https://app.codecov.io/gh/scverse/scanpy/commit/81f4aa39a45739c2f832b0f452ad07b717bcecc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3307?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.45455%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`2f0afac`)](https://app.codecov.io/gh/scverse/scanpy/commit/2f0afac72be3644624cf996323197239580f14f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`65c74cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/65c74cfa67b2f9d9493b9cd2384685245ecacc2c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3307?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/3307?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_qc.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19xYy5weQ==) | 94.28% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3307?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3307 +/- ##; ==========================================; + Coverage 77.21% 77.23% +0.02% ; ==========================================; Files 111 111 ; Lines 12597 12618 +21 ; ==========================================; + Hits 9727 9746 +19 ; - Misses 2870 2872 +2 ; ```. |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3307#issuecomment-2429279414:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307#issuecomment-2429279414,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3314?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.95%. Comparing base [(`947afa1`)](https://app.codecov.io/gh/scverse/scanpy/commit/947afa157474130bd94b5130dd2de433692e06ff?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ca18a68`)](https://app.codecov.io/gh/scverse/scanpy/commit/ca18a68e60d72a0b16263ea43d5b950fcf9b0c44?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3314?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3314?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3314?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3314 +/- ##; =======================================; Coverage 76.94% 76.95% ; =======================================; Files 109 109 ; Lines 12462 12467 +5 ; =======================================; + Hits 9589 9594 +5 ; Misses 2873 2873 ; ```. | [Files wi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3314#issuecomment-2434892685:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3314#issuecomment-2434892685,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3316?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 77.21%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f5f2775`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5f27756930da430c3f6d803800076e8501952e6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3316?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3316?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 85.71% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3316?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3316 +/- ##; ==========================================; - Coverage 77.23% 77.21% -0.02% ; ==========================================; Files 111 111 ; Lines 12605 12597 -8 ; ==========================================; - Hits 9735 9727 -8 ; Misses 2870 2870 ; `,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3316#issuecomment-2435332939:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3316#issuecomment-2435332939,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3317?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `91.66667%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7fdeda1`)](https://app.codecov.io/gh/scverse/scanpy/commit/7fdeda1f70297e30c1990232a35a53bbfd33940c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3317?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_scale.py](https://app.codecov.io/gh/scverse/scanpy/pull/3317?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_scale.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zY2FsZS5weQ==) | 91.66% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3317?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3317 +/- ##; ==========================================; - Coverage 77.23% 77.22% -0.01% ; ==========================================; Files 111 111 ; Lines 12605 12604 -1 ; ==========================================; - Hits 9735 9734 -1 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.co,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3317#issuecomment-2435647972:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3317#issuecomment-2435647972,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3325?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `58.82353%` with `7 lines` in your changes missing coverage. Please review.; > Project coverage is 77.20%. Comparing base [(`9a9f17e`)](https://app.codecov.io/gh/scverse/scanpy/commit/9a9f17e4d4afdd3c2e1395dfe9aec5cce5489248?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d5e994e`)](https://app.codecov.io/gh/scverse/scanpy/commit/d5e994ef08ebfc8c2c683b5ea07de37c8158d638?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3325?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9leHBvcnRpbmcucHk=) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/external/tl/\_phenograph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_phenograph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fcGhlbm9ncmFwaC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3325#issuecomment-2438028067:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3325#issuecomment-2438028067,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3330?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `22.44898%` with `38 lines` in your changes missing coverage. Please review.; > Project coverage is 72.25%. Comparing base [(`a70582e`)](https://app.codecov.io/gh/scverse/scanpy/commit/a70582ee03556cf6821eb45148560cb259a5fb34?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`25e7cd4`)](https://app.codecov.io/gh/scverse/scanpy/commit/25e7cd418ac258329944ced2b4ba443d5d06865b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 103 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3330?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3330?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 22.44% | [38 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3330?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3330 +/- ##; ==========================================; - Coverage 76.27% 72.25% -4.03% ; ==========================================; Files 117 111 -6 ; Lines 12795 12639 -156 ; ==========================================; - Hits 9760 9132 -628 ; - Misses ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3330#issuecomment-2443557729:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3330#issuecomment-2443557729,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bbb9469`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbb94697549e9980eb039d3a5c174b2cc72a51ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3335?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.54054%` with `7 lines` in your changes missing coverage. Please review.; > Project coverage is 76.56%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b426035`)](https://app.codecov.io/gh/scverse/scanpy/commit/b4260358866324a1097cdce17315ceebfe0cef0b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3335?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 87.23% | [6 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 87.50% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/33,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450235904:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450235904,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`dda1f6e`)](https://app.codecov.io/gh/scverse/scanpy/commit/dda1f6eafad19e1a53947c54401ac4573b0a1cc3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c4a1e0a`)](https://app.codecov.io/gh/scverse/scanpy/commit/c4a1e0a829f553e14a91be9c1e441345e6b9a66c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 5 commits behind head on ig/fix_pca_args. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pul,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.92308%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.24%. Comparing base [(`0d04447`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d04447448747337e2d3adb15ecdfdbfa1ad91c7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`41666cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/41666cffcc228a2ebe0c1837e87c074c5d097367?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3339 +/- ##; =======================================; Coverage 77.23% 77.24% ; =======================================; Files 111 111 ; Lines 12608 12609 +1 ; =======================================; + Hits 9738 9740 +2 ; + Misses 2870 2869 -1 ; ```. | [Files with missing lin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3340?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.29630%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.26%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`11a711e`)](https://app.codecov.io/gh/scverse/scanpy/commit/11a711e97b84c01dcd73d5b17b8e68c6b6d047c6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3340?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3340?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | 96.29% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3340?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3340 +/- ##; ==========================================; + Coverage 77.22% 77.26% +0.03% ; ==========================================; Files 111 111 ; Lines 12601 12618 +17 ; ==========================================; + Hits 9731 9749 +18 ; + Misses 28,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3340#issuecomment-2456911184:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3340#issuecomment-2456911184,2,['Patch'],['Patch']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. I'm working with the `sc.get.aggregate` function from the latest release candidate. In certain combinations of `groupby` variables, some valuese get lost. . I wasn't able to make a minimal reproducible example, but I obfuscated the `obs` table of my real data and can share it here: ; https://www.dropbox.com/scl/fi/jsbrb2ulki7mmih2242kc/adata_aggregate_bug.h5ad?rlkey=qczuaf2v5vlwb00zyuxmzjkix&dl=1. ### Minimal code sample. ```python; >>> test_adata = sc.read_h5ad(""adata_aggregate_bug.h5ad""). >>> test_adata.obs[""patient_id""].nunique(); 69. >>> test_adata.obs.isnull().sum(); patient_id 0; timepoint 0; external_batch_id 0; dtype: int64. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 15. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""external_batch_id"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69. >>> pb = sc.get.aggregate(; test_adata,; by=[; ""patient_id"",; ""timepoint"",; ],; func=""mean"",; ); pb.obs[""patient_id""].nunique(). 69; ```. ### Error output. ```pytb; So only if using all three variables, some patient IDs are lost. I don't see why this would be happening.; ```. ### Versions. <details>. ```; Package Version Editable project location; ------------------------- --------------- -------------------------------------------------------------------------------------------------------------------------; aiohttp 3.9.3; aiosignal 1.3.1; anndata 0.10.5.post1; anyio 4.3.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array_api_compat 1.5; arrow 1.3.0; asciitree 0.3.3; asttokens 2.4.1; async-lru 2.0.4; async-timeout 4.0.3; attrs 23.2.0; Babel 2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2964:354,release,release,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2964,1,['release'],['release']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. On import, I'm getting:; `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python; import scanpy; ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3071:504,install,installed,504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071,1,['install'],['installed']
Deployability,### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Our pre-release tests started failing. ```; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-None] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[seurat-10] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-None] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_highly_variable_genes.py::test_keep_layer[cell_ranger-10] - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_paga.py::test_paga_path - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_sparse_nanmean - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_sparse_vs_dense - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_score_genes_deplete - AttributeError: 'csr_matrix' object has no attribute 'A'; FAILED scanpy/tests/test_score_genes.py::test_npnanmean_vs_sparsemean - AttributeError: 'csr_matrix' object has no attribute 'A'; ```. ### Minimal code sample. ```python; pip install scipy==1.14.0rc1; pytest; ```. ### Error output. _No response_. ### Versions. <details>. ```; + anndata==0.11.0.dev116+g1bff5fb (from git+https://github.com/scverse/anndata@1bff5fbf0894185c0759b61d78c6df66d6dfeeba); + annoy==1.17.3; + anyio==4.4.0; + array-api-compat==1.7.1; + pillow==10.3.0; + platformdirs==4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3083:297,release,release,297,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3083,1,['release'],['release']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Somewhere, we broke zappy tests. This diff is the start of fixing this: https://github.com/scverse/scanpy/compare/d3a8c7981321e4f0afa3290dd84c06fed3654b0a..fd90edb71b6f5fc4cc58638583ea4ff37b34e660. ### Minimal code sample. ```python; pip install zappy; pytest scanpy/tests/test_preprocessing_distributed.py; ```. ### Error output. ```pytb; ____________________________________________________________________________________________________________________________________ test_normalize_total[direct] ____________________________________________________________________________________________________________________________________. adata = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids', adata_dist = AnnData object with n_obs × n_vars = 10000 × 1000; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_total(adata: AnnData, adata_dist: AnnData):; > normalize_total(adata_dist). scanpy/tests/test_preprocessing_distributed.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /home/phil/.local/share/hatch/env/virtual/scanpy/q4In3tK-/hatch-test.stable/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80: in fn_compatible; return fn(*args_all, **kw); scanpy/preprocessing/_normalization.py:240: in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; scanpy/preprocessing/_normalization.py:49: in _normalize_data; return axis_mul_or_truediv(; /usr/lib/python3.12/functools.py:909: in wrapper;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3087:527,install,install,527,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3087,1,['install'],['install']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. ```; /opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/ehrapy/plot/_scanpy_pl_api.py:606: in <module>; scale: Literal[""area"", ""count"", ""width""] = StackedViolin.DEFAULT_SCALE,; E AttributeError: type object 'StackedViolin' has no attribute 'DEFAULT_SCALE'; ```. ### Minimal code sample. ```python; `import scanpy as sc`; ```. ### Error output. _No response_. ### Versions. Latest main -> pre-release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2899:698,release,release,698,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2899,1,['release'],['release']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello,. With the new scanpy version `1.9.7` I'm not able to plot embeddings such as UMAPs when using numpy `1.23` (it's probably also true for other ""old"" versions of numpy). Note that I can't update numpy to a newer version because of other packages I'm using, but `1.23` is more recent that what scanpy requires anyway (i.e., `numpy>=1.17.0`). For instance, the `spatialdata` library requires `numpy<=1.23.4` because of `xarray-spatial`: thus, it seems that the latest version of `scanpy` is not compatible with `spatialdata` (cc @LucaMarconato for information). The error seems to be due to this commit in `_validate_palette`: https://github.com/scverse/scanpy/commit/d1fe8da28ab4865b6c2b3d9cd151a8186f148844 (@flying-sheep). ### Minimal code sample. ```python; # Just plotting a dummy UMAP. import anndata; import pandas as pd; import numpy as np; import scanpy as sc. n_obs = 10. adata = anndata.AnnData(; X=np.random.randint(0, 5, size=(n_obs, 8)),; obs=pd.DataFrame({; ""cell_type"": np.random.choice([""A"", ""B"", ""C""], size=n_obs)},; index=[str(i) for i in range(n_obs)]; ),; ). sc.pp.neighbors(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""cell_type""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; UFuncTypeError Traceback (most recent call last); Cell In[6], line 1; ----> 1 sc.pl.umap(adata, color=""cell_type""). File ~/mambaforge/envs/new/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:674, in umap(adata, **kwargs); 615 @_wraps_plot_scatter; 616 @_doc_params(; 617 adata_color_etc=doc_adata_color_etc,; (...); 621 ); 622 def umap(adata, **kwargs) -> Union[Axes, List[Axes], None]:; 623 """"""\; 624 Scatter plot in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830:484,update,update,484,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830,1,['update'],['update']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2564:293,install,installed,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564,1,['install'],['installed']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2542:507,pipeline,pipeline,507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542,1,['pipeline'],['pipeline']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2706:291,Install,Installation,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706,5,"['Install', 'install']","['Installation', 'Installing', 'install', 'installation']"
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2747:324,release,release,324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747,2,"['install', 'release']","['install', 'release']"
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The `read_10x_mtx()` function does not work due to the update of the anndata package to 0.10.4 (January 14, 2024); (?Error reading the file *features.tsv.gz*). The launch was carried out on the following data: ; https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM5733023. You can also download files using my google drive:; https://drive.google.com/drive/folders/1p6ilbsJX_cYZb4HG0OSbLHAwQObqmncW?usp=sharing. # **My actions**:. 1) I have installed the latest version of `scanpy=1.9.6` using conda:; ```console; $ conda --version; conda 23.10.0; $ conda install scanpy; # Channels:; # - conda-forge; # - bioconda; # - defaults; # Platform: linux-64. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; anndata 0.10.4 pyhd8ed1ab_0 conda-forge; array-api-compat 1.4 pyhd8ed1ab_0 conda-forge; brotli 1.1.0 hd590300_1 conda-forge; brotli-bin 1.1.0 hd590300_1 conda-forge; bzip2 1.0.8 hd590300_5 conda-forge; c-ares 1.25.0 hd590300_0 conda-forge; ca-certificates 2023.11.17 hbcca054_0 conda-forge; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2023.11.17 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; contourpy 1.2.0 py311h9547e67_0 conda-forge; cycler 0.12.1 pyhd8ed1ab_0 conda-forge; exceptiongroup 1.2.0 pyhd8ed1ab_2 conda-forge; fonttools 4.47.2 py311h459d7ec_0 conda-forge; freetype 2.12.1 h267a509_2 conda-forge; get-annotations 0.1.2 pyhd8ed1ab_0 conda-forge; h5py 3.10.0 nompi_py311hebc2b07_101 conda-forge; hdf5 1.14.3 nompi_h4f84152_100 conda-forge; icu 73.2 h59595ed_0 conda-forge; joblib 1.3.2 pyhd8ed1ab_0 conda-forge; keyutils 1.6.1 h166bdaf_0 conda-forge; kiwiso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806:346,update,update,346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806,3,"['install', 'update']","['install', 'installed', 'update']"
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I install scanpy==1.9.6 with pip (anndata==0.10.4), something wrong and adata.X.nnz is 0.; I changed the version of anndata to 0.9.2, it works normal. ### Minimal code sample. ```python; import numpy as np; import pandas as pd; import scanpy as sc; sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'); results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results; adata = sc.read_10x_mtx(my_sample, # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=False) # write a cache file for faster subsequent reading; # sc.pl.highest_expr_genes(adata, n_top=20, ); adata.X.nnz; ```. ### Error output. _No response_. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.5; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; bottleneck 1.3.5; cffi 1.16.0; comm 0.1.2; cycler 0.12.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 4.4.2; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.7.0; hurry NA; ipykernel 6.25.0; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numexpr 2.8.7; numpy 1.26.0; packaging 23.2; pandas 1.5.3; parso 0.8.3; patsy 0.5.6; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydev",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2822:298,install,install,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2822,1,['install'],['install']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Issue was observed and documented more in https://github.com/IGS/gEAR/issues/753. We have recreated the Seurat pipeline (2017 legacy version) from the Scanpy tutorial on it, and we have a step that lets users filter their AnnData object based on genes in cells or cells in genes. The filtered AnnData object is written to disk, and then the top 20 expressed genes are plotted with `scanpy.pl.highest_expr_genes`. . However what seems to happen is that the `counts_top_genes` DataFrame (created in https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/plotting/_qc.py#L78-L93) will still preserve the original Categorical set from the passed in AnnData object. The `counts_top_genes` DataFrame shape is correct. When Seaborn plots in https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/plotting/_qc.py#L100 it seems to also plot all the Categoricals that are not present in the `counts_top_genes` DataFrame. My temporary hack to fix this is to force my ""gene_symbols"" argument column to be a mixed-object dtype, which drops the Categoricals and renders the boxplot correctly; ```python; if 'gene_symbol' in adata.var.columns and adata.var['gene_symbol'].dtype.name != 'object':; adata.var['gene_symbol'] = adata.var['gene_symbol'].astype('object'); ```. ### Minimal code sample. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. sc.pl.highest_expr_genes(adata, n_top=20, gene_symbols='gene_symbol', show=True, save="".png""); ```. I also tried this with the same results. ```python; import scanpy as sc. <anndata object with a categorical adata.var.gene_symbol column>. adata.var.index = ada",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3158:400,pipeline,pipeline,400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3158,1,['pipeline'],['pipeline']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When I try to plot a scatter plot color coded by categorical data, it still output the image, but the legend does not include colors. Additionally, if i use continuous data as the key for plotting, the code executes as expected. Thanks!. ![image](https://github.com/scverse/scanpy/assets/43973217/8c1b0a03-3c0b-4452-b759-9cf588b45c53). ### Minimal code sample. ```python; sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[37], line 1; ----> 1 sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color='reference', show=True). File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /project/hipaa_ycheng11lab/atlas/CAMR2024/py311env/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:166, in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, marker, title, show, save, ax); 160 raise ValueError(""Either provide a `basis` or `x` and `y`.""); 161 if (; 162 (x in adata.obs.keys() or x in var_index); 163 and (y in adata.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102:446,continuous,continuous,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102,1,['continuous'],['continuous']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. When reading docs from the readthedocs website, clicking the ""source"" link will navigate to the wrong spot. I think the structure was changed slightly in a commit since these were updated. The locations are still obtainable by manually walking the tree, but they are no longer what is pointed to in those [source] links. I am happy to try my hand at a fix, I just need some direction in terms of whether this is would be helpful, and how the docs are updated. ; This is where I am navigated to when i click the link for scanpy.pp.calculate_qc_metrics.; <img width=""690"" alt=""image"" src=""https://github.com/user-attachments/assets/1cd8f7ba-a54b-49c4-9f00-a19633d5e606"">. ### Minimal code sample. ```python; no code, UI fix.; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3219:469,update,updated,469,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3219,2,['update'],['updated']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. was running the standard pipeline on some data and when i run; `sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False) `; it spits out infinite lines of ignored exceptions. it does not actually crash the kernel, but does bog it down and causes everything to to take much more time than necesarry. ; I am working in a conda env on a Win 10 , 64bit, x64 system; the problem also occurs using the pbmc3k dataset. ### Minimal code sample. ```python; # example with own data, but same happens with pbmc3k data; sc.pp.filter_cells(em_adata, min_genes=200); sc.pp.filter_genes(em_adata, min_cells=3); em_adata.shape; # [out] -> (42753, 21636). sc.pp.calculate_qc_metrics(em_adata, qc_vars=[""mt""], percent_top=None, log1p=False, inplace=True); em_adata.obs[""outlier_mt""] = em_adata.obs.pct_counts_mt > 15; em_adata.obs[""outlier_total""] = em_adata.obs.total_counts > 30000; em_adata.obs[""outlier_ngenes""] = em_adata.obs.n_genes_by_counts > 6000; em_adata = em_adata[~em_adata.obs[""outlier_mt""], :]; em_adata = em_adata[~em_adata.obs[""outlier_total""], :]; em_adata = em_adata[~em_adata.obs[""outlier_ngenes""], :]; sc.pp.filter_genes(em_adata,min_cells=1). sc.pp.scrublet(em_adata); em_adata.layers['counts'] = em_adata.X.copy(); sc.pp.normalize_total(em_adata); sc.pp.log1p(em_adata); sc.pp.highly_variable_genes(em_adata,flavor='seurat'); sc.pl.highly_variable_genes(em_adata); em_adata = em_adata[:, em_adata.var[""highly_variable""]]; em_adata.shape; # [out] -> (41749, 1425); sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```. ### Error output. ```pytb; Exception i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969:314,pipeline,pipeline,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969,1,['pipeline'],['pipeline']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was trying to install `scanpy=1.9.6` using conda in a `python=3.9` environment that had 1.9.5 working with `seaborn=0.13`.; Conda raised a solving issue due to ; `package scanpy-1.9.6-pyhd8ed1ab_0 requires seaborn !=0.13.0, but none of the providers can be installed`; I tried the second build (1ab_1) and the error stayed:; ` package scanpy-1.9.6-pyhd8ed1ab_1 requires seaborn !=0.13.0, but none of the providers can be installed`. I checked github and saw that the dependency in `pyproject.toml` is `""seaborn>=0.13.0""` but when i checked the conda package's `index.json` i saw `""seaborn !=0.13.0""`. The discrepancy between the dependencies is unclear. the full `index.json`:; ```json; {; ""arch"": null,; ""build"": ""pyhd8ed1ab_1"",; ""build_number"": 1,; ""depends"": [; ""anndata >=0.7.4"",; ""get-annotations"",; ""h5py >=3"",; ""joblib"",; ""matplotlib-base >=3.6"",; ""natsort"",; ""networkx >=2.3"",; ""numba >=0.41"",; ""numpy >=1.17"",; ""packaging"",; ""pandas >=1.1.1,!=2.1.2"",; ""patsy"",; ""python >=3.8"",; ""scikit-learn >=0.24"",; ""scipy >=1.4"",; ""seaborn !=0.13.0"",; ""session-info"",; ""statsmodels >=0.11"",; ""tqdm"",; ""umap-learn >=0.3.10""; ],; ""license"": ""BSD-3-Clause"",; ""license_family"": ""BSD"",; ""name"": ""scanpy"",; ""noarch"": ""python"",; ""platform"": null,; ""subdir"": ""noarch"",; ""timestamp"": 1699376683854,; ""version"": ""1.9.6""; }; ```. ### Minimal code sample. ```python; conda create -n test ""python=3.9"" ""scanpy=1.9.6"" ""seaborn=0.13"" -c conda-forge; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2791:307,install,install,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2791,3,['install'],"['install', 'installed']"
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2562:1395,update,updated,1395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562,1,['update'],['updated']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Many different calls in scanpy emit warnings that are currently suppressed by our testing framework (I think). . ### Minimal code sample. I discovered this unrelatedly by editing the notebooks, see for example: https://github.com/scverse/scanpy-tutorials/blob/master/spatial/integration-scanorama.ipynb. @flying-sheep mentioned that the scanpy tests filter out warnings and indeed you can reproduce these by e.g.,:; ```sh; pytest -W error::FutureWarning -n auto scanpy/tests/test_plotting.py; ```. ### Error output. - [x] `…/scanpy/plotting/_tools/scatterplots.py:401:`. > UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored. - [x] `…/scanpy/plotting/_tools/__init__.py:1269:`. > FutureWarning: The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect. ; > `_ax = sns.violinplot(`. - [x] `…/scanpy/preprocessing/_simple.py:274:`. > ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; > `adata.var[""n_cells""] = number`. - [x] `…/scanpy/plotting/_stacked_violin.py:503: FutureWarning:`. > Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect. ; > `row_ax = sns.violinplot(`. ### Versions. <details>. ```; -----; anndata 0.10.4; scanpy 1.10.0.dev191+gf7f5d5c6; -----; IPython 8.20.0; PIL 10.2.0; asciitree NA; asttokens NA; cffi 1.16.0; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2024.1.0; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 2.0.1; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jedi 0.19.1; jinja2 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2839:566,integrat,integration-scanorama,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2839,1,['integrat'],['integration-scanorama']
Deployability,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened?. Hello scanpy!; First time, please let me know what to fix about my question asking!; When running sc.pp.highly_variable_genes I get this error; ""ImportError: Please install skmisc package via `pip install --user scikit-misc ""; I've tried numerous times to install the package through pip and conda, pip gives me a metadata error and conda can't find the package even using the command the website gives at [https://anaconda.org/conda-forge/scikit-misc](url). I checked around online and there was a two year old thread on the subject (https://github.com/scverse/scanpy/issues/2073), but none of the solutions worked on my machine. I tried version control of all the packages, most importantly numpy as it was mentioned as a problem. I was wondering if this you all have any newer solutions for this issue. Due to my inexperience im really not sure what is causing this issue and therefore what to provide you all with. I also just realized that after a clean install trying to pip3 install scikit-misc returns this . (scanpy_env) user@Mac ~ % pip3 install scikit-misc ; Requirement already satisfied: scikit-misc in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (0.3.1); Requirement already satisfied: numpy>=1.22.3 in /opt/miniconda3/envs/scanpy_env/lib/python3.9/site-packages (from scikit-misc) (1.26.4). Still getting the error though... Hardware: M2 max mac, macos 15 beta (could this be it somehow?). ### Minimal code sample. Original error upon running highly variable genes; ```python; <details>. ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); File /opt/miniconda3/envs/scanpyenvt/lib/python3.12/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3144:454,install,install,454,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144,3,['install'],['install']
Deployability,"### Test failures as of d36b977fa0c85d67b96799da4cb86b8582868048. Significantly improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:804,continuous,continuous-,804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['continuous'],['continuous-']
Deployability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. #### Summary; Integration of the `polars` and `fast_matrix_market` libraries into Scanpy's data loading functions, specifically `scanpy.read_10x_mtx` and `scanpy.read_mtx`. This will improve the loading speed of `.mtx` and `.csv` files, which is crucial for handling large-scale single-cell datasets more efficiently. #### The problem; The current data loading mechanisms in Scanpy, while effective for small to medium datasets, could be substantially optimized for speed when dealing with larger datasets. #### Expected Impact; - Reduced loading times; - Improving the user experience; - Enhanced scalability. #### Code snipped. ```; import fast_matrix_market; import os; import scanpy as sc; import scipy as sp. def read_10x_faster(; path: str; )-> sc.AnnData:; """"""; Read a sparse matrix in Matrix Market format and two CSV files with gene and cell metadata; into an AnnData object.; ; Args:; path: Path to the directory containing the matrix.mtx, genes.tsv, and barcodes.tsv files.; ; Returns:; An AnnData object with the matrix, gene metadata, and cell metadata. """"""; mtx_file = os.path.join(path, ""matrix.mtx""); gene_info = os.path.join(path, ""genes.tsv""); cell_metadata = os.path.join(path, ""barcodes.tsv""); ; # Read the .mtx file into a sparse matrix using the fast_matrix_market package (faster than scanpy, uses multiprocessing); mtx = fast_matrix_market.mmread(mtx_file). # Convert the sparse matrix to a CSR matrix; # Otherwise you will not be able to use it with scanpy; if isinstance(mtx, sp.sparse.coo.coo_matrix):; mtx = mtx.tocsr(); ; # Create an AnnData object; adata = sc.AnnData(X=mtx.T). # Polars is faster than pandas reading csv files; # Read the gene names and cell names into the AnnData object; adata.var = pl.read_csv(gene_info, separator= '\t', has_header=False).to_pandas(); ; # Read the cell names and cell met",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2846:176,Integrat,Integration,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2846,1,['Integrat'],['Integration']
Deployability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. 10X updated to Space Ranger v3.0, and the output files differ from the v2.0 version. Scanpy is unable to read the output files from v3.0. Can you add support for Space Ranger v3.0?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973:166,update,updated,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973,1,['update'],['updated']
Deployability,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis?. Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2662:185,integrat,integrate,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662,2,['integrat'],['integrate']
Deployability,### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello: . I have multiome snRNA+snATAC data and the snRNA seq data were analyzed with `scanpy`. ; How to integrate the snRNA seq data generated by `scanpy` with the snATAC seq data generated by `ArchR` ?; From the documents https://www.archrproject.com/bookdown/cross-platform-linkage-of-scatac-seq-cells-with-scrna-seq-cells.html; How to generate the `RangedSummarizedExperiment` data set ? Is it possible to convert the `anndata` used by `scanpy` to `RangedSummarizedExperiment` data?; Thanks a lot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3273:266,integrat,integrate,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3273,1,['integrat'],['integrate']
Deployability,### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. currently `pp.scale` with a `mask_obs` with a sparse matrix and with `zero_center== False` takes a really long time to update the sparse matrix. This also takes up a lot of memory because of the parity calculations. I would suggest a numba kernel that just swaps out the data. This works really well for rapids-singlecell and greatly improves performance and reduces the memory overhead.; I would open a PR with this kernel. ------; Performance for 90k cells and 25k genes:; without mask:; CPU 645 ms | GPU 37 ms | 20x; with mask:; CPU 22 s | GPU 50 ms | 460x,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2941:281,update,update,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2941,1,['update'],['update']
Deployability,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2644:142,release,release,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644,2,['release'],['release']
Deployability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667:781,install,install,781,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667,1,['install'],['install']
Deployability,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Once we branch for the 1.10 release series we should do the branch renaming. Some docs about this:. * https://github.com/github/renaming,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2869:122,release,release,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2869,1,['release'],['release']
Deployability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2636:587,release,release,587,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636,1,['release'],['release']
Deployability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. There are two levels of shared parameters that people could benefit from:. 1. Multiple Notebooks that work with the same data and could benefit from shared configuration, e.g. labels and color maps defined for a certain axis/annotation; 2. Plotting using the same labels, color map or so. This could be achieved using object oriented plotting (todo issue number). Having shared configuration files could be achieved either by direct support in the plotting functions (`x='cell type'`) or by adding a convenience function that loads a config object.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2767:250,configurat,configuration,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2767,2,['configurat'],['configuration']
Deployability,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. https://github.com/lmcinnes/pynndescent/pull/242 is released in [0.5.13](https://github.com/lmcinnes/pynndescent/releases/tag/release-0.5.13), so we can do that now",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3114:146,release,released,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3114,3,['release'],"['release-', 'released', 'releases']"
Deployability,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip?. Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR; * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:12,install,installs,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,6,"['install', 'update']","['install', 'installation', 'installs', 'update']"
Deployability,"#### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.30; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.8.1; session_info 1.0.0; six 1.16.0; sklearn 1.1.1; socks 1.7.1; sphinxcontrib NA; stack_data 0.4.0; tensorboard 2.11.0; tensorflow 2.11.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zmq 23.2.1; zope NA; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.5; notebook 6.4.12; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2022-12-15 16:32. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2381:3919,update,updated,3919,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381,1,['update'],['updated']
Deployability,"#### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; tqdm 4.64.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 6.0; zipp NA; zmq 22.3.0; zope NA; -----; IPython 8.2.0; jupyter_client 6.1.12; jupyter_core 4.9.2; jupyterlab 3.3.2; notebook 6.4.8; -----; Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.17763-SP0; </details>. -----; Session information updated at 2023-04-18 14:50; ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2471:2589,update,updated,2589,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471,1,['update'],['updated']
Deployability,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:116,install,installing,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816,2,['install'],['installing']
Deployability,#2210 is triggered by not having dask installed. Our current CI setup can't test for this. This should be addressed with a CI run that uses minimal dependencies.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211:38,install,installed,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211,1,['install'],['installed']
Deployability,"' is not installed, falling back to layout 'fr'.To use the faster and better ForceAtlas2 layout, install package 'fa2' (`pip install fa2`).**. installation error. Collecting fa2; Using cached fa2-0.3.5.tar.gz (435 kB); Requirement already satisfied: numpy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.18.4); Requirement already satisfied: scipy in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:1273,install,install-,1273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['install'],['install-']
Deployability,"'s name to *features.tsv.gz but still got the same error. Here is the full error log:; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); Cell In[62], [line 1](vscode-notebook-cell:?execution_count=62&line=1); ----> [1](vscode-notebook-cell:?execution_count=62&line=1) data1 = sc.read_10x_mtx(""GSE212966"", prefix=""GSM6567159_PDAC2_"", var_names='gene_symbols', cache=True); [2](vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:79) if len(args_all) <= n_positional:; ---> [80](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:80) return fn(*args_all, **kw); [82](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:82) args_pos: P.args; [83](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:83) args_pos, args_rest = args_all[:n_positional], args_all[n_positi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:1758,Pipeline,PipelineDevelope,1758,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"(1.4.1); Requirement already satisfied: tqdm in c:\programdata\miniconda3\envs\jayalal_2_miniconda\lib\site-packages (from fa2) (4.46.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: 'C:\ProgramData\Miniconda3\envs\Jayalal_2_Miniconda\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""'; __file__='""'""'C:\\Users\\xkalaj\\AppData\\Local\\Temp\\pip-install-golo7r_8\\fa2\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d 'C:\Users\xkalaj\AppData\Local\Temp\pip-wheel-yjh93oit'; cwd: C:\Users\xkalaj\AppData\Local\Temp\pip-install-golo7r_8\fa2\; Complete output (30 lines):; Installing fa2 package (fastest forceatlas2 python implementation). >>>> Cython is installed?; Yes. >>>> Starting to install!. running bdist_wheel; running build; running build_py; creating build; creating build\lib.win-amd64-3.6; creating build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.py -> build\lib.win-amd64-3.6\fa2; copying fa2\forceatlas2.py -> build\lib.win-amd64-3.6\fa2; copying fa2\__init__.py -> build\lib.win-amd64-3.6\fa2; running egg_info; writing fa2.egg-info\PKG-INFO; writing dependency_links to fa2.egg-info\dependency_links.txt; writing requirements to fa2.egg-info\requires.txt; writing top-level names to fa2.egg-info\top_level.txt; reading manifest file 'fa2.egg-info\SOURCES.txt'; reading manifest template 'MANIFEST.in'; writing manifest file 'fa2.egg-info\SOURCES.txt'; copying fa2\fa2util.c -> build\lib.win-amd64-3.6\fa2; copying fa2\fa2util.pxd -> build\lib.win-amd64-3.6\fa2; running build_ext; skipping 'fa2\fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; error: Microsoft Visual C++ 14.0 is required. Get it with ""Build T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1256:1722,install,installed,1722,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256,1,['install'],['installed']
Deployability,"(= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-nondeterminism (= 1.12.0-2),; diffutils (= 1:3.7-5),; dmsetup (= 2:1.02.175-2.1),; docutils-common (= 0.17.1+dfsg-2),; dpkg (= 1.20.9),; dpkg-dev (= 1.20.9),; dwz (= 0.14-1),; file (= 1:5.39-3),; findutils (= 4.8.0-1),; flit (= 3.0.0-1),; fontconfig (= 2.13.1-4.2),; fontconfig-config (= 2.13.1-4.2),; fonts-font-awesome (= 5.0.10+really4.7.0~dfsg-4.1),; fonts-lato (= 2.0-2.1),; fonts-lyx (= 2.3.6-1),; g++ (= 4:11.2.0-2),; g++-11 (= 11.2.0-10),; gcc (= 4:11.2.0-2),; gcc-11 (= 11.2.0-10),; gcc-11-base (= 11.2.0-10),; gettext (= 0.21-4),; gettext-base (= 0.21-4),; gir1.2-atk-1.0 (= 2.36.0-2),; gir1.2-freedesktop (= 1.70.0-2),; gir1.2-gdkpixbuf-2.0 (= 2.42.6+dfsg-2),; gir1.2-glib-2.0 (= 1.70.0-2),; gir1.2-gtk-3.0 (= 3.24.30-3),; gir1.2-harfbuzz-0.0 (= 2.7.4-1),; gir1.2-pango-1.0 (= 1.48.10+ds1-1),; grep (= 3.7-1),; groff-base (= 1.22.4-7),; gtk-update-icon-cache (= 3.24.30-3),; gzip (= 1.10-4),; hicolor-icon-theme (= 0.17-2),; hostname (= 3.23),; imagemagick (= 8:6.9.11.60+dfsg-1.3),; imagemagick-6-common (= 8:6.9.11.60+dfsg-1.3),; imagemagick-6.q16 (= 8:6.9.11.60+dfsg-1.3),; init-system-helpers (= 1.60),; intltool-debian (= 0.35.0+20060710.5),; libacl1 (= 2.3.1-1),; libaec0 (= 1.0.6-1),; libamd2 (= 1:5.10.1+dfsg-2),; libaom3 (= 3.2.0-1),; libapparmor1 (= 3.0.3-5),; libarchive-zip-perl (= 1.68-1),; libargon2-1 (= 0~20171227-0.2),; libarpack2 (= 3.8.0-1),; libasan6 (= 11.2.0-10),; libatk-bridge2.0-0 (= 2.38.0-2),; libatk1.0-0 (= 2.36.0-2),; libatk1.0-data (= 2.36.0-2),; libatlas3-base (= 3.10.3-11),; libatomic1 (= 11.2.0-10),; libatspi2.0-0 (= 2.42.0-2),; libattr1 (= 1:2.5.1-1),; libaudit-common (= 1:3.0.6-1),; libaudit1 (= 1:3.0.6-1),; libavahi-client3 (= 0.8-5),; libavahi-common-data (= 0.8-5),; libavahi-common3 (= 0.8-5),; libbinutils (= 2.37-8),; libblas3 (= 3.10.0-1),; libblkid1 (= 2.37.2-4),; libblosc1 (= 1.21.1+ds1-1),; libbr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:2851,update,update-icon-cache,2851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['update'],['update-icon-cache']
Deployability,"(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackages/forceatlas2-0.3.5$; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:30193,Rolling,Rolling,30193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,"['Rolling', 'install']","['Rolling', 'install', 'install-failure']"
Deployability,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983:3986,install,installs,3986,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983,1,['install'],['installs']
Deployability,"(and fingers crossed for a release soon, I currently have a nasty patch in place for our pipelines)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1076139906:27,release,release,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1076139906,3,"['patch', 'pipeline', 'release']","['patch', 'pipelines', 'release']"
Deployability,(chore): add preparation-of-release documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3122:28,release,release,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122,1,['release'],['release']
Deployability,(chore): generate 1.10.3 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3235:25,release,release,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3235,1,['release'],['release']
Deployability,(chore): prepare release notes for 0.10.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3121:17,release,release,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3121,2,['release'],['release']
Deployability,(fix): correct anndata release for `io` usage,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3298:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3298,1,['release'],['release']
Deployability,"(from matplotlib==2.0.0->scanpy); Collecting python-dateutil (from matplotlib==2.0.0->scanpy); Using cached python_dateutil-2.6.1-py2.py3-none-any.whl; Collecting pytz (from matplotlib==2.0.0->scanpy); Using cached pytz-2018.3-py2.py3-none-any.whl; Requirement already up-to-date: six>=1.10 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: numpy>=1.7.1 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scanpy); Requirement already up-to-date: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /cluster/software/lib/python3.6/site-packages (from matplotlib==2.0.0->scan; Requirement already up-to-date: patsy in /cluster/software/lib/python3.6/site-packages (from statsmodels->scanpy); Requirement already up-to-date: decorator>=4.1.0 in /cluster/software/lib/python3.6/site-packages (from networkx->scanpy); Installing collected packages: scanpy, python-dateutil, pytz; Running setup.py install for scanpy: started; Running setup.py install for scanpy: finished with status 'error'; Complete output from command /cluster/software/bin/python3.6 -u -c ""import setuptools, tokenize;__file__='/scratch/tmp/pip-build-g14yf1xi/scanpy/setup.py';; running install; running build; running build_py; creating build; creating build/lib.linux-x86_64-3.6; creating build/lib.linux-x86_64-3.6/scanpy; copying scanpy/settings.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/_version.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__init__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/__main__.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/readwrite.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/utils.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/exporting.py -> build/lib.linux-x86_64-3.6/scanpy; copying scanpy/logging.py -> build/lib.linux-x86_64-3.6/scanpy; creating build/lib.linux-x86_64-3.6/scanpy/plotting copying scanpy/plotting/top_genes_visual.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/90:2724,install,install,2724,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/90,1,['install'],['install']
Deployability,"(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index); 1303 def _getitem_view(self, index):; 1304 oidx, vidx = self._normalize_indices(index); -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1306 ; 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 662 if not isinstance(X, AnnData):; 663 raise ValueError('`X` has to be an AnnData object.'); --> 664 self._init_as_view(X, oidx, vidx); 665 else:; 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx); 691 self._varm = ArrayView(adata_ref.varm[vidx_normalized], view_args=(self, 'varm')); 692 # hackish solution here, no copy should be necessary; --> 693 uns_new = deepcopy(self._adata_ref._uns); 694 # need to do the slicing before setting the updated self._n_obs, self._n_vars; 695 self._n_obs = self._adata_ref.n_obs # use the original n_obs here. ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 178 y = x; 179 else:; --> 180 y = _reconstruct(x, memo, *rv); 181 ; 182 # If is its own copy, don't memoize. ~/anaconda3/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy); 278 if state is not None:; 279 if deep:; --> 280 state = deepcopy(state, memo); 281 if hasattr(y, '__setstate__'):; 282 y.__setstate__(state). ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 148 copier = _deepcopy_dispatch.get(cls); 149 if copier:; --> 150 y = copier(x, memo); 151 else:; 152 try:. ~/anaconda3/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy); 238 memo[id(x)] = y; 239 for key, value in x.items():; --> 240 y[deepcopy(key, memo)] = deepcopy(value, memo); 241 return y; 242 d[dict] = _deepcopy_dict. ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-442366170:2240,update,updated,2240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-442366170,1,['update'],['updated']
Deployability,"(vscode-notebook-cell:?execution_count=62&line=2) data1.var_names_make_unique(). File ~\AppData\Roaming\Python\Python312\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); [77](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:77) @wraps(fn); [78](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:78) def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; [79](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:79) if len(args_all) <= n_positional:; ---> [80](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:80) return fn(*args_all, **kw); [82](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:82) args_pos: P.args; [83](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/legacy_api_wrap/__init__.py:83) args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Roaming\Python\Python312\site-packages\scanpy\readwrite.py:560, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); [558](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/scanpy/readwrite.py:558) prefix = """" if prefix is None else prefix; [559](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:2218,Pipeline,PipelineDevelope,2218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,"). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0; seaborn 0.9.0; setuptools 41.4.0; setuptools_scm NA; simplejson 3.17.2; six 1.12.0; sklearn 0.24.2; skmisc 0.1.4; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; tblib 1.4.0; tensorboard 2.6.0; threadpoolctl 2.2.0; toolz 0.10.0; torch 1.9.0; torchmetrics 0.5.1; tornado 6.0.3; tqdm 4.56.0; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.1.2; zipp NA; zmq 18.1.0; -----; IPython 7.8.0; jupyter_client 5.3.3; jupyter_core 4.5.0; jupyterlab 1.1.4; notebook 6.0.1; -----; Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]; Darwin-20.5.0-x86_64-i386-64bit; 8 logical CPU cores, i386; -----; Session information updated at 2021-09-08 10:28. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1995:3986,update,updated,3986,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995,1,['update'],['updated']
Deployability,"); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with Sim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:7081,pipeline,pipeline,7081,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,1,['pipeline'],['pipeline']
Deployability,"* I think it fits the standard tutorial, I calculate these things all the time. All the tutorials are in the [`scanpy_usage`](https://github.com/theislab/scanpy_usage) repo, right?; * Do you mean the `top_segment_proportions` and/ or `top_proportions` functions?. ## Sparse matrix support. I took the easy way out for calculations on other sparse matrices types – just converted them to a `CSR` – so there's room for improvement. I'm considering writing a more involved implementation, but I'd have to benchmark it against conversion. . I'd probably try an online sort (insertion?) for each cell, keeping only the top `max(ns)` expression values, while iterating through the `COO` or `CSC` matrix. ## Numba. This currently throws a lot of warnings about `np.partition` not being implemented in `numba`. This should change with their next release, and give some speedup here. ## `cell_controls`. I'm trying to decide on including this. I haven't used data with control wells, so I don't know how common it is. It could be nice to implement it a bit differently, and have able to get something like`.var[""mean_counts_in_sampletype-CD8""]`, but I'm already returning a lot of values. Any thoughts?. ## f-strings. Just noticed this is why my builds are failing. This might get ugly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663:838,release,release,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663,1,['release'],['release']
Deployability,* Minor kwarg fixes in pl.correlation_matrix; * Update test correlation image; * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1769:48,Update,Update,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769,1,['Update'],['Update']
Deployability,* Now actually allows passing an array (previously threw error from `if init_pos in adata.obsm.keys()`); * Additionally allows providing an array (even through key of obsm or via paga) of dtype other than float32; * Code converting arrays to float32 can be removed if https://github.com/lmcinnes/umap/pull/262 gets merged and released; * Should solve #666 related issues,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/724:326,release,released,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/724,1,['release'],['released']
Deployability,"* Release note, yeah, a new PR.; * Backport, up to you. Docs should be fine to backport. [Instructions here](https://scanpy.readthedocs.io/en/latest/dev/versioning.html), but you basically just need to write a comment with the right format and a backport PR will be opened.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1680#issuecomment-787580560:2,Release,Release,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680#issuecomment-787580560,1,['Release'],['Release']
Deployability,* Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2659:51,release,release,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659,2,['release'],['release']
Deployability,* fixed vmin/vmax for categorical data #800 ; * added error message when vmin is not valid to point out how to format it; * updated test to cover categorical data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/804:124,update,updated,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/804,1,['update'],['updated']
Deployability,"* installing the master branch via `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git` fails:. ```; UPDATING build/lib.linux-x86_64-3.5/None; error: [Errno 2] No such file or directory: 'build/lib.linux-x86_64-3.5/None'; ```; ; maybe `_version.py` returns `None` instead of a version string for the master branch. * installing the tag works: `pip3 install --user --upgrade git+https://github.com/theislab/scanpy.git@0.0` but the installed version will be `0.1`, not `0.0` as the tag says (i’m not sure 0.0 is a legal version anyway)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/15:2,install,installing,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15,7,"['install', 'upgrade']","['install', 'installed', 'installing', 'upgrade']"
Deployability,"* is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2435:252,Release,Release,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435,1,['Release'],['Release']
Deployability,* updated documentation images; * fix overwrite of style parameters after multiple calls to `style()`; * added padding parameter to dotplot and stacked_violin to address #1270; * added units to legend width in documentation.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1316:2,update,updated,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1316,1,['update'],['updated']
Deployability,"***); 253 for chunk, _, _ in adata_comp.chunked_X(chunk_size):; 254 chunk = chunk.toarray() if issparse(chunk) else chunk; --> 255 pca_.partial_fit(chunk); 257 for chunk, start, end in adata_comp.chunked_X(chunk_size):; 258 chunk = chunk.toarray() if issparse(chunk) else chunk. File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/base.py:1473, in _fit_context.<locals>.decorator.<locals>.wrapper(estimator, *args, **kwargs); 1466 estimator._validate_params(); 1468 with config_context(; 1469 skip_parameter_validation=(; 1470 prefer_skip_nested_validation or global_skip_validation; 1471 ); 1472 ):; -> 1473 return fit_method(estimator, *args, **kwargs). File /anvil/projects/x-mcb130189/Wubin/Software/miniconda3/envs/m3c/lib/python3.9/site-packages/sklearn/decomposition/_incremental_pca.py:304, in IncrementalPCA.partial_fit(self, X, y, check_input); 298 raise ValueError(; 299 ""n_components=%r invalid for n_features=%d, need ""; 300 ""more rows than columns for IncrementalPCA ""; 301 ""processing"" % (self.n_components, n_features); 302 ); 303 elif not self.n_components <= n_samples:; --> 304 raise ValueError(; 305 ""n_components=%r must be less or equal to ""; 306 ""the batch number of samples ""; 307 ""%d."" % (self.n_components, n_samples); 308 ); 309 else:; 310 self.n_components_ = self.n_components. ValueError: n_components=100 must be less or equal to the batch number of samples 77; ```. To fix this bug, I added a `try` and `except` to line 255 of _pca.py. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (“- [x]”) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227:2799,release,release,2799,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227,2,"['Release', 'release']","['Release', 'release']"
Deployability,"**Description**. Currently, sc.pl.umap provides an option to plot cells with higher values on top using an internal sorting step (np.argsort). However, for some use cases, it’s desirable to plot cells with the highest absolute values on top to highlight both large positive and large negative values in continuous color mappings. **Proposed Solution**. Add a new option, such as sort_order='abs', to plot the highest absolute values on top, while preserving the original behavior as the default. **Example**. Here’s how the option could be used in practice:; ```; sc.pl.umap(adata, color='example_feature', cmap='coolwarm', sort_order='abs'); ```. With this feature, cells with the largest magnitudes (either positive or negative) would be displayed on top, making them more visually prominent when using diverging color maps. **Suggested Implementation**. > [scanpy/source/scanpy/plotting/_tools/scatterplots.py - line 293-295](https://github.com/scverse/scanpy/blob/0cde4cf14c129f4ba3226e4b45c7794ce6f16ef3/src/scanpy/plotting/_tools/scatterplots.py#L293-L295). Instead of; ```; if sort_order and value_to_plot is not None and color_type == ""cont"":; # Higher values plotted on top, null values on bottom; order = np.argsort(-color_vector, kind=""stable"")[::-1]; ```. I suggest; ```; if sort_order and value_to_plot is not None and color_type == ""cont"":; if sort_order == ""abs"":; order = np.argsort(-np.abs(color_vector), kind=""stable"")[::-1]; else:; order = np.argsort(-color_vector, kind=""stable"")[::-1]; ```. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3326:303,continuous,continuous,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3326,1,['continuous'],['continuous']
Deployability,"**I installed the newest versions of JAVA and VC+++, didn't work.; Here also attaches the information of install scapy[leiden]:**; Collecting scanpy[leiden]; Using cached scanpy-1.7.2-py3-none-any.whl (10.3 MB); Collecting h5py>=2.10.0; Using cached h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB); Collecting tables; Using cached tables-3.6.1-2-cp36-cp36m-win_amd64.whl (3.2 MB); Collecting numpy>=1.17.0; Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB); Collecting joblib; Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB); Collecting pandas>=0.21; Using cached pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB); Collecting tqdm; Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB); Collecting matplotlib>=3.1.2; Using cached matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB); Collecting networkx>=2.3; Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB); Collecting sinfo; Using cached sinfo-0.3.4-py3-none-any.whl; Requirement already satisfied: importlib-metadata>=0.7 in c:\users\yuanjian\.conda\envs\py363636\lib\site-packages (from scanpy[leiden]) (4.8.1); Collecting scikit-learn>=0.21.2; Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB); Collecting scipy>=1.4; Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB); Collecting numba>=0.41.0; Using cached numba-0.53.1-cp36-cp36m-win_amd64.whl (2.3 MB); Collecting patsy; Using cached patsy-0.5.2-py2.py3-none-any.whl (233 kB); Collecting natsort; Using cached natsort-8.0.0-py3-none-any.whl (37 kB); Collecting seaborn; Using cached seaborn-0.11.2-py3-none-any.whl (292 kB); Requirement already satisfied: packaging in c:\users\yuanjian\.conda\envs\py363636\lib\site-packages (from scanpy[leiden]) (21.0); Collecting statsmodels>=0.10.0rc2; Using cached statsmodels-0.12.2-cp36-none-win_amd64.whl (9.3 MB); Collecting umap-learn>=0.3.10; Using cached umap_learn-0.5.2-py3-none-any.whl; Collecting anndata>=0.7.4; Using cached anndata-0.7.6-py3-none-any.whl (127 kB); Collecting legacy-api-wrap; Usin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-962562955:4,install,installed,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-962562955,2,['install'],"['install', 'installed']"
Deployability,"**Set name for storing Umap coordinates explicitly in tl.umap and pl.umap**; tl.umap(..., x_umap = ""X_umap""); pl.umap(..., x_umap = ""X_umap""). Sometimes it would be helpful to specify the adata obsm field for storing the umap coordinates.; For example : ; -if I want to compute and plot the umap for the raw data and afterwards for the integrated or in any way modified data. The first x_umap is going to be overwritten and needs to be computed again, if I need to plot the first step again.; So it would be cool to enable a workflow like the following:. ```; tl.umap(adata, ..., x_umap = ""X_umap_raw""); # do some operations ...; tl.umap(adata, ..., x_umap = ""X_umap_mod). # now after computation I might need to take a look on both umaps again, or plot them in direct comparison; pl.umap(adata, ..., x_umap = ""X_umap_raw""); pl.umap(adata, ..., x_umap = ""X_umap_mod""). ```. I hope I was able to explain what I mean and did not oversee such feature or misunderstood the usage.; All the best ; maflot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2245:336,integrat,integrated,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245,1,['integrat'],['integrated']
Deployability,"**The following is what this function does (we can see it with ?sc.pp.recipe_zheng17):**; ```; sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean; ```. **But in the original paper Zheng et al. (2017 (https://www.nature.com/articles/ncomms14049#Sec11), it said:**; Only genes with at least one UMI count detected in at least one cell are used. UMI normalization was performed by first dividing UMI counts by the total UMI counts in each cell, **followed by multiplication with the median of the total UMI counts across cells**. Then, we took the natural log of the UMI counts. Finally, each gene was normalized such that the mean signal for each gene is 0, and standard deviation is 1. **So, comparing these two pipelines, the pipeline implemented in scanpy is not the same with the method described in the original paper, in the paper, there is a step**: _multiplication with the median of the total UMI counts across cells_, but this step was skipped inside the function sc.pp.recipe_zheng17. **Is there anyone who can tell me why they are different?** @flying-sheep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/905:1265,pipeline,pipelines,1265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/905,2,['pipeline'],"['pipeline', 'pipelines']"
Deployability,"**Update** Note sure if it is a problem with our script. However, if colors are not found, can it use default color-map and let us plot after raising a warning?. Log is following. ~Working on a PR.~ This issue is for reference. Could not upload source file since it depends on data file which are huge. ```; (Py36) pragati@wasabi-simons ~/Work/scanpy_exp $ python planaria.py ; scanpy==1.3.2+4.g7c9fb1a anndata==0.6.11 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 ; ... storing 'clusters' as categorical; computing tSNE; using data matrix X directly; using the 'MulticoreTSNE' package by Ulyanov (2017); finished (0:02:39.15); Traceback (most recent call last):; File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 158, in to_rgba; rgba = _colors_full_map.cache[c, alpha]; KeyError: ('grey80', None). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py"", line 4210, in scatter; colors = mcolors.to_rgba_array(c); File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 259, in to_rgba_array; result[i] = to_rgba(cc, alpha); File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 160, in to_rgba; rgba = _to_rgba_no_colorcycle(c, alpha); File ""/home/pragati/Py36/lib/python3.6/site-packages/matplotlib/colors.py"", line 204, in _to_rgba_no_colorcycle; raise ValueError(""Invalid RGBA argument: {!r}"".format(orig_c)); ValueError: Invalid RGBA argument: 'grey80'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""planaria.py"", line 47, in <module>; sc.pl.tsne(adata, color='clusters', legend_loc='on data', legend_fontsize=5, save='_full'); File ""/home/pragati/Py36/lib/python3.6/site-packages/scanpy/plotting/tools/scatterplots.py"", line 47, in tsne; return plot_scatter(adata, basis='tsne', **k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286:2,Update,Update,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286,1,['Update'],['Update']
Deployability,"**solution please :** ; scanpy ; During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); computing neighbors; using 'X_pca' with n_pcs = 40; ; LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x000001FF1D57B970> (trying to write member #1). File ""C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py (53). TypeError Traceback (most recent call last); C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 822 try:; --> 823 yield; 824 except NumbaError as e:. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 438 ty = self.typeof(inst.target.name); --> 439 val = self.lower_assign(ty, inst); 440 argidx = None. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_assign(self, ty, inst); 625 elif isinstance(value, ir.Expr):; --> 626 return self.lower_expr(ty, value); 627 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_expr(self, resty, expr); 1161 elif expr.op == 'call':; -> 1162 res = self.lower_call(resty, expr); 1163 return res. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:410,pipeline,pipeline,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['pipeline'],['pipeline']
Deployability,"+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1883) encoding=self.options.get(""encoding"", None),; [1884](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1884) compression=self.options.get(""compression"", None),; [1885](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1885) memory_map=self.options.get(""memory_map"", False),; [1886](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1886) is_text=is_text,; [1887](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1887) errors=self.options.get(""encoding_errors"", ""strict""),; [1888](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1888) storage_options=self.options.get(""storage_options"", None),; [1889](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1889) ); [1890](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1890) assert self.handles is not None; [1891](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1891) f = self.handles.handle. File ~\AppD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:14700,Pipeline,PipelineDevelope,14700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,", cholesterol tags, etc.) we've been doing. However, most of the time I'll just load the tags matrix in as a pandas dataframe and run them through a demuxing function that'll modify `adata.obs`. A couple challenges/ideas to consider:. * at our facility, we're typically building the same Illumina i7 index (`ATTACTCG`) into all tag libraries. This leads to some tricky situations when using a NovaSeq for sequencing since the multiple tag libraries (with disjoint sets of tags) may be run on the same sequencing flowcell lane. This results in a single set of FASTQ files and thus a single barcode-tag matrix for all tag libraries on that lane. Therefore, the mapping between transcriptome AnnData objects <-> tag library matrices is not always 1-to-1.; * in my experience, HTO libraries have a large variance in quality, so for the most part I've been using the transcriptome as my ""ground truth"" as to what is a cell. However, I imagine others use HTOs to ""rescue"" cells that were not called by their pipeline of choice (and I hope to do this once I build enough trust in the data). In that case, one would want to intersect the HTO classifications with the raw cell-gene matrix.; * not all tags are antibody based, so I'd vote for naming all related functions `*hashtags()`. I'd therefore vote for something like the following design:; ```{python}; # htos is a AnnData object; htos = sc.read_hashtags(filename) . # classify_hashtags adds a classification to the hto AnnData object; # kwargs might involve things like `use_tags=[""tag1"", ""tag2"", ""tag3""]`; sc.pp.classify_hashtags(htos, **kwargs); print(htos.obs.classification) . # demuxing cell-gene matrix(es) could then be done like; rna1 = sc.read_10x_h5(...); rna2 = sc.read_10x_h5(...); # sc.pp.demux_by_hashtag(adata_hto, *adata_rna, tag_groups=None, ...); sc.pp.demux_by_hashtag(; htos, ; rna1, rna2, ; tag_groups=[(""tag1"", ""tag3"", ""tag5""), (""tag2"", ""tag4"", ""tag6"")]; ); ```; @gokceneraslan This is more complex than what you suggested, but I ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900:1567,pipeline,pipeline,1567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900,1,['pipeline'],['pipeline']
Deployability,", delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 698 if ext in {'h5', 'h5ad'}:; 699 if sheet is None:; --> 700 return read_h5ad(filename, backed=backed); 701 else:; 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 427 _clean_uns(d) # backwards compat; 428 ; --> 429 return AnnData(**d); 430 ; 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.4; autoreload NA; backcall 0.2.0; cellrank 1.0.0; cffi 1.14.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.1; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jax 0.2.5; jaxlib 0.1.56; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; lapack NA; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; opt_einsum v3.3.0; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pyparsing 2.4.7; python_utils NA; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; scvelo 0.2.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; threadpoolctl 2.1.0; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-3-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2020-11-03 13:36. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1480:3875,update,updated,3875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480,1,['update'],['updated']
Deployability,", kwds); [617](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:617) _validate_names(kwds.get(""names"", None)); [619](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:619) # Create the parser.; --> [620](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:620) parser = TextFileReader(filepath_or_buffer, **kwds); [622](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:622) if chunksize or iterator:; [623](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:623) return parser. File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\parsers\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds); [1617](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1617) self.options[""has_index_names""] = kwds[""has_index_names""]; [1619](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1619) self.handles: IOHandles | None = None; -> [1620](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/pmbm1/MEGA/PhD/PipelineDevelope/scRNA/~/AppData/Roaming/Python/Python312/site-packages/pandas/io/parsers/readers.py:1620) self._engine = self._make_engine(f, self.engine). File ~\AppData\Roaming\Python\Python312\site-packages\pandas\io\p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3214:11607,Pipeline,PipelineDevelope,11607,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3214,1,['Pipeline'],['PipelineDevelope']
Deployability,", n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; annoy NA; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-09-01 08:49; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1989:5053,update,updated,5053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989,1,['update'],['updated']
Deployability,", our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; return True; ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:1870,install,install,1870,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,2,['install'],['install']
Deployability,", which gives scanpy users an obvious advantage. . I've learned so much using this package and it has allowed me to display my data in a simple and intuitive way. Truly, from the bottom of my heart, thank you, this package is awesome and I deeply appreciate all the work the scanpy team and Theis lab has put into it. . With that said, I find myself wanting to do things with scanpy that aren't currently supported. . (1) Clustering cells based on a restricted set of genes as opposed to principle components: I understand that this is a biased approach, but I find myself wanting to do this to explore datasets and how genes vary together. I believe it would aid in understanding data topology to reduce the dimensionality of the dataset by looking at a subset of key genes that are picked by an expert who has domain knowledge. I think this is best integrated with a separate sc.pp.neighbors-like function that uses a gene list, as opposed to PCs. Integration into downstream plotting can be done with separate functions that have a similar name (sc.tl.umap_genelist or sc.tl.umap_sparse; sc.tl.paga_genelist or sc.tl.paga_sparse). . I envision that this would also be a nice stepping stone towards multi-modal analysis with CITE-seq. . (2) I want to use PAGA and UMAP to display my CytOF data as well as integrate scRNA-seq/CytOF data together. I saw a pre-print on bioRxiv that indicated that you are working on this aspect of PAGA/scanpy. This was very exciting to me and I am glad that this is being developed. Is it possible to access the current version of this software? . I think that major partitions identified with CytOF or scRNA-seq can be linked together providing a coarse-grained mechanism to demonstrate how heterogeneity identified with each technique relates to each other based on a given experimental time point. . (3) Histogram integration in the plotting api for QC metrics would be helpful. While scatter plots and violin plots are effective, I find myself wanting to make cut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510:1366,Integrat,Integration,1366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510,1,['Integrat'],['Integration']
Deployability,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414; - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077206877:9,upgrade,upgrade,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077206877,2,['upgrade'],['upgrade']
Deployability,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy.api as sc; ```. ```pytb; File ""./scanpy_normalization.py"", line 4, in <module>; import scanpy.api as sc; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/usr/local/lib/python3.8/site-packages/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py); ```. This is with the latest version of scanpy. I looked at the code and scanpy/apt/pl.py still has **from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot**, even as the plotting library has been refactored and the dotplot, matrixplot and stacked_violin are now in separate files. I tested this a few days ago and it was working fine then, the update to anndata probably happened in the last couple of days",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397:1234,update,update,1234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397,1,['update'],['update']
Deployability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579:518,Integrat,Integrating,518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579,2,"['Integrat', 'integrat']","['Integrating', 'integrating-data-using-ingest']"
Deployability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### This is the code I'm using which was copied from the tutorial:. ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.pp.neighbors(adata, n_neighbors=20, use_rep='X', method='gauss'); sc.tl.diffmap(adata); sc.tl.dpt(adata, n_branchings=1, n_dcs=10); sc.pl.diffmap(adata, color=['dpt_pseudotime', 'dpt_groups', 'paul15_clusters']); ```; The results I got are:; ![image](https://user-images.githubusercontent.com/33322882/168080076-f6767970-0b3b-4623-ab25-e9e38201e6ef.png). Which is totally different than in the tutorial:; ![image](https://user-images.githubusercontent.com/33322882/168081015-cddf77eb-7b83-4802-8890-3b0d87a5755d.png). Can anyone run into this problem ever? Thanks for your help. #### Versions. <details>; -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.6.0. google NA. h5py 3.6.0. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. joblib 0.17.0. kiwisolver 1.3.1. llvmlite 0.38.0. ... Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-3.16.0-11-amd64-x86_64-with-glibc2.19. -----. Session information updated at 2022-05-12 14:59. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2254:1682,update,updated,1682,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254,1,['update'],['updated']
Deployability,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1675:355,install,installing,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675,1,['install'],['installing']
Deployability,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2306:240,install,installed,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306,1,['install'],['installed']
Deployability,"- [ y] I have checked that this issue has not already been reported.; - [ y] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2441:296,install,install,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441,3,['install'],"['install', 'installed']"
Deployability,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1545:855,update,updated,855,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545,1,['update'],['updated']
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048:147,release,released,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048,1,['release'],['released']
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import anndata as ad; import scanpy as sc. adata = ad.AnnData(np.random.poisson(0.2, (100, 200))); sc.pp.normalize_per_cell(adata, 1e6); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/scottgigante/envs/immunaISR/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 527, in normalize_per_cell; normalize_per_cell(adata.X, counts_per_cell_after, counts_per_cell); File ""/Users/scottgigante/envs/immunaISR/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 562, in normalize_per_cell; counts_per_cell /= counts_per_cell_after; numpy.core._exceptions.UFuncTypeError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; cffi 1.15.1; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; dill 0.3.6; google NA; h5py 3.8.0; importlib_resources NA; joblib 1.3.0.dev0; kiwisolver 1.4.4; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; packaging 23.1; pandas 2.0.2; psutil 5.9.5; pyarrow 12.0.0; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; six 1.16.0; sklearn 1.2.2; sympy 1.11.1; threadpoolctl 3.1.0; torch 2.0.0; tqdm 4.65.0; typing_extensions NA; yaml 6.0; zipp NA; -----; Python 3.8.10 (v3.8.10:3d8993a744, May 3 2021, 08:55:58) [Clang 6.0 (clang-600.0.57)]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-06-05 12:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500:1885,update,updated,1885,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500,1,['update'],['updated']
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2062:1401,install,installed,1401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062,1,['install'],['installed']
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1625:414,install,installed,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625,2,['install'],['installed']
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[‘resolution_parameter’] = resolution; 143 # clustering proper; → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[‘weights’] = weights; —> 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341:565,install,installing,565,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341,2,['install'],"['install', 'installing']"
Deployability,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; import warnings; warnings.simplefilter('always'); import scanpy; ```. ```pytb; /home/scottgigante/.local/lib/python3.6/site-packages/scanpy/tools/_louvain.py:17: DeprecationWarning: This package has been superseded by the `leidenalg` package and will no longer be maintained. Please upgrade to the `leidenalg` package.; from louvain.VertexPartition import MutableVertexPartition; ```. #### Versions. <details>. ```; -----; anndata 0.7.3; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.3; apport_python_hook NA; cffi 1.14.1; colorama 0.3.7; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.2; importlib_metadata 1.6.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.50.1; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.0.5; pkg_resources NA; psutil 5.7.2; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.2; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.23.1; tables 3.6.1; texttable 1.6.2; wcwidth 0.2.5; yaml 3.12; zipp NA; zope NA; -----; Python 3.6.9 (default, Nov 7 2019, 10:44:02) [GCC 8.3.0]; Linux-4.4.0-18362-Microsoft-x86_64-with-Ubuntu-18.04-bionic; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-08-18 15:10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1379:523,upgrade,upgrade,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1379,2,"['update', 'upgrade']","['updated', 'upgrade']"
Deployability,- [X] Tests included or not required because it's minor; - [x] Release notes not necessary because it's minor. I'm pretty sure that we've had this warning for a looooong time and it keeps showing up in a lot of downstream packages. People are either aware of it now or don't care (with the latter probably being more likely ^_^).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798:63,Release,Release,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798,1,['Release'],['Release']
Deployability,"- [Yes ] I have checked that this issue has not already been reported.; - [Yes ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi all, I am wondering if anyone has had similar situation as mine. ; After data normalization, batch correction with combat, and work through the pipeline on my own data, I was having issues generating rank gene groups. The error is as below. I understand that there are issues with using highly_variable_genes after combat, and this can be resolved after converting raw data back to sparse matrix using "" adata.X = scipy.sparse.csr_matrix(adata.X) "", but this method does not address my error. . Look forward to your response, thanks a lot! . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <ipython-input-16-961d52bd7e16> in <module>(); ----> 1 sc.tl.rank_genes_groups(all_case,groupby='louvain',method='wilcoxon'). 7 frames; <__array_function__ internals> in matrix_power(*args, **kwargs). /usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py in _assert_stacked_square(*arrays); 211 m, n = a.shape[-2:]; 212 if m != n:; --> 213 raise LinAlgError('Last 2 dimensions of the array must be square'); 214 ; 215 def _assert_finite(*arrays):. LinAlgError: Last 2 dimensions of the array must be square; ```. #### Versions. <details>; scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.4.1 pandas==1.1.2 scikit-learn==0.22.2.post1 statsmodels==0.10.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467:382,pipeline,pipeline,382,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467,1,['pipeline'],['pipeline']
Deployability,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2282:525,install,install,525,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282,4,['install'],"['install', 'installed']"
Deployability,"- [x] Additional function parameters / changed functionality / changed defaults?. At the moment when we are plotting data points in e.g., `sc.pl.umap()` with `color='covariate'` we determine the plotting order in two ways:; 1. if `'covariate'` is continuous the highest values are plotted on top, to showcase the peaks of the distribution;; 2. if `'covariate'` is a categorical variable, the order of `adata.obs_names` is used (i believe). As we often concatenate datasets after integration or loading from multiple sources, covariates we plot are usually not randomly ordered here. I think the first case is fine (and it can be turned off), but we should probably not be doing case 2. Instead, it would be good if the default was to plot in a random order unless the covariate is ordered internally (I believe this is already taken into account, but not sure). I have come across this issue several times now, and we're not solving this in a good way imo. Fabian has mentioned this to me several times as well. What do you think @fidelram @ivirshup ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263:247,continuous,continuous,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263,2,"['continuous', 'integrat']","['continuous', 'integration']"
Deployability,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955:538,integrat,integrate,538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955,2,['integrat'],"['integrate', 'integrated']"
Deployability,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208:473,update,update,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208,3,"['install', 'update']","['install', 'installing', 'update']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ### Minimal code sample (that we can copy&paste without having any data). ```bash; conda create -n Scanpy python=3.7; conda activate Scanpy; conda install -c bioconda scanpy; conda install -c bioconda anndata2ri; ```; ```; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>; import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>; from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172:376,install,install,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172,2,['install'],['install']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494:299,install,install,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494,1,['install'],['install']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2191:402,Integrat,Integrating,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191,3,"['Integrat', 'integrat']","['Integrating', 'Integrating-data-using-ingest-and-BBKNN', 'integrating-data-using-ingest']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1556:721,pipeline,pipeline,721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556,1,['pipeline'],['pipeline']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. After running sc.tl.rank_genes_groups and sc.get.rank_genes_groups_df using the same data and python/scanpy code, Spider and Jupyter (both installed in the same environment of Anaconda) generate two different values for the ""names"" column. Whereas Spider gives the expected adata.var_names (e.g. Rpl5; see below), Jupyter gives a numerical code (15721, which is not included in adata.var). ### Minimal code sample (that we can copy&paste without having any data). In Spider:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ; scores names logfoldchanges pvals pvals_adj; 0 9.194006 Rpl15 0.815534 3.784770e-20 1.006711e-15; 1 8.427418 Rps28 0.653911 3.533771e-17 4.699739e-13; 2 7.989542 Rps21 0.676462 1.354418e-15 1.200872e-11; 3 7.871397 Rps27 0.483027 3.507037e-15 2.055341e-11; 4 7.859277 Rps24 0.507071 3.863569e-15 2.055341e-11; ```. In Jupyter:; ```python; de_df.head(5); ```; ```pytb; Out[34]: ;   | scores | names | logfoldchanges | pvals | pvals_adj; 9.194006 | 15721 | 0.815534 | 3.784770e-20 | 1.006711e-15; 8.427418 | 23746 | 0.653911 | 3.533771e-17 | 4.699739e-13; 7.989542 | 3910 | 0.676462 | 1.354418e-15 | 1.200872e-11; 7.871397 | 5571 | 0.483027 | 3.507037e-15 | 2.055341e-11; 7.859277 | 15774 | 0.507071 | 3.863569e-15 | 2.055341e-11. In both cases, Spider and Jupyter; ```python; adata.var_names; ```; ```pytb; Index(['Xkr4', 'Gm1992', 'Gm37381', 'Rp1', 'Sox17', 'Gm37323', 'Mrpl15',; 'Lypla1', 'Gm37988', 'Tcea1',; ```. If I try to specify a different column in Jupyter I get this. ```python; de_df = sc.get.rank_genes_groups_df(database, group=groupA, gene_symbols=""symbol""); ```; ```pytb; You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat; ```. #### Versions; [Paste the output of scanpy.logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1426:368,install,installed,368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426,1,['install'],['installed']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2236:264,pipeline,pipeline,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236,1,['pipeline'],['pipeline']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:; ```python; sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run; ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python; import random; random.seed(0). sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run; ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.6; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; nt NA; ntsecuritycon NA; numba 0.51.2; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1859:353,pipeline,pipeline,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859,1,['pipeline'],['pipeline']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; When trying to plot the PAGA graph some of the nodes don't show up in the graph. The nodes/clusters don't show up specifically for color=dpt_pseudotime. The nodes are still visible with categorical variables, and with other continuous variables.; Even when copying dpt_pseudotime column, the color=dpt_pseudotime_copy does not show up correctly. ### Minimal code sample ; ```python; # preprocessing; sc.pp.recipe_zheng17(adata); adata_wt= adata[adata.obs[""genotype""].isin([""WT""])]; adata_pca = sc.tl.pca(adata_wt, svd_solver='arpack', copy=True); adata_n = sc.pp.neighbors(adata_pca, n_neighbors=4, n_pcs=20, copy=True); adata_graph = sc.tl.draw_graph(adata_n, copy=True); # paga; adata_full = sc.tl.paga(adata_graph, groups='final_bulk_labels', copy=True); # dpt; adata_full.uns['iroot'] = np.flatnonzero(adata_full.obs['final_bulk_labels'] == 'HSC')[1000]; adata_paga_dpt_nonan = sc.tl.diffmap(adata_full, copy=True, n_comps=10); adata_paga_dpt_nonan = sc.tl.dpt(adata_paga_dpt_nonan, copy=True). adata_paga_dpt_nonan.obs[""dpt_pseudotime_copy""]=adata_paga_dpt_nonan.obs[""dpt_pseudotime""]. sc.pl.paga(adata_paga_dpt_nonan, ; threshold=0.05, ; color=['dpt_pseudotime', 'final_bulk_labels', 'dpt_pseudotime_copy', 'total_counts'],; ; # layout: Optional[_IGraphLayout] = None,; # layout_kwds: Mapping[str, Any] = MappingProxyType({}),; # init_pos: Optional[np.ndarray] = None,; # root: Union[int, str, Sequence[int], None] = 0,; # labels: Union[str, Sequence[str], Mapping[str, str], None] = None,; single_component = True,; solid_edges= 'connectivities',; # dashed_edges: Optional[str] = None,; # transitions: Optional[str] = None,; fontsize = 5,. fontweight='light', ; # fontoutline=2, ; # text_kwds: Mapping[str, Any] = MappingProxyType({}),; node_size_scale = 3, ; node_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2292:453,continuous,continuous,453,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292,1,['continuous'],['continuous']
Deployability,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---; ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python; import scanpy as sc; ```; returns:; ```pytb; Illegal instruction (core dumped); ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions; scanpy 1.7.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823:460,install,installation,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823,1,['install'],['installation']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2459:247,install,installing,247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459,3,"['install', 'update']","['installation', 'installing', 'update']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2465:476,release,released,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465,2,"['install', 'release']","['install', 'released']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # update to h5py e.g. as: pip install h5py==3.0.0; import scanpy as sc. adata = sc.datasets.blobs(); sc.read(""foo.h5ad"").obs_names # names are bytes, not str; # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640); ```; When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):; ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'); ```; The last line raises:. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-24-3d2f3a02bf09> in <module>; ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1480:501,update,update,501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480,2,"['install', 'update']","['install', 'update']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/; ├── cli.py; ├── _compat.py; ├── datasets; ├── experimental; ├── external; ├── get; ├── __init__.py; ├── logging.py; ├── __main__.py; ├── _metadata.py; ├── metrics; ├── neighbors; ├── plotting; ├── preprocessing; ├── __pycache__; ├── queries; ├── readwrite.py; ├── _settings.py; ├── sim_models; ├── tools; └── _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2378:1149,update,updated,1149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378,1,['update'],['updated']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields; 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters; 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2408:301,update,updated,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408,1,['update'],['updated']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1519:677,update,update,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519,1,['update'],['update']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2144:333,install,install,333,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144,4,['install'],"['install', 'install-instructions', 'installation']"
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2479:548,install,installed,548,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479,3,['install'],['installed']
Deployability,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When scanpy gets installed with the latest version of `importlib_metadata` (2.0), the ; command `sc.logging.print_versions()` fails with the following error: . ```pytb; WARNING: If you miss a compact list, please try `print_header`!; Traceback (most recent call last):; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 195, in sinfo; mod_version = _find_version(mod.__version__); AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/scanpy/logging.py"", line 161, in print_versions; sinfo(dependencies=True); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 198, in sinfo; mod_version = _find_version(mod.version); File ""/home/sturm/anaconda3/envs/scanpy_test/lib/python3.7/site-packages/sinfo/main.py"", line 42, in _find_version; return mod_version_attr(); TypeError: version() missing 1 required positional argument: 'distribution_name'; ```. According to the `importlib_metadata` changelog, the `__version__` attribute has been removed from the package: . ```; =========================; importlib_metadata NEWS; =========================. v2.0.0; ======. * ``importlib_metadata`` no longer presents a; ``__version__`` attribute. Consumers wishing to; resolve the version of the package should query it; directly with; ``importlib_metadata.version('importlib-metadata')``.; Closes #71.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1437:246,install,installed,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437,1,['install'],['installed']
